---
slug: /en/getting-started/quick-start
sidebar_label: Quick Start
sidebar_position: 1
keywords: [clickhouse, install, getting started, quick start]
pagination_next: 'en/getting-started/index'
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

# ClickHouse Quick Start

##  1: Download the binary

ClickHouse runs natively on Linux, FreeBSD and macOS, and runs on Windows via the [WSL](https://learn.microsoft.com/en-us/windows/wsl/about).
The simplest way to download ClickHouse locally is to run the following `curl` command. It determines if your operating system is supported,
then downloads an appropriate ClickHouse binary:

  ```bash
  curl https://clickhouse.com/ | sh
  ```



## 2: Start the server

Run the following command to start the ClickHouse server:
  ```bash
  ./clickhouse server
  ```



## 3: Start the client

Use the `clickhouse-client` to connect to your ClickHouse service. Open a new Terminal, change directories to where your `clickhouse`
binary is saved, and run the following command:

```bash
./clickhouse client
```

You should see a smiling face as it connects to your service running on localhost:

  ```response
  my-host :)
  ```

## 4: Create a table

Use `CREATE TABLE` to define a new table. Typical SQL DDL commans work in ClickHouse with one addition - tables in ClickHouse require
an `ENGINE` clause. Use `MergeTree` to take advantage of the performance benefits of ClickHouse:

```sql
CREATE TABLE my_first_table
(
    user_id UInt32,
    message String,
    timestamp DateTime,
    metric Float32
)
ENGINE = MergeTree
PRIMARY KEY (user_id, timestamp)
```

## 5. Insert data

You can use the familiar `INSERT INTO TABLE` command with ClickHouse, but it is important to understand that each insert into a
`MergeTree` table causes a **part** (folder) to be created in storage. To minimize parts, bulk insert lots of rows at a time (tens of
thousands or even millions at once).

```sql
INSERT INTO my_first_table (user_id, message, timestamp, metric) VALUES
    (101, 'Hello, ClickHouse!',                                 now(),       -1.0    ),
    (102, 'Insert a lot of rows per batch',                     yesterday(), 1.41421 ),
    (102, 'Sort your data based on your commonly-used queries', today(),     2.718   ),
    (101, 'Granules are the smallest chunks of data read',      now() + 5,   3.14159 )
```

## 6. Query your new table

You can write a SELECT query just like you would with any SQL database:

 ```sql
  SELECT *
  FROM my_first_table
  ORDER BY timestamp
  ```
  Notice the response comes back in a nice table format:
   ```response
   ┌─user_id─┬─message────────────────────────────────────────────┬───────────timestamp─┬──metric─┐
   │     102 │ Insert a lot of rows per batch                     │ 2022-03-21 00:00:00 │ 1.41421 │
   │     102 │ Sort your data based on your commonly-used queries │ 2022-03-22 00:00:00 │   2.718 │
   │     101 │ Hello, ClickHouse!                                 │ 2022-03-22 14:04:09 │      -1 │
   │     101 │ Granules are the smallest chunks of data read      │ 2022-03-22 14:04:14 │ 3.14159 │
   └─────────┴────────────────────────────────────────────────────┴─────────────────────┴─────────┘

   4 rows in set. Elapsed: 0.008 sec.
   ```

## 7: Where is your data now?

The next step is to get your current into ClickHouse. We have lots of table functions and integrations for ingesting data.

Where does your data sit now?

<Tabs groupId="read_data">
<TabItem value="S3" label="S3" default>

Use the [`s3` table function](/en/sql-reference/table-functions/s3) to read files from S3. It's a table function - meaning that the
result is a table that can be:

1. used as the source of a `SELECT` query (allowing you to run ad-hoc queries and leave your data in S3), or...
2. insert the resulting table into a `MergeTree` table (when you are ready to move your data into ClickHouse)

An ad-hoc query looks like:

```sql
SELECT
   passenger_count,
   avg(toFloat32(total_amount))
FROM s3(
    'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
    'TabSeparatedWithNames'
)
GROUP BY passenger_count
ORDER BY passenger_count;
```

Moving the data into a ClickHouse table looks like the following, where `nyc_taxi` is a `MergeTree` table:

```sql
INSERT INTO nyc_taxi
   SELECT * FROM s3(
    'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
    'TabSeparatedWithNames'
)
SETTINGS input_format_allow_errors_num=25000;
```

View our [collection of AWS S3 documentation pages](/en/integrations/data-ingestion/s3) for lots more details and examples of using S3 with ClickHouse.

</TabItem>
<TabItem value="GCS" label="GCS">

The [`s3` table function](/en/sql-reference/table-functions/s3) used for reading data in AWS S3 also works on files in Google Cloud Storage. For example:

```sql
SELECT
   *
FROM s3(
  'https://storage.googleapis.com/my-bucket/trips.parquet',
  'MY_GCS_HMAC_KEY',
  'MY_GCS_HMAC_SECRET_KEY',
  'Parquet'
)
LIMIT 1000
```

Find more details on the [`s3` table function page](/en/sql-reference/table-functions/s3/).

</TabItem>
<TabItem value="URL" label="Web">

The [`url` table function](/en/sql-reference/table-functions/url) reads files accessible from the web:

```sql
SELECT *
FROM url(
    'http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv',
    'CSV'
  );
```

Find more details on the [`url` table function page](/en/sql-reference/table-functions/url).

</TabItem>
<TabItem value="local_file" label="Local">

Use the [`file` table engine](/en/sql-reference/table-functions/file) to read a local file. For simplicity, copy the file to the `user_files` directory (which is
found in the directory where you downloaded the ClickHouse binary).

```sql
DESCRIBE TABLE file('comments.tsv')

Query id: 8ca9b2f9-65a2-4982-954a-890de710a336

┌─name──────┬─type────────────────────┬─default_type─┬─default_expression─┬─comment─┬─codec_expression─┬─ttl_expression─┐
│ id        │ Nullable(Int64)         │              │                    │         │                  │                │
│ type      │ Nullable(String)        │              │                    │         │                  │                │
│ author    │ Nullable(String)        │              │                    │         │                  │                │
│ timestamp │ Nullable(DateTime64(9)) │              │                    │         │                  │                │
│ comment   │ Nullable(String)        │              │                    │         │                  │                │
│ children  │ Array(Nullable(Int64))  │              │                    │         │                  │                │
└───────────┴─────────────────────────┴──────────────┴────────────────────┴─────────┴──────────────────┴────────────────┘
```

Notice ClickHouse infers the names and data types of your columns by analyzing a large batch of rows.
If ClickHouse can not determine the storage type from the filename, you can specify it as the second argument:

```sql
SELECT count()
FROM file(
  'comments.tsv',
  'TabSeparatedWithNames'
)
```

View the [`file` table function](/en/sql-reference/table-functions/file) docs page for more details.

</TabItem>
<TabItem value="PostgreSQL" label="PostgreSQL">

Use the [`postgresql` table function](/en/sql-reference/table-functions/postgresql) to read data from a table in PostgreSQL:


```sql
SELECT *
FROM
   postgresql(
    'localhost:5432',
    'my_database',
    'my_table',
    'postgresql_user',
    'password')
;
```

View the [`postgresql` table function](/en/sql-reference/table-functions/postgresql) docs page for more details.

</TabItem>
<TabItem value="MySQL" label="MySQL">

Use the [`mysql` table function](/en/sql-reference/table-functions/mysql) to read data from a table in MySQL:


```sql
SELECT *
FROM
   mysql(
    'localhost:3306',
    'my_database',
    'my_table',
    'postgresql_user',
    'password')
;
```

View the [`mysql` table function](/en/sql-reference/table-functions/mysql) docs page for more details.


</TabItem>
<TabItem value="Other DBMS" label="ODBC/JDBC">

ClickHouse can read data from any ODBC or JDBC data source:

```sql
SELECT *
FROM
   odbc(
    'DSN=mysqlconn',
    'my_database',
    'my_table'
  );
```

View the [`odbc` table function](/en/sql-reference/table-functions/odbc) and the [`jdbc` table function](/en/sql-reference/table-functions/jdbc) docs pages for more details.

</TabItem>
<TabItem value="Other" label="Other">

Check out our [long list of ClickHouse integrations](../integrations) to find how to connect your existing frameworks and data sources to ClickHouse.

</TabItem>
</Tabs>

## What's Next?

- Check out the [Advanced Tutorial](tutorial.md) which takes a much deeper dive into the key concepts and capabilities of ClickHouse
- Continue your learning by taking our free on-demand training courses at the [ClickHouse Academy](https://learn.clickhouse.com/visitor_class_catalog)
- We have a list of [example datasets](/en/getting-started/example-datasets/) with instructions on how to insert them
- If your data is coming from an external source, view our [collection of integration guides](/en/integrations/) for connecting to message queues, databases, pipelines and more
- If you are using a UI/BI visualization tool, view the [user guides for connecting a UI to ClickHouse](/en/integrations/data-visualization/)
- The user guide on [primary keys](/en/guides/improving-query-performance/sparse-primary-indexes/sparse-primary-indexes-intro.md) is everything you need to know about primary keys and how to define them
