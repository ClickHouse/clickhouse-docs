---
title: 为什么我的主键没有被使用？我该如何检查？
description: "解释主键在排序中未被使用的常见原因，以及如何进行确认"
date: 2024-12-12
tags: ['性能与优化']
keywords: ['主键']
---

{frontMatter.description}

{/* 截断 */}


## 检查你的主键 \{#checking-your-primary-key\}

用户可能会遇到查询比预期更慢的情况，并认为自己正在按主键进行排序或过滤。本文将介绍如何确认主键是否真正被使用，并重点说明其未被使用的一些常见原因。

## 创建表

请看下面这个简单的表：

```sql
CREATE TABLE logs
(
    `code` LowCardinality(String),
    `timestamp` DateTime64(3)
)
ENGINE = MergeTree
ORDER BY (code, toUnixTimestamp(timestamp))
```

请注意，我们的排序键中的第二个字段是 `toUnixTimestamp(timestamp)`。


## 填充数据

向该表中插入 1 亿行数据：

```sql
INSERT INTO logs SELECT
 ['200', '404', '502', '403'][toInt32(randBinomial(4, 0.1)) + 1] AS code,
    now() + toIntervalMinute(number) AS timestamp
FROM numbers(100000000)

0 rows in set. Elapsed: 15.845 sec. Processed 100.00 million rows, 800.00 MB (6.31 million rows/s., 50.49 MB/s.)

SELECT count()
FROM logs

┌───count()─┐
│ 100000000 │ -- 100.00 million
└───────────┘

1 row in set. Elapsed: 0.002 sec.
```


## 基本过滤

如果我们按代码进行过滤，可以在输出中看到扫描的行数为 `49.15 thousand`。注意，这只是总共 1 亿行中的一部分。

```sql
SELECT count() AS c
FROM logs
WHERE code = '200'

┌────────c─┐
│ 65607542 │ -- 6561 万
└──────────┘

返回 1 行。耗时:0.021 秒。已处理 4.915 万行,49.17 KB(234 万行/秒,2.34 MB/秒)
内存峰值:92.70 KiB。
```

此外，我们可以通过 `EXPLAIN indexes=1` 子句来确认索引是否被使用：

```sql
EXPLAIN indexes = 1
SELECT count() AS c
FROM logs
WHERE code = '200'

┌─explain────────────────────────────────────────────────────────────┐
│ Expression ((投影名称 + 投影))                                        │
│   AggregatingProjection                                            │
│     Expression (GROUP BY 之前)                                      │
│       Filter ((WHERE + 将列名转换为列标识符))                          │
│         ReadFromMergeTree (default.logs)                           │
│         Indexes:                                                   │
│           PrimaryKey                                               │
│             Keys:                                                  │
│               code                                                 │
│             Condition: (code in ['200', '200'])                    │
│             Parts: 3/3 │
│             Granules: 8012/12209 │
│     ReadFromPreparedSource (_minmax_count_projection)              │
└────────────────────────────────────────────────────────────────────┘
```

请注意，被扫描的 granule 数量 `8012` 只占总数 `12209` 的一小部分。下面高亮的部分则确认了主键相关代码的使用。

```bash
主键
  键: 
   code 
```

Granules 是 ClickHouse 中的数据处理单元，每个 Granule 通常包含 8192 行记录。要了解 Granules 以及它们的过滤方式的更多细节，建议阅读 [本指南](/guides/best-practices/sparse-primary-indexes#mark-files-are-used-for-locating-granules)。

:::note
在排序键（ordering key）中，对位置更靠后的键进行过滤，其效率不如对元组中更靠前的键进行过滤。原因详见 [此处](/guides/best-practices/sparse-primary-indexes#secondary-key-columns-can-not-be-inefficient)
:::


## 多键过滤

假设我们根据 `code` 和 `timestamp` 进行过滤：

```sql
SELECT count()
FROM logs
WHERE (code = '200') AND (timestamp >= '2025-01-01 00:00:00') AND (timestamp <= '2026-01-01 00:00:00')

┌─count()─┐
│  689742 │
└─────────┘

1 row in set. Elapsed: 0.008 sec. Processed 712.70 thousand rows, 6.41 MB (88.92 million rows/s., 799.27 MB/s.)


EXPLAIN indexes = 1
SELECT count()
FROM logs
WHERE (code = '200') AND (timestamp >= '2025-01-01 00:00:00') AND (timestamp <= '2026-01-01 00:00:00')

┌─explain───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ Expression ((Project names + Projection))                                                                                                                         │
│   Aggregating                                                                                                                                                     │
│     Expression (Before GROUP BY)                                                                                                                                  │
│       Expression                                                                                                                                                  │
│         ReadFromMergeTree (default.logs)                                                                                                                          │
│         Indexes:                                                                                                                                                  │
│           PrimaryKey                                                                                                                                              │
│             Keys:                                                                                                                                                 │
│               code                                                                                                                                                │
│               toUnixTimestamp(timestamp)                                                                                                                          │
│             Condition: and((toUnixTimestamp(timestamp) in (-Inf, 1767225600]), and((toUnixTimestamp(timestamp) in [1735689600, +Inf)), (code in ['200', '200']))) │
│             Parts: 3/3 │
│             Granules: 87/12209 │
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

13 rows in set. Elapsed: 0.002 sec.

```

在这种情况下，两个排序键都参与了行过滤，因此只需读取 `87` 个数据块。


## 在排序中使用键

ClickHouse 也可以利用排序键来实现高效排序。具体来说：

当启用 [optimize&#95;read&#95;in&#95;order](/sql-reference/statements/select/order-by#optimization-of-data-reading) 设置时（默认启用），ClickHouse 服务器会使用表索引，并按照 ORDER BY 键的顺序读取数据。这样，在指定 LIMIT 的情况下，即可避免读取全部数据。因此，针对大数据集但 LIMIT 较小的查询，处理速度会更快。详细说明参见[此处](/sql-reference/statements/select/order-by#optimization-of-data-reading)和[此处](/docs/knowledgebase/async_vs_optimize_read_in_order#what-about-optimize_read_in_order)。

但这要求所使用的键彼此对齐。

例如，考虑如下查询：

```sql
SELECT *
FROM logs
WHERE (code = '200') AND (timestamp >= '2025-01-01 00:00:00') AND (timestamp <= '2026-01-01 00:00:00')
ORDER BY timestamp ASC
LIMIT 10

┌─code─┬───────────────timestamp─┐
│ 200 │ 2025-01-01 00:00:01.000 │
│ 200 │ 2025-01-01 00:00:45.000 │
│ 200 │ 2025-01-01 00:01:01.000 │
│ 200 │ 2025-01-01 00:01:45.000 │
│ 200 │ 2025-01-01 00:02:01.000 │
│ 200 │ 2025-01-01 00:03:01.000 │
│ 200 │ 2025-01-01 00:03:45.000 │
│ 200 │ 2025-01-01 00:04:01.000 │
│ 200 │ 2025-01-01 00:05:45.000 │
│ 200 │ 2025-01-01 00:06:01.000 │
└──────┴─────────────────────────

返回 10 行。用时：0.009 秒。已处理 71.27 万行，6.41 MB（8013 万行/秒，720.27 MB/秒）。
内存峰值：125.50 KiB。
```

我们可以通过 `EXPLAIN pipeline` 来确认这里没有使用该优化：

```sql
EXPLAIN PIPELINE
SELECT *
FROM logs
WHERE (code = '200') AND (timestamp >= '2025-01-01 00:00:00') AND (timestamp <= '2026-01-01 00:00:00')
ORDER BY timestamp ASC
LIMIT 10

┌─explain───────────────────────────────────────────────────────────────────────┐
│ (Expression)                                                                  │
│ ExpressionTransform                                                           │
│   (Limit)                                                                     │
│   Limit │
│     (Sorting)                                                                 │
│     MergingSortedTransform 12 → 1 │
│       MergeSortingTransform × 12 │
│         LimitsCheckingTransform × 12 │
│           PartialSortingTransform × 12 │
│             (Expression)                                                      │
│             ExpressionTransform × 12 │
│               (Expression)                                                    │
│               ExpressionTransform × 12 │
│                 (ReadFromMergeTree)                                           │
│                 MergeTreeSelect(pool: ReadPool, algorithm: Thread) × 12 0 → 1 │
└───────────────────────────────────────────────────────────────────────────────┘

返回 15 行。用时:0.004 秒。
```

此处的 `MergeTreeSelect(pool: ReadPool, algorithm: Thread)` 并不表示启用了该优化，而只是一次标准读取。其原因在于我们的表排序键使用的是 `toUnixTimestamp(Timestamp)`，而**不是** `timestamp`。修正这一不一致即可解决问题：


```sql
EXPLAIN PIPELINE
SELECT *
FROM logs
WHERE (code = '200') AND (timestamp >= '2025-01-01 00:00:00') AND (timestamp <= '2026-01-01 00:00:00')
ORDER BY toUnixTimestamp(timestamp) ASC
LIMIT 10

┌─explain──────────────────────────────────────────────────────────────────────────┐
│ (Expression)                                                                     │
│ ExpressionTransform                                                              │
│   (Limit)                                                                        │
│   Limit │
│     (Sorting)                                                                    │
│     MergingSortedTransform 3 → 1 │
│       BufferChunks × 3 │
│         (Expression)                                                             │
│         ExpressionTransform × 3 │
│           (Expression)                                                           │
│           ExpressionTransform × 3 │
│             (ReadFromMergeTree)                                                  │
│             MergeTreeSelect(pool: ReadPoolInOrder, algorithm: InOrder) × 3 0 → 1 │
└──────────────────────────────────────────────────────────────────────────────────┘

13 rows in set. Elapsed: 0.003 sec.
```
