---
slug: /whats-new/changelog/2017
sidebar_position: 10
sidebar_label: "2017"
title: "2017 更新日志"
description: "2017 年更新日志"
doc_type: "changelog"
keywords:
  [
    "ClickHouse 2017",
    "2017 更新日志",
    "发布说明",
    "版本历史",
    "早期版本"
  ]
---

### ClickHouse Release 1.1.54327, 2017-12-21 {#clickhouse-release-1-1-54327-2017-12-21}

此版本包含对先前版本 1.1.54318 的错误修复:

- 修复了复制中可能导致数据丢失的竞态条件错误。此问题影响版本 1.1.54310 和 1.1.54318。如果您在使用 Replicated 表时使用了这些版本之一,强烈建议进行更新。此问题在日志中显示为类似 `Part ... from own log does not exist.` 的警告消息。即使您在日志中没有看到这些消息,该问题仍然存在。

### ClickHouse Release 1.1.54318, 2017-11-30 {#clickhouse-release-1-1-54318-2017-11-30}

此版本包含对先前版本 1.1.54310 的错误修复:

- 修复了 SummingMergeTree 引擎在合并期间错误删除行的问题
- 修复了非复制 MergeTree 引擎中的内存泄漏问题
- 修复了 MergeTree 引擎频繁插入时的性能下降问题
- 修复了导致复制队列停止运行的问题
- 修复了服务器日志的轮转和归档问题

### ClickHouse Release 1.1.54310, 2017-11-01 {#clickhouse-release-1-1-54310-2017-11-01}

#### 新特性: {#new-features}

- MergeTree 系列表引擎支持自定义分区键。
- [Kafka](/engines/table-engines/integrations/kafka) 表引擎。
- 添加了对加载 [CatBoost](https://yandex.com/dev/catboost/) 模型并将其应用于 ClickHouse 中存储的数据的支持。
- 添加了对与 UTC 偏移量为非整数的时区的支持。
- 添加了对时间间隔算术运算的支持。
- Date 和 DateTime 类型的值范围扩展到 2105 年。
- 添加了 `CREATE MATERIALIZED VIEW x TO y` 查询(指定用于存储物化视图数据的现有表)。
- 添加了不带参数的 `ATTACH TABLE` 查询。
- SummingMergeTree 表中名称以 -Map 结尾的 Nested 列的处理逻辑被提取到 sumMap 聚合函数中。现在可以显式指定此类列。
- IP trie 字典的最大大小增加到 1.28 亿条目。
- 添加了 getSizeOfEnumType 函数。
- 添加了 sumWithOverflow 聚合函数。
- 添加了对 Cap'n Proto 输入格式的支持。
- 现在可以在使用 zstd 算法时自定义压缩级别。

#### 向后不兼容的变更: {#backward-incompatible-changes}

- 不允许使用 Memory 以外的引擎创建临时表。
- 不允许使用 View 或 MaterializedView 引擎显式创建表。
- 在创建表期间,新的检查会验证采样键表达式是否包含在主键中。

#### 错误修复: {#bug-fixes}

- 修复了同步插入 Distributed 表时的挂起问题。
- 修复了 Replicated 表中非原子性添加和删除分区的问题。
- 插入物化视图的数据不再进行不必要的去重。
- 对本地副本滞后且远程副本不可用的 Distributed 表执行查询不再导致错误。
- 用户不再需要对 `default` 数据库的访问权限即可创建临时表。
- 修复了在指定不带参数的 Array 类型时崩溃的问题。
- 修复了包含服务器日志的磁盘卷已满时的挂起问题。
- 修复了 toRelativeWeekNum 函数在 Unix 纪元第一周的溢出问题。

#### 构建改进: {#build-improvements}

- 更新了多个第三方库(特别是 Poco)并将其转换为 git 子模块。

### ClickHouse Release 1.1.54304, 2017-10-19 {#clickhouse-release-1-1-54304-2017-10-19}

#### 新特性: {#new-features-1}

- 原生协议中的 TLS 支持(要启用,请在 `config.xml` 中设置 `tcp_ssl_port`)。

#### 错误修复: {#bug-fixes-1}


- 复制表的 `ALTER` 操作现在会尽快开始执行。
- 修复了设置 `preferred_block_size_bytes=0` 时读取数据导致崩溃的问题。
- 修复了按下 `Page Down` 键时 `clickhouse-client` 崩溃的问题。
- 正确解释包含 `GLOBAL IN` 和 `UNION ALL` 的某些复杂查询。
- `FREEZE PARTITION` 现在始终以原子方式执行。
- 空的 POST 请求现在返回状态码 411 的响应。
- 修复了类似 `CAST(1 AS Nullable(UInt8))` 表达式的解释错误。
- 修复了从 `MergeTree` 表读取 `Array(Nullable(String))` 列时的错误。
- 修复了解析类似 `SELECT dummy AS dummy, dummy AS b` 查询时崩溃的问题。
- 当 `users.xml` 无效时,用户现在能正确更新。
- 正确处理可执行字典返回非零响应码的情况。

### ClickHouse 版本 1.1.54292,2017-09-20 {#clickhouse-release-1-1-54292-2017-09-20}

#### 新特性: {#new-features-2}

- 添加了 `pointInPolygon` 函数,用于处理坐标平面上的坐标。
- 添加了 `sumMap` 聚合函数,用于计算数组的总和,类似于 `SummingMergeTree`。
- 添加了 `trunc` 函数。改进了舍入函数(`round`、`floor`、`ceil`、`roundToExp2`)的性能并修正了它们的工作逻辑。更改了 `roundToExp2` 函数对小数和负数的处理逻辑。
- ClickHouse 可执行文件现在对 libc 版本的依赖性降低。同一个 ClickHouse 可执行文件可以在各种 Linux 系统上运行。使用编译查询时仍然存在依赖(设置 `compile = 1`,默认不使用)。
- 减少了查询动态编译所需的时间。

#### 错误修复: {#bug-fixes-2}

- 修复了有时会产生 `part ... intersects previous part` 消息并削弱副本一致性的错误。
- 修复了在关闭期间 ZooKeeper 不可用时导致服务器锁定的错误。
- 移除了恢复副本时的过多日志记录。
- 修复了 UNION ALL 实现中的错误。
- 修复了当块中第一列为 Array 类型时 concat 函数中出现的错误。
- 进度现在在 system.merges 表中正确显示。

### ClickHouse 版本 1.1.54289,2017-09-13 {#clickhouse-release-1-1-54289-2017-09-13}

#### 新特性: {#new-features-3}

- 用于服务器管理的 `SYSTEM` 查询:`SYSTEM RELOAD DICTIONARY`、`SYSTEM RELOAD DICTIONARIES`、`SYSTEM DROP DNS CACHE`、`SYSTEM SHUTDOWN`、`SYSTEM KILL`。
- 添加了用于处理数组的函数:`concat`、`arraySlice`、`arrayPushBack`、`arrayPushFront`、`arrayPopBack`、`arrayPopFront`。
- 为 ZooKeeper 配置添加了 `root` 和 `identity` 参数。这允许您在同一个 ZooKeeper 集群上隔离各个用户。
- 添加了聚合函数 `groupBitAnd`、`groupBitOr` 和 `groupBitXor`(为了兼容性,它们也可以使用名称 `BIT_AND`、`BIT_OR` 和 `BIT_XOR`)。
- 外部字典可以通过在文件系统中指定套接字从 MySQL 加载。
- 外部字典可以通过 SSL 从 MySQL 加载(`ssl_cert`、`ssl_key`、`ssl_ca` 参数)。
- 添加了 `max_network_bandwidth_for_user` 设置,用于限制每个用户查询的总体带宽使用。
- 支持对临时表执行 `DROP TABLE`。
- 支持从 `CSV` 和 `JSONEachRow` 格式读取 Unix 时间戳格式的 `DateTime` 值。
- 分布式查询中的滞后副本现在默认被排除(默认阈值为 5 分钟)。
- ALTER 期间使用 FIFO 锁定:ALTER 查询不会因持续运行的查询而无限期阻塞。
- 可以在配置文件中设置 `umask` 选项。
- 改进了带有 `DISTINCT` 的查询性能。

#### 错误修复: {#bug-fixes-3}


- 改进了 ZooKeeper 中删除旧节点的流程。以前,如果插入操作非常频繁,旧节点有时不会被删除,这会导致服务器关闭缓慢等问题。
- 修复了选择 ZooKeeper 连接主机时的随机化问题。
- 修复了当副本为 localhost 时,分布式查询中排除滞后副本的问题。
- 修复了在 `Nested` 结构的元素上运行 `ALTER MODIFY` 后,`ReplicatedMergeTree` 表中的数据部分可能损坏的错误。
- 修复了可能导致 SELECT 查询"挂起"的错误。
- 改进了分布式 DDL 查询。
- 修复了 `CREATE TABLE ... AS <materialized view>` 查询。
- 解决了 `Buffer` 表的 `ALTER ... CLEAR COLUMN IN PARTITION` 查询中的死锁问题。
- 修复了使用 `JSONEachRow` 和 `TSKV` 格式时 `Enum` 的无效默认值(0 而不是最小值)问题。
- 解决了使用带有 `executable` 源的字典时出现僵尸进程的问题。
- 修复了 HEAD 查询的段错误。

#### 改进的 ClickHouse 开发和构建工作流: {#improved-workflow-for-developing-and-assembling-clickhouse}

- 可以使用 `pbuilder` 构建 ClickHouse。
- 在 Linux 上构建时,可以使用 `libc++` 代替 `libstdc++`。
- 添加了使用静态代码分析工具的说明:`Coverage`、`clang-tidy`、`cppcheck`。

#### 升级时请注意: {#please-note-when-upgrading}

- MergeTree 设置 `max_bytes_to_merge_at_max_space_in_pool`(要合并的数据部分的最大总大小,以字节为单位)的默认值现在更高:已从 100 GiB 增加到 150 GiB。这可能导致服务器升级后运行大型合并操作,从而增加磁盘子系统的负载。如果服务器上的可用空间少于正在运行的合并操作总量的两倍,这将导致所有其他合并操作停止运行,包括小数据部分的合并。因此,INSERT 查询将失败并显示消息"Merges are processing significantly slower than inserts."。使用 `SELECT * FROM system.merges` 查询监控情况。您还可以在 `system.metrics` 表或 Graphite 中检查 `DiskSpaceReservedForMerge` 指标。您无需执行任何操作来修复此问题,因为一旦大型合并完成,问题将自行解决。如果您认为这不可接受,可以恢复 `max_bytes_to_merge_at_max_space_in_pool` 设置的先前值。为此,请转到 config.xml 中的 `<merge_tree>` 部分,设置 `<merge_tree>``<max_bytes_to_merge_at_max_space_in_pool>107374182400</max_bytes_to_merge_at_max_space_in_pool>` 并重启服务器。

### ClickHouse 版本 1.1.54284,2017-08-29 {#clickhouse-release-1-1-54284-2017-08-29}

- 这是针对先前 1.1.54282 版本的错误修复版本。它修复了 ZooKeeper 中 parts 目录的泄漏问题。

### ClickHouse 版本 1.1.54282,2017-08-23 {#clickhouse-release-1-1-54282-2017-08-23}

此版本包含针对先前版本 1.1.54276 的错误修复:

- 修复了插入 Distributed 表时的 `DB::Exception: Assertion violation: !_path.empty()` 错误。
- 修复了当输入数据以 ';' 开头时,以 RowBinary 格式插入时的解析问题。
- 修复了某些聚合函数(例如 `groupArray()`)运行时编译期间的错误。

### ClickHouse 版本 1.1.54276,2017-08-16 {#clickhouse-release-1-1-54276-2017-08-16}

#### 新功能: {#new-features-4}


- 为 SELECT 查询添加了可选的 WITH 子句。示例查询：`WITH 1+1 AS a SELECT a, a*a`
- INSERT 可以在 Distributed 表中同步执行：只有在所有数据都保存到所有分片后才返回 OK。通过设置 insert_distributed_sync=1 启用此功能。
- 添加了 UUID 数据类型，用于处理 16 字节标识符。
- 添加了 CHAR、FLOAT 等类型的别名，以兼容 Tableau。
- 添加了 toYYYYMM、toYYYYMMDD 和 toYYYYMMDDhhmmss 函数，用于将时间转换为数字。
- 可以使用 IP 地址（与主机名一起）来标识集群 DDL 查询的服务器。
- 在函数 `substring(str, pos, len)` 中添加了对非常量参数和负偏移量的支持。
- 为聚合函数 `groupArray(max_size)(column)` 添加了 max_size 参数，并优化了其性能。

#### 主要变更： {#main-changes}

- 安全性改进：所有服务器文件以 0640 权限创建（可通过 `<umask>` 配置参数更改）。
- 改进了无效语法查询的错误消息。
- 显著降低了合并大型 MergeTree 数据段时的内存消耗并提高了性能。
- 显著提高了 ReplacingMergeTree 引擎的数据合并性能。
- 通过合并多个源插入操作，提高了从 Distributed 表进行异步插入的性能。要启用此功能，请使用设置 distributed_directory_monitor_batch_inserts=1。

#### 向后不兼容的变更： {#backward-incompatible-changes-1}

- 更改了数组的 `groupArray(array_column)` 函数聚合状态的二进制格式。

#### 完整变更列表： {#complete-list-of-changes}

- 添加了 `output_format_json_quote_denormals` 设置，用于在 JSON 格式中输出 nan 和 inf 值。
- 优化了从 Distributed 表读取时的流分配。
- 如果值不变，可以在只读模式下配置设置。
- 添加了检索 MergeTree 引擎非整数粒度的功能，以满足 preferred_block_size_bytes 设置中指定的块大小限制。目的是在处理具有大列的表的查询时减少 RAM 消耗并提高缓存局部性。
- 对于 `toStartOfHour(x) op сonstexpr` 这样的条件，高效使用包含 `toStartOfHour(x)` 等表达式的索引。
- 为 MergeTree 引擎添加了新设置（config.xml 中的 merge_tree 部分）：
  - replicated_deduplication_window_seconds 设置 Replicated 表中允许去重插入的秒数。
  - cleanup_delay_period 设置启动清理以删除过期数据的频率。
  - replicated_can_become_leader 可以防止副本成为 leader（并分配合并）。
- 加速清理以从 ZooKeeper 中删除过期数据。
- 对集群 DDL 查询进行了多项改进和修复。特别值得关注的是新设置 distributed_ddl_task_timeout，它限制了等待集群中服务器响应的时间。如果 DDL 请求未在所有主机上执行，响应将包含超时错误，并且请求将以异步模式执行。
- 改进了服务器日志中堆栈跟踪的显示。
- 为压缩方法添加了 "none" 值。
- 可以在 config.xml 中使用多个 dictionaries_config 部分。
- 可以通过文件系统中的套接字连接到 MySQL。
- system.parts 表新增了一列，包含有关标记大小的信息（以字节为单位）。

#### 错误修复： {#bug-fixes-4}


- 对使用 Merge 表的 Distributed 表，在包含 `_table` 字段条件的 SELECT 查询中现在可以正确工作。
- 修复了在检查数据分片时 ReplicatedMergeTree 中出现的罕见竞争条件。
- 修复了在服务器启动时进行“leader 选举”过程中可能发生的卡死问题。
- 修复了在使用数据源的本地副本时，设置 max_replica_delay_for_distributed_queries 会被忽略的问题。
- 修复了在尝试清理不存在的列时，`ALTER TABLE CLEAR COLUMN IN PARTITION` 的错误行为。
- 修复了在 multiIf 函数中使用空数组或空字符串时抛出异常的问题。
- 修复了反序列化 Native 格式时过多内存分配的问题。
- 修复了 Trie 字典自动更新行为不正确的问题。
- 修复了在 Merge 表上运行带有 GROUP BY 子句并使用 SAMPLE 时出现异常的问题。
- 修复了在设置 distributed_aggregation_memory_efficient=1 时 GROUP BY 崩溃的问题。
- 现在可以在 IN 和 JOIN 的右侧显式指定 database.table。
- 修复了并行聚合使用线程数过多的问题。
- 修复了 `if` 函数在处理 FixedString 参数时的行为。
- 修复了从 Distributed 表中对权重为 0 的分片执行 SELECT 时行为不正确的问题。
- 运行 `CREATE VIEW IF EXISTS` 不再导致崩溃。
- 修复了在设置 input_format_skip_unknown_fields=1 且存在负数时的错误行为。
- 修复了当字典中存在无效数据时，`dictGetHierarchy()` 函数可能进入死循环的问题。
- 修复了在包含 IN 或 JOIN 子句子查询以及 Merge 表的分布式查询中出现 `Syntax error: unexpected (...)` 错误的问题。
- 修复了对来自 Dictionary 表的 SELECT 查询解析不正确的问题。
- 修复了在 IN 和 JOIN 子句中使用包含超过 20 亿个元素的数组时出现的 “Cannot mremap” 错误。
- 修复了以 MySQL 作为源的字典在故障切换时的问题。

#### 改进的 ClickHouse 开发与构建流程：{#improved-workflow-for-developing-and-assembling-clickhouse-1}

- 可以在 Arcadia 中进行构建组装。
- 可以使用 gcc 7 编译 ClickHouse。
- 使用 ccache+distcc 进行的并行构建现在更快。

### ClickHouse 版本 1.1.54245，2017-07-04 {#clickhouse-release-1-1-54245-2017-07-04}

#### 新特性：{#new-features-5}

- 分布式 DDL（例如 `CREATE TABLE ON CLUSTER`）
- 新增复制场景下的查询语句：`ALTER TABLE CLEAR COLUMN IN PARTITION`。
- Dictionary 表引擎（以数据表形式访问字典数据）。
- Dictionary 数据库引擎（此类数据库会为所有已连接的外部字典自动提供对应的 Dictionary 表）。
- 可以通过向源端发送请求来检查字典是否有更新。
- 支持限定列名（qualified column names）。
- 支持使用双引号对标识符进行引用。
- HTTP 接口中的会话支持。
- 对 Replicated 表执行 OPTIMIZE 查询时，不再只能在 leader 上运行。

#### 向后不兼容的变更：{#backward-incompatible-changes-2}

- 移除了 SET GLOBAL。

#### 次要变更：{#minor-changes}

- 现在在告警被触发后，日志会打印完整的堆栈跟踪。
- 放宽了启动时对损坏/多余数据分片数量的校验（此前误报过多）。

#### 缺陷修复：{#bug-fixes-5}

- 修复了向 Distributed 表插入数据时，异常连接“粘住”无法释放的问题。
- 现在，从 Merge 表发起、读取 Distributed 表数据的查询可以正确使用 GLOBAL IN。
- 修复了在 Google Compute Engine 虚拟机上检测到的 CPU 核心数不正确的问题。
- 调整了可执行程序作为缓存外部字典数据源时的工作方式。
- 修复了比较包含空字符的字符串时的问题。
- 修复了 Float32 主键字段与常量比较的问题。
- 之前对字段大小估算不准确，可能导致分配的内存过大，现已修复。
- 修复了对通过 ALTER 添加的 Nullable 列进行查询时发生崩溃的问题。
- 修复了在按 Nullable 列排序且行数小于 LIMIT 时发生的崩溃问题。
- 修复了仅由常量值组成的 ORDER BY 子查询的问题。
- 此前在 DROP TABLE 失败后，Replicated 表可能会一直处于无效状态，现已修复。
- 对结果为空的标量子查询，其别名不再丢失。
- 现在，即使相关 .so 文件损坏，使用编译执行的查询也不会再因错误而失败。
