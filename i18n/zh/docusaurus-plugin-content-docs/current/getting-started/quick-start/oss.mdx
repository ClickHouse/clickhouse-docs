---
slug: /getting-started/quick-start/oss
sidebar_label: '开源版'
sidebar_position: 2
keywords: ['入门', '快速开始', '新手友好']
title: 'ClickHouse 开源版快速开始'
description: 'ClickHouse 快速开始指南'
show_related_blogs: true
doc_type: 'guide'
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';
import {VerticalStepper} from '@clickhouse/click-ui/bundled';


# ClickHouse OSS 快速入门

> 在本快速入门教程中，我们将通过 8 个简单步骤帮助你完成 OSS ClickHouse 的设置。你将下载适用于你操作系统的二进制文件，学习如何运行 ClickHouse server，并使用 ClickHouse client 创建一张表，然后向其中插入数据并运行查询来选取这些数据。

<VerticalStepper>
  ## 下载 ClickHouse

  ClickHouse 原生支持 Linux、FreeBSD 和 macOS,并可通过 [WSL](https://learn.microsoft.com/en-us/windows/wsl/about) 在 Windows 上运行。 在本地下载 ClickHouse 最简单的方式是运行以下 `curl` 命令。 该命令将检测您的操作系统是否受支持,然后下载从 master 分支构建的相应 ClickHouse 二进制文件。

  :::note
  建议在新建的空子目录中运行以下命令,因为首次运行 ClickHouse 服务器时,会在二进制文件所在目录中创建一些配置文件。

  以下脚本不是在生产环境中安装 ClickHouse 的推荐方式。
  如需安装生产环境的 ClickHouse 实例,请参阅[安装页面](/install)。
  :::

  ```bash
  curl https://clickhouse.com/ | sh
  ```

  您应该会看到:

  ```
  成功下载 ClickHouse 二进制文件后,可以通过以下方式运行:
      ./clickhouse

  也可以进行安装:
  sudo ./clickhouse install
  ```

  在此阶段,可以忽略运行 `install` 命令的提示。

  :::note
  Mac 用户注意：如果您遇到无法验证二进制文件开发者的错误，请参阅[&quot;修复 macOS 中的开发者验证错误&quot;](https://clickhouse.com/docs/knowledgebase/fix-developer-verification-error-in-macos)。
  :::

  ## 启动服务器

  运行以下命令启动 ClickHouse 服务器：

  ```bash
  ./clickhouse server
  ```

  您应该会看到终端中充满日志输出。这是预期行为。在 ClickHouse 中,
  [默认日志级别](https://clickhouse.com/docs/knowledgebase/why_default_logging_verbose)
  设置为 `trace` 而非 `warning`。

  ## 启动客户端

  使用 `clickhouse-client` 连接到您的 ClickHouse 服务。打开新终端，切换到 `clickhouse` 二进制文件所在的目录，然后运行以下命令：

  ```bash
  ./clickhouse client
  ```

  您应该会看到一个笑脸,表示已成功连接到本地运行的服务:

  ```response
  my-host :)
  ```

  ## 创建表

  使用 `CREATE TABLE` 定义新表。常规 SQL DDL 命令在 ClickHouse 中均可使用,但需注意一点——ClickHouse 中的表必须指定 `ENGINE` 子句。使用 [`MergeTree`](/engines/table-engines/mergetree-family/mergetree) 引擎可充分发挥 ClickHouse 的性能优势:

  ```sql
  CREATE TABLE my_first_table
  (
      user_id UInt32,
      message String,
      timestamp DateTime,
      metric Float32
  )
  ENGINE = MergeTree
  PRIMARY KEY (user_id, timestamp)
  ```

  ## 插入数据

  您可以使用熟悉的 `INSERT INTO TABLE` 命令操作 ClickHouse,但需要理解的是,每次向 `MergeTree` 表插入数据都会在存储中创建我们所称的 **part**(数据部分)。这些 ^^part^^ 随后会由 ClickHouse 在后台进行合并。

  在 ClickHouse 中,我们建议一次性批量插入大量数据行(单次插入数万甚至数百万行),以最小化后台进程中需要合并的 [**parts**](/parts) 数量。

  在本指南中,我们暂时不必担心这个问题。运行以下命令向表中插入几行数据:

  ```sql
  INSERT INTO my_first_table (user_id, message, timestamp, metric) VALUES
      (101, '你好,ClickHouse!',                                 now(),       -1.0    ),
      (102, '每批次插入大量数据行',                     yesterday(), 1.41421 ),
      (102, '根据常用查询对数据进行排序', today(),     2.718   ),
      (101, 'Granule 是数据读取的最小单元',      now() + 5,   3.14159 )
  ```

  ## 查询您的新表

  您可以像在任何 SQL 数据库中一样编写 `SELECT` 查询:

  ```sql
  SELECT *
  FROM my_first_table
  ORDER BY timestamp
  ```

  注意响应以表格格式返回：

  ```text
  ┌─user_id─┬─message────────────────────────────────────────────┬───────────timestamp─┬──metric─┐
  │     102 │ 每批插入大量行                                      │ 2022-03-21 00:00:00 │ 1.41421 │
  │     102 │ 根据常用查询对数据进行排序                          │ 2022-03-22 00:00:00 │   2.718 │
  │     101 │ 你好,ClickHouse!                                   │ 2022-03-22 14:04:09 │      -1 │
  │     101 │ 颗粒是读取的最小数据块                              │ 2022-03-22 14:04:14 │ 3.14159 │
  └─────────┴────────────────────────────────────────────────────┴─────────────────────┴─────────┘

  返回 4 行。耗时:0.008 秒。
  ```

  ## 插入您自己的数据

  下一步是将您自己的数据导入 ClickHouse。我们提供了大量的[表函数](/sql-reference/table-functions/index.md)和[集成](/integrations)用于摄取数据。您可以参考下方选项卡中的示例,或访问我们的[集成](/integrations)页面查看与 ClickHouse 集成的完整技术列表。

  <Tabs groupId="read_data">
    <TabItem value="S3" label="S3" default>
      使用 [`s3` 表函数](/sql-reference/table-functions/s3.md)
      从 S3 中读取文件。它是一个表函数，这意味着其返回结果是一个表，
      该表可以：

      1. 作为 `SELECT` 查询的数据源（允许你运行即席查询，同时将数据保留在 S3 中），或者……
      2. 将该结果表插入到一个 `MergeTree` 表中（当你准备好将数据迁移到 ClickHouse 中时）

      一个即席查询示例如下：

      ```sql
      SELECT
      passenger_count,
      avg(toFloat32(total_amount))
      FROM s3(
      'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
      'TabSeparatedWithNames'
      )
      GROUP BY passenger_count
      ORDER BY passenger_count;
      ```

      将数据写入 ClickHouse 表的操作如下所示，其中
      `nyc_taxi` 是一个 `MergeTree` 表：

      ```sql
      INSERT INTO nyc_taxi
      SELECT * FROM s3(
      'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
      'TabSeparatedWithNames'
      )
      SETTINGS input_format_allow_errors_num=25000;
      ```

      查看我们的 [AWS S3 文档页面集合](/integrations/data-ingestion/s3/index.md)，了解更多将 S3 与 ClickHouse 结合使用的详细信息和示例。

      <br />
    </TabItem>

    <TabItem value="GCS" label="GCS">
      用于在 AWS S3 中读取数据的 [`s3` table function](/sql-reference/table-functions/s3.md) 也适用于 Google Cloud Storage 中的文件。

      例如：

      ```sql
      SELECT
      *
      FROM s3(
      'https://storage.googleapis.com/my-bucket/trips.parquet',
      'MY_GCS_HMAC_KEY',
      'MY_GCS_HMAC_SECRET_KEY',
      'Parquet'
      )
      LIMIT 1000
      ```

      有关更多详细信息，请参阅 [`s3` 表函数页面](/sql-reference/table-functions/s3.md)。

      <br />
    </TabItem>

    <TabItem value="URL" label="Web">
      [`url` 表函数](/sql-reference/table-functions/url) 用于读取
      可通过 Web 访问的文件：

      ```sql
      --默认情况下,ClickHouse 会阻止重定向以防范 SSRF 攻击。
      --以下 URL 需要重定向,因此必须设置 max_http_get_redirects > 0。
      SET max_http_get_redirects=10;

      SELECT *
      FROM url(
      'http://prod2.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv',
      'CSV'
      );
      ```

      有关更多详细信息，请参阅 [`url` 表函数页面](/sql-reference/table-functions/url)。

      <br />
    </TabItem>

    <TabItem value="local_file" label="本地">
      使用 [`file` 表引擎](/sql-reference/table-functions/file) 来读取本地文件。为方便起见，将文件复制到 `user_files` 目录，该目录位于你下载 ClickHouse 二进制文件的目录下。

      ```sql
      DESCRIBE TABLE file('comments.tsv')

      Query id: 8ca9b2f9-65a2-4982-954a-890de710a336

      ┌─name──────┬─type────────────────────┐
      │ id        │ Nullable(Int64)         │
      │ type      │ Nullable(String)        │
      │ author    │ Nullable(String)        │
      │ timestamp │ Nullable(DateTime64(9)) │
      │ comment   │ Nullable(String)        │
      │ children  │ Array(Nullable(Int64))  │
      └───────────┴─────────────────────────┘
      ```

      请注意，ClickHouse 会通过分析大量行数据来推断列名和数据类型。\
      如果 ClickHouse 无法从文件名中确定文件格式，则可以将其作为第二个参数进行指定：

      ```sql
      SELECT count()
      FROM file(
      'comments.tsv',
      'TabSeparatedWithNames'
      )
      ```

      有关更多详细信息，请参阅 [`file` 表函数](/sql-reference/table-functions/file) 的文档页面。

      <br />
    </TabItem>

    <TabItem value="PostgreSQL" label="PostgreSQL">
      使用 [`postgresql` 表函数](/sql-reference/table-functions/postgresql)
      从 PostgreSQL 的表中读取数据：

      ```sql
      SELECT *
      FROM
      postgresql(
      'localhost:5432',
      'my_database',
      'my_table',
      'postgresql_user',
      'password')
      ;
      ```

      有关更多详细信息，请参阅 [`postgresql` 表函数](/sql-reference/table-functions/postgresql)
      文档页面。

      <br />
    </TabItem>

    <TabItem value="MySQL" label="MySQL">
      使用 [`mysql` 表函数](/sql-reference/table-functions/mysql)
      从 MySQL 的表中读取数据：

      ```sql
      SELECT *
      FROM
      mysql(
      'localhost:3306',
      'my_database',
      'my_table',
      'mysql_user',
      'password')
      ;
      ```

      查看 [`mysql` 表函数](/sql-reference/table-functions/mysql)
      的文档页面，了解更多详细信息。

      <br />
    </TabItem>

    <TabItem value="其他数据库管理系统" label="ODBC/JDBC">
      ClickHouse 可以从任何 ODBC 或 JDBC 数据源读取数据：

      ```sql
      SELECT *
      FROM
      odbc(
      'DSN=mysqlconn',
      'my_database',
      'my_table'
      );
      ```

      查看 [`odbc` 表函数](/sql-reference/table-functions/odbc)
      和 [`jdbc` 表函数](/sql-reference/table-functions/jdbc) 文档，了解更多详细信息。

      <br />
    </TabItem>

    <TabItem value="消息队列" label="消息队列">
      消息队列可以使用相应的表引擎将数据以流式方式写入 ClickHouse，包括：

      * **Kafka**：通过 [`Kafka` 表引擎](/engines/table-engines/integrations/kafka) 与 Kafka 集成
      * **Amazon MSK**：与 [Amazon Managed Streaming for Apache Kafka (MSK)](/integrations/kafka/cloud/amazon-msk/) 集成
      * **RabbitMQ**：通过 [`RabbitMQ` 表引擎](/engines/table-engines/integrations/rabbitmq) 与 RabbitMQ 集成

      <br />
    </TabItem>

    <TabItem value="数据湖" label="数据湖">
      ClickHouse 提供了表函数，用于从以下数据源读取数据：

      * **Hadoop**：通过 [`hdfs` 表函数](/sql-reference/table-functions/hdfs) 与 Apache Hadoop 集成
      * **Hudi**：通过 [`hudi` 表函数](/sql-reference/table-functions/hudi) 从 S3 中现有的 Apache Hudi 表读取数据
      * **Iceberg**：通过 [`iceberg` 表函数](/sql-reference/table-functions/iceberg) 从 S3 中现有的 Apache Iceberg 表读取数据
      * **DeltaLake**：通过 [`deltaLake` 表函数](/sql-reference/table-functions/deltalake) 从 S3 中现有的 Delta Lake 表读取数据

      <br />
    </TabItem>

    <TabItem value="其他" label="其他">
      查看我们的[ClickHouse 集成详尽列表](/integrations)，以了解如何将您现有的框架和数据源连接到 ClickHouse。

      <br />
    </TabItem>
  </Tabs>

  ## 探索

  * 查看我们的[核心概念](/managing-data/core-concepts)章节，了解一些 ClickHouse 底层工作原理的基础概念。
  * 请查看 [进阶教程](tutorial.md)，该教程将更深入地探讨 ClickHouse 的核心概念和功能。
  * 前往 [ClickHouse Academy](https://learn.clickhouse.com/visitor_class_catalog) 参加我们的免费按需培训课程，继续学习。
  * 我们提供了一系列[示例数据集](/getting-started/example-datasets/)，并附有插入这些数据集的具体说明。
  * 如果您的数据来自外部系统，请参阅我们的[集成指南汇总](/integrations/)，了解如何连接消息队列、数据库、数据管道等。
  * 如果您正在使用 UI/BI 可视化工具，请参阅[将 UI 工具连接到 ClickHouse 的用户指南](/integrations/data-visualization/)。
  * [主键](/guides/best-practices/sparse-primary-indexes.md)用户指南包含了你需要了解的所有主键信息以及如何定义主键。
</VerticalStepper>