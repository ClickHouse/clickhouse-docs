---
description: '显示所有可用分词器的系统表。'
keywords: ['系统表', '分词器']
slug: /operations/system-tables/tokenizers
title: 'system.tokenizers'
doc_type: 'reference'
---

import SystemTableCloud from '@site/i18n/zh/docusaurus-plugin-content-docs/current/_snippets/_system_table_cloud.md';

# system.tokenizers \{#systemtokenizers\}

<SystemTableCloud />

显示所有可用的分词器。
这些分词器可用于函数 [tokens](../../sql-reference/functions/splitting-merging-functions.md#tokens)、[hasAllTokens](../../sql-reference/functions/string-search-functions.md#hasAllTokens)、[hasAnyTokens](../../sql-reference/functions/string-search-functions.md#hasAnyTokens)，以及 [text index](../../engines/table-engines/mergetree-family/textindexes.md)。

列：

{/*AUTOGENERATED_START*/ }

* `name` ([String](../../sql-reference/data-types/)) — 分词器的名称
* `type` ([String](../../sql-reference/data-types/)) — 分词器的类型

{/*AUTOGENERATED_END*/ }

**示例**

```sql
SELECT * FROM system.tokenizers;
```

```text
┌─name────────────┬─type────────────┐
│ ngrams          │ Ngrams          │
│ splitByNonAlpha │ SplitByNonAlpha │
│ sparseGrams     │ SparseGrams     │
│ tokenbf_v1      │ SplitByNonAlpha │
│ ngrambf_v1      │ Ngrams          │
│ array           │ Array           │
│ splitByString   │ SplitByString   │
│ sparse_grams    │ SparseGrams     │
└─────────────────┴─────────────────┘
```
