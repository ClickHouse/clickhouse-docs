---
title: "会话设置"
sidebar_label: "会话设置"
slug: /operations/settings/settings
toc_max_heading_level: 2
description: "可在 ``system.settings`` 表中查询的设置项。"
doc_type: "reference"
---

import ExperimentalBadge from "@theme/badges/ExperimentalBadge"
import BetaBadge from "@theme/badges/BetaBadge"
import CloudOnlyBadge from "@theme/badges/CloudOnlyBadge"
import SettingsInfoBlock from "@theme/SettingsInfoBlock/SettingsInfoBlock"
import VersionHistory from "@theme/VersionHistory/VersionHistory"

<!-- Autogenerated -->

以下所有设置项也可在 [system.settings](/docs/operations/system-tables/settings) 表中查询。这些设置项由[源代码](https://github.com/ClickHouse/ClickHouse/blob/master/src/Core/Settings.cpp)自动生成。


## add_http_cors_header {#add_http_cors_header}

<SettingsInfoBlock type='Bool' default_value='0' />

添加 HTTP CORS 响应头。


## additional_result_filter {#additional_result_filter}

用于对 `SELECT` 查询结果进行额外过滤的表达式。
此设置不会应用于任何子查询。

**示例**

```sql
INSERT INTO table_1 VALUES (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');
SElECT * FROM table_1;
```

```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 2 │ bb   │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```

```sql
SELECT *
FROM table_1
SETTINGS additional_result_filter = 'x != 2'
```

```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```


## additional_table_filters {#additional_table_filters}

<SettingsInfoBlock type='Map' default_value='{}' />

从指定表读取后应用的附加过滤表达式。

**示例**

```sql
INSERT INTO table_1 VALUES (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');
SELECT * FROM table_1;
```

```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 2 │ bb   │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```

```sql
SELECT *
FROM table_1
SETTINGS additional_table_filters = {'table_1': 'x != 2'}
```

```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```


## aggregate_functions_null_for_empty {#aggregate_functions_null_for_empty}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用对查询中所有聚合函数的重写,为其添加 [-OrNull](/sql-reference/aggregate-functions/combinators#-ornull) 后缀。启用此设置以符合 SQL 标准。
该功能通过查询重写实现(类似于 [count_distinct_implementation](#count_distinct_implementation) 设置),以确保分布式查询结果的一致性。

可选值:

- 0 — 禁用。
- 1 — 启用。

**示例**

考虑以下使用聚合函数的查询:

```sql
SELECT SUM(-1), MAX(0) FROM system.one WHERE 0;
```

当 `aggregate_functions_null_for_empty = 0` 时,将产生以下结果:

```text
┌─SUM(-1)─┬─MAX(0)─┐
│       0 │      0 │
└─────────┴────────┘
```

当 `aggregate_functions_null_for_empty = 1` 时,结果为:

```text
┌─SUMOrNull(-1)─┬─MAXOrNull(0)─┐
│          NULL │         NULL │
└───────────────┴──────────────┘
```


## aggregation_in_order_max_block_bytes {#aggregation_in_order_max_block_bytes}

<SettingsInfoBlock type='UInt64' default_value='50000000' />

按主键顺序进行聚合时累积的数据块的最大字节数。较小的数据块大小可以提高聚合最终合并阶段的并行化程度。


## aggregation_memory_efficient_merge_threads {#aggregation_memory_efficient_merge_threads}

<SettingsInfoBlock type='UInt64' default_value='0' />

在内存高效模式下用于合并中间聚合结果的线程数。该值越大,消耗的内存越多。设置为 0 表示使用与 'max_threads' 相同的值。


## allow_aggregate_partitions_independently {#allow_aggregate_partitions_independently}

<SettingsInfoBlock type='Bool' default_value='0' />

当分区键与 GROUP BY 键匹配时,启用在独立线程上对分区进行独立聚合。当分区数量接近 CPU 核心数且各分区大小大致相同时,此设置可提升性能


## allow_archive_path_syntax {#allow_archive_path_syntax}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.8" },
        { label: "1" },
        { label: "新增设置,允许禁用归档路径语法。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.5" },
        { label: "1" },
        { label: "新增设置,允许禁用归档路径语法。" }
      ]
    }
  ]}
/>

如果归档文件具有正确的扩展名,File/S3 引擎/表函数会将包含 '::' 的路径解析为 `<archive> :: <file>`。


## allow_asynchronous_read_from_io_pool_for_merge_tree {#allow_asynchronous_read_from_io_pool_for_merge_tree}

<SettingsInfoBlock type='Bool' default_value='0' />

使用后台 I/O 池从 MergeTree 表读取数据。此设置可提升 I/O 密集型查询的性能


## allow_changing_replica_until_first_data_packet {#allow_changing_replica_until_first_data_packet}

<SettingsInfoBlock type='Bool' default_value='0' />

启用此设置后,在对冲请求中,即使已经取得一些进展(但进展在 `receive_data_timeout` 超时时间内未更新),仍可以在接收到第一个数据包之前启动新连接;否则,在首次取得进展后将禁用副本切换。


## allow_create_index_without_type {#allow_create_index_without_type}

<SettingsInfoBlock type='Bool' default_value='0' />

允许执行不带 TYPE 的 CREATE INDEX 查询。此类查询将被忽略。用于 SQL 兼容性测试。


## allow_custom_error_code_in_throwif {#allow_custom_error_code_in_throwif}

<SettingsInfoBlock type='Bool' default_value='0' />

在 throwIf() 函数中启用自定义错误代码。如果设置为 true,抛出的异常可能会包含非预期的错误代码。


## allow_ddl {#allow_ddl}

<SettingsInfoBlock type='Bool' default_value='1' />

如果设置为 true,则允许用户执行 DDL 查询。


## allow_deprecated_database_ordinary {#allow_deprecated_database_ordinary}

<SettingsInfoBlock type='Bool' default_value='0' />

允许创建使用已弃用 Ordinary 引擎的数据库


## allow_deprecated_error_prone_window_functions {#allow_deprecated_error_prone_window_functions}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.5" },
        { label: "0" },
        {
          label:
            "允许使用已弃用的易出错窗口函数(neighbor、runningAccumulate、runningDifferenceStartingWithFirstValue、runningDifference)"
        }
      ]
    }
  ]}
/>

允许使用已弃用的易出错窗口函数(neighbor、runningAccumulate、runningDifferenceStartingWithFirstValue、runningDifference)


## allow_deprecated_snowflake_conversion_functions {#allow_deprecated_snowflake_conversion_functions}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "已禁用弃用的函数 snowflakeToDateTime[64] 和 dateTime[64]ToSnowflake。"
        }
      ]
    }
  ]}
/>

函数 `snowflakeToDateTime`、`snowflakeToDateTime64`、`dateTimeToSnowflake` 和 `dateTime64ToSnowflake` 已弃用,默认处于禁用状态。
请使用函数 `snowflakeIDToDateTime`、`snowflakeIDToDateTime64`、`dateTimeToSnowflakeID` 和 `dateTime64ToSnowflakeID` 代替。

如需重新启用已弃用的函数(例如在过渡期间),请将此设置设为 `true`。


## allow_deprecated_syntax_for_merge_tree {#allow_deprecated_syntax_for_merge_tree}

<SettingsInfoBlock type='Bool' default_value='0' />

允许使用已弃用的引擎定义语法创建 \*MergeTree 表


## allow_distributed_ddl {#allow_distributed_ddl}

<SettingsInfoBlock type='Bool' default_value='1' />

如果设置为 true，则允许用户执行分布式 DDL 查询。


## allow_drop_detached {#allow_drop_detached}

<SettingsInfoBlock type='Bool' default_value='0' />

允许 ALTER TABLE ... DROP DETACHED PART[ITION] ... 查询


## allow_dynamic_type_in_join_keys {#allow_dynamic_type_in_join_keys}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.10" },
        { label: "0" },
        { label: "默认禁止在 JOIN 键中使用 Dynamic 类型" }
      ]
    }
  ]}
/>

允许在 JOIN 键中使用 Dynamic 类型。添加此设置是为了保持兼容性。不建议在 JOIN 键中使用 Dynamic 类型,因为与其他类型进行比较可能导致意外结果。


## allow_execute_multiif_columnar {#allow_execute_multiif_columnar}

<SettingsInfoBlock type='Bool' default_value='1' />

允许以列式方式执行 multiIf 函数


## allow_experimental_alias_table_engine {#allow_experimental_alias_table_engine}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

允许使用 Alias 引擎创建表。


## allow_experimental_analyzer {#allow_experimental_analyzer}

**别名**：`enable_analyzer`

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1" },
        { label: "默认启用分析器和查询规划器。" }
      ]
    }
  ]}
/>

启用新的查询分析器。


## allow_experimental_codecs {#allow_experimental_codecs}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

如果设置为 true,则允许指定实验性压缩编解码器(但目前尚无此类编解码器,该选项暂无实际作用)。


## allow_experimental_correlated_subqueries {#allow_experimental_correlated_subqueries}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "1" },
        { label: "将关联子查询支持标记为 Beta 版。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.4" },
        { label: "0" },
        { label: "新增设置以允许执行关联子查询。" }
      ]
    }
  ]}
/>

允许执行关联子查询。


## allow_experimental_database_glue_catalog {#allow_experimental_database_glue_catalog}

<BetaBadge />

**别名**: `allow_database_glue_catalog`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.3" },
        { label: "0" },
        {
          label:
            "允许使用 catalog_type = 'glue' 的实验性数据库引擎 DataLakeCatalog"
        }
      ]
    }
  ]}
/>

允许使用 catalog_type = 'glue' 的实验性数据库引擎 DataLakeCatalog


## allow_experimental_database_hms_catalog {#allow_experimental_database_hms_catalog}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        {
          label:
            "允许使用实验性数据库引擎 DataLakeCatalog,catalog_type = 'hive'"
        }
      ]
    }
  ]}
/>

允许使用实验性数据库引擎 DataLakeCatalog,catalog_type = 'hms'


## allow_experimental_database_iceberg {#allow_experimental_database_iceberg}

<BetaBadge />

**别名**:`allow_database_iceberg`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.12" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

允许使用实验性数据库引擎 DataLakeCatalog,catalog_type 为 'iceberg'


## allow_experimental_database_materialized_postgresql {#allow_experimental_database_materialized_postgresql}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

允许创建使用 Engine=MaterializedPostgreSQL(...) 引擎的数据库。


## allow_experimental_database_unity_catalog {#allow_experimental_database_unity_catalog}

<BetaBadge />

**别名**: `allow_database_unity_catalog`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.3" },
        { label: "0" },
        {
          label:
            "允许使用 catalog_type = 'unity' 的实验性数据库引擎 DataLakeCatalog"
        }
      ]
    }
  ]}
/>

允许使用 catalog_type = 'unity' 的实验性数据库引擎 DataLakeCatalog


## allow_experimental_delta_kernel_rs {#allow_experimental_delta_kernel_rs}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "1" }, { label: "新增设置" }]
    }
  ]}
/>

允许使用实验性的 delta-kernel-rs 实现。


## allow_experimental_delta_lake_writes {#allow_experimental_delta_lake_writes}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

启用 delta-kernel 写入功能。


## allow_experimental_full_text_index {#allow_experimental_full_text_index}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        { label: "启用实验性全文索引" }
      ]
    }
  ]}
/>

设置为 true 时,允许使用实验性全文索引。


## allow_experimental_funnel_functions {#allow_experimental_funnel_functions}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

启用漏斗分析的实验性函数。


## allow_experimental_hash_functions {#allow_experimental_hash_functions}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

启用实验性哈希函数


## allow_experimental_iceberg_compaction {#allow_experimental_iceberg_compaction}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "New setting " }]
    }
  ]}
/>

允许对 Iceberg 表显式使用 'OPTIMIZE' 命令。


## allow_experimental_insert_into_iceberg {#allow_experimental_insert_into_iceberg}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.7" }, { label: "0" }, { label: "New setting." }]
    }
  ]}
/>

允许向 Iceberg 执行 `INSERT` 查询。


## allow_experimental_join_right_table_sorting {#allow_experimental_join_right_table_sorting}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        {
          label:
            "如果设置为 true,且满足 `join_to_sort_minimum_perkey_rows` 和 `join_to_sort_maximum_table_rows` 的条件,则按键对右表进行重新排序,以提高左连接或内连接中哈希连接的性能"
        }
      ]
    }
  ]}
/>

如果设置为 true,且满足 `join_to_sort_minimum_perkey_rows` 和 `join_to_sort_maximum_table_rows` 的条件,则按键对右表进行重新排序,以提高左连接或内连接中哈希连接的性能.


## allow_experimental_kafka_offsets_storage_in_keeper {#allow_experimental_kafka_offsets_storage_in_keeper}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.8" },
        { label: "0" },
        {
          label:
            "允许使用实验性 Kafka 存储引擎,该引擎在 ClickHouse Keeper 中存储已提交的偏移量"
        }
      ]
    }
  ]}
/>

允许使用实验性功能在 ClickHouse Keeper 中存储 Kafka 相关的偏移量。启用后,可以为 Kafka 表引擎指定 ClickHouse Keeper 路径和副本名称。这样将使用新型存储引擎代替常规 Kafka 引擎,该引擎主要在 ClickHouse Keeper 中存储已提交的偏移量


## allow_experimental_kusto_dialect {#allow_experimental_kusto_dialect}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "0" }, { label: "A new setting" }]
    }
  ]}
/>

启用 Kusto 查询语言（KQL）——一种 SQL 替代方案。


## allow_experimental_materialized_postgresql_table {#allow_experimental_materialized_postgresql_table}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

允许使用 MaterializedPostgreSQL 表引擎。默认禁用,因为该功能处于实验阶段


## allow_experimental_nlp_functions {#allow_experimental_nlp_functions}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

启用自然语言处理的实验性函数。


## allow_experimental_parallel_reading_from_replicas {#allow_experimental_parallel_reading_from_replicas}

<BetaBadge />

**别名**: `enable_parallel_replicas`

<SettingsInfoBlock type='UInt64' default_value='0' />

在执行 SELECT 查询时,每个分片最多使用 `max_parallel_replicas` 指定数量的副本。读取操作将被并行化并动态协调。0 - 禁用,1 - 启用,失败时静默禁用,2 - 启用,失败时抛出异常


## allow_experimental_prql_dialect {#allow_experimental_prql_dialect}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

启用 PRQL——一种 SQL 的替代方案。


## allow_experimental_qbit_type {#allow_experimental_qbit_type}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.10" },
        { label: "0" },
        { label: "新增实验性设置" }
      ]
    }
  ]}
/>

允许创建 [QBit](../../sql-reference/data-types/qbit.md) 数据类型。


## allow_experimental_query_deduplication {#allow_experimental_query_deduplication}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

基于数据分片 UUID 的 SELECT 查询实验性数据去重


## allow_experimental_statistics {#allow_experimental_statistics}

<ExperimentalBadge />

**别名**: `allow_experimental_statistic`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "该设置已重命名。之前的名称为 `allow_experimental_statistic`。"
        }
      ]
    }
  ]}
/>

允许定义带有[统计信息](../../engines/table-engines/mergetree-family/mergetree.md/#table_engine-mergetree-creating-a-table)的列并[操作统计信息](../../engines/table-engines/mergetree-family/mergetree.md/#column-statistics)。


## allow_experimental_time_series_aggregate_functions {#allow_experimental_time_series_aggregate_functions}

<ExperimentalBadge />

**别名**: `allow_experimental_ts_to_grid_aggregate_function`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "0" },
        {
          label:
            "新增设置以启用实验性 timeSeries* 聚合函数。"
        }
      ]
    }
  ]}
/>

实验性 timeSeries\* 聚合函数,用于类 Prometheus 时间序列重采样、速率和增量计算。


## allow_experimental_time_series_table {#allow_experimental_time_series_table}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.8" },
        { label: "0" },
        { label: "新增设置以允许使用 TimeSeries 表引擎" }
      ]
    }
  ]}
/>

允许创建使用 [TimeSeries](../../engines/table-engines/integrations/time-series.md) 表引擎的表。可选值：

- 0 — 禁用 [TimeSeries](../../engines/table-engines/integrations/time-series.md) 表引擎。
- 1 — 启用 [TimeSeries](../../engines/table-engines/integrations/time-series.md) 表引擎。


## allow_experimental_time_time64_type {#allow_experimental_time_time64_type}

<ExperimentalBadge />

**别名**: `enable_time_time64_type`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "0" },
        {
          label:
            "新增设置。允许使用实验性的 Time 和 Time64 数据类型。"
        }
      ]
    }
  ]}
/>

允许创建 [Time](../../sql-reference/data-types/time.md) 和 [Time64](../../sql-reference/data-types/time64.md) 数据类型。


## allow_experimental_window_view {#allow_experimental_window_view}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

启用 WINDOW VIEW。功能尚不成熟。


## allow_experimental_ytsaurus_dictionary_source {#allow_experimental_ytsaurus_dictionary_source}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "New setting." }]
    }
  ]}
/>

    用于与 YTsaurus 集成的实验性字典源。


## allow_experimental_ytsaurus_table_engine {#allow_experimental_ytsaurus_table_engine}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

用于与 YTsaurus 集成的实验性表引擎。


## allow_experimental_ytsaurus_table_function {#allow_experimental_ytsaurus_table_function}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

用于与 YTsaurus 集成的实验性表函数。


## allow_general_join_planning {#allow_general_join_planning}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "1" },
        {
          label:
            "启用哈希连接算法时,允许使用更通用的连接规划算法。"
        }
      ]
    }
  ]}
/>

允许使用更通用的连接规划算法来处理更复杂的条件,但仅适用于哈希连接。如果未启用哈希连接,则无论此设置的值如何,都会使用常规连接规划算法。


## allow_get_client_http_header {#allow_get_client_http_header}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        { label: "引入新函数。" }
      ]
    }
  ]}
/>

允许使用 `getClientHTTPHeader` 函数获取当前 HTTP 请求头的值。出于安全原因,此功能默认未启用,因为某些请求头(如 `Cookie`)可能包含敏感信息。请注意,`X-ClickHouse-*` 和 `Authentication` 请求头始终受限,无法通过此函数获取。


## allow_hyperscan {#allow_hyperscan}

<SettingsInfoBlock type='Bool' default_value='1' />

允许使用 Hyperscan 库的函数。禁用此选项可避免潜在的长编译时间和过度的资源占用。


## allow_introspection_functions {#allow_introspection_functions}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用用于查询性能分析的[内省函数](../../sql-reference/functions/introspection.md)。

可选值:

- 1 — 启用内省函数。
- 0 — 禁用内省函数。

**另请参阅**

- [采样查询分析器](../../operations/optimizing-performance/sampling-query-profiler.md)
- 系统表 [trace_log](/operations/system-tables/trace_log)


## allow_materialized_view_with_bad_select {#allow_materialized_view_with_bad_select}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.4" },
        { label: "0" },
        {
          label:
            "不允许创建引用不存在的列或表的物化视图"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.9" },
        { label: "1" },
        {
          label:
            "支持(但尚未启用)CREATE MATERIALIZED VIEW 中更严格的验证"
        }
      ]
    }
  ]}
/>

允许使用引用不存在的表或列的 SELECT 查询来创建物化视图(CREATE MATERIALIZED VIEW)。该查询仍必须符合语法规范。不适用于可刷新物化视图。如果物化视图的架构需要从 SELECT 查询中推断(即 CREATE 语句中没有列列表且没有 TO 表),则不适用。可用于在源表创建之前先创建物化视图。


## allow_named_collection_override_by_default {#allow_named_collection_override_by_default}

<SettingsInfoBlock type='Bool' default_value='1' />

默认允许覆盖命名集合字段。


## allow_non_metadata_alters {#allow_non_metadata_alters}

<SettingsInfoBlock type='Bool' default_value='1' />

允许执行不仅影响表元数据，同时也影响磁盘数据的 ALTER 操作


## allow_nonconst_timezone_arguments {#allow_nonconst_timezone_arguments}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "0" },
        {
          label:
            "允许在某些时间相关函数(如 toTimeZone()、fromUnixTimestamp*()、snowflakeToDateTime*())中使用非常量时区参数。"
        }
      ]
    }
  ]}
/>

允许在某些时间相关函数(如 toTimeZone()、fromUnixTimestamp*()、snowflakeToDateTime*())中使用非常量时区参数。
此设置仅出于兼容性原因而存在。在 ClickHouse 中,时区是数据类型的属性,同时也是列的属性。
启用此设置会产生一种错误的印象,即同一列中的不同值可以具有不同的时区。
因此,请勿启用此设置。


## allow_nondeterministic_mutations {#allow_nondeterministic_mutations}

<SettingsInfoBlock type='Bool' default_value='0' />

用户级设置,允许复制表的变更操作使用非确定性函数,例如 `dictGet`。

由于字典等资源可能在各节点间不同步,默认情况下禁止在复制表上执行从字典中提取值的变更操作。启用此设置将允许该行为,但用户需自行确保所使用的数据在所有节点间保持同步。

**示例**

```xml
<profiles>
    <default>
        <allow_nondeterministic_mutations>1</allow_nondeterministic_mutations>

        <!-- ... -->
    </default>

    <!-- ... -->

</profiles>
```


## allow_nondeterministic_optimize_skip_unused_shards {#allow_nondeterministic_optimize_skip_unused_shards}

<SettingsInfoBlock type='Bool' default_value='0' />

允许在分片键中使用非确定性函数(如 `rand` 或 `dictGet`,由于后者在更新时存在一些限制)。

可能的值:

- 0 — 不允许。
- 1 — 允许。


## allow_not_comparable_types_in_comparison_functions {#allow_not_comparable_types_in_comparison_functions}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "0" },
        {
          label:
            "默认情况下不允许在比较函数中使用不可比较类型"
        }
      ]
    }
  ]}
/>

允许或限制在比较函数 `equal/less/greater/etc` 中使用不可比较类型(如 JSON/AggregateFunction)。


## allow_not_comparable_types_in_order_by {#allow_not_comparable_types_in_order_by}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "0" },
        { label: "默认不允许在 ORDER BY 中使用不可比较类型" }
      ]
    }
  ]}
/>

允许或限制在 ORDER BY 键中使用不可比较类型(如 JSON/AggregateFunction)。


## allow_prefetched_read_pool_for_local_filesystem {#allow_prefetched_read_pool_for_local_filesystem}

<SettingsInfoBlock type='Bool' default_value='0' />

当所有数据分区都位于本地文件系统时,优先使用预取线程池


## allow_prefetched_read_pool_for_remote_filesystem {#allow_prefetched_read_pool_for_remote_filesystem}

<SettingsInfoBlock type='Bool' default_value='1' />

当所有数据分区都位于远程文件系统时,优先使用预取线程池


## allow_push_predicate_ast_for_distributed_subqueries {#allow_push_predicate_ast_for_distributed_subqueries}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "1" }, { label: "新增设置" }]
    }
  ]}
/>

允许在启用分析器的分布式子查询中进行 AST 级别的谓词下推


## allow_push_predicate_when_subquery_contains_with {#allow_push_predicate_when_subquery_contains_with}

<SettingsInfoBlock type='Bool' default_value='1' />

允许在子查询包含 WITH 子句时进行谓词下推


## allow_reorder_prewhere_conditions {#allow_reorder_prewhere_conditions}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "1" }, { label: "新增设置" }]
    }
  ]}
/>

将条件从 WHERE 移动到 PREWHERE 时,允许重新排序以优化过滤性能


## allow_settings_after_format_in_insert {#allow_settings_after_format_in_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.4" },
        { label: "0" },
        {
          label:
            "不允许在 INSERT 查询的 FORMAT 之后使用 SETTINGS,因为 ClickHouse 会将 SETTINGS 解释为数据值,容易产生误导"
        }
      ]
    }
  ]}
/>

控制是否允许在 `INSERT` 查询中的 `FORMAT` 之后使用 `SETTINGS`。不建议使用此设置,因为这可能导致 `SETTINGS` 的部分内容被误解释为数据值。

示例:

```sql
INSERT INTO FUNCTION null('foo String') SETTINGS max_threads=1 VALUES ('bar');
```

但以下查询只有在启用 `allow_settings_after_format_in_insert` 时才能正常工作:

```sql
SET allow_settings_after_format_in_insert=1;
INSERT INTO FUNCTION null('foo String') VALUES ('bar') SETTINGS max_threads=1;
```

可选值:

- 0 — 禁止。
- 1 — 允许。

:::note
仅当您的使用场景依赖旧语法时,才应使用此设置以保持向后兼容性。
:::


## allow_simdjson {#allow_simdjson}

<SettingsInfoBlock type='Bool' default_value='1' />

当 AVX2 指令集可用时,允许在 'JSON\*' 函数中使用 simdjson 库。禁用时将使用 rapidjson 库。


## allow_special_serialization_kinds_in_output_formats {#allow_special_serialization_kinds_in_output_formats}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1" },
        {
          label:
            "在部分输出格式中启用 Sparse/Replicated 等特殊列表示形式的直接输出"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.10" },
        { label: "0" },
        {
          label:
            "新增设置,允许直接输出 Sparse/Replicated 等特殊列表示形式,无需转换为完整列"
        }
      ]
    }
  ]}
/>

允许直接输出具有特殊序列化类型(如 Sparse 和 Replicated)的列,无需转换为完整列表示形式。
这有助于在格式化过程中避免不必要的数据复制。


## allow_statistics_optimize {#allow_statistics_optimize}

<ExperimentalBadge />

**别名**: `allow_statistic_optimize`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "此设置已重命名。原名称为 `allow_statistic_optimize`。"
        }
      ]
    }
  ]}
/>

允许使用统计信息优化查询


## allow_suspicious_codecs {#allow_suspicious_codecs}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "20.5" },
        { label: "0" },
        { label: "不允许指定无意义的压缩编解码器" }
      ]
    }
  ]}
/>

如果设置为 true,则允许指定无意义的压缩编解码器。


## allow_suspicious_fixed_string_types {#allow_suspicious_fixed_string_types}

<SettingsInfoBlock type='Bool' default_value='0' />

在 CREATE TABLE 语句中允许创建 FixedString(n) 类型的列,其中 n > 256。长度 >= 256 的 FixedString 是可疑的,很可能表示使用不当


## allow_suspicious_indices {#allow_suspicious_indices}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "0" },
        { label: "如果为 true,则允许使用相同表达式定义索引" }
      ]
    }
  ]}
/>

拒绝使用相同表达式定义的主索引/二级索引和排序键


## allow_suspicious_low_cardinality_types {#allow_suspicious_low_cardinality_types}

<SettingsInfoBlock type='Bool' default_value='0' />

允许或限制对固定大小为 8 字节或更小的数据类型使用 [LowCardinality](../../sql-reference/data-types/lowcardinality.md):数值数据类型和 `FixedString(8_bytes_or_less)`。

对于小的固定值,使用 `LowCardinality` 通常效率不高,因为 ClickHouse 会为每一行存储一个数值索引。因此:

- 磁盘空间使用量可能会增加。
- 内存消耗可能会更高,具体取决于字典大小。
- 由于额外的编码/解码操作,某些函数的运行速度可能会变慢。

由于上述所有原因,[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 引擎表中的合并时间可能会增加。

可能的值:

- 1 — 不限制使用 `LowCardinality`。
- 0 — 限制使用 `LowCardinality`。


## allow_suspicious_primary_key {#allow_suspicious_primary_key}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        {
          label:
            "禁止 MergeTree 使用可疑的 PRIMARY KEY/ORDER BY(例如 SimpleAggregateFunction)"
        }
      ]
    }
  ]}
/>

允许 MergeTree 使用可疑的 `PRIMARY KEY`/`ORDER BY`(例如 SimpleAggregateFunction)。


## allow_suspicious_ttl_expressions {#allow_suspicious_ttl_expressions}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.12" },
        { label: "0" },
        {
          label:
            "这是一个新设置,在之前的版本中,其行为等同于允许。"
        }
      ]
    }
  ]}
/>

拒绝不依赖于表中任何列的 TTL 表达式。这通常表示用户配置错误。


## allow_suspicious_types_in_group_by {#allow_suspicious_types_in_group_by}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "0" },
        { label: "默认情况下不允许在 GROUP BY 中使用 Variant/Dynamic 类型" }
      ]
    }
  ]}
/>

允许或限制在 GROUP BY 键中使用 [Variant](../../sql-reference/data-types/variant.md) 和 [Dynamic](../../sql-reference/data-types/dynamic.md) 类型。


## allow_suspicious_types_in_order_by {#allow_suspicious_types_in_order_by}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "0" },
        { label: "默认情况下不允许在 ORDER BY 中使用 Variant/Dynamic 类型" }
      ]
    }
  ]}
/>

允许或限制在 ORDER BY 子句中使用 [Variant](../../sql-reference/data-types/variant.md) 和 [Dynamic](../../sql-reference/data-types/dynamic.md) 类型。


## allow_suspicious_variant_types {#allow_suspicious_variant_types}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "0" },
        {
          label:
            "默认情况下不允许创建包含可疑变体的 Variant 类型"
        }
      ]
    }
  ]}
/>

在 CREATE TABLE 语句中允许指定包含相似变体类型的 Variant 类型(例如,不同的数值类型或日期类型)。启用此设置可能会在处理相似类型的值时引入歧义。


## allow_unrestricted_reads_from_keeper {#allow_unrestricted_reads_from_keeper}

<SettingsInfoBlock type='Bool' default_value='0' />

允许从 system.zookeeper 表进行无限制读取(无路径条件限制),这可能很方便,但对 ZooKeeper 不安全


## alter_move_to_space_execute_async {#alter_move_to_space_execute_async}

<SettingsInfoBlock type='Bool' default_value='0' />

异步执行 ALTER TABLE MOVE ... TO [DISK|VOLUME] 操作


## alter_partition_verbose_result {#alter_partition_verbose_result}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用显示分区和数据部分操作成功应用后的相关信息。
适用于 [ATTACH PARTITION|PART](/sql-reference/statements/alter/partition#attach-partitionpart) 和 [FREEZE PARTITION](/sql-reference/statements/alter/partition#freeze-partition)。

可能的值:

- 0 — 禁用详细输出。
- 1 — 启用详细输出。

**示例**

```sql
CREATE TABLE test(a Int64, d Date, s String) ENGINE = MergeTree PARTITION BY toYYYYMDECLARE(d) ORDER BY a;
INSERT INTO test VALUES(1, '2021-01-01', '');
INSERT INTO test VALUES(1, '2021-01-01', '');
ALTER TABLE test DETACH PARTITION ID '202101';

ALTER TABLE test ATTACH PARTITION ID '202101' SETTINGS alter_partition_verbose_result = 1;

┌─command_type─────┬─partition_id─┬─part_name────┬─old_part_name─┐
│ ATTACH PARTITION │ 202101       │ 202101_7_7_0 │ 202101_5_5_0  │
│ ATTACH PARTITION │ 202101       │ 202101_8_8_0 │ 202101_6_6_0  │
└──────────────────┴──────────────┴──────────────┴───────────────┘

ALTER TABLE test FREEZE SETTINGS alter_partition_verbose_result = 1;

┌─command_type─┬─partition_id─┬─part_name────┬─backup_name─┬─backup_path───────────────────┬─part_backup_path────────────────────────────────────────────┐
│ FREEZE ALL   │ 202101       │ 202101_7_7_0 │ 8           │ /var/lib/clickhouse/shadow/8/ │ /var/lib/clickhouse/shadow/8/data/default/test/202101_7_7_0 │
│ FREEZE ALL   │ 202101       │ 202101_8_8_0 │ 8           │ /var/lib/clickhouse/shadow/8/ │ /var/lib/clickhouse/shadow/8/data/default/test/202101_8_8_0 │
└──────────────┴──────────────┴──────────────┴─────────────┴───────────────────────────────┴─────────────────────────────────────────────────────────────┘
```


## alter_sync {#alter_sync}

**别名**: `replication_alter_partitions_sync`

<SettingsInfoBlock type='UInt64' default_value='1' />

允许设置等待副本执行 [ALTER](../../sql-reference/statements/alter/index.md)、[OPTIMIZE](../../sql-reference/statements/optimize.md) 或 [TRUNCATE](../../sql-reference/statements/truncate.md) 查询中的操作。

可能的值:

- `0` — 不等待。
- `1` — 等待本地执行完成。
- `2` — 等待所有副本执行完成。

Cloud 默认值:`1`。

:::note
`alter_sync` 仅适用于 `Replicated` 表,对非 `Replicated` 表的修改操作无效。
:::


## alter_update_mode {#alter_update_mode}

<SettingsInfoBlock type='AlterUpdateMode' default_value='heavy' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "heavy" }, { label: "新增设置" }]
    }
  ]}
/>

用于包含 `UPDATE` 命令的 `ALTER` 查询的模式。

可能的值:

- `heavy` - 执行常规 mutation。
- `lightweight` - 如果可能则执行轻量级更新,否则执行常规 mutation。
- `lightweight_force` - 如果可能则执行轻量级更新,否则抛出异常。


## analyze_index_with_space_filling_curves {#analyze_index_with_space_filling_curves}

<SettingsInfoBlock type='Bool' default_value='1' />

如果表的索引中使用了空间填充曲线,例如 `ORDER BY mortonEncode(x, y)` 或 `ORDER BY hilbertEncode(x, y)`,且查询中包含对其参数的条件约束,例如 `x >= 10 AND x <= 20 AND y >= 20 AND y <= 30`,则会使用空间填充曲线进行索引分析。


## analyzer_compatibility_allow_compound_identifiers_in_unflatten_nested {#analyzer_compatibility_allow_compound_identifiers_in_unflatten_nested}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1" }, { label: "新设置。" }]
    }
  ]}
/>

允许向嵌套结构添加复合标识符。这是一个兼容性设置,因为它会改变查询结果。禁用时,`SELECT a.b.c FROM table ARRAY JOIN a` 将无法执行,且 `SELECT a FROM table` 不会将 `a.b.c` 列包含在 `Nested a` 结果中。


## analyzer_compatibility_join_using_top_level_identifier {#analyzer_compatibility_join_using_top_level_identifier}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        { label: "强制从投影表达式中解析 JOIN USING 的标识符" }
      ]
    }
  ]}
/>

强制从投影表达式中解析 JOIN USING 的标识符(例如,在 `SELECT a + 1 AS b FROM t1 JOIN t2 USING (b)` 中,连接将按 `t1.a + 1 = t2.b` 执行,而不是 `t1.b = t2.b`)。


## any_join_distinct_right_table_keys {#any_join_distinct_right_table_keys}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "19.14" },
        { label: "0" },
        {
          label:
            "默认禁用 ANY RIGHT 和 ANY FULL JOIN 以避免不一致性"
        }
      ]
    }
  ]}
/>

在 `ANY INNER|LEFT JOIN` 操作中启用 ClickHouse 服务器的旧版行为。

:::note
仅当您的使用场景依赖于旧版 `JOIN` 行为时,才应使用此设置以保持向后兼容性。
:::

启用旧版行为时:

- `t1 ANY LEFT JOIN t2` 和 `t2 ANY RIGHT JOIN t1` 操作的结果不相等,因为 ClickHouse 使用多对一的从左到右表键映射逻辑。
- `ANY INNER JOIN` 操作的结果包含左表的所有行,与 `SEMI LEFT JOIN` 操作相同。

禁用旧版行为时:

- `t1 ANY LEFT JOIN t2` 和 `t2 ANY RIGHT JOIN t1` 操作的结果相等,因为 ClickHouse 在 `ANY RIGHT JOIN` 操作中使用一对多键映射逻辑。
- `ANY INNER JOIN` 操作的结果对于左表和右表中的每个键各包含一行。

可能的值:

- 0 — 禁用旧版行为。
- 1 — 启用旧版行为。

另请参阅:

- [JOIN 严格性](/sql-reference/statements/select/join#settings)


## apply_deleted_mask {#apply_deleted_mask}

<SettingsInfoBlock type='Bool' default_value='1' />

启用后，将过滤掉通过轻量级 DELETE 删除的行。若禁用此设置，查询仍可读取这些行。这对于调试和“撤销删除（undelete）”等场景非常有用


## apply_mutations_on_fly {#apply_mutations_on_fly}

<SettingsInfoBlock type='Bool' default_value='0' />

如果为 true,则未在数据部分中物化的变更操作(UPDATE 和 DELETE)将在执行 SELECT 查询时应用。


## apply_patch_parts {#apply_patch_parts}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

如果为 true，则在 SELECT 查询时应用补丁部分（代表轻量级更新）。


## apply_patch_parts_join_cache_buckets {#apply_patch_parts_join_cache_buckets}

<SettingsInfoBlock type='NonZeroUInt64' default_value='8' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "8" }, { label: "新设置" }]
    }
  ]}
/>

在 Join 模式下应用补丁部分的临时缓存桶数量。


## apply_settings_from_server {#apply_settings_from_server}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.2" },
        { label: "1" },
        {
          label:
            "客户端代码(例如 INSERT 输入解析和查询输出格式化)将使用与服务器相同的设置,包括服务器配置中的设置。"
        }
      ]
    }
  ]}
/>

客户端是否应接受来自服务器的设置。

此设置仅影响客户端执行的操作,特别是 INSERT 输入数据的解析和查询结果的格式化。大部分查询执行在服务器端进行,不受此设置影响。

通常应在用户配置文件中设置此项(users.xml 或类似 `ALTER USER` 的查询),而不是通过客户端设置(客户端命令行参数、`SET` 查询或 `SELECT` 查询的 `SETTINGS` 部分)。通过客户端可以将其更改为 false,但无法更改为 true(因为如果用户配置文件中设置了 `apply_settings_from_server = false`,服务器将不会发送设置)。

注意:最初(24.12 版本)存在一个服务器端设置(`send_settings_to_client`),但后来为了提高可用性,已被替换为此客户端设置。


## arrow_flight_request_descriptor_type {#arrow_flight_request_descriptor_type}

<SettingsInfoBlock type='ArrowFlightDescriptorType' default_value='path' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "path" },
        {
          label:
            "新增设置。Arrow Flight 请求使用的描述符类型:'path' 或 'command'。Dremio 需要使用 'command'。"
        }
      ]
    }
  ]}
/>

Arrow Flight 请求使用的描述符类型。'path' 将数据集名称作为路径描述符发送。'command' 将 SQL 查询作为命令描述符发送(Dremio 需要)。

可选值:

- 'path' — 使用 FlightDescriptor::Path(默认,适用于大多数 Arrow Flight 服务器)
- 'command' — 使用 FlightDescriptor::Command 配合 SELECT 查询(Dremio 需要)


## asterisk_include_alias_columns {#asterisk_include_alias_columns}

<SettingsInfoBlock type='Bool' default_value='0' />

在通配符查询（`SELECT *`）中包含 [ALIAS](../../sql-reference/statements/create/table.md/#alias) 列。

可能的值：

- 0 - 禁用
- 1 - 启用


## asterisk_include_materialized_columns {#asterisk_include_materialized_columns}

<SettingsInfoBlock type='Bool' default_value='0' />

在通配符查询（`SELECT *`）中包含 [MATERIALIZED](/sql-reference/statements/create/view#materialized-view) 列。

可选值：

- 0 - 禁用
- 1 - 启用


## async_insert {#async_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

如果为 true,INSERT 查询的数据将存储在队列中,随后在后台刷新到表中。如果 wait_for_async_insert 为 false,INSERT 查询将几乎立即处理完成,否则客户端将等待数据刷新到表中


## async_insert_busy_timeout_decrease_rate {#async_insert_busy_timeout_decrease_rate}

<SettingsInfoBlock type='Double' default_value='0.2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "0.2" },
        {
          label:
            "自适应异步插入超时时间的指数递减率"
        }
      ]
    }
  ]}
/>

自适应异步插入超时时间的指数递减率


## async_insert_busy_timeout_increase_rate {#async_insert_busy_timeout_increase_rate}

<SettingsInfoBlock type='Double' default_value='0.2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "0.2" },
        {
          label:
            "自适应异步插入超时的指数增长率"
        }
      ]
    }
  ]}
/>

自适应异步插入超时的指数增长率


## async_insert_busy_timeout_max_ms {#async_insert_busy_timeout_max_ms}

**别名**: `async_insert_busy_timeout_ms`

<SettingsInfoBlock type='Milliseconds' default_value='200' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "200" },
        {
          label:
            "异步插入超时的最小值(以毫秒为单位);async_insert_busy_timeout_ms 是 async_insert_busy_timeout_max_ms 的别名"
        }
      ]
    }
  ]}
/>

自首次数据出现后,转储每个查询所收集数据前的最长等待时间。


## async_insert_busy_timeout_min_ms {#async_insert_busy_timeout_min_ms}

<SettingsInfoBlock type='毫秒' default_value='50' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "50" },
        {
          label:
            "异步插入超时的最小值(以毫秒为单位);同时也作为初始值,后续可能会被自适应算法调整增加"
        }
      ]
    }
  ]}
/>

如果通过 async_insert_use_adaptive_busy_timeout 启用了自动调整,此参数表示自首次数据到达后,在转储每个查询所收集的数据之前需要等待的最短时间。它同时也作为自适应算法的初始值


## async_insert_deduplicate {#async_insert_deduplicate}

<SettingsInfoBlock type='Bool' default_value='0' />

对于复制表中的异步 INSERT 查询，指定是否对插入的数据块执行去重


## async_insert_max_data_size {#async_insert_max_data_size}

<SettingsInfoBlock type='UInt64' default_value='10485760' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "10485760" },
        { label: "先前的值过小。" }
      ]
    }
  ]}
/>

插入前每个查询收集的未解析数据的最大字节数


## async_insert_max_query_number {#async_insert_max_query_number}

<SettingsInfoBlock type='UInt64' default_value='450' />

执行插入操作前累积的最大插入查询数量。
仅当设置 [`async_insert_deduplicate`](#async_insert_deduplicate) 为 1 时生效。


## async_insert_poll_timeout_ms {#async_insert_poll_timeout_ms}

<SettingsInfoBlock type='Milliseconds' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "10" },
        {
          label:
            "从异步插入队列轮询数据的超时时间(以毫秒为单位)"
        }
      ]
    }
  ]}
/>

从异步插入队列轮询数据的超时时间


## async_insert_use_adaptive_busy_timeout {#async_insert_use_adaptive_busy_timeout}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        { label: "使用自适应异步插入超时" }
      ]
    }
  ]}
/>

如果设置为 true,则对异步插入使用自适应忙等超时


## async_query_sending_for_remote {#async_query_sending_for_remote}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.3" },
        { label: "1" },
        { label: "跨分片异步创建连接并发送查询" }
      ]
    }
  ]}
/>

在执行远程查询时启用异步连接创建和查询发送。

默认启用。


## async_socket_for_remote {#async_socket_for_remote}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.5" },
        { label: "1" },
        {
          label:
            "修复所有问题并再次默认启用远程查询的套接字异步读取"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "21.3" },
        { label: "0" },
        {
          label:
            "由于某些问题而关闭远程查询的套接字异步读取"
        }
      ]
    }
  ]}
/>

在执行远程查询时启用套接字异步读取。

默认启用。


## azure_allow_parallel_part_upload {#azure_allow_parallel_part_upload}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "true" },
        { label: "使用多线程进行 Azure 分块上传。" }
      ]
    }
  ]}
/>

使用多线程进行 Azure 分块上传。


## azure_check_objects_after_upload {#azure_check_objects_after_upload}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "0" },
        {
          label:
            "检查 Azure Blob 存储中的每个已上传对象，以确保上传成功"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.10" },
        { label: "0" },
        {
          label:
            "检查 Azure Blob 存储中的每个已上传对象，以确保上传成功"
        }
      ]
    }
  ]}
/>

检查 Azure Blob 存储中的每个已上传对象，以确保上传成功


## azure_connect_timeout_ms {#azure_connect_timeout_ms}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1000" }, { label: "新设置" }]
    }
  ]}
/>

Azure 磁盘主机的连接超时。


## azure_create_new_file_on_insert {#azure_create_new_file_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在 Azure 引擎表中每次插入数据时创建新文件的功能


## azure_ignore_file_doesnt_exist {#azure_ignore_file_doesnt_exist}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "允许在 AzureBlobStorage 表引擎中,当请求的文件不存在时返回 0 行,而不是抛出异常"
        }
      ]
    }
  ]}
/>

读取特定键时,如果文件不存在则忽略其缺失。

可能的值:

- 1 — `SELECT` 返回空结果。
- 0 — `SELECT` 抛出异常。


## azure_list_object_keys_size {#azure_list_object_keys_size}

<SettingsInfoBlock type='UInt64' default_value='1000' />

ListObject 请求批量返回的最大文件数


## azure_max_blocks_in_multipart_upload {#azure_max_blocks_in_multipart_upload}

<SettingsInfoBlock type='UInt64' default_value='50000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.5" },
        { label: "50000" },
        { label: "Azure 分段上传中的最大块数量。" }
      ]
    }
  ]}
/>

Azure 分段上传中的最大块数量。


## azure_max_get_burst {#azure_max_get_burst}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

在达到每秒请求限制之前可同时发出的最大请求数。默认值 (0) 等于 `azure_max_get_rps`


## azure_max_get_rps {#azure_max_get_rps}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

Azure GET 请求每秒速率限制,超过此限制后将进行节流。零表示无限制。


## azure_max_inflight_parts_for_one_file {#azure_max_inflight_parts_for_one_file}

<SettingsInfoBlock type='UInt64' default_value='20' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "20" },
        {
          label:
            "分段上传请求中并发加载分段的最大数量。0 表示不限制。"
        }
      ]
    }
  ]}
/>

分段上传请求中并发加载分段的最大数量。0 表示不限制。


## azure_max_put_burst {#azure_max_put_burst}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

在达到每秒请求限制之前可同时发出的最大请求数。默认值 (0) 等于 `azure_max_put_rps`


## azure_max_put_rps {#azure_max_put_rps}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

限制 Azure PUT 请求的每秒速率，超过此限制将触发节流。零表示无限制。


## azure_max_redirects {#azure_max_redirects}

<SettingsInfoBlock type='UInt64' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "10" }, { label: "New setting" }]
    }
  ]}
/>

允许的 Azure 重定向跳数上限。


## azure_max_single_part_copy_size {#azure_max_single_part_copy_size}

<SettingsInfoBlock type='UInt64' default_value='268435456' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "268435456" },
        {
          label:
            "使用单部分复制到 Azure Blob 存储的对象的最大大小。"
        }
      ]
    }
  ]}
/>

使用单部分复制到 Azure Blob 存储的对象的最大大小。


## azure_max_single_part_upload_size {#azure_max_single_part_upload_size}

<SettingsInfoBlock type='UInt64' default_value='33554432' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "33554432" },
        { label: "与 S3 对齐" }
      ]
    }
  ]}
/>

使用单部分上传到 Azure Blob 存储的对象最大大小。


## azure_max_single_read_retries {#azure_max_single_read_retries}

<SettingsInfoBlock type='UInt64' default_value='4' />

单次 Azure Blob 存储读取的最大重试次数。


## azure_max_unexpected_write_error_retries {#azure_max_unexpected_write_error_retries}

<SettingsInfoBlock type='UInt64' default_value='4' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "4" },
        {
          label:
            "Azure Blob 存储写入时发生意外错误的最大重试次数"
        }
      ]
    }
  ]}
/>

Azure Blob 存储写入时发生意外错误的最大重试次数


## azure_max_upload_part_size {#azure_max_upload_part_size}

<SettingsInfoBlock type='UInt64' default_value='5368709120' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "5368709120" },
        {
          label:
            "向 Azure Blob 存储进行分块上传时，每个分块的最大大小。"
        }
      ]
    }
  ]}
/>

向 Azure Blob 存储进行分块上传时，每个分块的最大大小。


## azure_min_upload_part_size {#azure_min_upload_part_size}

<SettingsInfoBlock type='UInt64' default_value='16777216' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "16777216" },
        {
          label:
            "向 Azure Blob 存储进行分块上传时每个分块的最小大小。"
        }
      ]
    }
  ]}
/>

向 Azure Blob 存储进行分块上传时每个分块的最小大小。


## azure_request_timeout_ms {#azure_request_timeout_ms}

<SettingsInfoBlock type='UInt64' default_value='30000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "30000" }, { label: "新设置" }]
    }
  ]}
/>

与 Azure 之间发送和接收数据的空闲超时时间。如果单次 TCP 读取或写入调用的阻塞时间超过此值,则操作失败。


## azure_sdk_max_retries {#azure_sdk_max_retries}

<SettingsInfoBlock type='UInt64' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "10" },
        { label: "Azure SDK 的最大重试次数" }
      ]
    }
  ]}
/>

Azure SDK 的最大重试次数


## azure_sdk_retry_initial_backoff_ms {#azure_sdk_retry_initial_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "10" },
        { label: "Azure SDK 重试之间的最小退避时间" }
      ]
    }
  ]}
/>

Azure SDK 重试之间的最小退避时间


## azure_sdk_retry_max_backoff_ms {#azure_sdk_retry_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "1000" },
        { label: "Azure SDK 重试之间的最大退避时间" }
      ]
    }
  ]}
/>

Azure SDK 重试之间的最大退避时间


## azure_skip_empty_files {#azure_skip_empty_files}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        { label: "允许在 Azure 表引擎中跳过空文件" }
      ]
    }
  ]}
/>

启用或禁用在 Azure 引擎中跳过空文件。

可能的值：

- 0 — 如果空文件与请求的格式不兼容，`SELECT` 将抛出异常。
- 1 — 对于空文件，`SELECT` 返回空结果。


## azure_strict_upload_part_size {#azure_strict_upload_part_size}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        {
          label:
            "多部分上传到 Azure Blob 存储时每个分块的精确大小。"
        }
      ]
    }
  ]}
/>

多部分上传到 Azure Blob 存储时每个分块的精确大小。


## azure_throw_on_zero_files_match {#azure_throw_on_zero_files_match}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "当 AzureBlobStorage 引擎中的 ListObjects 请求无法匹配任何文件时,允许抛出错误而非返回空查询结果"
        }
      ]
    }
  ]}
/>

根据 glob 扩展规则匹配到零个文件时抛出错误。

可能的值:

- 1 — `SELECT` 抛出异常。
- 0 — `SELECT` 返回空结果。


## azure_truncate_on_insert {#azure_truncate_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在 Azure 引擎表中插入数据前的截断操作。


## azure_upload_part_size_multiply_factor {#azure_upload_part_size_multiply_factor}

<SettingsInfoBlock type='UInt64' default_value='2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "2" },
        {
          label:
            "每当单次写入 Azure Blob 存储上传 azure_multiply_parts_count_threshold 个分块后,将 azure_min_upload_part_size 乘以此系数。"
        }
      ]
    }
  ]}
/>

每当单次写入 Azure Blob 存储上传 azure_multiply_parts_count_threshold 个分块后,将 azure_min_upload_part_size 乘以此系数。


## azure_upload_part_size_multiply_parts_count_threshold {#azure_upload_part_size_multiply_parts_count_threshold}

<SettingsInfoBlock type='UInt64' default_value='500' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "500" },
        {
          label:
            "每当上传到 Azure Blob 存储的分片数量达到此值时,azure_min_upload_part_size 会乘以 azure_upload_part_size_multiply_factor。"
        }
      ]
    }
  ]}
/>

每当上传到 Azure Blob 存储的分片数量达到此值时,azure_min_upload_part_size 会乘以 azure_upload_part_size_multiply_factor。


## azure_use_adaptive_timeouts {#azure_use_adaptive_timeouts}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

当设置为 `true` 时,所有 Azure 请求的前两次尝试将使用较低的发送和接收超时时间。
当设置为 `false` 时,所有尝试将使用相同的超时时间。


## backup_restore_batch_size_for_keeper_multi {#backup_restore_batch_size_for_keeper_multi}

<SettingsInfoBlock type='UInt64' default_value='1000' />

备份或恢复期间向 [Zoo]Keeper 发送批量请求的最大批次大小


## backup_restore_batch_size_for_keeper_multiread {#backup_restore_batch_size_for_keeper_multiread}

<SettingsInfoBlock type='UInt64' default_value='10000' />

备份或恢复期间向 [Zoo]Keeper 发送 multiread 请求的最大批次大小


## backup_restore_failure_after_host_disconnected_for_seconds {#backup_restore_failure_after_host_disconnected_for_seconds}

<SettingsInfoBlock type='UInt64' default_value='3600' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "3600" }, { label: "新增设置。" }]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "3600" }, { label: "新增设置。" }]
    }
  ]}
/>

如果在执行 BACKUP ON CLUSTER 或 RESTORE ON CLUSTER 操作期间,某个主机在此时间段内未能在 ZooKeeper 中重新创建其临时 'alive' 节点,则整个备份或恢复操作将被视为失败。
此值应大于主机在发生故障后重新连接到 ZooKeeper 所需的任何合理时间。
设置为零表示不限制。


## backup_restore_finish_timeout_after_error_sec {#backup_restore_finish_timeout_after_error_sec}

<SettingsInfoBlock type='UInt64' default_value='180' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "180" }, { label: "新设置。" }]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "180" }, { label: "新设置。" }]
    }
  ]}
/>

发起者等待其他主机响应 'error' 节点并停止当前 BACKUP ON CLUSTER 或 RESTORE ON CLUSTER 操作的超时时长。


## backup_restore_keeper_fault_injection_probability {#backup_restore_keeper_fault_injection_probability}

<SettingsInfoBlock type='Float' default_value='0' />

备份或恢复期间 Keeper 请求失败的近似概率。有效值区间为 [0.0f, 1.0f]


## backup_restore_keeper_fault_injection_seed {#backup_restore_keeper_fault_injection_seed}

<SettingsInfoBlock type='UInt64' default_value='0' />

0 - 随机种子,其他值 - 使用该设置值


## backup_restore_keeper_max_retries {#backup_restore_keeper_max_retries}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "1000" },
        {
          label:
            "该值应足够大,以确保整个 BACKUP 或 RESTORE 操作不会因执行过程中出现临时的 [Zoo]Keeper 故障而失败。"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.10" },
        { label: "1000" },
        {
          label:
            "该值应足够大,以确保整个 BACKUP 或 RESTORE 操作不会因执行过程中出现临时的 [Zoo]Keeper 故障而失败。"
        }
      ]
    }
  ]}
/>

BACKUP 或 RESTORE 操作执行过程中 [Zoo]Keeper 操作的最大重试次数。
该值应足够大,以确保整个操作不会因临时的 [Zoo]Keeper 故障而失败。


## backup_restore_keeper_max_retries_while_handling_error {#backup_restore_keeper_max_retries_while_handling_error}

<SettingsInfoBlock type='UInt64' default_value='20' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "20" }, { label: "新增设置。" }]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "20" }, { label: "新增设置。" }]
    }
  ]}
/>

在处理 BACKUP ON CLUSTER 或 RESTORE ON CLUSTER 操作的错误时，[Zoo]Keeper 操作的最大重试次数。


## backup_restore_keeper_max_retries_while_initializing {#backup_restore_keeper_max_retries_while_initializing}

<SettingsInfoBlock type='UInt64' default_value='20' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "20" }, { label: "新增设置。" }]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "20" }, { label: "新增设置。" }]
    }
  ]}
/>

在 BACKUP ON CLUSTER 或 RESTORE ON CLUSTER 操作初始化期间,[Zoo]Keeper 操作的最大重试次数。


## backup_restore_keeper_retry_initial_backoff_ms {#backup_restore_keeper_retry_initial_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='100' />

备份或恢复期间 [Zoo]Keeper 操作的初始退避超时


## backup_restore_keeper_retry_max_backoff_ms {#backup_restore_keeper_retry_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='5000' />

备份或恢复期间 [Zoo]Keeper 操作的最大退避超时


## backup_restore_keeper_value_max_size {#backup_restore_keeper_value_max_size}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

备份期间 [Zoo]Keeper 节点数据的最大大小


## backup_restore_s3_retry_attempts {#backup_restore_s3_retry_attempts}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "1000" },
        {
          label:
            "Aws::Client::RetryStrategy 的配置项,Aws::Client 会自动执行重试,0 表示不重试。仅适用于备份/恢复操作。"
        }
      ]
    }
  ]}
/>

Aws::Client::RetryStrategy 的配置项,Aws::Client 会自动执行重试,0 表示不重试。仅适用于备份/恢复操作。


## backup_restore_s3_retry_initial_backoff_ms {#backup_restore_s3_retry_initial_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='25' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "25" }, { label: "新增设置" }]
    }
  ]}
/>

    备份和恢复过程中首次重试前的初始退避延迟时间(毫秒)。后续每次重试的延迟时间将呈指数级增长,直至达到 `backup_restore_s3_retry_max_backoff_ms` 所指定的最大值


## backup_restore_s3_retry_jitter_factor {#backup_restore_s3_retry_jitter_factor}

<SettingsInfoBlock type='Float' default_value='0.1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0.1" }, { label: "新设置" }]
    }
  ]}
/>

    在备份和恢复操作期间,应用于 Aws::Client::RetryStrategy 中重试退避延迟的抖动因子。计算得出的退避延迟将乘以 [1.0, 1.0 + jitter] 范围内的随机因子,最大不超过 `backup_restore_s3_retry_max_backoff_ms`。取值必须在 [0.0, 1.0] 区间内


## backup_restore_s3_retry_max_backoff_ms {#backup_restore_s3_retry_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='5000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "5000" }, { label: "新设置" }]
    }
  ]}
/>

    备份和恢复操作期间重试的最大延迟(毫秒)。


## backup_slow_all_threads_after_retryable_s3_error {#backup_slow_all_threads_after_retryable_s3_error}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新增设置" }]
    },
    {
      id: "row-2",
      items: [{ label: "25.6" }, { label: "0" }, { label: "新增设置" }]
    },
    {
      id: "row-3",
      items: [
        { label: "25.10" },
        { label: "0" },
        { label: "默认禁用该设置" }
      ]
    }
  ]}
/>

当设置为 `true` 时,一旦任意单个 S3 请求遇到可重试的 S3 错误(如 'Slow Down'),所有向同一备份端点执行 S3 请求的线程都将被降速。
当设置为 `false` 时,每个线程独立处理 S3 请求退避,互不影响。


## cache_warmer_threads {#cache_warmer_threads}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='4' />

仅在 ClickHouse Cloud 中生效。当启用 [cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch) 时,用于预测性下载新数据分片到文件缓存的后台线程数量。设置为 0 可禁用此功能。


## calculate_text_stack_trace {#calculate_text_stack_trace}

<SettingsInfoBlock type='Bool' default_value='1' />

在查询执行期间发生异常时计算文本堆栈跟踪。此为默认设置。该功能需要进行符号查找,当执行大量错误查询时可能会降低模糊测试的速度。正常情况下,不应禁用此选项。


## cancel_http_readonly_queries_on_client_close {#cancel_http_readonly_queries_on_client_close}

<SettingsInfoBlock type='Bool' default_value='0' />

当客户端关闭连接而未等待响应时,取消 HTTP 只读查询(例如 SELECT)。

Cloud 默认值:`0`。


## cast_ipv4_ipv6_default_on_conversion_error {#cast_ipv4_ipv6_default_on_conversion_error}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.3" },
        { label: "0" },
        {
          label:
            "使 cast(value, 'IPv4') 和 cast(value, 'IPv6') 函数的行为与 toIPv4 和 toIPv6 函数保持一致"
        }
      ]
    }
  ]}
/>

将 CAST 运算符转换为 IPv4 类型、将 CAST 运算符转换为 IPv6 类型、toIPv4 函数、toIPv6 函数在转换错误时将返回默认值,而不是抛出异常。


## cast_keep_nullable {#cast_keep_nullable}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在 [CAST](/sql-reference/functions/type-conversion-functions#cast) 操作中保留 `Nullable` 数据类型。

当启用此设置且 `CAST` 函数的参数为 `Nullable` 类型时,结果也会转换为 `Nullable` 类型。当禁用此设置时,结果将始终为指定的目标类型。

可能的值:

- 0 — `CAST` 结果为指定的目标类型。
- 1 — 如果参数类型为 `Nullable`,则 `CAST` 结果转换为 `Nullable(DestinationDataType)`。

**示例**

以下查询的结果为目标数据类型:

```sql
SET cast_keep_nullable = 0;
SELECT CAST(toNullable(toInt32(0)) AS Int32) as x, toTypeName(x);
```

结果:

```text
┌─x─┬─toTypeName(CAST(toNullable(toInt32(0)), 'Int32'))─┐
│ 0 │ Int32                                             │
└───┴───────────────────────────────────────────────────┘
```

以下查询的结果在目标数据类型上应用了 `Nullable` 修饰:

```sql
SET cast_keep_nullable = 1;
SELECT CAST(toNullable(toInt32(0)) AS Int32) as x, toTypeName(x);
```

结果:

```text
┌─x─┬─toTypeName(CAST(toNullable(toInt32(0)), 'Int32'))─┐
│ 0 │ Nullable(Int32)                                   │
└───┴───────────────────────────────────────────────────┘
```

**另请参阅**

- [CAST](/sql-reference/functions/type-conversion-functions#cast) 函数


## cast_string_to_date_time_mode {#cast_string_to_date_time_mode}

<SettingsInfoBlock type='DateTimeInputFormat' default_value='basic' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "basic" },
        {
          label:
            "允许在 String 到 DateTime 的类型转换中使用不同的 DateTime 解析模式"
        }
      ]
    }
  ]}
/>

允许在从 String 类型转换时选择日期和时间文本表示形式的解析器。

可能的值：

- `'best_effort'` — 启用扩展解析。

  ClickHouse 可以解析基本的 `YYYY-MM-DD HH:MM:SS` 格式以及所有 [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601) 日期和时间格式。例如：`'2018-06-08T01:02:03.000Z'`。

- `'best_effort_us'` — 类似于 `best_effort`（差异请参见 [parseDateTimeBestEffortUS](../../sql-reference/functions/type-conversion-functions#parsedatetimebesteffortus)）

- `'basic'` — 使用基本解析器。

  ClickHouse 只能解析基本的 `YYYY-MM-DD HH:MM:SS` 或 `YYYY-MM-DD` 格式。例如：`2019-08-20 10:18:56` 或 `2019-08-20`。

另请参阅：

- [DateTime 数据类型](../../sql-reference/data-types/datetime.md)
- [日期和时间处理函数](../../sql-reference/functions/date-time-functions.md)


## cast_string_to_dynamic_use_inference {#cast_string_to_dynamic_use_inference}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.5" },
        { label: "0" },
        {
          label:
            "添加设置以允许通过解析将 String 转换为 Dynamic"
        }
      ]
    }
  ]}
/>

在 String 到 Dynamic 转换过程中使用类型推断


## cast_string_to_variant_use_inference {#cast_string_to_variant_use_inference}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.4" },
        { label: "1" },
        {
          label:
            "新增设置,用于启用/禁用 String 到 Variant 的 CAST 转换中的类型推断"
        }
      ]
    }
  ]}
/>

在 String 到 Variant 转换过程中使用类型推断。


## check_query_single_value_result {#check_query_single_value_result}

<SettingsInfoBlock type='Bool' default_value='1' />

定义 `MergeTree` 系列引擎的 [CHECK TABLE](/sql-reference/statements/check-table) 查询结果的详细级别。

可能的值:

- 0 — 查询显示表中每个数据部分的检查状态。
- 1 — 查询显示表的整体检查状态。


## check_referential_table_dependencies {#check_referential_table_dependencies}

<SettingsInfoBlock type='Bool' default_value='0' />

检查 DDL 查询(例如 DROP TABLE 或 RENAME)是否会破坏引用依赖关系


## check_table_dependencies {#check_table_dependencies}

<SettingsInfoBlock type='Bool' default_value='1' />

检查 DDL 查询(例如 DROP TABLE 或 RENAME)是否会破坏依赖关系


## checksum_on_read {#checksum_on_read}

<SettingsInfoBlock type='Bool' default_value='1' />

在读取时验证校验和。默认启用该设置,且在生产环境中应始终保持启用。禁用此设置不会带来任何收益,仅可用于实验和基准测试。该设置仅适用于 MergeTree 系列表。对于其他表引擎以及通过网络接收数据时,始终会验证校验和。


## cloud_mode {#cloud_mode}

<SettingsInfoBlock type='Bool' default_value='0' />

云模式


## cloud_mode_database_engine {#cloud_mode_database_engine}

<SettingsInfoBlock type='UInt64' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "1" },
        { label: "ClickHouse Cloud 设置" }
      ]
    }
  ]}
/>

Cloud 中允许的数据库引擎。1 - 将 DDL 重写为使用 Replicated 数据库,2 - 将 DDL 重写为使用 Shared 数据库


## cloud_mode_engine {#cloud_mode_engine}

<SettingsInfoBlock type='UInt64' default_value='1' />

云模式下允许使用的引擎系列。

- 0 - 允许所有引擎
- 1 - 将 DDL 语句重写为使用 \*ReplicatedMergeTree
- 2 - 将 DDL 语句重写为使用 SharedMergeTree
- 3 - 将 DDL 语句重写为使用 SharedMergeTree,除非显式指定了远程磁盘

使用 UInt64 类型以最小化公开部分


## cluster_for_parallel_replicas {#cluster_for_parallel_replicas}

<BetaBadge />

当前服务器所在分片对应的集群


## cluster_function_process_archive_on_multiple_nodes {#cluster_function_process_archive_on_multiple_nodes}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.7" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

如果设置为 `true`,可提升集群函数处理归档文件的性能。如果在早期版本中使用了带归档文件的集群函数,为保持兼容性并避免升级到 25.7+ 版本时出现错误,应将其设置为 `false`。


## cluster_table_function_buckets_batch_size {#cluster_table_function_buckets_batch_size}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "新设置。" }]
    }
  ]}
/>

定义在使用 `bucket` 分割粒度的集群表函数中进行分布式任务处理时的批次近似大小(以字节为单位)。系统会累积数据,直到至少达到此数量。实际大小可能会略大,以便与数据边界对齐。


## cluster_table_function_split_granularity {#cluster_table_function_split_granularity}

<SettingsInfoBlock type='ObjectStorageGranularityLevel' default_value='file' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "file" }, { label: "新增设置。" }]
    }
  ]}
/>

控制执行 CLUSTER TABLE FUNCTION 时数据拆分为任务的方式。

此设置定义集群中工作分配的粒度级别:

- `file` — 每个任务处理一个完整文件。
- `bucket` — 按文件内的内部数据块创建任务(例如 Parquet 行组)。

处理少量大文件时,选择更细的粒度(如 `bucket`)可以提高并行度。
例如,如果 Parquet 文件包含多个行组,启用 `bucket` 粒度可使不同工作节点独立处理每个行组。


## collect_hash_table_stats_during_aggregation {#collect_hash_table_stats_during_aggregation}

<SettingsInfoBlock type='Bool' default_value='1' />

启用收集哈希表统计信息以优化内存分配


## collect_hash_table_stats_during_joins {#collect_hash_table_stats_during_joins}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.7" }, { label: "1" }, { label: "新增设置。" }]
    }
  ]}
/>

启用收集哈希表统计信息以优化内存分配


## compatibility {#compatibility}

`compatibility` 设置使 ClickHouse 使用先前版本的默认设置,其中先前版本通过该设置的值指定。

如果某些设置已被设为非默认值,则这些设置将被保留(只有未被修改的设置才会受到 `compatibility` 设置的影响)。

此设置接受 ClickHouse 版本号字符串,例如 `22.3`、`22.8`。空值表示禁用此设置。

默认禁用。

:::note
在 ClickHouse Cloud 中,服务级别的默认兼容性设置必须由 ClickHouse Cloud 支持团队设置。请[提交工单](https://clickhouse.cloud/support)进行设置。
但是,可以使用标准的 ClickHouse 设置机制在用户、角色、配置文件、查询或会话级别覆盖兼容性设置,例如在会话中使用 `SET compatibility = '22.3'`,或在查询中使用 `SETTINGS compatibility = '22.3'`。
:::


## compatibility_ignore_auto_increment_in_create_table {#compatibility_ignore_auto_increment_in_create_table}

<SettingsInfoBlock type='Bool' default_value='0' />

若设置为 true，则在列声明中忽略 AUTO_INCREMENT 关键字，否则返回错误。此设置可简化从 MySQL 的迁移过程


## compatibility_ignore_collation_in_create_table {#compatibility_ignore_collation_in_create_table}

<SettingsInfoBlock type='Bool' default_value='1' />

在 CREATE TABLE 时忽略排序规则以保持兼容性


## compile_aggregate_expressions {#compile_aggregate_expressions}

<SettingsInfoBlock type='Bool' default_value='1' />

启用或禁用将聚合函数 JIT 编译为本机代码。启用此设置可以提升性能。

可能的值：

- 0 — 不使用 JIT 编译进行聚合。
- 1 — 使用 JIT 编译进行聚合。

**另请参阅**

- [min_count_to_compile_aggregate_expression](#min_count_to_compile_aggregate_expression)


## compile_expressions {#compile_expressions}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "1" },
        {
          label:
            "我们认为 JIT 编译器所依赖的 LLVM 基础设施已足够稳定,可以默认启用此设置。"
        }
      ]
    }
  ]}
/>

将部分标量函数和运算符编译为本机代码。


## compile_sort_description {#compile_sort_description}

<SettingsInfoBlock type='Bool' default_value='1' />

将排序描述编译为原生代码。


## connect_timeout {#connect_timeout}

<SettingsInfoBlock type='Seconds' default_value='10' />

无可用副本时的连接超时时间。


## connect_timeout_with_failover_ms {#connect_timeout_with_failover_ms}

<SettingsInfoBlock type='Milliseconds' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "1000" },
        { label: "因异步连接而增加默认连接超时时间" }
      ]
    }
  ]}
/>

当集群定义中使用了 'shard' 和 'replica' 配置时,Distributed 表引擎连接远程服务器的超时时间(毫秒)。
连接失败时,会尝试连接到其他副本。


## connect_timeout_with_failover_secure_ms {#connect_timeout_with_failover_secure_ms}

<SettingsInfoBlock type='Milliseconds' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "1000" },
        {
          label:
            "由于异步连接,增加了默认安全连接超时时间"
        }
      ]
    }
  ]}
/>

选择第一个健康副本的连接超时时间(用于安全连接)。


## connection_pool_max_wait_ms {#connection_pool_max_wait_ms}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

当连接池已满时等待连接的时间（毫秒）。

可能的值：

- 正整数。
- 0 — 无限超时。


## connections_with_failover_max_tries {#connections_with_failover_max_tries}

<SettingsInfoBlock type='UInt64' default_value='3' />

Distributed 表引擎与每个副本进行连接尝试的最大次数。


## convert_query_to_cnf {#convert_query_to_cnf}

<SettingsInfoBlock type='Bool' default_value='0' />

当设置为 `true` 时,`SELECT` 查询将被转换为合取范式(CNF)。在某些场景下,将查询重写为 CNF 形式可能会执行得更快(查看此 [Github issue](https://github.com/ClickHouse/ClickHouse/issues/11749) 了解详情)。

例如,请注意以下 `SELECT` 查询未被修改(默认行为):

```sql
EXPLAIN SYNTAX
SELECT *
FROM
(
    SELECT number AS x
    FROM numbers(20)
) AS a
WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))
SETTINGS convert_query_to_cnf = false;
```

结果如下:

```response
┌─explain────────────────────────────────────────────────────────┐
│ SELECT x                                                       │
│ FROM                                                           │
│ (                                                              │
│     SELECT number AS x                                         │
│     FROM numbers(20)                                           │
│     WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15)) │
│ ) AS a                                                         │
│ WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))     │
│ SETTINGS convert_query_to_cnf = 0                              │
└────────────────────────────────────────────────────────────────┘
```

将 `convert_query_to_cnf` 设置为 `true` 并查看变化:

```sql
EXPLAIN SYNTAX
SELECT *
FROM
(
    SELECT number AS x
    FROM numbers(20)
) AS a
WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))
SETTINGS convert_query_to_cnf = true;
```

请注意 `WHERE` 子句被重写为 CNF 形式,但结果集完全相同 - 布尔逻辑保持不变:

```response
┌─explain───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SELECT x                                                                                                              │
│ FROM                                                                                                                  │
│ (                                                                                                                     │
│     SELECT number AS x                                                                                                │
│     FROM numbers(20)                                                                                                  │
│     WHERE ((x <= 15) OR (x <= 5)) AND ((x <= 15) OR (x >= 1)) AND ((x >= 10) OR (x <= 5)) AND ((x >= 10) OR (x >= 1)) │
│ ) AS a                                                                                                                │
│ WHERE ((x >= 10) OR (x >= 1)) AND ((x >= 10) OR (x <= 5)) AND ((x <= 15) OR (x >= 1)) AND ((x <= 15) OR (x <= 5))     │
│ SETTINGS convert_query_to_cnf = 1                                                                                     │
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

可能的值:true、false


## correlated_subqueries_default_join_kind {#correlated_subqueries_default_join_kind}

<SettingsInfoBlock type='DecorrelationJoinKind' default_value='right' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "right" },
        { label: "新设置。解相关查询计划的默认连接类型。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.10" },
        { label: "right" },
        { label: "新设置。解相关查询计划的默认连接类型。" }
      ]
    }
  ]}
/>

控制解相关查询计划中的连接类型。默认值为 `right`,表示解相关计划将包含 RIGHT JOIN,子查询输入位于右侧。

可能的值:

- `left` - 解相关过程将生成 LEFT JOIN,输入表将出现在左侧。
- `right` - 解相关过程将生成 RIGHT JOIN,输入表将出现在右侧。


## correlated_subqueries_substitute_equivalent_expressions {#correlated_subqueries_substitute_equivalent_expressions}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "1" },
        { label: "关联子查询规划优化的新设置。" }
      ]
    }
  ]}
/>

使用过滤表达式推断等价表达式并进行替换,而不是创建 CROSS JOIN。


## count_distinct_implementation {#count_distinct_implementation}

<SettingsInfoBlock type='String' default_value='uniqExact' />

指定用于执行 [COUNT(DISTINCT ...)](/sql-reference/aggregate-functions/reference/count) 构造的 `uniq*` 函数。

可选值：

- [uniq](/sql-reference/aggregate-functions/reference/uniq)
- [uniqCombined](/sql-reference/aggregate-functions/reference/uniqcombined)
- [uniqCombined64](/sql-reference/aggregate-functions/reference/uniqcombined64)
- [uniqHLL12](/sql-reference/aggregate-functions/reference/uniqhll12)
- [uniqExact](/sql-reference/aggregate-functions/reference/uniqexact)


## count_distinct_optimization {#count_distinct_optimization}

<SettingsInfoBlock type='Bool' default_value='0' />

将 count distinct 重写为 group by 子查询


## count_matches_stop_at_empty_match {#count_matches_stop_at_empty_match}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.6" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

在 `countMatches` 函数中,一旦模式匹配到零长度内容,则停止计数。


## create_if_not_exists {#create_if_not_exists}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.9" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

默认为 `CREATE` 语句启用 `IF NOT EXISTS`。如果指定了此设置或 `IF NOT EXISTS`,且具有指定名称的表已存在,则不会抛出异常。


## create_index_ignore_unique {#create_index_ignore_unique}

<SettingsInfoBlock type='Bool' default_value='0' />

忽略 CREATE UNIQUE INDEX 中的 UNIQUE 关键字。用于 SQL 兼容性测试。


## create_replicated_merge_tree_fault_injection_probability {#create_replicated_merge_tree_fault_injection_probability}

<SettingsInfoBlock type='Float' default_value='0' />

在 ZooKeeper 中创建元数据后,表创建过程中故障注入的概率


## create_table_empty_primary_key_by_default {#create_table_empty_primary_key_by_default}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "1" }, { label: "Better usability" }]
    }
  ]}
/>

当未指定 ORDER BY 和 PRIMARY KEY 时,允许创建空主键的 \*MergeTree 表


## cross_join_min_bytes_to_compress {#cross_join_min_bytes_to_compress}

<SettingsInfoBlock type='UInt64' default_value='1073741824' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.5" },
        { label: "1073741824" },
        {
          label:
            "CROSS JOIN 中需要压缩的数据块的最小字节大小。零值表示禁用此阈值。当达到两个阈值(按行数或按字节数)中的任意一个时,数据块将被压缩。"
        }
      ]
    }
  ]}
/>

CROSS JOIN 中需要压缩的数据块的最小字节大小。零值表示禁用此阈值。当达到两个阈值(按行数或按字节数)中的任意一个时,数据块将被压缩。


## cross_join_min_rows_to_compress {#cross_join_min_rows_to_compress}

<SettingsInfoBlock type='UInt64' default_value='10000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.5" },
        { label: "10000000" },
        {
          label:
            "CROSS JOIN 中压缩数据块所需的最小行数。设置为零表示禁用此阈值。当满足两个阈值(按行数或按字节数)中的任意一个时,数据块将被压缩。"
        }
      ]
    }
  ]}
/>

CROSS JOIN 中压缩数据块所需的最小行数。设置为零表示禁用此阈值。当满足两个阈值(按行数或按字节数)中的任意一个时,数据块将被压缩。


## data_type_default_nullable {#data_type_default_nullable}

<SettingsInfoBlock type='Bool' default_value='0' />

允许在列定义中未显式指定 [NULL 或 NOT NULL](/sql-reference/statements/create/table#null-or-not-null-modifiers) 修饰符的数据类型成为 [Nullable](/sql-reference/data-types/nullable) 类型。

可能的值:

- 1 — 列定义中的数据类型默认设置为 `Nullable`。
- 0 — 列定义中的数据类型默认设置为非 `Nullable`。


## database_atomic_wait_for_drop_and_detach_synchronously {#database_atomic_wait_for_drop_and_detach_synchronously}

<SettingsInfoBlock type='Bool' default_value='0' />

为所有 `DROP` 和 `DETACH` 查询添加 `SYNC` 修饰符。

可能的值:

- 0 — 查询将异步执行。
- 1 — 查询将同步执行。


## database_replicated_allow_explicit_uuid {#database_replicated_allow_explicit_uuid}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        {
          label:
            "新增设置以禁止显式指定表 UUID"
        }
      ]
    }
  ]}
/>

0 - 不允许在 Replicated 数据库中显式指定表的 UUID。1 - 允许。2 - 允许,但忽略指定的 UUID 并随机生成一个。


## database_replicated_allow_heavy_create {#database_replicated_allow_heavy_create}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "0" },
        {
          label:
            "禁止 Replicated 数据库引擎执行长时间运行的 DDL 查询(CREATE AS SELECT 和 POPULATE)"
        }
      ]
    }
  ]}
/>

允许在 Replicated 数据库引擎中执行长时间运行的 DDL 查询(CREATE AS SELECT 和 POPULATE)。注意:这可能会长时间阻塞 DDL 队列。


## database_replicated_allow_only_replicated_engine {#database_replicated_allow_only_replicated_engine}

<SettingsInfoBlock type='Bool' default_value='0' />

仅允许在使用 Replicated 引擎的数据库中创建 Replicated 表


## database_replicated_allow_replicated_engine_arguments {#database_replicated_allow_replicated_engine_arguments}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        { label: "默认不允许显式参数" }
      ]
    }
  ]}
/>

0 - 不允许在 Replicated 数据库中为 \*MergeTree 表显式指定 ZooKeeper 路径和副本名称。1 - 允许。2 - 允许,但忽略指定的路径并使用默认路径。3 - 允许且不记录警告日志。


## database_replicated_always_detach_permanently {#database_replicated_always_detach_permanently}

<SettingsInfoBlock type='Bool' default_value='0' />

当数据库引擎为 Replicated 时,将 DETACH TABLE 执行为 DETACH TABLE PERMANENTLY


## database_replicated_enforce_synchronous_settings {#database_replicated_enforce_synchronous_settings}

<SettingsInfoBlock type='Bool' default_value='0' />

对某些查询强制执行同步等待(另请参阅 database_atomic_wait_for_drop_and_detach_synchronously、mutations_sync、alter_sync)。不建议启用此设置。


## database_replicated_initial_query_timeout_sec {#database_replicated_initial_query_timeout_sec}

<SettingsInfoBlock type='UInt64' default_value='300' />

设置初始 DDL 查询应等待 Replicated 数据库处理之前 DDL 队列条目的时长(以秒为单位)。

可选值:

- 正整数。
- 0 — 无限制。


## database_shared_drop_table_delay_seconds {#database_shared_drop_table_delay_seconds}

<SettingsInfoBlock type='UInt64' default_value='28800' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "28800" }, { label: "新设置。" }]
    }
  ]}
/>

在共享数据库中删除表后,实际移除该表之前的延迟时间(以秒为单位)。此设置允许在延迟时间内使用 `UNDROP TABLE` 语句恢复已删除的表。


## decimal_check_overflow {#decimal_check_overflow}

<SettingsInfoBlock type='Bool' default_value='1' />

检查 Decimal 类型算术/比较运算的溢出


## deduplicate_blocks_in_dependent_materialized_views {#deduplicate_blocks_in_dependent_materialized_views}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用对从 Replicated\* 表接收数据的物化视图的去重检查。

可能的值:

      0 — 禁用。
      1 — 启用。

启用后,ClickHouse 会对依赖于 Replicated\* 表的物化视图中的数据块执行去重。
此设置用于确保在因故障重试插入操作时,物化视图不会包含重复数据。

**另请参阅**

- [IN 运算符中的 NULL 处理](/guides/developer/deduplicating-inserts-on-retries#insert-deduplication-with-materialized-views)


## default_materialized_view_sql_security {#default_materialized_view_sql_security}

<SettingsInfoBlock type='SQLSecurityType' default_value='DEFINER' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "DEFINER" },
        {
          label:
            "允许在创建物化视图时为 SQL SECURITY 选项设置默认值"
        }
      ]
    }
  ]}
/>

允许在创建物化视图时为 SQL SECURITY 选项设置默认值。[了解更多关于 SQL 安全的信息](../../sql-reference/statements/create/view.md/#sql_security)。

默认值为 `DEFINER`。


## default_max_bytes_in_join {#default_max_bytes_in_join}

<SettingsInfoBlock type='UInt64' default_value='1000000000' />

当需要限制但未设置 `max_bytes_in_join` 时右侧表的最大字节数。


## default_normal_view_sql_security {#default_normal_view_sql_security}

<SettingsInfoBlock type='SQLSecurityType' default_value='INVOKER' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "INVOKER" },
        {
          label:
            "允许在创建普通视图时设置默认 `SQL SECURITY` 选项"
        }
      ]
    }
  ]}
/>

允许在创建普通视图时设置默认 `SQL SECURITY` 选项。[了解更多关于 SQL 安全性](../../sql-reference/statements/create/view.md/#sql_security)。

默认值为 `INVOKER`。


## default_table_engine {#default_table_engine}

<SettingsInfoBlock type='DefaultTableEngine' default_value='MergeTree' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "MergeTree" },
        { label: "将默认表引擎设置为 MergeTree 以提升易用性" }
      ]
    }
  ]}
/>

当 `CREATE` 语句中未设置 `ENGINE` 时使用的默认表引擎。

可选值：

- 表示任何有效表引擎名称的字符串

云版本默认值：`SharedMergeTree`。

**示例**

查询：

```sql
SET default_table_engine = 'Log';

SELECT name, value, changed FROM system.settings WHERE name = 'default_table_engine';
```

结果：

```response
┌─name─────────────────┬─value─┬─changed─┐
│ default_table_engine │ Log   │       1 │
└──────────────────────┴───────┴─────────┘
```

在此示例中，任何未指定 `Engine` 的新表都将使用 `Log` 表引擎：

查询：

```sql
CREATE TABLE my_table (
    x UInt32,
    y UInt32
);

SHOW CREATE TABLE my_table;
```

结果：

```response
┌─statement────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.my_table
(
    `x` UInt32,
    `y` UInt32
)
ENGINE = Log
└──────────────────────────────────────────────────────────────────────────┘
```


## default_temporary_table_engine {#default_temporary_table_engine}

<SettingsInfoBlock type='DefaultTableEngine' default_value='Memory' />

与 [default_table_engine](#default_table_engine) 相同,但适用于临时表。

在此示例中,任何未指定 `Engine` 的新临时表都将使用 `Log` 表引擎:

查询:

```sql
SET default_temporary_table_engine = 'Log';

CREATE TEMPORARY TABLE my_table (
    x UInt32,
    y UInt32
);

SHOW CREATE TEMPORARY TABLE my_table;
```

结果:

```response
┌─statement────────────────────────────────────────────────────────────────┐
│ CREATE TEMPORARY TABLE default.my_table
(
    `x` UInt32,
    `y` UInt32
)
ENGINE = Log
└──────────────────────────────────────────────────────────────────────────┘
```


## default_view_definer {#default_view_definer}

<SettingsInfoBlock type='String' default_value='CURRENT_USER' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "CURRENT_USER" },
        {
          label: "允许在创建视图时设置默认 `DEFINER` 选项"
        }
      ]
    }
  ]}
/>

允许在创建视图时设置默认 `DEFINER` 选项。[更多关于 SQL 安全性的信息](../../sql-reference/statements/create/view.md/#sql_security)。

默认值为 `CURRENT_USER`。


## delta_lake_enable_engine_predicate {#delta_lake_enable_engine_predicate}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1" }, { label: "New setting" }]
    }
  ]}
/>

启用 delta-kernel 内部数据剪枝。


## delta_lake_enable_expression_visitor_logging {#delta_lake_enable_expression_visitor_logging}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "New setting" }]
    }
  ]}
/>

启用 DeltaLake 表达式访问器的测试级别日志。即使在测试日志记录中,这些日志也可能过于详细。


## delta_lake_insert_max_bytes_in_data_file {#delta_lake_insert_max_bytes_in_data_file}

<SettingsInfoBlock type='NonZeroUInt64' default_value='1073741824' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.9" },
        { label: "1073741824" },
        { label: "新增设置。" }
      ]
    }
  ]}
/>

定义 Delta Lake 中单个插入数据文件的字节限制。


## delta_lake_insert_max_rows_in_data_file {#delta_lake_insert_max_rows_in_data_file}

<SettingsInfoBlock type='NonZeroUInt64' default_value='1000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.9" },
        { label: "1000000" },
        { label: "新增设置。" }
      ]
    }
  ]}
/>

定义 Delta Lake 中单个插入数据文件的行数限制。


## delta_lake_log_metadata {#delta_lake_log_metadata}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

启用将 Delta Lake 元数据文件记录到系统表中。


## delta_lake_snapshot_version {#delta_lake_snapshot_version}

<SettingsInfoBlock type='Int64' default_value='-1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "-1" }, { label: "新设置" }]
    }
  ]}
/>

要读取的 Delta Lake 快照版本。值 -1 表示读取最新版本(值 0 是有效的快照版本)。


## delta_lake_throw_on_engine_predicate_error {#delta_lake_throw_on_engine_predicate_error}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

启用在 delta-kernel 中分析扫描谓词时出错时抛出异常。


## describe_compact_output {#describe_compact_output}

<SettingsInfoBlock type='Bool' default_value='0' />

如果为 true，DESCRIBE 查询结果将仅包含列名和类型


## describe_include_subcolumns {#describe_include_subcolumns}

<SettingsInfoBlock type='Bool' default_value='0' />

启用在 [DESCRIBE](../../sql-reference/statements/describe-table.md) 查询中描述子列。例如,[Tuple](../../sql-reference/data-types/tuple.md) 的成员,或 [Map](/sql-reference/data-types/map#reading-subcolumns-of-map)、[Nullable](../../sql-reference/data-types/nullable.md/#finding-null) 或 [Array](../../sql-reference/data-types/array.md/#array-size) 数据类型的子列。

可能的值:

- 0 — `DESCRIBE` 查询中不包含子列。
- 1 — `DESCRIBE` 查询中包含子列。

**示例**

参见 [DESCRIBE](../../sql-reference/statements/describe-table.md) 语句的示例。


## describe_include_virtual_columns {#describe_include_virtual_columns}

<SettingsInfoBlock type='Bool' default_value='0' />

如果设置为 true,DESCRIBE 查询的结果将包含表的虚拟列


## dialect {#dialect}

<SettingsInfoBlock type='Dialect' default_value='clickhouse' />

用于解析查询的 SQL 方言


## dictionary_validate_primary_key_type {#dictionary_validate_primary_key_type}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "0" },
        {
          label:
            "验证字典的主键类型。默认情况下，简单布局的 id 类型将隐式转换为 UInt64。"
        }
      ]
    }
  ]}
/>

验证字典的主键类型。默认情况下，简单布局的 id 类型将隐式转换为 UInt64。


## distinct_overflow_mode {#distinct_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

设置当数据量超过其中一个限制时的处理方式。

可选值：

- `throw`：抛出异常（默认值）。
- `break`：停止执行查询并返回部分结果，如同源数据已耗尽。


## distributed_aggregation_memory_efficient {#distributed_aggregation_memory_efficient}

<SettingsInfoBlock type='Bool' default_value='1' />

是否启用分布式聚合的内存优化模式。


## distributed_background_insert_batch {#distributed_background_insert_batch}

**别名**: `distributed_directory_monitor_batch_inserts`

<SettingsInfoBlock type='Bool' default_value='0' />

启用/禁用批量发送插入的数据。

启用批量发送后,[Distributed](../../engines/table-engines/special/distributed.md) 表引擎会尝试在单次操作中发送多个插入数据文件,而不是逐个单独发送。批量发送通过更充分地利用服务器和网络资源来提升集群性能。

可能的值:

- 1 — 启用。
- 0 — 禁用。


## distributed_background_insert_max_sleep_time_ms {#distributed_background_insert_max_sleep_time_ms}

**别名**: `distributed_directory_monitor_max_sleep_time_ms`

<SettingsInfoBlock type='Milliseconds' default_value='30000' />

[Distributed](../../engines/table-engines/special/distributed.md) 表引擎发送数据的最大时间间隔。用于限制 [distributed_background_insert_sleep_time_ms](#distributed_background_insert_sleep_time_ms) 设置中时间间隔的指数增长。

可能的值:

- 正整数,单位为毫秒。


## distributed_background_insert_sleep_time_ms {#distributed_background_insert_sleep_time_ms}

**别名**：`distributed_directory_monitor_sleep_time_ms`

<SettingsInfoBlock type='Milliseconds' default_value='100' />

[Distributed](../../engines/table-engines/special/distributed.md) 表引擎发送数据的基础时间间隔。当发生错误时,实际间隔将呈指数级增长。

可选值：

- 正整数,单位为毫秒。


## distributed_background_insert_split_batch_on_failure {#distributed_background_insert_split_batch_on_failure}

**别名**: `distributed_directory_monitor_split_batch_on_failure`

<SettingsInfoBlock type='Bool' default_value='0' />

启用/禁用失败时拆分批次的功能。

有时向远程分片发送特定批次可能会失败,原因是后续存在复杂的处理流程(例如带有 `GROUP BY` 的 `MATERIALIZED VIEW`)导致 `Memory limit exceeded` 或类似错误。在这种情况下,重试无法解决问题(并且会导致该表的分布式发送被阻塞),但逐个发送该批次中的文件可能会成功完成 INSERT 操作。

因此将此设置设为 `1` 将对此类批次禁用批处理(即对失败的批次临时禁用 `distributed_background_insert_batch`)。

可能的值:

- 1 — 启用。
- 0 — 禁用。

:::note
此设置还会影响损坏的批次(这些批次可能由于服务器(机器)异常终止且 [Distributed](../../engines/table-engines/special/distributed.md) 表引擎未启用 `fsync_after_insert`/`fsync_directories` 而出现)。
:::

:::note
您不应依赖自动批次拆分功能,因为这可能会降低性能。
:::


## distributed_background_insert_timeout {#distributed_background_insert_timeout}

**别名**: `insert_distributed_timeout`

<SettingsInfoBlock type='UInt64' default_value='0' />

分布式表插入查询的超时时间。此设置仅在启用 insert_distributed_sync 时生效。值为零表示不设置超时。


## distributed_cache_alignment {#distributed_cache_alignment}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "0" },
        { label: "由 distributed_cache_read_alignment 重命名而来" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。此设置仅用于测试目的,请勿修改


## distributed_cache_bypass_connection_pool {#distributed_cache_bypass_connection_pool}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "ClickHouse Cloud 设置" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。允许绕过分布式缓存连接池


## distributed_cache_connect_backoff_max_ms {#distributed_cache_connect_backoff_max_ms}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='50' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "50" }, { label: "新增设置" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。分布式缓存连接创建的最大退避时间（毫秒）。


## distributed_cache_connect_backoff_min_ms {#distributed_cache_connect_backoff_min_ms}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。分布式缓存连接创建的最小退避时间（毫秒）。


## distributed_cache_connect_max_tries {#distributed_cache_connect_max_tries}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='5' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "5" },
        { label: "修改了设置值" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "25.1" }, { label: "20" }, { label: "仅限云版本" }]
    },
    {
      id: "row-3",
      items: [
        { label: "24.10" },
        { label: "20" },
        { label: "ClickHouse Cloud 专用设置" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。连接分布式缓存失败时的重试次数


## distributed_cache_connect_timeout_ms {#distributed_cache_connect_timeout_ms}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='50' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "50" }, { label: "New setting" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。连接分布式缓存服务器时的连接超时时间。


## distributed_cache_credentials_refresh_period_seconds {#distributed_cache_credentials_refresh_period_seconds}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='5' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "5" },
        { label: "新增私有设置" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。凭证刷新周期。


## distributed_cache_data_packet_ack_window {#distributed_cache_data_packet_ack_window}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='5' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "5" },
        { label: "ClickHouse Cloud 专用设置" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。用于在单个分布式缓存读取请求中为 DataPacket 序列发送 ACK 的窗口大小


## distributed_cache_discard_connection_if_unread_data {#distributed_cache_discard_connection_if_unread_data}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "1" }, { label: "New setting" }]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "1" }, { label: "New setting" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。如果有未读数据,则丢弃连接。


## distributed_cache_fetch_metrics_only_from_current_az {#distributed_cache_fetch_metrics_only_from_current_az}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "1" },
        { label: "ClickHouse Cloud 配置项" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。仅从当前可用区获取 system.distributed_cache_metrics 和 system.distributed_cache_events 中的指标


## distributed_cache_log_mode {#distributed_cache_log_mode}

<CloudOnlyBadge />

<SettingsInfoBlock type='DistributedCacheLogMode' default_value='on_error' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "on_error" },
        { label: "ClickHouse Cloud 设置" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。用于写入 system.distributed_cache_log 的模式。


## distributed_cache_max_unacked_inflight_packets {#distributed_cache_max_unacked_inflight_packets}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "10" },
        { label: "ClickHouse Cloud 配置项" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。单个分布式缓存读取请求中未确认的在途数据包的最大数量


## distributed_cache_min_bytes_for_seek {#distributed_cache_min_bytes_for_seek}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "0" },
        { label: "新增私有设置。" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。在分布式缓存中执行定位操作所需的最小字节数。


## distributed_cache_pool_behaviour_on_limit {#distributed_cache_pool_behaviour_on_limit}

<CloudOnlyBadge />

<SettingsInfoBlock
  type='DistributedCachePoolBehaviourOnLimit'
  default_value='wait'
/>

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "wait" }, { label: "Cloud only" }]
    },
    {
      id: "row-2",
      items: [
        { label: "24.10" },
        { label: "allocate_bypassing_pool" },
        { label: "A setting for ClickHouse Cloud" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。指定当达到连接池限制时分布式缓存连接的行为


## distributed_cache_prefer_bigger_buffer_size {#distributed_cache_prefer_bigger_buffer_size}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。与 filesystem_cache_prefer_bigger_buffer_size 相同,但适用于分布式缓存。


## distributed_cache_read_only_from_current_az {#distributed_cache_read_only_from_current_az}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。允许仅从当前可用区读取数据。如果禁用,将从所有可用区中的所有缓存服务器读取数据。


## distributed_cache_read_request_max_tries {#distributed_cache_read_request_max_tries}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "10" },
        { label: "修改了设置值" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "25.4" }, { label: "20" }, { label: "新增设置" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。分布式缓存请求失败时的重试次数


## distributed_cache_receive_response_wait_milliseconds {#distributed_cache_receive_response_wait_milliseconds}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='60000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "60000" },
        { label: "ClickHouse Cloud 设置" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。从分布式缓存接收请求数据的等待时间(毫秒)


## distributed_cache_receive_timeout_milliseconds {#distributed_cache_receive_timeout_milliseconds}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='10000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "10000" },
        { label: "ClickHouse Cloud 设置" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。从分布式缓存接收任何响应的等待时间(毫秒)


## distributed_cache_receive_timeout_ms {#distributed_cache_receive_timeout_ms}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='3000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "3000" }, { label: "新增设置" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。从分布式缓存服务器接收数据的超时时间,单位为毫秒。如果在此时间间隔内未接收到任何字节,将抛出异常。


## distributed_cache_send_timeout_ms {#distributed_cache_send_timeout_ms}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='3000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "3000" }, { label: "新设置" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。向分布式缓存服务器发送数据的超时时间,单位为毫秒。如果客户端需要发送数据,但在此时间间隔内无法发送任何字节,则会抛出异常。


## distributed_cache_tcp_keep_alive_timeout_ms {#distributed_cache_tcp_keep_alive_timeout_ms}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='2900' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "2900" }, { label: "新增设置" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。连接到分布式缓存服务器保持空闲状态多长时间后,TCP 才开始发送 keepalive 探测包,以毫秒为单位。


## distributed_cache_throw_on_error {#distributed_cache_throw_on_error}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "ClickHouse Cloud 设置" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。重新抛出与分布式缓存通信期间发生的异常或从分布式缓存接收到的异常。否则在出错时回退到跳过分布式缓存


## distributed_cache_wait_connection_from_pool_milliseconds {#distributed_cache_wait_connection_from_pool_milliseconds}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='100' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "100" },
        { label: "ClickHouse Cloud 设置" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。当 distributed_cache_pool_behaviour_on_limit 设置为 wait 时,从连接池获取连接的等待时间(以毫秒为单位)


## distributed_connections_pool_size {#distributed_connections_pool_size}

<SettingsInfoBlock type='UInt64' default_value='1024' />

用于对单个 Distributed 表的所有查询进行分布式处理时,与远程服务器的最大并发连接数。建议将此值设置为不小于集群中的服务器数量。


## distributed_ddl_entry_format_version {#distributed_ddl_entry_format_version}

<SettingsInfoBlock type='UInt64' default_value='5' />

分布式 DDL（ON CLUSTER）查询的兼容版本


## distributed_ddl_output_mode {#distributed_ddl_output_mode}

<SettingsInfoBlock type='DistributedDDLOutputMode' default_value='throw' />

设置分布式 DDL 查询结果的格式。

可选值:

- `throw` — 返回包含所有已完成查询的主机的查询执行状态的结果集。如果查询在某些主机上失败,则会重新抛出第一个异常。如果查询在某些主机上尚未完成且超过了 [distributed_ddl_task_timeout](#distributed_ddl_task_timeout),则会抛出 `TIMEOUT_EXCEEDED` 异常。
- `none` — 与 `throw` 类似,但分布式 DDL 查询不返回结果集。
- `null_status_on_timeout` — 如果查询在相应主机上未完成,则在结果集的某些行中返回 `NULL` 作为执行状态,而不是抛出 `TIMEOUT_EXCEEDED` 异常。
- `never_throw` — 不抛出 `TIMEOUT_EXCEEDED` 异常,如果查询在某些主机上失败也不重新抛出异常。
- `none_only_active` — 与 `none` 类似,但不等待 `Replicated` 数据库的非活动副本。注意:使用此模式无法确定查询是否未在某些副本上执行,该查询将在后台执行。
- `null_status_on_timeout_only_active` — 与 `null_status_on_timeout` 类似,但不等待 `Replicated` 数据库的非活动副本
- `throw_only_active` — 与 `throw` 类似,但不等待 `Replicated` 数据库的非活动副本

Cloud 默认值:`throw`。


## distributed_ddl_task_timeout {#distributed_ddl_task_timeout}

<SettingsInfoBlock type='Int64' default_value='180' />

设置集群中所有主机 DDL 查询响应的超时时间。如果 DDL 请求未能在所有主机上执行完成,响应将包含超时错误,且该请求将以异步模式执行。负值表示无限超时。

可选值:

- 正整数。
- 0 — 异步模式。
- 负整数 — 无限超时。


## distributed_foreground_insert {#distributed_foreground_insert}

**别名**: `insert_distributed_sync`

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用向 [Distributed](/engines/table-engines/special/distributed) 表同步插入数据。

默认情况下,向 `Distributed` 表插入数据时,ClickHouse 服务器以后台模式将数据发送到集群节点。当 `distributed_foreground_insert=1` 时,数据将以同步方式处理,只有在所有数据都保存到所有分片后(如果 `internal_replication` 为 true,则每个分片至少保存到一个副本),`INSERT` 操作才会成功。

可能的值:

- `0` — 以后台模式插入数据。
- `1` — 以同步模式插入数据。

Cloud 默认值:`0`。

**另请参阅**

- [Distributed 表引擎](/engines/table-engines/special/distributed)
- [管理分布式表](/sql-reference/statements/system#managing-distributed-tables)


## distributed_group_by_no_merge {#distributed_group_by_no_merge}

<SettingsInfoBlock type='UInt64' default_value='0' />

在分布式查询处理中不合并来自不同服务器的聚合状态。当确定不同分片上的键各不相同时，可以使用此选项。

可能的值：

- `0` — 禁用（最终查询处理在发起节点上完成）。
- `1` - 在分布式查询处理中不合并来自不同服务器的聚合状态（查询完全在分片上处理，发起节点仅代理数据）。当确定不同分片上的键各不相同时可以使用。
- `2` - 与 `1` 相同，但在发起节点上应用 `ORDER BY` 和 `LIMIT`（当查询完全在远程节点上处理时此功能不可用，如 `distributed_group_by_no_merge=1` 的情况）（可用于带有 `ORDER BY` 和/或 `LIMIT` 的查询）。

**示例**

```sql
SELECT *
FROM remote('127.0.0.{2,3}', system.one)
GROUP BY dummy
LIMIT 1
SETTINGS distributed_group_by_no_merge = 1
FORMAT PrettyCompactMonoBlock

┌─dummy─┐
│     0 │
│     0 │
└───────┘
```

```sql
SELECT *
FROM remote('127.0.0.{2,3}', system.one)
GROUP BY dummy
LIMIT 1
SETTINGS distributed_group_by_no_merge = 2
FORMAT PrettyCompactMonoBlock

┌─dummy─┐
│     0 │
└───────┘
```


## distributed_insert_skip_read_only_replicas {#distributed_insert_skip_read_only_replicas}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        {
          label: "如果为 true,向 Distributed 表执行 INSERT 时将跳过只读副本"
        }
      ]
    }
  ]}
/>

启用在向 Distributed 表执行 INSERT 查询时跳过只读副本。

可能的值:

- 0 — INSERT 按常规方式执行,如果数据将写入只读副本则会失败
- 1 — 发起节点在向分片发送数据之前会跳过只读副本。


## distributed_plan_default_reader_bucket_count {#distributed_plan_default_reader_bucket_count}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='8' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "8" },
        { label: "新增实验性设置。" }
      ]
    }
  ]}
/>

分布式查询中并行读取的默认任务数。任务在各副本之间分配。


## distributed_plan_default_shuffle_join_bucket_count {#distributed_plan_default_shuffle_join_bucket_count}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='8' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "8" },
        { label: "新增实验性设置。" }
      ]
    }
  ]}
/>

分布式 shuffle-hash-join 的默认分桶数量。


## distributed_plan_execute_locally {#distributed_plan_execute_locally}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "新增实验性设置。" }
      ]
    }
  ]}
/>

在本地执行分布式查询计划的所有任务。用于测试和调试。


## distributed_plan_force_exchange_kind {#distributed_plan_force_exchange_kind}

<ExperimentalBadge />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "" },
        { label: "新增实验性设置。" }
      ]
    }
  ]}
/>

强制指定分布式查询阶段之间使用的 Exchange 算子类型。

可选值：

- '' - 不强制指定 Exchange 算子类型，由优化器自动选择，
- 'Persisted' - 使用对象存储中的临时文件，
- 'Streaming' - 通过网络流式传输交换数据。


## distributed_plan_force_shuffle_aggregation {#distributed_plan_force_shuffle_aggregation}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "0" },
        { label: "新增实验性设置" }
      ]
    }
  ]}
/>

在分布式查询计划中使用 Shuffle 聚合策略代替 PartialAggregation + Merge。


## distributed_plan_max_rows_to_broadcast {#distributed_plan_max_rows_to_broadcast}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='20000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "20000" },
        { label: "新增实验性设置。" }
      ]
    }
  ]}
/>

分布式查询计划中使用广播连接代替洗牌连接的最大行数。


## distributed_plan_optimize_exchanges {#distributed_plan_optimize_exchanges}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "1" },
        { label: "新增实验性设置。" }
      ]
    }
  ]}
/>

移除分布式查询计划中不必要的交换操作。可禁用此设置以进行调试。


## distributed_product_mode {#distributed_product_mode}

<SettingsInfoBlock type='DistributedProductMode' default_value='deny' />

更改[分布式子查询](../../sql-reference/operators/in.md)的行为。

当查询包含分布式表的笛卡尔积时,ClickHouse 会应用此设置,即当针对分布式表的查询包含该分布式表的非 GLOBAL 子查询时。

限制条件:

- 仅适用于 IN 和 JOIN 子查询。
- 仅当 FROM 子句使用包含多个分片的分布式表时。
- 仅当子查询涉及包含多个分片的分布式表时。
- 不适用于表值函数 [remote](../../sql-reference/table-functions/remote.md)。

可能的取值:

- `deny` — 默认值。禁止使用这些类型的子查询(返回 "Double-distributed in/JOIN subqueries is denied" 异常)。
- `local` — 将子查询中的数据库和表替换为目标服务器(分片)上的本地数据库和表,保留正常的 `IN`/`JOIN`。
- `global` — 将 `IN`/`JOIN` 查询替换为 `GLOBAL IN`/`GLOBAL JOIN`。
- `allow` — 允许使用这些类型的子查询。


## distributed_push_down_limit {#distributed_push_down_limit}

<SettingsInfoBlock type='UInt64' default_value='1' />

启用或禁用在每个分片上单独应用 [LIMIT](#limit)。

这样可以避免：

- 通过网络发送多余的数据行；
- 在发起节点上处理超出限制的数据行。

从 21.9 版本开始，您不会再获得不准确的结果，因为 `distributed_push_down_limit` 仅在满足以下至少一个条件时才会改变查询执行方式：

- [distributed_group_by_no_merge](#distributed_group_by_no_merge) > 0。
- 查询**不包含** `GROUP BY`/`DISTINCT`/`LIMIT BY`，但包含 `ORDER BY`/`LIMIT`。
- 查询**包含** `GROUP BY`/`DISTINCT`/`LIMIT BY` 以及 `ORDER BY`/`LIMIT`，并且：
  - [optimize_skip_unused_shards](#optimize_skip_unused_shards) 已启用。
  - [optimize_distributed_group_by_sharding_key](#optimize_distributed_group_by_sharding_key) 已启用。

可能的值：

- 0 — 已禁用。
- 1 — 已启用。

另请参阅：

- [distributed_group_by_no_merge](#distributed_group_by_no_merge)
- [optimize_skip_unused_shards](#optimize_skip_unused_shards)
- [optimize_distributed_group_by_sharding_key](#optimize_distributed_group_by_sharding_key)


## distributed_replica_error_cap {#distributed_replica_error_cap}

<SettingsInfoBlock type='UInt64' default_value='1000' />

- 类型：无符号整数
- 默认值：1000

每个副本的错误计数上限为此值，防止单个副本累积过多错误。

另请参阅：

- [load_balancing](#load_balancing-round_robin)
- [表引擎 Distributed](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_half_life](#distributed_replica_error_half_life)
- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)


## distributed_replica_error_half_life {#distributed_replica_error_half_life}

<SettingsInfoBlock type='Seconds' default_value='60' />

- Type: seconds
- Default value: 60 seconds

控制分布式表中错误清零的速度。如果某个副本在一段时间内不可用并累积了 5 个错误,且 distributed_replica_error_half_life 设置为 1 秒,则该副本在最后一次错误发生后 3 秒被视为正常。

另请参阅:

- [load_balancing](#load_balancing-round_robin)
- [Distributed 表引擎](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_cap](#distributed_replica_error_cap)
- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)


## distributed_replica_max_ignored_errors {#distributed_replica_max_ignored_errors}

<SettingsInfoBlock type='UInt64' default_value='0' />

- 类型: 无符号整数
- 默认值: 0

在选择副本时将忽略的错误数量(根据 `load_balancing` 算法)。

另请参阅:

- [load_balancing](#load_balancing-round_robin)
- [表引擎 Distributed](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_cap](#distributed_replica_error_cap)
- [distributed_replica_error_half_life](#distributed_replica_error_half_life)


## do_not_merge_across_partitions_select_final {#do_not_merge_across_partitions_select_final}

<SettingsInfoBlock type='Bool' default_value='0' />

在 SELECT FINAL 查询中仅合并单个分区内的数据部分


## empty_result_for_aggregation_by_constant_keys_on_empty_set {#empty_result_for_aggregation_by_constant_keys_on_empty_set}

<SettingsInfoBlock type='Bool' default_value='1' />

当对空集按常量键进行聚合时返回空结果。


## empty_result_for_aggregation_by_empty_set {#empty_result_for_aggregation_by_empty_set}

<SettingsInfoBlock type='Bool' default_value='0' />

对空集进行无键聚合时返回空结果。


## enable_adaptive_memory_spill_scheduler {#enable_adaptive_memory_spill_scheduler}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.2" },
        { label: "0" },
        {
          label:
            "新设置。启用将内存数据自适应溢出到外部存储。"
        }
      ]
    }
  ]}
/>

触发处理器自适应地将数据溢出到外部存储。目前支持 grace join。


## enable_add_distinct_to_in_subqueries {#enable_add_distinct_to_in_subqueries}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "0" },
        {
          label:
            "新增设置,用于减少分布式 IN 子查询所传输的临时表大小。"
        }
      ]
    }
  ]}
/>

在 `IN` 子查询中启用 `DISTINCT`。这是一个权衡设置:启用后可通过确保仅发送唯一值,大幅减少分布式 IN 子查询所传输的临时表大小,并显著加快分片间的数据传输速度。
但是,启用此设置会在每个节点上增加额外的合并开销,因为必须执行去重(DISTINCT)操作。当网络传输成为瓶颈且可以接受额外的合并成本时,使用此设置。


## enable_blob_storage_log {#enable_blob_storage_log}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "1" },
        {
          label:
            "将 Blob 存储操作信息写入 system.blob_storage_log 表"
        }
      ]
    }
  ]}
/>

将 Blob 存储操作信息写入 system.blob_storage_log 表


## enable_deflate_qpl_codec {#enable_deflate_qpl_codec}

<SettingsInfoBlock type='Bool' default_value='0' />

启用后，可使用 DEFLATE_QPL 编解码器压缩列。


## enable_early_constant_folding {#enable_early_constant_folding}

<SettingsInfoBlock type='Bool' default_value='1' />

启用查询优化，该优化会分析函数和子查询的结果，并在存在常量时重写查询


## enable_extended_results_for_datetime_functions {#enable_extended_results_for_datetime_functions}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用返回扩展范围的 `Date32` 类型结果(相对于 `Date` 类型)
或扩展范围的 `DateTime64` 类型结果(相对于 `DateTime` 类型)。

可选值:

- `0` — 函数对所有类型的参数均返回 `Date` 或 `DateTime`。
- `1` — 函数对 `Date32` 或 `DateTime64` 参数返回 `Date32` 或 `DateTime64`,对其他参数返回 `Date` 或 `DateTime`。

下表展示了此设置对各种日期时间函数行为的影响。


| 函数                        | `enable_extended_results_for_datetime_functions = 0`     | `enable_extended_results_for_datetime_functions = 1`                                                           |
| ------------------------- | -------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- |
| `toStartOfYear`           | 返回 `Date` 或 `DateTime`                                   | 对 `Date`/`DateTime` 类型的输入返回 `Date`/`DateTime`<br />对 `Date32`/`DateTime64` 类型的输入返回 `Date32`/`DateTime64`       |
| `toStartOfISOYear`        | 返回 `Date` 或 `DateTime` 类型                                | 对于 `Date`/`DateTime` 输入，返回 `Date`/`DateTime`<br />对于 `Date32`/`DateTime64` 输入，返回 `Date32`/`DateTime64`         |
| `toStartOfQuarter`        | 返回 `Date` 或 `DateTime`                                   | 对于 `Date`/`DateTime` 输入返回 `Date`/`DateTime` 类型<br />对于 `Date32`/`DateTime64` 输入返回 `Date32`/`DateTime64` 类型     |
| `toStartOfMonth`          | 返回 `Date` 或 `DateTime`                                   | 对 `Date`/`DateTime` 输入返回 `Date`/`DateTime`<br />对 `Date32`/`DateTime64` 输入返回 `Date32`/`DateTime64`             |
| `toStartOfWeek`           | 返回 `Date` 或 `DateTime`                                   | 对于 `Date`/`DateTime` 输入返回 `Date`/`DateTime`<br />对于 `Date32`/`DateTime64` 输入返回 `Date32`/`DateTime64`           |
| `toLastDayOfWeek`         | 返回 `Date` 或 `DateTime`                                   | 对 `Date`/`DateTime` 类型的输入返回 `Date`/`DateTime` 类型<br />对 `Date32`/`DateTime64` 类型的输入返回 `Date32`/`DateTime64` 类型 |
| `toLastDayOfMonth`        | 返回 `Date` 或 `DateTime`                                   | `Date`/`DateTime` 输入时返回 `Date`/`DateTime`<br />`Date32`/`DateTime64` 输入时返回 `Date32`/`DateTime64`               |
| `toMonday`                | 返回 `Date` 或 `DateTime`                                   | 对 `Date`/`DateTime` 类型输入返回 `Date`/`DateTime`<br />对 `Date32`/`DateTime64` 类型输入返回 `Date32`/`DateTime64`         |
| `toStartOfDay`            | 返回 `DateTime`<br />*注意：对于超出 1970–2149 年范围的值，可能会产生不正确的结果* | 对于 `Date`/`DateTime` 类型的输入返回 `DateTime`<br />对于 `Date32`/`DateTime64` 类型的输入返回 `DateTime64`                     |
| `toStartOfHour`           | 返回 `DateTime`<br />*注意：对于超出 1970-2149 年范围的值会产生错误结果*      | 对于 `Date`/`DateTime` 输入返回 `DateTime`<br />对于 `Date32`/`DateTime64` 输入返回 `DateTime64`                           |
| `toStartOfFifteenMinutes` | 返回 `DateTime`<br />*注意：对于 1970-2149 年范围以外的值，结果将不正确*      | 对 `Date`/`DateTime` 输入返回 `DateTime`<br />对 `Date32`/`DateTime64` 输入返回 `DateTime64`                             |
| `toStartOfTenMinutes`     | Returns `DateTime`<br />*注意：对于超出 1970-2149 年范围的值会返回错误结果* | 对 `Date`/`DateTime` 输入，返回 `DateTime`<br />对 `Date32`/`DateTime64` 输入，返回 `DateTime64`                           |
| `toStartOfFiveMinutes`    | 返回 `DateTime`<br />*注意：对超出 1970–2149 范围的值会返回错误结果*        | 对 `Date`/`DateTime` 类型的输入返回 `DateTime` 类型<br />对 `Date32`/`DateTime64` 类型的输入返回 `DateTime64` 类型                 |
| `toStartOfMinute`         | 返回 `DateTime`<br />*注意：对于超出 1970-2149 年范围的值，将返回错误结果*     | `Date`/`DateTime` 类型输入时返回 `DateTime`<br />`Date32`/`DateTime64` 类型输入时返回 `DateTime64`                           |
| `timeSlot`                | 返回 `DateTime`<br />*注意：对于超出 1970-2149 范围的值将产生错误结果*       | 对 `Date`/`DateTime` 输入返回 `DateTime`<br />对 `Date32`/`DateTime64` 输入返回 `DateTime64`                             |





## enable_filesystem_cache {#enable_filesystem_cache}

<SettingsInfoBlock type='Bool' default_value='1' />

为远程文件系统启用缓存。此设置不控制磁盘缓存的开启/关闭(需通过磁盘配置完成),但允许在必要时为特定查询绕过缓存


## enable_filesystem_cache_log {#enable_filesystem_cache_log}

<SettingsInfoBlock type='Bool' default_value='0' />

允许记录每个查询的文件系统缓存日志


## enable_filesystem_cache_on_write_operations {#enable_filesystem_cache_on_write_operations}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用 `write-through` 缓存。设置为 `false` 时,写操作的 `write-through` 缓存将被禁用。设置为 `true` 时,只要服务器配置的缓存磁盘配置部分中开启了 `cache_on_write_operations`,`write-through` 缓存就会启用。
详情请参阅["使用本地缓存"](/operations/storing-data#using-local-cache)。


## enable_filesystem_read_prefetches_log {#enable_filesystem_read_prefetches_log}

<SettingsInfoBlock type='Bool' default_value='0' />

在查询期间将日志记录到 system.filesystem_prefetch_log。此选项仅用于测试或调试目的,不建议在生产环境中默认启用


## enable_global_with_statement {#enable_global_with_statement}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.2" },
        { label: "1" },
        {
          label:
            "默认将 WITH 语句传播至 UNION 查询及所有子查询"
        }
      ]
    }
  ]}
/>

将 WITH 语句传播至 UNION 查询及所有子查询


## enable_hdfs_pread {#enable_hdfs_pread}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "1" }, { label: "新设置。" }]
    }
  ]}
/>

启用或禁用 HDFS 文件的 pread 功能。默认使用 `hdfsPread`。禁用后,将使用 `hdfsRead` 和 `hdfsSeek` 读取 HDFS 文件。


## enable_http_compression {#enable_http_compression}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.10" },
        { label: "1" },
        { label: "通常情况下应该有益" }
      ]
    }
  ]}
/>

启用或禁用 HTTP 请求响应中的数据压缩。

更多信息请参阅 [HTTP 接口说明](../../interfaces/http.md)。

可选值:

- 0 — 禁用。
- 1 — 启用。


## enable_job_stack_trace {#enable_job_stack_trace}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "0" },
        {
          label:
            "为避免性能开销,该设置默认禁用。"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.11" },
        { label: "0" },
        {
          label:
            "启用从作业调度收集堆栈跟踪。为避免性能开销,默认禁用。"
        }
      ]
    }
  ]}
/>

当作业引发异常时,输出作业创建者的堆栈跟踪。为避免性能开销,默认禁用。


## enable_join_runtime_filters {#enable_join_runtime_filters}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "New setting" }]
    }
  ]}
/>

在运行时根据从右表收集的 JOIN 键集合过滤左表。


## enable_lazy_columns_replication {#enable_lazy_columns_replication}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1" },
        {
          label:
            "默认启用 JOIN 和 ARRAY JOIN 中的延迟列复制"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.10" },
        { label: "0" },
        {
          label:
            "添加设置以启用 JOIN 和 ARRAY JOIN 中的延迟列复制"
        }
      ]
    }
  ]}
/>

启用 JOIN 和 ARRAY JOIN 中的延迟列复制,避免在内存中对相同行进行多次不必要的复制。


## enable_lightweight_delete {#enable_lightweight_delete}

**别名**: `allow_experimental_lightweight_delete`

<SettingsInfoBlock type='Bool' default_value='1' />

为 MergeTree 表启用轻量级 DELETE 变更。


## enable_lightweight_update {#enable_lightweight_update}

<BetaBadge />

**别名**: `allow_experimental_lightweight_update`

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "1" },
        {
          label:
            "轻量级更新已移至 Beta 版本。为设置 'allow_experimental_lightweight_update' 添加了别名。"
        }
      ]
    }
  ]}
/>

    允许使用轻量级更新。


## enable_memory_bound_merging_of_aggregation_results {#enable_memory_bound_merging_of_aggregation_results}

<SettingsInfoBlock type='Bool' default_value='1' />

启用聚合结果的内存限制合并策略。


## enable_multiple_prewhere_read_steps {#enable_multiple_prewhere_read_steps}

<SettingsInfoBlock type='Bool' default_value='1' />

当存在多个 AND 组合的条件时,将更多条件从 WHERE 移至 PREWHERE,并分多步骤执行磁盘读取和过滤


## enable_named_columns_in_function_tuple {#enable_named_columns_in_function_tuple}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "0" },
        {
          label:
            "当所有名称唯一且可作为无引号标识符时,在 tuple() 函数中生成命名元组。"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "因可用性改进待完成而禁用" }
      ]
    }
  ]}
/>

当所有名称唯一且可作为无引号标识符时,在 tuple() 函数中生成命名元组。


## enable_optimize_predicate_expression {#enable_optimize_predicate_expression}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "18.12.17" },
        { label: "1" },
        { label: "默认启用子查询谓词优化" }
      ]
    }
  ]}
/>

在 `SELECT` 查询中启用谓词下推。

谓词下推可以显著减少分布式查询的网络流量。

可选值：

- 0 — 禁用。
- 1 — 启用。

使用示例

考虑以下查询：

1.  `SELECT count() FROM test_table WHERE date = '2018-10-10'`
2.  `SELECT count() FROM (SELECT * FROM test_table) WHERE date = '2018-10-10'`

如果 `enable_optimize_predicate_expression = 1`，则这两个查询的执行时间相同，因为 ClickHouse 在处理子查询时会将 `WHERE` 条件下推到子查询中。

如果 `enable_optimize_predicate_expression = 0`，则第二个查询的执行时间会长得多，因为 `WHERE` 子句会在子查询完成后应用于所有数据。


## enable_optimize_predicate_expression_to_final_subquery {#enable_optimize_predicate_expression_to_final_subquery}

<SettingsInfoBlock type='Bool' default_value='1' />

允许将谓词下推到最终子查询。


## enable_order_by_all {#enable_order_by_all}

<SettingsInfoBlock type='Bool' default_value='1' />

启用或禁用 `ORDER BY ALL` 语法排序,详见 [ORDER BY](../../sql-reference/statements/select/order-by.md)。

可能的值:

- 0 — 禁用 ORDER BY ALL。
- 1 — 启用 ORDER BY ALL。

**示例**

查询:

```sql
CREATE TABLE TAB(C1 Int, C2 Int, ALL Int) ENGINE=Memory();

INSERT INTO TAB VALUES (10, 20, 30), (20, 20, 10), (30, 10, 20);

SELECT * FROM TAB ORDER BY ALL; -- 返回错误,提示 ALL 存在歧义

SELECT * FROM TAB ORDER BY ALL SETTINGS enable_order_by_all = 0;
```

结果:

```text
┌─C1─┬─C2─┬─ALL─┐
│ 20 │ 20 │  10 │
│ 30 │ 10 │  20 │
│ 10 │ 20 │  30 │
└────┴────┴─────┘
```


## enable_parallel_blocks_marshalling {#enable_parallel_blocks_marshalling}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.6" }, { label: "true" }, { label: "新增设置" }]
    }
  ]}
/>

仅影响分布式查询。启用后,数据块将在发送到发起节点之前/之后,在流水线线程上进行(反)序列化和(解)压缩(即相比默认情况具有更高的并行度)。


## enable_parsing_to_custom_serialization {#enable_parsing_to_custom_serialization}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

如果为 true,则数据可以根据从表中获得的序列化提示,直接解析到使用自定义序列化(例如 Sparse)的列中。


## enable_positional_arguments {#enable_positional_arguments}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.7" },
        { label: "1" },
        { label: "默认启用位置参数功能" }
      ]
    }
  ]}
/>

启用或禁用 [GROUP BY](/sql-reference/statements/select/group-by)、[LIMIT BY](../../sql-reference/statements/select/limit-by.md)、[ORDER BY](../../sql-reference/statements/select/order-by.md) 语句的位置参数支持。

可能的值:

- 0 — 不支持位置参数。
- 1 — 支持位置参数:可以使用列编号代替列名。

**示例**

查询:

```sql
CREATE TABLE positional_arguments(one Int, two Int, three Int) ENGINE=Memory();

INSERT INTO positional_arguments VALUES (10, 20, 30), (20, 20, 10), (30, 10, 20);

SELECT * FROM positional_arguments ORDER BY 2,3;
```

结果:

```text
┌─one─┬─two─┬─three─┐
│  30 │  10 │   20  │
│  20 │  20 │   10  │
│  10 │  20 │   30  │
└─────┴─────┴───────┘
```


## enable_producing_buckets_out_of_order_in_aggregation {#enable_producing_buckets_out_of_order_in_aggregation}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

允许内存高效聚合(参见 `distributed_aggregation_memory_efficient`)以乱序方式生成桶。
当聚合桶大小分布不均时,此设置可以提升性能,允许副本在仍在处理某些 ID 较低的大型桶时,向发起节点发送 ID 较高的桶。
缺点是可能会增加内存使用量。


## enable_reads_from_query_cache {#enable_reads_from_query_cache}

<SettingsInfoBlock type='Bool' default_value='1' />

启用后，`SELECT` 查询的结果将从[查询缓存](../query-cache.md)中获取。

可选值：

- 0 - 禁用
- 1 - 启用


## enable_s3_requests_logging {#enable_s3_requests_logging}

<SettingsInfoBlock type='Bool' default_value='0' />

启用 S3 请求的详细日志记录。仅用于调试目的。


## enable_scalar_subquery_optimization {#enable_scalar_subquery_optimization}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "19.18" },
        { label: "1" },
        {
          label:
            "防止标量子查询对大标量值进行序列化/反序列化,并可能避免多次运行相同的子查询"
        }
      ]
    }
  ]}
/>

如果设置为 true,则防止标量子查询对大标量值进行序列化/反序列化,并可能避免多次运行相同的子查询。


## enable_scopes_for_with_statement {#enable_scopes_for_with_statement}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "1" },
        {
          label: "新增设置,用于与旧版分析器保持向后兼容。"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.6" },
        { label: "1" },
        {
          label: "新增设置,用于与旧版分析器保持向后兼容。"
        }
      ]
    },
    {
      id: "row-3",
      items: [
        { label: "25.5" },
        { label: "1" },
        {
          label: "新增设置,用于与旧版分析器保持向后兼容。"
        }
      ]
    },
    {
      id: "row-4",
      items: [
        { label: "25.4" },
        { label: "1" },
        {
          label: "新增设置,用于与旧版分析器保持向后兼容。"
        }
      ]
    }
  ]}
/>

如果禁用,父级 WITH 子句中的声明将与当前作用域中的声明具有相同的作用域行为。

注意:这是新版分析器的兼容性设置,用于允许运行某些旧版分析器可以执行但实际无效的查询。


## enable_shared_storage_snapshot_in_query {#enable_shared_storage_snapshot_in_query}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "0" },
        { label: "新增设置,用于在查询中共享存储快照" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.11" },
        { label: "1" },
        { label: "提供更好的一致性保证。" }
      ]
    }
  ]}
/>

启用后,单个查询中的所有子查询将为每个表共享相同的 StorageSnapshot。
这可确保整个查询过程中数据视图的一致性,即使多次访问同一张表也是如此。

对于需要保证数据部分内部一致性的查询,此设置是必需的。示例:

```sql
SELECT
    count()
FROM events
WHERE (_part, _part_offset) IN (
    SELECT _part, _part_offset
    FROM events
    WHERE user_id = 42
)
```

如果不启用此设置,外部查询和内部查询可能会操作不同的数据快照,从而导致错误的结果。

:::note
启用此设置会禁用在规划阶段完成后从快照中删除不必要数据部分的优化。
因此,长时间运行的查询可能会在整个执行期间保留过时的部分,从而延迟部分清理并增加存储压力。

此设置目前仅适用于 MergeTree 系列表。
:::

可能的值:

- 0 - 禁用
- 1 - 启用


## enable_sharing_sets_for_mutations {#enable_sharing_sets_for_mutations}

<SettingsInfoBlock type='Bool' default_value='1' />

允许在同一 mutation 的不同任务之间共享为 IN 子查询构建的集合对象。这可以减少内存使用量和 CPU 消耗


## enable_software_prefetch_in_aggregation {#enable_software_prefetch_in_aggregation}

<SettingsInfoBlock type='Bool' default_value='1' />

在聚合中启用软件预取


## enable_unaligned_array_join {#enable_unaligned_array_join}

<SettingsInfoBlock type='Bool' default_value='0' />

允许对大小不同的多个数组执行 ARRAY JOIN 操作。启用此设置后,所有数组将调整为最长数组的大小。


## enable_url_encoding {#enable_url_encoding}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "已更改现有设置的默认值" }
      ]
    }
  ]}
/>

允许启用/禁用 [URL](../../engines/table-engines/special/url.md) 引擎表中 URI 路径的解码/编码。

默认禁用。


## enable_vertical_final {#enable_vertical_final}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "1" },
        { label: "修复错误后再次默认启用垂直 FINAL" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.1" },
        { label: "1" },
        { label: "默认使用垂直 FINAL" }
      ]
    }
  ]}
/>

如果启用,在执行 FINAL 操作时通过标记行为已删除并在后续过滤的方式来移除重复行,而不是合并行


## enable_writes_to_query_cache {#enable_writes_to_query_cache}

<SettingsInfoBlock type='Bool' default_value='1' />

启用后,`SELECT` 查询的结果将存储在[查询缓存](../query-cache.md)中。

可选值:

- 0 - 禁用
- 1 - 启用


## enable_zstd_qat_codec {#enable_zstd_qat_codec}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "0" },
        { label: "新增 ZSTD_QAT 编解码器" }
      ]
    }
  ]}
/>

启用后,可使用 ZSTD_QAT 编解码器压缩列。


## enforce_strict_identifier_format {#enforce_strict_identifier_format}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "0" }, { label: "新设置。" }]
    }
  ]}
/>

如果启用,则仅允许包含字母、数字和下划线的标识符。


## engine_file_allow_create_multiple_files {#engine_file_allow_create_multiple_files}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在文件引擎表中每次插入数据时创建新文件(当格式带有后缀时,如 `JSON`、`ORC`、`Parquet` 等)。启用后,每次插入时将按以下命名模式创建新文件:

`data.Parquet` -> `data.1.Parquet` -> `data.2.Parquet`,依此类推。

可选值:

- 0 — `INSERT` 查询将新数据追加到文件末尾。
- 1 — `INSERT` 查询创建新文件。


## engine_file_empty_if_not_exists {#engine_file_empty_if_not_exists}

<SettingsInfoBlock type='Bool' default_value='0' />

允许从文件不存在的文件引擎表中查询数据。

可选值:

- 0 — `SELECT` 抛出异常。
- 1 — `SELECT` 返回空结果。


## engine_file_skip_empty_files {#engine_file_skip_empty_files}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在 [File](../../engines/table-engines/special/file.md) 引擎表中跳过空文件。

可能的值:

- 0 — 如果空文件与请求的格式不兼容,`SELECT` 将抛出异常。
- 1 — 对于空文件,`SELECT` 返回空结果。


## engine_file_truncate_on_insert {#engine_file_truncate_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用 [File](../../engines/table-engines/special/file.md) 引擎表在插入前的截断操作。

可选值:

- 0 — `INSERT` 查询将新数据追加到文件末尾。
- 1 — `INSERT` 查询用新数据替换文件中的现有内容。


## engine_url_skip_empty_files {#engine_url_skip_empty_files}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在 [URL](../../engines/table-engines/special/url.md) 引擎表中跳过空文件。

可能的值:

- 0 — 如果空文件与请求的格式不兼容,`SELECT` 将抛出异常。
- 1 — 对于空文件,`SELECT` 返回空结果。


## except_default_mode {#except_default_mode}

<SettingsInfoBlock type='SetOperationMode' default_value='ALL' />

设置 EXCEPT 查询中的默认模式。可选值:空字符串、'ALL'、'DISTINCT'。如果为空,则不指定模式的查询将抛出异常。


## exclude_materialize_skip_indexes_on_insert {#exclude_materialize_skip_indexes_on_insert}

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "" }, { label: "新设置。" }]
    }
  ]}
/>

在 INSERT 操作期间排除指定跳数索引的构建和存储。被排除的跳数索引仍会在[合并期间](merge-tree-settings.md/#materialize_skip_indexes_on_merge)或通过显式的 [MATERIALIZE INDEX](/sql-reference/statements/alter/skipping-index.md/#materialize-index) 查询进行构建和存储。

如果 [materialize_skip_indexes_on_insert](#materialize_skip_indexes_on_insert) 为 false,则此设置无效。

示例:

```sql
CREATE TABLE tab
(
    a UInt64,
    b UInt64,
    INDEX idx_a a TYPE minmax,
    INDEX idx_b b TYPE set(3)
)
ENGINE = MergeTree ORDER BY tuple();

SET exclude_materialize_skip_indexes_on_insert='idx_a'; -- idx_a 在插入时不会被更新
--SET exclude_materialize_skip_indexes_on_insert='idx_a, idx_b'; -- 两个索引在插入时都不会被更新

INSERT INTO tab SELECT number, number / 50 FROM numbers(100); -- 仅 idx_b 被更新

-- 由于这是会话级设置,可以在单个查询级别进行设置
INSERT INTO tab SELECT number, number / 50 FROM numbers(100, 100) SETTINGS exclude_materialize_skip_indexes_on_insert='idx_b';

ALTER TABLE tab MATERIALIZE INDEX idx_a; -- 此查询可用于显式物化索引

SET exclude_materialize_skip_indexes_on_insert = DEFAULT; -- 将设置重置为默认值
```


## execute_exists_as_scalar_subquery {#execute_exists_as_scalar_subquery}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

将非相关 EXISTS 子查询作为标量子查询执行。对于标量子查询,将使用缓存,并对结果应用常量折叠。


## external_storage_connect_timeout_sec {#external_storage_connect_timeout_sec}

<SettingsInfoBlock type='UInt64' default_value='10' />

连接超时时间（以秒为单位）。目前仅支持 MySQL


## external_storage_max_read_bytes {#external_storage_max_read_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

限制外部引擎表刷新历史数据时的最大字节数。目前仅支持 MySQL 表引擎、数据库引擎和字典。如果设置为 0,则禁用此设置


## external_storage_max_read_rows {#external_storage_max_read_rows}

<SettingsInfoBlock type='UInt64' default_value='0' />

限制外部引擎表刷新历史数据时的最大行数。目前仅支持 MySQL 表引擎、数据库引擎和字典。如果设置为 0,则禁用此设置


## external_storage_rw_timeout_sec {#external_storage_rw_timeout_sec}

<SettingsInfoBlock type='UInt64' default_value='300' />

读写超时时间（秒）。目前仅支持 MySQL


## external_table_functions_use_nulls {#external_table_functions_use_nulls}

<SettingsInfoBlock type='Bool' default_value='1' />

定义 [mysql](../../sql-reference/table-functions/mysql.md)、[postgresql](../../sql-reference/table-functions/postgresql.md) 和 [odbc](../../sql-reference/table-functions/odbc.md) 表函数如何使用可空列。

可能的值:

- 0 — 表函数显式使用可空列。
- 1 — 表函数隐式使用可空列。

**用法**

如果该设置为 `0`,表函数不会创建可空列,而是插入默认值代替 NULL。这同样适用于数组内的 NULL 值。


## external_table_strict_query {#external_table_strict_query}

<SettingsInfoBlock type='Bool' default_value='0' />

如果设置为 true，则禁止在查询外部表时将表达式转换为本地过滤器。


## extract_key_value_pairs_max_pairs_per_row {#extract_key_value_pairs_max_pairs_per_row}

**别名**: `extract_kvp_max_pairs_per_row`

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "0" },
        {
          label:
            "`extractKeyValuePairs` 函数可生成的最大键值对数量。用于防止消耗过多内存。"
        }
      ]
    }
  ]}
/>

`extractKeyValuePairs` 函数可生成的最大键值对数量。用于防止消耗过多内存。


## extremes {#extremes}

<SettingsInfoBlock type='Bool' default_value='0' />

是否计算极值(查询结果各列中的最小值和最大值)。可设置为 0 或 1。默认为 0(禁用)。
更多信息请参阅"极值"章节。


## fallback_to_stale_replicas_for_distributed_queries {#fallback_to_stale_replicas_for_distributed_queries}

<SettingsInfoBlock type='Bool' default_value='1' />

当最新数据不可用时,强制查询回退到过期副本。请参阅[复制](../../engines/table-engines/mergetree-family/replication.md)。

ClickHouse 会从表的过期副本中选择最相关的副本。

在对指向复制表的分布式表执行 `SELECT` 查询时使用。

默认值为 1(已启用)。


## filesystem_cache_allow_background_download {#filesystem_cache_allow_background_download}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1" },
        {
          label:
            "用于按查询控制文件系统缓存后台下载的新设置。"
        }
      ]
    }
  ]}
/>

允许文件系统缓存对从远程存储读取的数据进行后台下载排队。禁用后,下载将在当前查询/会话中以前台方式进行。


## filesystem_cache_boundary_alignment {#filesystem_cache_boundary_alignment}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

文件系统缓存边界对齐。此设置仅应用于非磁盘读取操作（例如远程表引擎/表函数的缓存，但不包括 MergeTree 表的存储配置）。值为 0 表示无对齐。


## filesystem_cache_enable_background_download_during_fetch {#filesystem_cache_enable_background_download_during_fetch}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。文件系统缓存中为空间预留而锁定缓存的等待时间


## filesystem_cache_enable_background_download_for_metadata_files_in_packed_storage {#filesystem_cache_enable_background_download_for_metadata_files_in_packed_storage}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "1" }, { label: "New setting" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。文件系统缓存中为空间预留而锁定缓存的等待时间


## filesystem_cache_max_download_size {#filesystem_cache_max_download_size}

<SettingsInfoBlock type='UInt64' default_value='137438953472' />

单个查询可下载的远程文件系统缓存最大大小


## filesystem_cache_name {#filesystem_cache_name}

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "" },
        {
          label:
            "用于无状态表引擎或数据湖的文件系统缓存名称"
        }
      ]
    }
  ]}
/>

用于无状态表引擎或数据湖的文件系统缓存名称


## filesystem_cache_prefer_bigger_buffer_size {#filesystem_cache_prefer_bigger_buffer_size}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

启用文件系统缓存时,优先使用较大的缓冲区大小,以避免写入小文件段导致缓存性能下降。另一方面,启用此设置可能会增加内存使用量。


## filesystem_cache_reserve_space_wait_lock_timeout_milliseconds {#filesystem_cache_reserve_space_wait_lock_timeout_milliseconds}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1000" },
        {
          label:
            "文件系统缓存中为空间预留而锁定缓存的等待时间"
        }
      ]
    }
  ]}
/>

文件系统缓存中为空间预留而锁定缓存的等待时间


## filesystem_cache_segments_batch_size {#filesystem_cache_segments_batch_size}

<SettingsInfoBlock type='UInt64' default_value='20' />

限制读取缓冲区从缓存中请求的单批文件段的大小。该值过低会导致对缓存的请求过多,过大则可能降低缓存淘汰的速度


## filesystem_cache_skip_download_if_exceeds_per_query_cache_write_limit {#filesystem_cache_skip_download_if_exceeds_per_query_cache_write_limit}

**别名**: `skip_download_if_exceeds_query_cache`

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "1" },
        {
          label: "重命名自设置 skip_download_if_exceeds_query_cache_limit"
        }
      ]
    }
  ]}
/>

当超过查询缓存大小时跳过从远程文件系统下载


## filesystem_prefetch_max_memory_usage {#filesystem_prefetch_max_memory_usage}

<SettingsInfoBlock type='NonZeroUInt64' default_value='1073741824' />

预取的最大内存使用量。


## filesystem_prefetch_step_bytes {#filesystem_prefetch_step_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

预取步长(以字节为单位)。设置为零表示 `auto` - 系统将自动推导出近似最佳的预取步长,但可能无法达到 100% 最优。实际值可能会受到 filesystem_prefetch_min_bytes_for_single_read_task 设置的影响而有所不同


## filesystem_prefetch_step_marks {#filesystem_prefetch_step_marks}

<SettingsInfoBlock type='UInt64' default_value='0' />

以标记（marks）为单位的预取步长。设置为零表示 `auto` - 系统将自动推导出近似最佳的预取步长，但可能无法达到 100% 最优。实际值可能会因 filesystem_prefetch_min_bytes_for_single_read_task 设置而有所不同


## filesystem_prefetches_limit {#filesystem_prefetches_limit}

<SettingsInfoBlock type='UInt64' default_value='200' />

预取操作的最大数量。设置为零表示不限制。如果需要限制预取数量,建议使用 `filesystem_prefetches_max_memory_usage` 设置


## final {#final}

<SettingsInfoBlock type='Bool' default_value='0' />

自动对查询中的所有表应用 [FINAL](../../sql-reference/statements/select/from.md/#final-modifier) 修饰符，包括适用 [FINAL](../../sql-reference/statements/select/from.md/#final-modifier) 的表、连接表、子查询中的表以及分布式表。

可能的值：

- 0 - 禁用
- 1 - 启用

示例：

```sql
CREATE TABLE test
(
    key Int64,
    some String
)
ENGINE = ReplacingMergeTree
ORDER BY key;

INSERT INTO test FORMAT Values (1, 'first');
INSERT INTO test FORMAT Values (1, 'second');

SELECT * FROM test;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘
┌─key─┬─some──┐
│   1 │ first │
└─────┴───────┘

SELECT * FROM test SETTINGS final = 1;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘

SET final = 1;
SELECT * FROM test;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘
```


## flatten_nested {#flatten_nested}

<SettingsInfoBlock type='Bool' default_value='1' />

设置 [嵌套](../../sql-reference/data-types/nested-data-structures/index.md) 列的数据格式。

可选值:

- 1 — 嵌套列被展平为多个独立数组。
- 0 — 嵌套列保持为单个元组数组。

**用法**

当该设置为 `0` 时,可以使用任意层级的嵌套。

**示例**

查询:

```sql
SET flatten_nested = 1;
CREATE TABLE t_nest (`n` Nested(a UInt32, b UInt32)) ENGINE = MergeTree ORDER BY tuple();

SHOW CREATE TABLE t_nest;
```

结果:

```text
┌─statement───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.t_nest
(
    `n.a` Array(UInt32),
    `n.b` Array(UInt32)
)
ENGINE = MergeTree
ORDER BY tuple()
SETTINGS index_granularity = 8192 │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

查询:

```sql
SET flatten_nested = 0;

CREATE TABLE t_nest (`n` Nested(a UInt32, b UInt32)) ENGINE = MergeTree ORDER BY tuple();

SHOW CREATE TABLE t_nest;
```

结果:

```text
┌─statement──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.t_nest
(
    `n` Nested(a UInt32, b UInt32)
)
ENGINE = MergeTree
ORDER BY tuple()
SETTINGS index_granularity = 8192 │
└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```


## force_aggregate_partitions_independently {#force_aggregate_partitions_independently}

<SettingsInfoBlock type='Bool' default_value='0' />

当优化可用但启发式决策判定不使用时,强制启用该优化


## force_aggregation_in_order {#force_aggregation_in_order}

<SettingsInfoBlock type='Bool' default_value='0' />

此设置由服务器内部用于支持分布式查询。请勿手动修改,否则会导致正常操作中断。(在分布式聚合过程中强制远程节点按顺序执行聚合)。


## force_data_skipping_indices {#force_data_skipping_indices}

如果指定的数据跳过索引未被使用，则禁止执行查询。

请参考以下示例：

```sql
CREATE TABLE data
(
    key Int,
    d1 Int,
    d1_null Nullable(Int),
    INDEX d1_idx d1 TYPE minmax GRANULARITY 1,
    INDEX d1_null_idx assumeNotNull(d1_null) TYPE minmax GRANULARITY 1
)
Engine=MergeTree()
ORDER BY key;

SELECT * FROM data_01515;
SELECT * FROM data_01515 SETTINGS force_data_skipping_indices=''; -- query will produce CANNOT_PARSE_TEXT error.
SELECT * FROM data_01515 SETTINGS force_data_skipping_indices='d1_idx'; -- query will produce INDEX_NOT_USED error.
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='d1_idx'; -- Ok.
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='`d1_idx`'; -- Ok (example of full featured parser).
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='`d1_idx`, d1_null_idx'; -- query will produce INDEX_NOT_USED error, since d1_null_idx is not used.
SELECT * FROM data_01515 WHERE d1 = 0 AND assumeNotNull(d1_null) = 0 SETTINGS force_data_skipping_indices='`d1_idx`, d1_null_idx'; -- Ok.
```


## force_grouping_standard_compatibility {#force_grouping_standard_compatibility}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.9" },
        { label: "1" },
        {
          label:
            "使 GROUPING 函数的输出与 SQL 标准及其他数据库管理系统保持一致"
        }
      ]
    }
  ]}
/>

当参数未用作聚合键时,使 GROUPING 函数返回 1


## force_index_by_date {#force_index_by_date}

<SettingsInfoBlock type='Bool' default_value='0' />

当无法使用日期索引时禁用查询执行。

适用于 MergeTree 系列表。

当 `force_index_by_date=1` 时,ClickHouse 会检查查询是否包含可用于限制数据范围的日期键条件。如果不存在合适的条件,则抛出异常。但是,它不会检查该条件是否减少了需要读取的数据量。例如,即使条件 `Date != ' 2000-01-01 '` 匹配表中的所有数据(即运行查询需要全表扫描),该条件仍然是可接受的。有关 MergeTree 表中数据范围的更多信息,请参阅 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)。


## force_optimize_projection {#force_optimize_projection}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在 `SELECT` 查询中强制使用[投影](../../engines/table-engines/mergetree-family/mergetree.md/#projections),当投影优化已启用时(参见 [optimize_use_projections](#optimize_use_projections) 设置)。

可选值:

- 0 — 不强制使用投影优化。
- 1 — 强制使用投影优化。


## force_optimize_projection_name {#force_optimize_projection_name}

如果设置为非空字符串，则检查该投影在查询中是否至少使用了一次。

可能的值：

- string：查询中使用的投影名称


## force_optimize_skip_unused_shards {#force_optimize_skip_unused_shards}

<SettingsInfoBlock type='UInt64' default_value='0' />

当 [optimize_skip_unused_shards](#optimize_skip_unused_shards) 启用且无法跳过未使用的分片时,控制是否允许执行查询。如果无法跳过分片且该设置已启用,将抛出异常。

可能的值:

- 0 — 禁用。ClickHouse 不抛出异常。
- 1 — 启用。仅当表具有分片键时禁用查询执行。
- 2 — 启用。无论表是否定义分片键,均禁用查询执行。


## force_optimize_skip_unused_shards_nesting {#force_optimize_skip_unused_shards_nesting}

<SettingsInfoBlock type='UInt64' default_value='0' />

控制 [`force_optimize_skip_unused_shards`](#force_optimize_skip_unused_shards) 的行为(因此仍需启用 [`force_optimize_skip_unused_shards`](#force_optimize_skip_unused_shards)),具体取决于分布式查询的嵌套层级(即当一个 `Distributed` 表查询另一个 `Distributed` 表时的情况)。

可能的值:

- 0 - 禁用,`force_optimize_skip_unused_shards` 始终生效。
- 1 — 仅对第一层级启用 `force_optimize_skip_unused_shards`。
- 2 — 对最多两层级启用 `force_optimize_skip_unused_shards`。


## force_primary_key {#force_primary_key}

<SettingsInfoBlock type='Bool' default_value='0' />

当无法通过主键进行索引时,禁止执行查询。

适用于 MergeTree 系列表引擎。

当 `force_primary_key=1` 时,ClickHouse 会检查查询是否包含可用于限制数据范围的主键条件。如果不存在合适的条件,将抛出异常。但是,该设置不会检查条件是否实际减少了需要读取的数据量。有关 MergeTree 表中数据范围的更多信息,请参阅 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)。


## force_remove_data_recursively_on_drop {#force_remove_data_recursively_on_drop}

<SettingsInfoBlock type='Bool' default_value='0' />

在执行 DROP 查询时递归删除数据。可避免"目录非空"错误,但可能会静默删除已分离(detached)的数据


## formatdatetime_e_with_space_padding {#formatdatetime_e_with_space_padding}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "改进了与 MySQL DATE_FORMAT/STR_TO_DATE 的兼容性" }
      ]
    }
  ]}
/>

函数 'formatDateTime' 中的格式化符 '%e' 会在个位数日期前添加前导空格,例如 ' 2' 而不是 '2'。


## formatdatetime_f_prints_scale_number_of_digits {#formatdatetime_f_prints_scale_number_of_digits}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "0" }, { label: "新设置。" }]
    }
  ]}
/>

函数 'formatDateTime' 中的格式化符 '%f' 对于 DateTime64 类型仅打印与精度对应的位数，而非固定的 6 位数字。


## formatdatetime_f_prints_single_zero {#formatdatetime_f_prints_single_zero}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "0" },
        {
          label: "提升了与 MySQL DATE_FORMAT()/STR_TO_DATE() 的兼容性"
        }
      ]
    }
  ]}
/>

当格式化的值不包含小数秒时,函数 'formatDateTime' 中的格式化符 '%f' 将输出单个零而非六个零。


## formatdatetime_format_without_leading_zeros {#formatdatetime_format_without_leading_zeros}

<SettingsInfoBlock type='Bool' default_value='0' />

函数 `formatDateTime` 中的格式化符 `%c`、`%l` 和 `%k` 在打印月份和小时时不添加前导零。


## formatdatetime_parsedatetime_m_is_month_name {#formatdatetime_parsedatetime_m_is_month_name}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "1" },
        { label: "改进了与 MySQL DATE_FORMAT/STR_TO_DATE 的兼容性" }
      ]
    }
  ]}
/>

在 `formatDateTime` 和 `parseDateTime` 函数中,格式化符 `%M` 用于打印/解析月份名称而非分钟数。


## fsync_metadata {#fsync_metadata}

<SettingsInfoBlock type='Bool' default_value='1' />

启用或禁用写入 `.sql` 文件时的 [fsync](http://pubs.opengroup.org/onlinepubs/9699919799/functions/fsync.html) 操作。默认启用。

如果服务器存在数百万个频繁创建和销毁的小表,建议禁用此选项。


## function_date_trunc_return_type_behavior {#function_date_trunc_return_type_behavior}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "0" },
        {
          label:
            "添加新设置以保留 dateTrunc 函数的旧版行为"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.4" },
        { label: "0" },
        {
          label:
            "更改 dateTrunc 函数针对 DateTime64/Date32 参数的返回类型,无论时间单位如何均返回 DateTime64/Date32,以确保负值的正确结果"
        }
      ]
    }
  ]}
/>

控制 `dateTrunc` 函数返回类型的行为。

可选值:

- 0 - 当第二个参数为 `DateTime64/Date32` 时,无论第一个参数中的时间单位如何,返回类型均为 `DateTime64/Date32`。
- 1 - 对于 `Date32`,返回类型始终为 `Date`。对于 `DateTime64`,当时间单位为 `second` 或更高级别时,返回类型为 `DateTime`。


## function_implementation {#function_implementation}

为特定目标或变体选择函数实现(实验性)。如果为空,则启用所有实现。


## function_json_value_return_type_allow_complex {#function_json_value_return_type_allow_complex}

<SettingsInfoBlock type='Bool' default_value='0' />

控制 json_value 函数是否允许返回复杂类型(如:struct、array、map)。

```sql
SELECT JSON_VALUE('{"hello":{"world":"!"}}', '$.hello') settings function_json_value_return_type_allow_complex=true

┌─JSON_VALUE('{"hello":{"world":"!"}}', '$.hello')─┐
│ {"world":"!"}                                    │
└──────────────────────────────────────────────────┘

1 row in set. Elapsed: 0.001 sec.
```

可能的值:

- true — 允许。
- false — 不允许。


## function_json_value_return_type_allow_nullable {#function_json_value_return_type_allow_nullable}

<SettingsInfoBlock type='Bool' default_value='0' />

控制当 JSON_VALUE 函数中的值不存在时是否允许返回 `NULL`。

```sql
SELECT JSON_VALUE('{"hello":"world"}', '$.b') settings function_json_value_return_type_allow_nullable=true;

┌─JSON_VALUE('{"hello":"world"}', '$.b')─┐
│ ᴺᵁᴸᴸ                                   │
└────────────────────────────────────────┘

1 row in set. Elapsed: 0.001 sec.
```

可选值：

- true — 允许。
- false — 不允许。


## function_locate_has_mysql_compatible_argument_order {#function_locate_has_mysql_compatible_argument_order}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1" },
        { label: "增强与 MySQL locate 函数的兼容性。" }
      ]
    }
  ]}
/>

控制 [locate](../../sql-reference/functions/string-search-functions.md/#locate) 函数的参数顺序。

可选值：

- 0 — `locate` 函数接受参数 `(haystack, needle[, start_pos])`。
- 1 — `locate` 函数接受参数 `(needle, haystack[, start_pos])`(MySQL 兼容行为)


## function_range_max_elements_in_block {#function_range_max_elements_in_block}

<SettingsInfoBlock type='UInt64' default_value='500000000' />

设置函数 [range](/sql-reference/functions/array-functions#range) 生成的数据量安全阈值。定义函数在每个数据块中生成的最大值数量(即数据块中每行数组大小的总和)。

可能的值:

- 正整数。

**另请参阅**

- [`max_block_size`](#max_block_size)
- [`min_insert_block_size_rows`](#min_insert_block_size_rows)


## function_sleep_max_microseconds_per_block {#function_sleep_max_microseconds_per_block}

<SettingsInfoBlock type='UInt64' default_value='3000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.7" },
        { label: "3000000" },
        {
          label:
            "在之前的版本中,3 秒的最大休眠时间仅适用于 `sleep` 函数,而不适用于 `sleepEachRow` 函数。在新版本中引入了此设置。如果设置与之前版本的兼容性,将完全禁用此限制。"
        }
      ]
    }
  ]}
/>

函数 `sleep` 在每个数据块中允许休眠的最大微秒数。如果用户调用时使用了更大的值,将抛出异常。这是一个安全阈值。


## function_visible_width_behavior {#function_visible_width_behavior}

<SettingsInfoBlock type='UInt64' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "1" },
        {
          label:
            "我们更改了 `visibleWidth` 的默认行为以提高精确度"
        }
      ]
    }
  ]}
/>

`visibleWidth` 行为的版本。0 - 仅计算码点数量；1 - 正确计算零宽字符和组合字符,将全角字符计为两个字符宽度,估算制表符宽度,计算删除字符。


## geo_distance_returns_float64_on_float64_arguments {#geo_distance_returns_float64_on_float64_arguments}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1" },
        { label: "提高默认精度。" }
      ]
    }
  ]}
/>

如果 `geoDistance`、`greatCircleDistance`、`greatCircleAngle` 函数的全部四个参数均为 Float64 类型,则返回 Float64 并在内部计算时使用双精度。在早期的 ClickHouse 版本中,这些函数始终返回 Float32。


## geotoh3_argument_order {#geotoh3_argument_order}

<BetaBadge />

<SettingsInfoBlock type='GeoToH3ArgumentOrder' default_value='lat_lon' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "lat_lon" },
        {
          label:
            "用于保持旧版行为的新设置,可指定经度和纬度的参数顺序"
        }
      ]
    }
  ]}
/>

当设置为 'lon_lat' 时,函数 'geoToH3' 接受 (经度, 纬度) 参数顺序;当设置为 'lat_lon' 时,接受 (纬度, 经度) 参数顺序。


## glob_expansion_max_elements {#glob_expansion_max_elements}

<SettingsInfoBlock type='UInt64' default_value='1000' />

允许的最大地址数(用于外部存储、表函数等)。


## grace_hash_join_initial_buckets {#grace_hash_join_initial_buckets}

<ExperimentalBadge />

<SettingsInfoBlock type='NonZeroUInt64' default_value='1' />

Grace Hash Join 的初始分桶数量


## grace_hash_join_max_buckets {#grace_hash_join_max_buckets}

<ExperimentalBadge />

<SettingsInfoBlock type='NonZeroUInt64' default_value='1024' />

Grace Hash Join 分桶数量的上限


## group_by_overflow_mode {#group_by_overflow_mode}

<SettingsInfoBlock type='OverflowModeGroupBy' default_value='throw' />

设置当聚合的唯一键数量超过限制时的处理方式:

- `throw`: 抛出异常
- `break`: 停止执行查询并返回部分结果
- `any`: 对已进入集合的键继续聚合,但不向集合添加新键

使用 'any' 值可以运行近似的 GROUP BY。此近似结果的质量取决于数据的统计特性。


## group_by_two_level_threshold {#group_by_two_level_threshold}

<SettingsInfoBlock type='UInt64' default_value='100000' />

当键数量达到此值时启用两级聚合。0 表示不设置阈值。


## group_by_two_level_threshold_bytes {#group_by_two_level_threshold_bytes}

<SettingsInfoBlock type='UInt64' default_value='50000000' />

当聚合状态的大小达到指定字节数时,开始使用两级聚合。设置为 0 表示不设置阈值。当至少满足其中一个阈值条件时,将使用两级聚合。


## group_by_use_nulls {#group_by_use_nulls}

<SettingsInfoBlock type='Bool' default_value='0' />

更改 [GROUP BY 子句](/sql-reference/statements/select/group-by) 处理聚合键类型的方式。
当使用 `ROLLUP`、`CUBE` 或 `GROUPING SETS` 修饰符时,某些聚合键可能不会用于生成某些结果行。
根据此设置,这些键对应的列在相应行中将填充默认值或 `NULL`。

可能的值:

- 0 — 使用聚合键类型的默认值来填充缺失值。
- 1 — ClickHouse 按照 SQL 标准的方式执行 `GROUP BY`。聚合键的类型会转换为 [Nullable](/sql-reference/data-types/nullable)。对于未使用相应聚合键的行,其列将填充 [NULL](/sql-reference/syntax#null)。

另请参阅:

- [GROUP BY 子句](/sql-reference/statements/select/group-by)


## h3togeo_lon_lat_result_order {#h3togeo_lon_lat_result_order}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

当此设置为 true 时,函数 'h3ToGeo' 返回 (经度, 纬度),否则返回 (纬度, 经度)。


## handshake_timeout_ms {#handshake_timeout_ms}

<SettingsInfoBlock type='Milliseconds' default_value='10000' />

握手期间从副本接收 Hello 数据包的超时时间(以毫秒为单位)。


## hdfs_create_new_file_on_insert {#hdfs_create_new_file_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在 HDFS 引擎表中每次插入数据时创建新文件。启用后,每次插入操作都会创建一个新的 HDFS 文件,文件名遵循以下模式:

初始文件:`data.Parquet.gz` -> `data.1.Parquet.gz` -> `data.2.Parquet.gz`,依此类推。

可选值:

- 0 — `INSERT` 查询将新数据追加到文件末尾。
- 1 — `INSERT` 查询创建新文件。


## hdfs_ignore_file_doesnt_exist {#hdfs_ignore_file_doesnt_exist}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "允许在 HDFS 表引擎中当请求的文件不存在时返回 0 行,而不是抛出异常"
        }
      ]
    }
  ]}
/>

读取特定键时,如果文件不存在则忽略文件缺失。

可能的值:

- 1 — `SELECT` 返回空结果。
- 0 — `SELECT` 抛出异常。


## hdfs_replication {#hdfs_replication}

<SettingsInfoBlock type='UInt64' default_value='0' />

创建 HDFS 文件时可以指定实际的副本数量。


## hdfs_skip_empty_files {#hdfs_skip_empty_files}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在 [HDFS](../../engines/table-engines/integrations/hdfs.md) 引擎表中跳过空文件的功能。

可能的值：

- 0 — 当空文件与请求的格式不兼容时，`SELECT` 抛出异常。
- 1 — 对于空文件，`SELECT` 返回空结果。


## hdfs_throw_on_zero_files_match {#hdfs_throw_on_zero_files_match}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "当 HDFS 引擎中的 ListObjects 请求无法匹配任何文件时,允许抛出错误而非返回空查询结果"
        }
      ]
    }
  ]}
/>

当根据 glob 扩展规则未匹配到任何文件时抛出错误。

可选值:

- 1 — `SELECT` 抛出异常。
- 0 — `SELECT` 返回空结果。


## hdfs_truncate_on_insert {#hdfs_truncate_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在 HDFS 引擎表中插入数据前的截断操作。如果禁用,当 HDFS 中的文件已存在时,尝试插入将抛出异常。

可选值:

- 0 — `INSERT` 查询将新数据追加到文件末尾。
- 1 — `INSERT` 查询将文件的现有内容替换为新数据。


## hedged_connection_timeout_ms {#hedged_connection_timeout_ms}

<SettingsInfoBlock type='Milliseconds' default_value='50' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "50" },
        {
          label:
            "对冲请求在 50 毫秒后启动新连接（而非 100 毫秒），以与之前的连接超时设置保持一致"
        }
      ]
    }
  ]}
/>

对冲请求与副本建立连接的超时时间


## hnsw_candidate_list_size_for_search {#hnsw_candidate_list_size_for_search}

<SettingsInfoBlock type='UInt64' default_value='256' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "256" },
        {
          label:
            "新增设置。此前,该值可在 CREATE INDEX 中可选指定,默认值为 64。"
        }
      ]
    }
  ]}
/>

搜索向量相似度索引时的动态候选列表大小,也称为 'ef_search'。


## hsts_max_age {#hsts_max_age}

<SettingsInfoBlock type='UInt64' default_value='0' />

HSTS 的过期时间。设置为 0 表示禁用 HSTS。


## http_connection_timeout {#http_connection_timeout}

<SettingsInfoBlock type='Seconds' default_value='1' />

HTTP 连接超时时间(单位:秒)。

可选值:

- 任意正整数。
- 0 - 禁用(无限超时)。


## http_headers_progress_interval_ms {#http_headers_progress_interval_ms}

<SettingsInfoBlock type='UInt64' default_value='100' />

不要以超过指定间隔的频率发送 HTTP 头 X-ClickHouse-Progress。


## http_make_head_request {#http_make_head_request}

<SettingsInfoBlock type='Bool' default_value='1' />

`http_make_head_request` 设置允许在从 HTTP 读取数据时执行 `HEAD` 请求,以获取待读取文件的信息(如文件大小)。由于默认启用该设置,当服务器不支持 `HEAD` 请求时,可能需要禁用此设置。


## http_max_field_name_size {#http_max_field_name_size}

<SettingsInfoBlock type='UInt64' default_value='131072' />

HTTP 头字段名称的最大长度


## http_max_field_value_size {#http_max_field_value_size}

<SettingsInfoBlock type='UInt64' default_value='131072' />

HTTP 头字段值的最大长度


## http_max_fields {#http_max_fields}

<SettingsInfoBlock type='UInt64' default_value='1000000' />

HTTP 标头中的最大字段数


## http_max_multipart_form_data_size {#http_max_multipart_form_data_size}

<SettingsInfoBlock type='UInt64' default_value='1073741824' />

限制 multipart/form-data 内容的大小。此设置无法通过 URL 参数解析,必须在用户配置文件中设置。请注意,在查询执行开始之前,内容会被解析且外部表会在内存中创建。这是唯一在该阶段生效的限制(最大内存使用量和最大执行时间的限制在读取 HTTP 表单数据时不生效)。


## http_max_request_param_data_size {#http_max_request_param_data_size}

<SettingsInfoBlock type='UInt64' default_value='10485760' />

限制预定义 HTTP 请求中作为查询参数使用的请求数据的大小。


## http_max_tries {#http_max_tries}

<SettingsInfoBlock type='UInt64' default_value='10' />

通过 HTTP 读取数据的最大尝试次数。


## http_max_uri_size {#http_max_uri_size}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

设置 HTTP 请求的最大 URI 长度。

可选值：

- 正整数。


## http_native_compression_disable_checksumming_on_decompress {#http_native_compression_disable_checksumming_on_decompress}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在解压缩来自客户端的 HTTP POST 数据时的校验和验证。仅适用于 ClickHouse 原生压缩格式(不适用于 `gzip` 或 `deflate`)。

更多信息请参阅 [HTTP 接口说明](../../interfaces/http.md)。

可能的值:

- 0 — 禁用。
- 1 — 启用。


## http_receive_timeout {#http_receive_timeout}

<SettingsInfoBlock type='Seconds' default_value='30' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.6" },
        { label: "30" },
        { label: "参见 http_send_timeout。" }
      ]
    }
  ]}
/>

HTTP 接收超时时间(以秒为单位)。

可选值:

- 任意正整数。
- 0 - 禁用(无限超时)。


## http_response_buffer_size {#http_response_buffer_size}

<SettingsInfoBlock type='UInt64' default_value='0' />

在向客户端发送 HTTP 响应或刷新到磁盘之前(当启用 http_wait_end_of_query 时),服务器内存中缓冲的字节数。


## http_response_headers {#http_response_headers}

<SettingsInfoBlock type='Map' default_value='{}' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.12" }, { label: "" }, { label: "新增设置。" }]
    }
  ]}
/>

允许添加或覆盖服务器在成功查询结果的响应中返回的 HTTP 头。
此设置仅影响 HTTP 接口。

如果某个头已有默认设置,提供的值将覆盖默认值。
如果某个头没有默认设置,它将被添加到头列表中。
服务器默认设置且未被此设置覆盖的头将保持不变。

此设置允许您将头设置为常量值。目前无法将头设置为动态计算的值。

名称和值均不能包含 ASCII 控制字符。

如果您实现的 UI 应用程序允许用户修改设置,但同时需要根据返回的头做出决策,建议将此设置限制为只读。

示例:`SET http_response_headers = '{"Content-Type": "image/png"}'`


## http_retry_initial_backoff_ms {#http_retry_initial_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='100' />

通过 HTTP 重试读取时的退避最小毫秒数


## http_retry_max_backoff_ms {#http_retry_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='10000' />

通过 HTTP 重试读取时退避的最大毫秒数


## http_send_timeout {#http_send_timeout}

<SettingsInfoBlock type='Seconds' default_value='30' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.6" },
        { label: "30" },
        {
          label:
            "3 分钟似乎过长。注意，这是单次网络写入调用的超时时间，而非整个上传操作的超时时间。"
        }
      ]
    }
  ]}
/>

HTTP 发送超时时间（秒）。

可选值：

- 任意正整数。
- 0 - 禁用（无限超时）。

:::note
仅适用于默认配置文件。更改生效需要重启服务器。
:::


## http_skip_not_found_url_for_globs {#http_skip_not_found_url_for_globs}

<SettingsInfoBlock type='Bool' default_value='1' />

跳过 glob 模式中返回 HTTP_NOT_FOUND 错误的 URL


## http_wait_end_of_query {#http_wait_end_of_query}

<SettingsInfoBlock type='Bool' default_value='0' />

在服务器端启用 HTTP 响应缓冲。


## http_write_exception_in_output_format {#http_write_exception_in_output_format}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "0" },
        { label: "为保持各格式间的一致性而更改" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "23.9" },
        { label: "1" },
        { label: "在 HTTP 流式传输中发生异常时输出有效的 JSON/XML 格式。" }
      ]
    }
  ]}
/>

在输出格式中写入异常信息以生成有效输出。适用于 JSON 和 XML 格式。


## http_zlib_compression_level {#http_zlib_compression_level}

<SettingsInfoBlock type='Int64' default_value='3' />

当 [enable_http_compression = 1](#enable_http_compression) 时,设置 HTTP 请求响应中的数据压缩级别。

可选值:1 到 9 的数字。


## iceberg_delete_data_on_drop {#iceberg_delete_data_on_drop}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "New setting" }]
    }
  ]}
/>

是否在删除表时删除所有 Iceberg 文件。


## iceberg_insert_max_bytes_in_data_file {#iceberg_insert_max_bytes_in_data_file}

<SettingsInfoBlock type='UInt64' default_value='1073741824' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.9" },
        { label: "1073741824" },
        { label: "新设置。" }
      ]
    }
  ]}
/>

插入操作时 Iceberg Parquet 数据文件的最大字节数。


## iceberg_insert_max_partitions {#iceberg_insert_max_partitions}

<SettingsInfoBlock type='UInt64' default_value='100' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "100" }, { label: "新增设置。" }]
    }
  ]}
/>

Iceberg 表引擎单次插入操作允许的最大分区数。


## iceberg_insert_max_rows_in_data_file {#iceberg_insert_max_rows_in_data_file}

<SettingsInfoBlock type='UInt64' default_value='1000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.9" },
        { label: "1000000" },
        { label: "新增设置。" }
      ]
    }
  ]}
/>

插入操作中 Iceberg Parquet 数据文件的最大行数。


## iceberg_metadata_compression_method {#iceberg_metadata_compression_method}

<ExperimentalBadge />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "" }, { label: "New setting" }]
    }
  ]}
/>

用于压缩 `.metadata.json` 文件的方法。


## iceberg_metadata_log_level {#iceberg_metadata_log_level}

<SettingsInfoBlock type='IcebergMetadataLogLevel' default_value='none' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "none" }, { label: "新增设置。" }]
    }
  ]}
/>

控制 Iceberg 表向 system.iceberg_metadata_log 记录元数据的日志级别。
通常可以出于调试目的修改此设置。

可能的值:

- none - 不记录元数据日志。
- metadata - 根 metadata.json 文件。
- manifest_list_metadata - 以上所有内容 + 对应快照的 avro 清单列表元数据。
- manifest_list_entry - 以上所有内容 + avro 清单列表条目。
- manifest_file_metadata - 以上所有内容 + 已遍历的 avro 清单文件元数据。
- manifest_file_entry - 以上所有内容 + 已遍历的 avro 清单文件条目。


## iceberg_snapshot_id {#iceberg_snapshot_id}

<SettingsInfoBlock type='Int64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

使用指定的快照 ID 查询 Iceberg 表。


## iceberg_timestamp_ms {#iceberg_timestamp_ms}

<SettingsInfoBlock type='Int64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

使用指定时间戳对应的快照查询 Iceberg 表。


## idle_connection_timeout {#idle_connection_timeout}

<SettingsInfoBlock type='UInt64' default_value='3600' />

在指定秒数后关闭空闲 TCP 连接的超时时间。

可能的值:

- 正整数(0 表示立即关闭)。


## ignore_cold_parts_seconds {#ignore_cold_parts_seconds}

<CloudOnlyBadge />

<SettingsInfoBlock type='Int64' default_value='0' />

仅在 ClickHouse Cloud 中生效。在新数据分区预热完成(参见 [cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch))或经过指定秒数之前,将其从 SELECT 查询中排除。仅适用于 Replicated-/SharedMergeTree 表引擎。


## ignore_data_skipping_indices {#ignore_data_skipping_indices}

忽略查询中使用的指定跳数索引。

请参考以下示例:

```sql
CREATE TABLE data
(
    key Int,
    x Int,
    y Int,
    INDEX x_idx x TYPE minmax GRANULARITY 1,
    INDEX y_idx y TYPE minmax GRANULARITY 1,
    INDEX xy_idx (x,y) TYPE minmax GRANULARITY 1
)
Engine=MergeTree()
ORDER BY key;

INSERT INTO data VALUES (1, 2, 3);

SELECT * FROM data;
SELECT * FROM data SETTINGS ignore_data_skipping_indices=''; -- 查询将产生 CANNOT_PARSE_TEXT 错误。
SELECT * FROM data SETTINGS ignore_data_skipping_indices='x_idx'; -- 正常。
SELECT * FROM data SETTINGS ignore_data_skipping_indices='na_idx'; -- 正常。

SELECT * FROM data WHERE x = 1 AND y = 1 SETTINGS ignore_data_skipping_indices='xy_idx',force_data_skipping_indices='xy_idx' ; -- 查询将产生 INDEX_NOT_USED 错误,因为 xy_idx 被显式忽略。
SELECT * FROM data WHERE x = 1 AND y = 2 SETTINGS ignore_data_skipping_indices='xy_idx';
```

不忽略任何索引的查询:

```sql
EXPLAIN indexes = 1 SELECT * FROM data WHERE x = 1 AND y = 2;

Expression ((Projection + Before ORDER BY))
  Filter (WHERE)
    ReadFromMergeTree (default.data)
    Indexes:
      PrimaryKey
        条件: true
        数据分片: 1/1
        数据粒度: 1/1
      Skip
        Name: x_idx
        描述: minmax GRANULARITY 1
        数据分片: 0/1
        数据粒度: 0/1
      Skip
        Name: y_idx
        描述: minmax GRANULARITY 1
        数据分片: 0/0
        数据粒度: 0/0
      Skip
        Name: xy_idx
        描述: minmax GRANULARITY 1
        数据分片: 0/0
        数据粒度: 0/0
```

忽略 `xy_idx` 索引:

```sql
EXPLAIN indexes = 1 SELECT * FROM data WHERE x = 1 AND y = 2 SETTINGS ignore_data_skipping_indices='xy_idx';

Expression ((Projection + Before ORDER BY))
  Filter (WHERE)
    ReadFromMergeTree (default.data)
    Indexes:
      PrimaryKey
        条件: true
        数据分片: 1/1
        数据粒度: 1/1
      Skip
        Name: x_idx
        描述: minmax GRANULARITY 1
        数据分片: 0/1
        数据粒度: 0/1
      Skip
        Name: y_idx
        描述: minmax GRANULARITY 1
        数据分片: 0/0
        数据粒度: 0/0
```

适用于 MergeTree 系列表。


## ignore_drop_queries_probability {#ignore_drop_queries_probability}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "0" },
        {
          label:
            "允许服务器以指定概率忽略 DROP 查询,用于测试目的"
        }
      ]
    }
  ]}
/>

启用后,服务器将以指定概率忽略所有 DROP TABLE 查询(对于 Memory 和 JOIN 引擎,会将 DROP 替换为 TRUNCATE)。用于测试目的


## ignore_materialized_views_with_dropped_target_table {#ignore_materialized_views_with_dropped_target_table}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "0" },
        {
          label:
            "新增设置,允许忽略目标表已被删除的物化视图"
        }
      ]
    }
  ]}
/>

在向视图推送数据时忽略目标表已被删除的物化视图


## ignore_on_cluster_for_replicated_access_entities_queries {#ignore_on_cluster_for_replicated_access_entities_queries}

<SettingsInfoBlock type='Bool' default_value='0' />

忽略复制访问实体管理查询的 ON CLUSTER 子句。


## ignore_on_cluster_for_replicated_named_collections_queries {#ignore_on_cluster_for_replicated_named_collections_queries}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "0" },
        {
          label:
            "忽略复制命名集合管理查询中的 ON CLUSTER 子句。"
        }
      ]
    }
  ]}
/>

忽略复制命名集合管理查询中的 ON CLUSTER 子句。


## ignore_on_cluster_for_replicated_udf_queries {#ignore_on_cluster_for_replicated_udf_queries}

<SettingsInfoBlock type='Bool' default_value='0' />

对于复制的 UDF 管理查询，忽略 ON CLUSTER 子句。


## implicit_select {#implicit_select}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

允许编写不带前导 SELECT 关键字的简单 SELECT 查询,从而简化计算器式的使用方式,例如 `1 + 2` 即可成为有效查询。

在 `clickhouse-local` 中此设置默认启用,可显式禁用。


## implicit_table_at_top_level {#implicit_table_at_top_level}

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "" },
        { label: "新增设置,用于 clickhouse-local" }
      ]
    }
  ]}
/>

如果不为空,顶层不含 FROM 子句的查询将从此表读取数据,而非从 system.one 读取。

此设置用于 clickhouse-local 的输入数据处理。
该设置可由用户显式设置,但并非为此类用途而设计。

子查询不受此设置影响(标量子查询、FROM 子查询和 IN 子查询均不受影响)。
UNION、INTERSECT、EXCEPT 链顶层的 SELECT 语句将被统一处理并受此设置影响,无论其在括号中如何分组。
此设置对视图和分布式查询的影响尚未明确定义。

该设置接受表名(表将从当前数据库解析)或 'database.table' 形式的限定名称。
数据库名和表名均不得使用引号 - 仅允许简单标识符。


## implicit_transaction {#implicit_transaction}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

如果启用该设置且当前不在事务中,则会将查询包装在一个完整的事务内(begin + commit 或 rollback)


## inject_random_order_for_select_without_order_by {#inject_random_order_for_select_without_order_by}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

启用后,会向没有 ORDER BY 子句的 SELECT 查询中注入 'ORDER BY rand()'。
仅应用于子查询深度为 0 的情况。子查询和 INSERT INTO ... SELECT 不受影响。
如果顶层结构是 UNION,则会独立地向所有子查询注入 'ORDER BY rand()'。
仅用于测试和开发(缺少 ORDER BY 会导致查询结果不确定)。


## input_format_parallel_parsing {#input_format_parallel_parsing}

<SettingsInfoBlock type='Bool' default_value='1' />

启用或禁用数据格式的保序并行解析。仅支持 [TabSeparated (TSV)](/interfaces/formats/TabSeparated)、[TSKV](/interfaces/formats/TSKV)、[CSV](/interfaces/formats/CSV) 和 [JSONEachRow](/interfaces/formats/JSONEachRow) 格式。

可选值：

- 1 — 启用。
- 0 — 禁用。


## insert_allow_materialized_columns {#insert_allow_materialized_columns}

<SettingsInfoBlock type='Bool' default_value='0' />

如果启用此设置,则允许在 INSERT 语句中使用物化列。


## insert_deduplicate {#insert_deduplicate}

<SettingsInfoBlock type='Bool' default_value='1' />

启用或禁用 `INSERT` 的块去重功能(适用于 Replicated\* 表)。

可能的值:

- 0 — 禁用。
- 1 — 启用。

默认情况下,通过 `INSERT` 语句插入到复制表中的数据块会进行去重(参见[数据复制](../../engines/table-engines/mergetree-family/replication.md))。
对于复制表,默认情况下每个分区仅对最近的 100 个数据块进行去重(参见 [replicated_deduplication_window](merge-tree-settings.md/#replicated_deduplication_window)、[replicated_deduplication_window_seconds](merge-tree-settings.md/#replicated_deduplication_window_seconds))。
对于非复制表,请参见 [non_replicated_deduplication_window](merge-tree-settings.md/#non_replicated_deduplication_window)。


## insert_deduplication_token {#insert_deduplication_token}

该设置允许用户在 MergeTree/ReplicatedMergeTree 中自定义去重语义。
例如,通过在每个 INSERT 语句中为该设置提供唯一值,
用户可以避免相同的插入数据被去重。

可能的值:

- 任意字符串

`insert_deduplication_token` _仅_在非空时用于去重。

对于复制表,默认情况下每个分区仅对最近的 100 次插入进行去重(参见 [replicated_deduplication_window](merge-tree-settings.md/#replicated_deduplication_window)、[replicated_deduplication_window_seconds](merge-tree-settings.md/#replicated_deduplication_window_seconds))。
对于非复制表,请参见 [non_replicated_deduplication_window](merge-tree-settings.md/#non_replicated_deduplication_window)。

:::note
`insert_deduplication_token` 在分区级别生效(与 `insert_deduplication` 校验和相同)。多个分区可以使用相同的 `insert_deduplication_token`。
:::

示例:

```sql
CREATE TABLE test_table
( A Int64 )
ENGINE = MergeTree
ORDER BY A
SETTINGS non_replicated_deduplication_window = 100;

INSERT INTO test_table SETTINGS insert_deduplication_token = 'test' VALUES (1);

-- 下一次插入不会被去重,因为 insert_deduplication_token 不同
INSERT INTO test_table SETTINGS insert_deduplication_token = 'test1' VALUES (1);

-- 下一次插入将被去重,因为 insert_deduplication_token
-- 与之前的某次插入相同
INSERT INTO test_table SETTINGS insert_deduplication_token = 'test' VALUES (2);

SELECT * FROM test_table

┌─A─┐
│ 1 │
└───┘
┌─A─┐
│ 1 │
└───┘
```


## insert_keeper_fault_injection_probability {#insert_keeper_fault_injection_probability}

<SettingsInfoBlock type='Float' default_value='0' />

插入操作期间 Keeper 请求失败的近似概率。有效值区间为 [0.0f, 1.0f]


## insert_keeper_fault_injection_seed {#insert_keeper_fault_injection_seed}

<SettingsInfoBlock type='UInt64' default_value='0' />

0 - 随机种子,其他值 - 使用该设置值


## insert_keeper_max_retries {#insert_keeper_max_retries}

<SettingsInfoBlock type='UInt64' default_value='20' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.2" },
        { label: "20" },
        {
          label: "在 INSERT 操作中启用 Keeper 重连,提升可靠性"
        }
      ]
    }
  ]}
/>

此设置用于设定向复制 MergeTree 表插入数据时,ClickHouse Keeper(或 ZooKeeper)请求的最大重试次数。仅当 Keeper 请求因网络错误、Keeper 会话超时或请求超时而失败时才会进行重试。

可能的值:

- 正整数。
- 0 — 禁用重试

Cloud 默认值:`20`。

Keeper 请求重试会在一定的超时时间后执行。超时时间由以下设置控制:`insert_keeper_retry_initial_backoff_ms`、`insert_keeper_retry_max_backoff_ms`。
首次重试会在 `insert_keeper_retry_initial_backoff_ms` 超时后执行。后续的超时时间将按以下方式计算:

```
timeout = min(insert_keeper_retry_max_backoff_ms, latest_timeout * 2)
```

例如,如果 `insert_keeper_retry_initial_backoff_ms=100`、`insert_keeper_retry_max_backoff_ms=10000` 且 `insert_keeper_max_retries=8`,则超时时间将为 `100, 200, 400, 800, 1600, 3200, 6400, 10000`。

除了提供容错能力之外,重试机制还旨在提升用户体验 — 当 Keeper 因升级等原因重启时,可以避免在 INSERT 执行期间返回错误。


## insert_keeper_retry_initial_backoff_ms {#insert_keeper_retry_initial_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='100' />

在执行 INSERT 查询期间重试失败的 Keeper 请求的初始退避超时时间(毫秒)

可选值:

- 正整数。
- 0 — 无超时


## insert_keeper_retry_max_backoff_ms {#insert_keeper_retry_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='10000' />

INSERT 查询执行期间重试失败 Keeper 请求的最大退避超时时间(毫秒)

可能的值:

- 正整数
- 0 — 不限制最大超时时间


## insert_null_as_default {#insert_null_as_default}

<SettingsInfoBlock type='Bool' default_value='1' />

启用或禁用在非[可空](/sql-reference/data-types/nullable)数据类型的列中插入[默认值](/sql-reference/statements/create/table#default_values)以替代 [NULL](/sql-reference/syntax#null)。
如果列类型不可空且此设置被禁用,则插入 `NULL` 会导致异常。如果列类型可空,则无论此设置如何,`NULL` 值都会按原样插入。

此设置适用于 [INSERT ... SELECT](../../sql-reference/statements/insert-into.md/#inserting-the-results-of-select) 查询。请注意,`SELECT` 子查询可以通过 `UNION ALL` 子句进行连接。

可能的值:

- 0 — 将 `NULL` 插入不可空列会导致异常。
- 1 — 插入默认列值以替代 `NULL`。


## insert_quorum {#insert_quorum}

<SettingsInfoBlock type='UInt64Auto' default_value='0' />

:::note
此设置不适用于 SharedMergeTree，更多信息请参阅 [SharedMergeTree 一致性](/cloud/reference/shared-merge-tree#consistency)。
:::

启用仲裁写入。

- 如果 `insert_quorum < 2`，则禁用仲裁写入。
- 如果 `insert_quorum >= 2`，则启用仲裁写入。
- 如果 `insert_quorum = 'auto'`，则使用多数值（`number_of_replicas / 2 + 1`）作为仲裁数。

仲裁写入

只有当 ClickHouse 在 `insert_quorum_timeout` 时间内成功将数据写入 `insert_quorum` 个副本时，`INSERT` 才会成功。如果由于任何原因成功写入的副本数量未达到 `insert_quorum`，则写入被视为失败，ClickHouse 将从所有已写入数据的副本中删除已插入的数据块。

当 `insert_quorum_parallel` 被禁用时，仲裁中的所有副本都是一致的，即它们包含所有先前 `INSERT` 查询的数据（`INSERT` 序列被线性化）。当读取使用 `insert_quorum` 写入的数据且 `insert_quorum_parallel` 被禁用时，您可以使用 [select_sequential_consistency](#select_sequential_consistency) 为 `SELECT` 查询启用顺序一致性。

ClickHouse 会生成异常：

- 如果查询时可用副本的数量少于 `insert_quorum`。
- 当 `insert_quorum_parallel` 被禁用且在前一个数据块尚未插入到 `insert_quorum` 个副本时尝试写入数据。如果用户在带有 `insert_quorum` 的前一个 `INSERT` 查询完成之前尝试对同一表执行另一个 `INSERT` 查询，则可能会出现这种情况。

另请参阅：

- [insert_quorum_timeout](#insert_quorum_timeout)
- [insert_quorum_parallel](#insert_quorum_parallel)
- [select_sequential_consistency](#select_sequential_consistency)


## insert_quorum_parallel {#insert_quorum_parallel}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.1" },
        { label: "1" },
        {
          label:
            "默认使用并行仲裁插入。相比顺序仲裁插入,使用起来更加便捷"
        }
      ]
    }
  ]}
/>

:::note
此设置不适用于 SharedMergeTree,详情请参阅 [SharedMergeTree 一致性](/cloud/reference/shared-merge-tree#consistency)。
:::

启用或禁用仲裁 `INSERT` 查询的并行执行。启用后,可以在先前的查询尚未完成时发送新的 `INSERT` 查询。禁用后,对同一表的后续写入将被拒绝。

可能的值:

- 0 — 禁用。
- 1 — 启用。

另请参阅:

- [insert_quorum](#insert_quorum)
- [insert_quorum_timeout](#insert_quorum_timeout)
- [select_sequential_consistency](#select_sequential_consistency)


## insert_quorum_timeout {#insert_quorum_timeout}

<SettingsInfoBlock type='Milliseconds' default_value='600000' />

写入仲裁的超时时间(以毫秒为单位)。如果超时时间已过但尚未完成写入,ClickHouse 将抛出异常,客户端必须重新执行查询以将相同的数据块写入相同或其他副本。

另请参阅:

- [insert_quorum](#insert_quorum)
- [insert_quorum_parallel](#insert_quorum_parallel)
- [select_sequential_consistency](#select_sequential_consistency)


## insert_shard_id {#insert_shard_id}

<SettingsInfoBlock type='UInt64' default_value='0' />

如果不为 `0`,则指定数据将同步插入到 [Distributed](/engines/table-engines/special/distributed) 表的哪个分片。

如果 `insert_shard_id` 的值不正确,服务器将抛出异常。

要获取 `requested_cluster` 的分片数量,可以检查服务器配置或使用以下查询:

```sql
SELECT uniq(shard_num) FROM system.clusters WHERE cluster = 'requested_cluster';
```

可能的值:

- 0 — 禁用。
- 从 `1` 到相应 [Distributed](/engines/table-engines/special/distributed) 表的 `shards_num` 之间的任意数字。

**示例**

查询:

```sql
CREATE TABLE x AS system.numbers ENGINE = MergeTree ORDER BY number;
CREATE TABLE x_dist AS x ENGINE = Distributed('test_cluster_two_shards_localhost', currentDatabase(), x);
INSERT INTO x_dist SELECT * FROM numbers(5) SETTINGS insert_shard_id = 1;
SELECT * FROM x_dist ORDER BY number ASC;
```

结果:

```text
┌─number─┐
│      0 │
│      0 │
│      1 │
│      1 │
│      2 │
│      2 │
│      3 │
│      3 │
│      4 │
│      4 │
└────────┘
```


## interactive_delay {#interactive_delay}

<SettingsInfoBlock type='UInt64' default_value='100000' />

以微秒为单位的时间间隔,用于检查请求执行是否已取消以及发送进度。


## intersect_default_mode {#intersect_default_mode}

<SettingsInfoBlock type='SetOperationMode' default_value='ALL' />

设置 INTERSECT 查询中的默认模式。可选值：空字符串、'ALL'、'DISTINCT'。如果为空，则不指定模式的查询将抛出异常。


## jemalloc_collect_profile_samples_in_trace_log {#jemalloc_collect_profile_samples_in_trace_log}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

在跟踪日志中收集 jemalloc 的内存分配和释放样本。


## jemalloc_enable_profiler {#jemalloc_enable_profiler}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

为查询启用 jemalloc 性能分析器。Jemalloc 将对内存分配以及已采样分配的释放操作进行采样。
可以使用 SYSTEM JEMALLOC FLUSH PROFILE 命令刷新性能分析数据,以便进行内存分配分析。
采样数据也可以通过配置项 jemalloc_collect_global_profile_samples_in_trace_log 或查询设置 jemalloc_collect_profile_samples_in_trace_log 存储到 system.trace_log 表中。
参见[内存分配性能分析](/operations/allocation-profiling)


## join_algorithm {#join_algorithm}

<SettingsInfoBlock
  type='JoinAlgorithm'
  default_value='direct,parallel_hash,hash'
/>

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "direct,parallel_hash,hash" },
        {
          label:
            "'default' 已弃用,改为显式指定连接算法,同时 parallel_hash 现在优先于 hash"
        }
      ]
    }
  ]}
/>

指定使用哪种 [JOIN](../../sql-reference/statements/select/join.md) 算法。

可以指定多个算法,系统会根据连接类型/严格性和表引擎为特定查询选择一个可用的算法。

可选值:

- grace_hash

使用 [Grace hash join](https://en.wikipedia.org/wiki/Hash_join#Grace_hash_join)。Grace hash 提供了一种算法选项,可在限制内存使用的同时实现高性能的复杂连接。

grace join 的第一阶段读取右表并根据键列的哈希值将其拆分为 N 个桶(初始时,N 为 `grace_hash_join_initial_buckets`)。这样做是为了确保每个桶可以独立处理。第一个桶中的行被添加到内存哈希表中,而其他行则保存到磁盘。如果哈希表增长超过内存限制(例如,由 [`max_bytes_in_join`](/operations/settings/settings#max_bytes_in_join) 设置),则会增加桶的数量并重新分配每行所属的桶。任何不属于当前桶的行都会被刷新并重新分配。

支持 `INNER/LEFT/RIGHT/FULL ALL/ANY JOIN`。

- hash

使用[哈希连接算法](https://en.wikipedia.org/wiki/Hash_join)。这是最通用的实现,支持所有类型和严格性的组合,以及在 `JOIN ON` 部分中使用 `OR` 组合的多个连接键。

使用 `hash` 算法时,`JOIN` 的右侧部分会被加载到内存中。

- parallel_hash

`hash` join 的一种变体,将数据拆分为多个桶并并发构建多个哈希表而不是一个,以加快此过程。

使用 `parallel_hash` 算法时,`JOIN` 的右侧部分会被加载到内存中。

- partial_merge

[排序合并算法](https://en.wikipedia.org/wiki/Sort-merge_join)的一种变体,其中仅对右表进行完全排序。

`RIGHT JOIN` 和 `FULL JOIN` 仅支持 `ALL` 严格性(不支持 `SEMI`、`ANTI`、`ANY` 和 `ASOF`)。

使用 `partial_merge` 算法时,ClickHouse 会对数据进行排序并将其转储到磁盘。ClickHouse 中的 `partial_merge` 算法与经典实现略有不同。首先,ClickHouse 按块中的连接键对右表进行排序,并为已排序的块创建最小-最大索引。然后,它按 `join key` 对左表的部分进行排序,并将它们与右表连接。最小-最大索引还用于跳过不需要的右表块。

- direct

当右表的存储支持键值请求时,可以应用此算法。

`direct` 算法使用左表中的行作为键在右表中执行查找。它仅受特殊存储(如 [Dictionary](/engines/table-engines/special/dictionary) 或 [EmbeddedRocksDB](../../engines/table-engines/integrations/embedded-rocksdb.md))支持,并且仅支持 `LEFT` 和 `INNER` JOIN。

- auto

设置为 `auto` 时,首先尝试 `hash` join,如果违反内存限制,则会动态切换到另一个算法。

- full_sorting_merge

[排序合并算法](https://en.wikipedia.org/wiki/Sort-merge_join),在连接之前对连接的表进行完全排序。

- prefer_partial_merge

ClickHouse 总是尝试尽可能使用 `partial_merge` join,否则使用 `hash`。_已弃用_,与 `partial_merge,hash` 相同。

- default(已弃用)

旧版值,请不要再使用。
与 `direct,hash` 相同,即尝试使用 direct join 和 hash join(按此顺序)。


## join_any_take_last_row {#join_any_take_last_row}

<SettingsInfoBlock type='Bool' default_value='0' />

更改 `ANY` 严格模式下连接操作的行为。

:::note
此设置仅适用于使用 [Join](../../engines/table-engines/special/join.md) 引擎表的 `JOIN` 操作。
:::

可能的值:

- 0 — 如果右表存在多个匹配行,仅连接找到的第一行。
- 1 — 如果右表存在多个匹配行,仅连接找到的最后一行。

另请参阅:

- [JOIN 子句](/sql-reference/statements/select/join)
- [Join 表引擎](../../engines/table-engines/special/join.md)
- [join_default_strictness](#join_default_strictness)


## join_default_strictness {#join_default_strictness}

<SettingsInfoBlock type='JoinStrictness' default_value='ALL' />

设置 [JOIN 子句](/sql-reference/statements/select/join) 的默认严格性。

可选值:

- `ALL` — 如果右表有多个匹配行,ClickHouse 会从匹配行创建[笛卡尔积](https://en.wikipedia.org/wiki/Cartesian_product)。这是标准 SQL 中 `JOIN` 的正常行为。
- `ANY` — 如果右表有多个匹配行,则仅连接找到的第一行。如果右表只有一个匹配行,则 `ANY` 和 `ALL` 的结果相同。
- `ASOF` — 用于连接具有不确定匹配的序列。
- `空字符串` — 如果查询中未指定 `ALL` 或 `ANY`,ClickHouse 将抛出异常。


## join_on_disk_max_files_to_merge {#join_on_disk_max_files_to_merge}

<SettingsInfoBlock type='UInt64' default_value='64' />

限制在磁盘上执行 MergeJoin 操作时允许用于并行排序的文件数量。

该设置值越大,使用的内存越多,所需的磁盘 I/O 越少。

可选值:

- 任意大于等于 2 的正整数。


## join_output_by_rowlist_perkey_rows_threshold {#join_output_by_rowlist_perkey_rows_threshold}

<SettingsInfoBlock type='UInt64' default_value='5' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "5" },
        {
          label:
            "右表中每个键平均行数的下限阈值,用于决定哈希连接是否采用行列表方式输出。"
        }
      ]
    }
  ]}
/>

右表中每个键平均行数的下限阈值,用于决定哈希连接是否采用行列表方式输出。


## join_overflow_mode {#join_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

定义当达到以下任一 JOIN 限制时 ClickHouse 执行的操作:

- [max_bytes_in_join](/operations/settings/settings#max_bytes_in_join)
- [max_rows_in_join](/operations/settings/settings#max_rows_in_join)

可能的值:

- `THROW` — ClickHouse 抛出异常并中断操作。
- `BREAK` — ClickHouse 中断操作但不抛出异常。

默认值:`THROW`。

**另请参阅**

- [JOIN 子句](/sql-reference/statements/select/join)
- [Join 表引擎](/engines/table-engines/special/join)


## join_runtime_bloom_filter_bytes {#join_runtime_bloom_filter_bytes}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='524288' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "524288" }, { label: "New setting" }]
    }
  ]}
/>

用作 JOIN 运行时过滤器的布隆过滤器大小(以字节为单位)(参见 enable_join_runtime_filters 设置)。


## join_runtime_bloom_filter_hash_functions {#join_runtime_bloom_filter_hash_functions}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='3' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "3" }, { label: "新设置" }]
    }
  ]}
/>

用作 JOIN 运行时过滤器的布隆过滤器中哈希函数的数量(参见 enable_join_runtime_filters 设置)。


## join_runtime_filter_exact_values_limit {#join_runtime_filter_exact_values_limit}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='10000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "10000" }, { label: "新设置" }]
    }
  ]}
/>

运行时过滤器中以集合形式存储的元素的最大数量，当超过此阈值时会切换到布隆过滤器。


## join_to_sort_maximum_table_rows {#join_to_sort_maximum_table_rows}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='10000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "10000" },
        {
          label:
            "右表的最大行数,用于确定在左连接或内连接中是否按键对右表进行重新排序"
        }
      ]
    }
  ]}
/>

右表的最大行数,用于确定在左连接或内连接中是否按键对右表进行重新排序.


## join_to_sort_minimum_perkey_rows {#join_to_sort_minimum_perkey_rows}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='40' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "40" },
        {
          label:
            "右表中每个键的平均行数下限,用于确定在左连接或内连接中是否按键对右表进行重新排序。此设置确保该优化不会应用于稀疏表键"
        }
      ]
    }
  ]}
/>

右表中每个键的平均行数下限,用于确定在左连接或内连接中是否按键对右表进行重新排序。此设置确保该优化不会应用于稀疏表键


## join_use_nulls {#join_use_nulls}

<SettingsInfoBlock type='Bool' default_value='0' />

设置 [JOIN](../../sql-reference/statements/select/join.md) 的行为类型。在合并表时,可能会出现空单元格。ClickHouse 会根据此设置以不同方式填充它们。

可能的值:

- 0 — 空单元格将使用相应字段类型的默认值填充。
- 1 — `JOIN` 的行为与标准 SQL 相同。相应字段的类型将转换为 [Nullable](/sql-reference/data-types/nullable),空单元格将使用 [NULL](/sql-reference/syntax) 填充。


## joined_block_split_single_row {#joined_block_split_single_row}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

允许按左表单行对应的行对哈希连接结果进行分块。
当右表中存在大量匹配行时,这可以减少内存使用,但可能会增加 CPU 使用率。
注意:此设置生效的前提是 `max_joined_block_size_rows != 0`。
将 `max_joined_block_size_bytes` 与此设置结合使用,有助于在数据倾斜且某些大行在右表中有大量匹配时避免内存使用过高。


## joined_subquery_requires_alias {#joined_subquery_requires_alias}

<SettingsInfoBlock type='Bool' default_value='1' />

强制要求连接的子查询和表函数具有别名，以确保名称限定的正确性。


## kafka_disable_num_consumers_limit {#kafka_disable_num_consumers_limit}

<SettingsInfoBlock type='Bool' default_value='0' />

禁用基于可用 CPU 核心数的 kafka_num_consumers 限制。


## kafka_max_wait_ms {#kafka_max_wait_ms}

<SettingsInfoBlock type='Milliseconds' default_value='5000' />

从 [Kafka](/engines/table-engines/integrations/kafka) 读取消息时的等待时间(毫秒),超时后重试。

可选值:

- 正整数。
- 0 — 无限等待。

另请参阅:

- [Apache Kafka](https://kafka.apache.org/)


## keeper_map_strict_mode {#keeper_map_strict_mode}

<SettingsInfoBlock type='Bool' default_value='0' />

对 KeeperMap 操作强制执行额外检查。例如，在插入已存在的键时抛出异常


## keeper_max_retries {#keeper_max_retries}

<SettingsInfoBlock type='UInt64' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "10" },
        { label: "通用 Keeper 操作的最大重试次数" }
      ]
    }
  ]}
/>

通用 Keeper 操作的最大重试次数


## keeper_retry_initial_backoff_ms {#keeper_retry_initial_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='100' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "100" },
        { label: "通用 Keeper 操作的初始退避超时时间" }
      ]
    }
  ]}
/>

通用 Keeper 操作的初始退避超时时间


## keeper_retry_max_backoff_ms {#keeper_retry_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='5000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "5000" },
        { label: "通用 Keeper 操作的最大退避超时时间" }
      ]
    }
  ]}
/>

通用 Keeper 操作的最大退避超时时间


## least_greatest_legacy_null_behavior {#least_greatest_legacy_null_behavior}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.12" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

如果启用此设置，当 `least` 和 `greatest` 函数的任一参数为 NULL 时，函数将返回 NULL。


## legacy_column_name_of_tuple_literal {#legacy_column_name_of_tuple_literal}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.7" },
        { label: "0" },
        {
          label:
            "添加此设置仅用于兼容性目的。在将集群从 21.7 以下版本滚动升级到更高版本时,建议将其设置为 'true'"
        }
      ]
    }
  ]}
/>

在列名中列出大型元组字面量的所有元素名称,而不是使用哈希值。此设置仅用于兼容性目的。在将集群从 21.7 以下版本滚动升级到更高版本时,建议将其设置为 'true'。


## lightweight_delete_mode {#lightweight_delete_mode}

<SettingsInfoBlock type='LightweightDeleteMode' default_value='alter_update' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "alter_update" },
        { label: "新增设置" }
      ]
    }
  ]}
/>

轻量级删除操作中执行的内部更新查询模式。

可选值：

- `alter_update` - 执行 `ALTER UPDATE` 查询，创建重量级变更。
- `lightweight_update` - 优先执行轻量级更新，若不可行则执行 `ALTER UPDATE`。
- `lightweight_update_force` - 优先执行轻量级更新，若不可行则抛出异常。


## lightweight_deletes_sync {#lightweight_deletes_sync}

<SettingsInfoBlock type='UInt64' default_value='2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "2" },
        {
          label:
            "与 'mutation_sync' 相同,但仅控制轻量级删除的执行"
        }
      ]
    }
  ]}
/>

与 [`mutations_sync`](#mutations_sync) 相同,但仅控制轻量级删除的执行。

可能的值:

| 值 | 描述                                                                                                                                            |
| ----- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `0`   | 变更操作异步执行。                                                                                                                      |
| `1`   | 查询等待轻量级删除在当前服务器上完成。                                                                         |
| `2`   | 查询等待轻量级删除在所有副本上完成(如果存在副本)。                                                               |
| `3`   | 查询仅等待活动副本。仅支持 `SharedMergeTree`。对于 `ReplicatedMergeTree`,其行为与 `mutations_sync = 2` 相同。 |

**另请参阅**

- [ALTER 查询的同步性](../../sql-reference/statements/alter/index.md/#synchronicity-of-alter-queries)
- [变更操作](../../sql-reference/statements/alter/index.md/#mutations)


## limit {#limit}

<SettingsInfoBlock type='UInt64' default_value='0' />

设置从查询结果中获取的最大行数。它会调整 [LIMIT](/sql-reference/statements/select/limit) 子句设置的值,确保查询中指定的限制不会超过此设置所设定的限制。

可能的值:

- 0 — 不限制行数。
- 正整数。


## load_balancing {#load_balancing}

<SettingsInfoBlock type='LoadBalancing' default_value='random' />

指定用于分布式查询处理的副本选择算法。

ClickHouse 支持以下副本选择算法:

- [随机](#load_balancing-random) (默认)
- [最近主机名](#load_balancing-nearest_hostname)
- [主机名莱文斯坦距离](#load_balancing-hostname_levenshtein_distance)
- [按顺序](#load_balancing-in_order)
- [首选或随机](#load_balancing-first_or_random)
- [轮询](#load_balancing-round_robin)

另请参阅:

- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)

### 随机 (默认) {#load_balancing-random}

```sql
load_balancing = random
```

系统会统计每个副本的错误数量。查询将发送到错误数量最少的副本,如果有多个这样的副本,则随机选择其中一个。
缺点:不考虑服务器的邻近性;如果副本数据不同,您获得的数据也会不同。

### 最近主机名 {#load_balancing-nearest_hostname}

```sql
load_balancing = nearest_hostname
```

系统会统计每个副本的错误数量。每 5 分钟,错误数量会整除以 2。因此,错误数量通过指数平滑方式计算近期值。如果有一个副本的错误数量最少(即其他副本最近发生了错误),查询将发送到该副本。如果有多个副本具有相同的最小错误数量,查询将发送到主机名与配置文件中服务器主机名最相似的副本(根据相同位置上不同字符的数量进行比较,比较长度为两个主机名的最小长度)。

例如,example01-01-1 和 example01-01-2 在一个位置上不同,而 example01-01-1 和 example01-02-2 在两个位置上不同。
这种方法可能看起来比较简单,但它不需要网络拓扑的外部数据,也不需要比较 IP 地址,这对于 IPv6 地址来说会比较复杂。

因此,如果存在等效的副本,则优先选择名称最接近的副本。
我们还可以假设,当向同一服务器发送查询时,在没有故障的情况下,分布式查询也会发送到相同的服务器。因此,即使副本上的数据不同,查询返回的结果也基本相同。

### 主机名莱文斯坦距离 {#load_balancing-hostname_levenshtein_distance}

```sql
load_balancing = hostname_levenshtein_distance
```

与 `nearest_hostname` 类似,但使用[莱文斯坦距离](https://en.wikipedia.org/wiki/Levenshtein_distance)方式比较主机名。例如:

```text
example-clickhouse-0-0 ample-clickhouse-0-0
1

example-clickhouse-0-0 example-clickhouse-1-10
2

example-clickhouse-0-0 example-clickhouse-12-0
3
```

### 按顺序 {#load_balancing-in_order}

```sql
load_balancing = in_order
```

具有相同错误数量的副本按照它们在配置中指定的顺序进行访问。
当您明确知道哪个副本更优时,此方法比较合适。

### 首选或随机 {#load_balancing-first_or_random}

```sql
load_balancing = first_or_random
```

此算法选择集合中的第一个副本,如果第一个副本不可用,则选择随机副本。它在跨副本拓扑设置中有效,但在其他配置中作用不大。

`first_or_random` 算法解决了 `in_order` 算法的问题。使用 `in_order` 时,如果一个副本宕机,下一个副本会承受双倍负载,而其余副本处理正常流量。使用 `first_or_random` 算法时,负载会在仍然可用的副本之间均匀分配。

可以通过 `load_balancing_first_offset` 设置显式定义第一个副本。这提供了更多控制,以便在副本之间重新平衡查询工作负载。

### 轮询 {#load_balancing-round_robin}

```sql
load_balancing = round_robin
```

此算法对具有相同错误数量的副本使用轮询策略(仅统计使用 `round_robin` 策略的查询)。


## load_balancing_first_offset {#load_balancing_first_offset}

<SettingsInfoBlock type='UInt64' default_value='0' />

当使用 FIRST_OR_RANDOM 负载均衡策略时,优先将查询发送到哪个副本。


## load_marks_asynchronously {#load_marks_asynchronously}

<SettingsInfoBlock type='Bool' default_value='0' />

异步加载 MergeTree 标记


## local_filesystem_read_method {#local_filesystem_read_method}

<SettingsInfoBlock type='String' default_value='pread_threadpool' />

从本地文件系统读取数据的方法,可选值为:read、pread、mmap、io_uring、pread_threadpool。

'io_uring' 方法为实验性功能,在存在并发读写时,不支持 Log、TinyLog、StripeLog、File、Set 和 Join 表,以及其他使用可追加文件的表。
如果您在互联网上阅读过各种关于 'io_uring' 的文章,请勿被其误导。它并非更优的文件读取方法,仅在存在大量小型 IO 请求的场景下才有优势,而这并非 ClickHouse 的典型使用场景。因此没有必要启用 'io_uring'。


## local_filesystem_read_prefetch {#local_filesystem_read_prefetch}

<SettingsInfoBlock type='Bool' default_value='0' />

从本地文件系统读取数据时是否使用预取功能。


## lock_acquire_timeout {#lock_acquire_timeout}

<SettingsInfoBlock type='Seconds' default_value='120' />

定义锁请求在失败前等待的秒数。

锁超时用于在对表执行读/写操作时防止死锁。当超时到期且锁请求失败时,ClickHouse 服务器会抛出异常 "Locking attempt timed out! Possible deadlock avoided. Client should retry.",错误代码为 `DEADLOCK_AVOIDED`。

可选值:

- 正整数(单位:秒)。
- 0 — 无锁超时限制。


## log_comment {#log_comment}

指定 [system.query_log](../system-tables/query_log.md) 表的 `log_comment` 字段值和服务器日志的注释文本。

可用于提高服务器日志的可读性。此外,在运行 [clickhouse-test](../../development/tests.md) 后,有助于从 `system.query_log` 中筛选与测试相关的查询。

可能的值:

- 任何长度不超过 [max_query_size](#max_query_size) 的字符串。如果超过 max_query_size,服务器将抛出异常。

**示例**

查询:

```sql
SET log_comment = 'log_comment test', log_queries = 1;
SELECT 1;
SYSTEM FLUSH LOGS;
SELECT type, query FROM system.query_log WHERE log_comment = 'log_comment test' AND event_date >= yesterday() ORDER BY event_time DESC LIMIT 2;
```

结果:

```text
┌─type────────┬─query─────┐
│ QueryStart  │ SELECT 1; │
│ QueryFinish │ SELECT 1; │
└─────────────┴───────────┘
```


## log_formatted_queries {#log_formatted_queries}

<SettingsInfoBlock type='Bool' default_value='0' />

允许将格式化后的查询记录到 [system.query_log](../../operations/system-tables/query_log.md) 系统表(填充 [system.query_log](../../operations/system-tables/query_log.md) 中的 `formatted_query` 列)。

可选值:

- 0 — 不记录格式化后的查询到系统表。
- 1 — 记录格式化后的查询到系统表。


## log_processors_profiles {#log_processors_profiles}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.3" }, { label: "1" }, { label: "默认启用" }]
    }
  ]}
/>

将处理器在执行/等待数据期间所花费的时间写入 `system.processors_profile_log` 表。

另请参阅：

- [`system.processors_profile_log`](../../operations/system-tables/processors_profile_log.md)
- [`EXPLAIN PIPELINE`](../../sql-reference/statements/explain.md/#explain-pipeline)


## log_profile_events {#log_profile_events}

<SettingsInfoBlock type='Bool' default_value='1' />

将查询性能统计信息记录到 query_log、query_thread_log 和 query_views_log 中。


## log_queries {#log_queries}

<SettingsInfoBlock type='Bool' default_value='1' />

配置查询日志记录。

启用此设置后，发送到 ClickHouse 的查询将按照 [query_log](../../operations/server-configuration-parameters/settings.md/#query_log) 服务器配置参数中定义的规则进行记录。

示例：

```text
log_queries=1
```


## log_queries_cut_to_length {#log_queries_cut_to_length}

<SettingsInfoBlock type='UInt64' default_value='100000' />

如果查询长度超过指定阈值(以字节为单位),则在写入查询日志时对查询进行截断。同时也会限制普通文本日志中打印的查询长度。


## log_queries_min_query_duration_ms {#log_queries_min_query_duration_ms}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

如果启用（非零值），执行时间短于此设置值的查询将不会被记录（您可以将其理解为 [MySQL 慢查询日志](https://dev.mysql.com/doc/refman/5.7/slow-query-log.html) 中的 `long_query_time`），这意味着您将无法在以下表中找到这些查询：

- `system.query_log`
- `system.query_thread_log`

只有以下类型的查询会被记录到日志：

- `QUERY_FINISH`
- `EXCEPTION_WHILE_PROCESSING`

- 类型：毫秒
- 默认值：0（任意查询）


## log_queries_min_type {#log_queries_min_type}

<SettingsInfoBlock type='LogQueriesType' default_value='QUERY_START' />

记录到 `query_log` 的最小类型。

可选值:

- `QUERY_START` (`=1`)
- `QUERY_FINISH` (`=2`)
- `EXCEPTION_BEFORE_START` (`=3`)
- `EXCEPTION_WHILE_PROCESSING` (`=4`)

可用于限制记录到 `query_log` 的条目类型。例如,如果您只关注错误,可以使用 `EXCEPTION_WHILE_PROCESSING`:

```text
log_queries_min_type='EXCEPTION_WHILE_PROCESSING'
```


## log_queries_probability {#log_queries_probability}

<SettingsInfoBlock type='Float' default_value='1' />

允许用户按指定概率随机抽样查询,仅将抽样的查询写入 [query_log](../../operations/system-tables/query_log.md)、[query_thread_log](../../operations/system-tables/query_thread_log.md) 和 [query_views_log](../../operations/system-tables/query_views_log.md) 系统表。这有助于在每秒查询量较大时降低负载。

可能的值:

- 0 — 查询不记录到系统表中。
- [0..1] 范围内的正浮点数。例如,如果设置值为 `0.5`,则约有一半的查询会记录到系统表中。
- 1 — 所有查询都记录到系统表中。


## log_query_settings {#log_query_settings}

<SettingsInfoBlock type='Bool' default_value='1' />

将查询设置记录到 query_log 和 OpenTelemetry span 日志中。


## log_query_threads {#log_query_threads}

<SettingsInfoBlock type='Bool' default_value='0' />

配置查询线程日志记录。

查询线程日志记录到 [system.query_thread_log](../../operations/system-tables/query_thread_log.md) 表中。此设置仅在 [log_queries](#log_queries) 为 true 时生效。ClickHouse 执行的查询线程将根据 [query_thread_log](/operations/server-configuration-parameters/settings#query_thread_log) 服务器配置参数中的规则进行日志记录。

可能的值:

- 0 — 禁用。
- 1 — 启用。

**示例**

```text
log_query_threads=1
```


## log_query_views {#log_query_views}

<SettingsInfoBlock type='Bool' default_value='1' />

配置查询视图的日志记录。

当 ClickHouse 执行的查询启用此设置且包含关联视图(物化视图或实时视图)时,这些视图将被记录到 [query_views_log](/operations/server-configuration-parameters/settings#query_views_log) 服务器配置参数中。

示例:

```text
log_query_views=1
```


## low_cardinality_allow_in_native_format {#low_cardinality_allow_in_native_format}

<SettingsInfoBlock type='Bool' default_value='1' />

允许或限制在 [Native](/interfaces/formats/Native) 格式中使用 [LowCardinality](../../sql-reference/data-types/lowcardinality.md) 数据类型。

如果限制使用 `LowCardinality`,ClickHouse 服务器会在 `SELECT` 查询时将 `LowCardinality` 列转换为普通列,在 `INSERT` 查询时将普通列转换为 `LowCardinality` 列。

此设置主要用于不支持 `LowCardinality` 数据类型的第三方客户端。

可能的值:

- 1 — 不限制使用 `LowCardinality`。
- 0 — 限制使用 `LowCardinality`。


## low_cardinality_max_dictionary_size {#low_cardinality_max_dictionary_size}

<SettingsInfoBlock type='UInt64' default_value='8192' />

设置 [LowCardinality](../../sql-reference/data-types/lowcardinality.md) 数据类型共享全局字典可写入存储文件系统的最大行数。此设置用于防止字典无限增长导致的内存问题。所有因字典大小超出限制而无法编码的数据,ClickHouse 会以常规方式写入。

可选值:

- 任意正整数。


## low_cardinality_use_single_dictionary_for_part {#low_cardinality_use_single_dictionary_for_part}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用为数据部分使用单一字典。

默认情况下,ClickHouse 服务器会监控字典大小,当字典溢出时,服务器会开始写入下一个字典。要禁止创建多个字典,请设置 `low_cardinality_use_single_dictionary_for_part = 1`。

可选值:

- 1 — 禁止为数据部分创建多个字典。
- 0 — 允许为数据部分创建多个字典。


## low_priority_query_wait_time_ms {#low_priority_query_wait_time_ms}

<BetaBadge />

<SettingsInfoBlock type='Milliseconds' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "1000" }, { label: "新增设置。" }]
    }
  ]}
/>

当使用查询优先级机制时(参见 `priority` 设置),低优先级查询将等待高优先级查询完成。此设置指定等待时长。


## make_distributed_plan {#make_distributed_plan}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "新增实验性设置。" }
      ]
    }
  ]}
/>

生成分布式查询计划。


## materialize_skip_indexes_on_insert {#materialize_skip_indexes_on_insert}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "1" },
        {
          label:
            "新增设置,允许在插入时禁用跳数索引的物化"
        }
      ]
    }
  ]}
/>

控制 INSERT 操作是否构建并存储跳数索引。如果禁用,跳数索引将仅在[合并期间](merge-tree-settings.md/#materialize_skip_indexes_on_merge)或通过显式执行 [MATERIALIZE INDEX](/sql-reference/statements/alter/skipping-index.md/#materialize-index) 时构建并存储。

另请参阅 [exclude_materialize_skip_indexes_on_insert](#exclude_materialize_skip_indexes_on_insert)。


## materialize_statistics_on_insert {#materialize_statistics_on_insert}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "1" },
        {
          label:
            "新增设置项,允许禁用插入时的统计信息物化"
        }
      ]
    }
  ]}
/>

启用时,INSERT 操作会构建并插入统计信息。禁用时,统计信息将在合并过程中构建和存储,或通过显式执行 MATERIALIZE STATISTICS 命令来构建和存储


## materialize_ttl_after_modify {#materialize_ttl_after_modify}

<SettingsInfoBlock type='Bool' default_value='1' />

在 ALTER MODIFY TTL 查询后,对旧数据应用 TTL


## materialized_views_ignore_errors {#materialized_views_ignore_errors}

<SettingsInfoBlock type='Bool' default_value='0' />

允许忽略物化视图(MATERIALIZED VIEW)的错误,并将原始数据块传递到表中,不受物化视图影响


## materialized_views_squash_parallel_inserts {#materialized_views_squash_parallel_inserts}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.10" },
        { label: "1" },
        { label: "添加此设置以便在需要时保留旧版行为。" }
      ]
    }
  ]}
/>

将来自并行插入的单个 INSERT 查询的数据合并写入物化视图目标表,以减少生成的数据分区数量。
如果设置为 false 且启用了 `parallel_view_processing`,INSERT 查询将为每个 `max_insert_thread` 在目标表中生成一个数据分区。


## max_analyze_depth {#max_analyze_depth}

<SettingsInfoBlock type='UInt64' default_value='5000' />

解释器执行的最大分析数量。


## max_ast_depth {#max_ast_depth}

<SettingsInfoBlock type='UInt64' default_value='1000' />

查询语法树的最大嵌套深度。超过此值时将抛出异常。

:::note
目前，该检查不在解析过程中进行,而是在查询解析完成后才执行。
这意味着解析过程中可能会生成嵌套过深的语法树,
但查询最终会执行失败。
:::


## max_ast_elements {#max_ast_elements}

<SettingsInfoBlock type='UInt64' default_value='50000' />

查询语法树中的最大元素数量。超过此限制时将抛出异常。

:::note
目前,该限制不在解析过程中检查,而仅在查询解析完成后检查。
这意味着解析过程中可能会创建过深的语法树,
但查询最终会失败。
:::


## max_autoincrement_series {#max_autoincrement_series}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "1000" }, { label: "新增设置" }]
    }
  ]}
/>

`generateSerialID` 函数创建的序列数量上限。

由于每个序列对应 Keeper 中的一个节点,建议序列总数不超过数百万个。


## max_backup_bandwidth {#max_backup_bandwidth}

<SettingsInfoBlock type='UInt64' default_value='0' />

服务器上特定备份的最大读取速度(以字节/秒为单位)。设置为 0 表示不限速。


## max_block_size {#max_block_size}

<SettingsInfoBlock type='NonZeroUInt64' default_value='65409' />

在 ClickHouse 中,数据以块(block)的形式进行处理,块是列片段的集合。单个块的内部处理周期效率很高,但处理每个块时都会产生显著的开销。

`max_block_size` 设置指定从表中加载数据时单个块建议包含的最大行数。并非总是从表中加载 `max_block_size` 大小的块:如果 ClickHouse 判断需要检索的数据量较少,则会处理更小的块。

块大小不应过小,以避免处理每个块时产生显著的开销。块大小也不应过大,以确保带有 LIMIT 子句的查询在处理完第一个块后能够快速执行。设置 `max_block_size` 时,目标是在多线程提取大量列时避免消耗过多内存,同时至少保持一定程度的缓存局部性。


## max_bytes_before_external_group_by {#max_bytes_before_external_group_by}

<SettingsInfoBlock type='UInt64' default_value='0' />

云默认值：每个副本内存量的一半。

启用或禁用 `GROUP BY` 子句在外部内存中的执行。
（参见[外部内存中的 GROUP BY](/sql-reference/statements/select/group-by#group-by-in-external-memory)）

可选值：

- 单个 [GROUP BY](/sql-reference/statements/select/group-by) 操作可使用的最大内存量（以字节为单位）。
- `0` — 禁用外部内存中的 `GROUP BY`。

:::note
当 GROUP BY 操作的内存使用量超过此阈值（以字节为单位）时，
将激活"外部聚合"模式（将数据溢出到磁盘）。

建议值为可用系统内存的一半。
:::


## max_bytes_before_external_sort {#max_bytes_before_external_sort}

<SettingsInfoBlock type='UInt64' default_value='0' />

云环境默认值：每个副本内存量的一半。

启用或禁用在外部内存中执行 `ORDER BY` 子句。请参阅 [ORDER BY 实现细节](../../sql-reference/statements/select/order-by.md#implementation-details)
如果 ORDER BY 操作期间的内存使用量（以字节为单位）超过此阈值,则会激活"外部排序"模式（将数据溢出到磁盘）。

可选值：

- 单个 [ORDER BY](../../sql-reference/statements/select/order-by.md) 操作可使用的最大内存量（以字节为单位）。
  建议值为可用系统内存的一半
- `0` — 禁用外部内存中的 `ORDER BY`。


## max_bytes_before_remerge_sort {#max_bytes_before_remerge_sort}

<SettingsInfoBlock type='UInt64' default_value='1000000000' />

当使用 ORDER BY 与 LIMIT 时,如果内存使用量超过指定阈值,则在最终合并之前执行额外的块合并步骤,以仅保留排序后的前 LIMIT 行。


## max_bytes_in_distinct {#max_bytes_in_distinct}

<SettingsInfoBlock type='UInt64' default_value='0' />

使用 DISTINCT 时哈希表在内存中使用的状态数据的最大字节数(未压缩)。


## max_bytes_in_join {#max_bytes_in_join}

<SettingsInfoBlock type='UInt64' default_value='0' />

连接表时使用的哈希表的最大字节数。

此设置适用于 [SELECT ... JOIN](/sql-reference/statements/select/join)
操作和 [Join 表引擎](/engines/table-engines/special/join)。

如果查询包含连接操作,ClickHouse 会对每个中间结果检查此设置。

当达到限制时,ClickHouse 可以执行不同的操作。使用
[join_overflow_mode](/operations/settings/settings#join_overflow_mode) 设置来选择操作。

可能的值:

- 正整数。
- 0 — 禁用内存控制。


## max_bytes_in_set {#max_bytes_in_set}

<SettingsInfoBlock type='UInt64' default_value='0' />

IN 子句中由子查询创建的集合所使用的最大字节数(未压缩数据)。


## max_bytes_ratio_before_external_group_by {#max_bytes_ratio_before_external_group_by}

<SettingsInfoBlock type='Double' default_value='0.5' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "0.5" },
        { label: "默认启用自动溢出到磁盘功能。" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "24.12" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

`GROUP BY` 允许使用的可用内存比例。达到此比例后,
将使用外部内存进行聚合。

例如,如果设置为 `0.6`,`GROUP BY` 在执行开始时将允许使用 60% 的可用内存
(针对服务器/用户/合并操作),达到该阈值后,
将开始使用外部聚合。


## max_bytes_ratio_before_external_sort {#max_bytes_ratio_before_external_sort}

<SettingsInfoBlock type='Double' default_value='0.5' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "0.5" },
        { label: "默认启用自动溢写到磁盘。" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "24.12" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

`ORDER BY` 允许使用的可用内存比例。达到该比例后,将使用外部排序。

例如,如果设置为 `0.6`,`ORDER BY` 在执行开始时将允许使用 `60%` 的可用内存(针对服务器/用户/合并操作),之后将开始使用外部排序。

注意,`max_bytes_before_external_sort` 设置仍然生效,只有当排序块大于 `max_bytes_before_external_sort` 时才会溢写到磁盘。


## max_bytes_to_read {#max_bytes_to_read}

<SettingsInfoBlock type='UInt64' default_value='0' />

执行查询时可从表中读取的最大字节数(未压缩数据)。
此限制针对每个已处理的数据块进行检查,仅应用于最深层的表表达式,且从远程服务器读取数据时,仅在远程服务器上执行检查。


## max_bytes_to_read_leaf {#max_bytes_to_read_leaf}

<SettingsInfoBlock type='UInt64' default_value='0' />

在运行分布式查询时,从叶子节点的本地表中可读取的最大字节数(未压缩数据)。虽然分布式查询可以向每个分片(叶子节点)发出多个子查询,但此限制仅在叶子节点的读取阶段进行检查,而在根节点的结果合并阶段会被忽略。

例如,一个集群由 2 个分片组成,每个分片包含一个有 100 字节数据的表。如果设置 `max_bytes_to_read=150`,一个试图从两个表读取所有数据的分布式查询将会失败,因为总共需要读取 200 字节。而如果设置 `max_bytes_to_read_leaf=150`,查询将会成功,因为每个叶子节点最多只读取 100 字节。

该限制针对每个处理的数据块进行检查。

:::note
当 `prefer_localhost_replica=1` 时,此设置不稳定。
:::


## max_bytes_to_sort {#max_bytes_to_sort}

<SettingsInfoBlock type='UInt64' default_value='0' />

排序前的最大字节数。如果 ORDER BY 操作需要处理的未压缩字节数超过指定的数量,其行为将由 `sort_overflow_mode` 决定,该设置默认值为 `throw`。


## max_bytes_to_transfer {#max_bytes_to_transfer}

<SettingsInfoBlock type='UInt64' default_value='0' />

执行 GLOBAL IN/JOIN 子句时,可传递到远程服务器或保存到临时表中的最大字节数(未压缩数据)。


## max_columns_to_read {#max_columns_to_read}

<SettingsInfoBlock type='UInt64' default_value='0' />

单个查询中可从表读取的最大列数。
如果查询需要读取的列数超过指定值，将抛出异常。

:::tip
此设置可用于防止过于复杂的查询。
:::

`0` 表示无限制。


## max_compress_block_size {#max_compress_block_size}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

写入表之前对未压缩数据块进行压缩的最大大小。默认值为 1,048,576 (1 MiB)。指定较小的块大小通常会导致压缩率略有降低,但由于缓存局部性的改善,压缩和解压缩速度会略有提升,同时内存消耗也会减少。

:::note
这是一个专家级设置,如果您刚开始使用 ClickHouse,请勿更改此设置。
:::

请勿将用于压缩的块(由字节组成的内存块)与用于查询处理的块(表中的行集合)混淆。


## max_concurrent_queries_for_all_users {#max_concurrent_queries_for_all_users}

<SettingsInfoBlock type='UInt64' default_value='0' />

如果此设置的值小于或等于当前并发处理的查询数量,则抛出异常。

示例:可以将所有用户的 `max_concurrent_queries_for_all_users` 设置为 99,而数据库管理员可以将自己的设置为 100,以便即使在服务器过载时也能运行查询进行故障排查。

修改单个查询或用户的此设置不会影响其他查询。

可能的值:

- 正整数。
- 0 — 无限制。

**示例**

```xml
<max_concurrent_queries_for_all_users>99</max_concurrent_queries_for_all_users>
```

**另请参阅**

- [max_concurrent_queries](/operations/server-configuration-parameters/settings#max_concurrent_queries)


## max_concurrent_queries_for_user {#max_concurrent_queries_for_user}

<SettingsInfoBlock type='UInt64' default_value='0' />

每个用户可同时处理的最大查询数。

可能的值：

- 正整数。
- 0 — 无限制。

**示例**

```xml
<max_concurrent_queries_for_user>5</max_concurrent_queries_for_user>
```


## max_distributed_connections {#max_distributed_connections}

<SettingsInfoBlock type='UInt64' default_value='1024' />

与远程服务器同时建立的最大连接数,用于对单个 Distributed 表执行单个查询的分布式处理。建议将此值设置为不小于集群中的服务器数量。

以下参数仅在创建 Distributed 表(以及启动服务器)时使用,因此无需在运行时更改。


## max_distributed_depth {#max_distributed_depth}

<SettingsInfoBlock type='UInt64' default_value='5' />

限制 [Distributed](../../engines/table-engines/special/distributed.md) 表的递归查询最大深度。

如果超过此值,服务器将抛出异常。

可选值:

- 正整数。
- 0 — 不限制深度。


## max_download_buffer_size {#max_download_buffer_size}

<SettingsInfoBlock type='UInt64' default_value='10485760' />

每个线程用于并行下载的缓冲区最大大小(例如用于 URL 引擎)。


## max_download_threads {#max_download_threads}

<SettingsInfoBlock type='MaxThreads' default_value='4' />

用于下载数据的最大线程数(例如 URL 引擎)。


## max_estimated_execution_time {#max_estimated_execution_time}

<SettingsInfoBlock type='Seconds' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "0" },
        {
          label: "将 max_execution_time 和 max_estimated_execution_time 分离"
        }
      ]
    }
  ]}
/>

查询估计执行时间的最大值,单位为秒。当 [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 超时后,将在每个数据块上进行检查。


## max_execution_speed {#max_execution_speed}

<SettingsInfoBlock type='UInt64' default_value='0' />

每秒执行的最大行数。当
[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)
超时后,将在每个数据块上进行检查。如果执行速度过高,将自动降低执行速度。


## max_execution_speed_bytes {#max_execution_speed_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

每秒执行的最大字节数。当
[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)
超时后,会对每个数据块进行检查。如果执行速度过高,将降低执行速度。


## max_execution_time {#max_execution_time}

<SettingsInfoBlock type='Seconds' default_value='0' />

查询执行的最大时长,以秒为单位。

`max_execution_time` 参数的理解可能有些复杂。
它基于当前查询执行速度进行插值估算
(此行为由 [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 控制)。

如果预估的执行时间超过指定的 `max_execution_time`,ClickHouse 将中断查询。默认情况下,`timeout_before_checking_execution_speed` 设置为 10 秒。这意味着在查询执行 10 秒后,ClickHouse 将开始估算总执行时间。例如,如果 `max_execution_time` 设置为 3600 秒(1 小时),当估算时间超过此 3600 秒限制时,ClickHouse 将终止查询。如果将 `timeout_before_checking_execution_speed` 设置为 0,ClickHouse 将使用实际时钟时间作为 `max_execution_time` 的判断依据。

如果查询运行时间超过指定的秒数,其行为将由 `timeout_overflow_mode` 决定,该参数默认设置为 `throw`。

:::note
超时检查和查询中断仅在数据处理过程中的指定位置进行。
目前无法在聚合状态合并或查询分析期间中断,
因此实际运行时间可能会超过此设置的值。
:::


## max_execution_time_leaf {#max_execution_time_leaf}

<SettingsInfoBlock type='Seconds' default_value='0' />

语义上与 [`max_execution_time`](#max_execution_time) 类似,但仅应用于分布式查询或远程查询的叶子节点。

例如,如果我们想将叶子节点的执行时间限制为 `10s`,但不限制初始节点的执行时间,则无需在嵌套子查询设置中使用 `max_execution_time`:

```sql
SELECT count()
FROM cluster(cluster, view(SELECT * FROM t SETTINGS max_execution_time = 10));
```

可以将 `max_execution_time_leaf` 用作查询设置:

```sql
SELECT count()
FROM cluster(cluster, view(SELECT * FROM t)) SETTINGS max_execution_time_leaf = 10;
```


## max_expanded_ast_elements {#max_expanded_ast_elements}

<SettingsInfoBlock type='UInt64' default_value='500000' />

别名和星号（*）展开后，查询语法树中节点数量的最大值。


## max_fetch_partition_retries_count {#max_fetch_partition_retries_count}

<SettingsInfoBlock type='UInt64' default_value='5' />

从其他主机获取分区时的重试次数。


## max_final_threads {#max_final_threads}

<SettingsInfoBlock type='MaxThreads' default_value="'auto(N)'" />

设置使用 [FINAL](/sql-reference/statements/select/from#final-modifier) 修饰符的 `SELECT` 查询在数据读取阶段的最大并行线程数。

可选值:

- 正整数。
- 0 或 1 — 禁用。`SELECT` 查询将在单线程中执行。


## max_http_get_redirects {#max_http_get_redirects}

<SettingsInfoBlock type='UInt64' default_value='0' />

允许的 HTTP GET 重定向跳数上限。此设置可确保采取额外的安全措施,防止恶意服务器将您的请求重定向到意外的服务。\n\n这种情况发生在外部服务器重定向到另一个地址,但该地址实际上属于公司内部基础设施时,通过向内部服务器发送 HTTP 请求,您可能会访问内部网络的内部 API,绕过身份验证,甚至查询其他服务(如 Redis 或 Memcached)。如果您没有内部基础设施(包括在 localhost 上运行的任何服务),或者您信任该服务器,则允许重定向是安全的。但请注意,如果 URL 使用 HTTP 而非 HTTPS,您不仅需要信任远程服务器,还需要信任您的 ISP 以及中间经过的所有网络。


## max_hyperscan_regexp_length {#max_hyperscan_regexp_length}

<SettingsInfoBlock type='UInt64' default_value='0' />

定义 [hyperscan 多重匹配函数](/sql-reference/functions/string-search-functions#multiMatchAny) 中每个正则表达式的最大长度。

可能的值：

- 正整数。
- 0 - 长度不受限制。

**示例**

查询：

```sql
SELECT multiMatchAny('abcd', ['ab','bcd','c','d']) SETTINGS max_hyperscan_regexp_length = 3;
```

结果：

```text
┌─multiMatchAny('abcd', ['ab', 'bcd', 'c', 'd'])─┐
│                                              1 │
└────────────────────────────────────────────────┘
```

查询：

```sql
SELECT multiMatchAny('abcd', ['ab','bcd','c','d']) SETTINGS max_hyperscan_regexp_length = 2;
```

结果：

```text
Exception: Regexp length too large.
```

**另请参阅**

- [max_hyperscan_regexp_total_length](#max_hyperscan_regexp_total_length)


## max_hyperscan_regexp_total_length {#max_hyperscan_regexp_total_length}

<SettingsInfoBlock type='UInt64' default_value='0' />

设置每个 [hyperscan 多重匹配函数](/sql-reference/functions/string-search-functions#multiMatchAny) 中所有正则表达式的总长度上限。

可能的值:

- 正整数。
- 0 - 不限制长度。

**示例**

查询:

```sql
SELECT multiMatchAny('abcd', ['a','b','c','d']) SETTINGS max_hyperscan_regexp_total_length = 5;
```

结果:

```text
┌─multiMatchAny('abcd', ['a', 'b', 'c', 'd'])─┐
│                                           1 │
└─────────────────────────────────────────────┘
```

查询:

```sql
SELECT multiMatchAny('abcd', ['ab','bc','c','d']) SETTINGS max_hyperscan_regexp_total_length = 5;
```

结果:

```text
Exception: Total regexp lengths too large.
```

**另请参阅**

- [max_hyperscan_regexp_length](#max_hyperscan_regexp_length)


## max_insert_block_size {#max_insert_block_size}

<SettingsInfoBlock type='NonZeroUInt64' default_value='1048449' />

用于插入表中的数据块大小(以行数计)。
此设置仅在服务器端构建数据块时生效。
例如,通过 HTTP 接口执行 INSERT 时,服务器会解析数据格式并构建指定大小的数据块。
但使用 clickhouse-client 时,客户端会自行解析数据,服务器上的 'max_insert_block_size' 设置不会影响插入数据块的大小。
使用 INSERT SELECT 时,此设置同样不起作用,因为数据使用的是 SELECT 后形成的数据块进行插入。

默认值略大于 `max_block_size`。这是因为某些表引擎(如 `*MergeTree`)会为每个插入的数据块在磁盘上创建一个数据部分,这是一个相当大的实体。同样,`*MergeTree` 表在插入时会对数据进行排序,足够大的数据块可以在内存中排序更多数据。


## max_insert_delayed_streams_for_parallel_write {#max_insert_delayed_streams_for_parallel_write}

<SettingsInfoBlock type='UInt64' default_value='0' />

延迟最终数据分片刷新的最大流(列)数。默认值 - 自动(当底层存储支持并行写入时为 100,例如 S3;否则禁用)


## max_insert_threads {#max_insert_threads}

<SettingsInfoBlock type='UInt64' default_value='0' />

执行 `INSERT SELECT` 查询时使用的最大线程数。

可选值:

- 0(或 1)— `INSERT SELECT` 不进行并行执行。
- 大于 1 的正整数。

Cloud 默认值:

- 8 GiB 内存节点:`1`
- 16 GiB 内存节点:`2`
- 更大规格节点:`4`

只有当 `SELECT` 部分并行执行时,并行 `INSERT SELECT` 才会生效,详见 [`max_threads`](#max_threads) 设置。
较高的值会导致更高的内存使用量。


## max_joined_block_size_bytes {#max_joined_block_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='4194304' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "4194304" }, { label: "新设置" }]
    }
  ]}
/>

JOIN 结果的最大数据块大小（以字节为单位）（如果连接算法支持）。0 表示无限制。


## max_joined_block_size_rows {#max_joined_block_size_rows}

<SettingsInfoBlock type='UInt64' default_value='65409' />

JOIN 结果的最大数据块大小(如果连接算法支持)。0 表示无限制。


## max_limit_for_vector_search_queries {#max_limit_for_vector_search_queries}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "1000" }, { label: "新增设置" }]
    }
  ]}
/>

当 SELECT 查询的 LIMIT 值大于此设置时,将无法使用向量相似度索引。这有助于防止向量相似度索引发生内存溢出。


## max_local_read_bandwidth {#max_local_read_bandwidth}

<SettingsInfoBlock type='UInt64' default_value='0' />

本地读取的最大速度(字节/秒)。


## max_local_write_bandwidth {#max_local_write_bandwidth}

<SettingsInfoBlock type='UInt64' default_value='0' />

本地写入的最大速度(字节/秒)。


## max_memory_usage {#max_memory_usage}

<SettingsInfoBlock type='UInt64' default_value='0' />

Cloud 默认值:取决于副本的内存量。

单个服务器上运行查询时可使用的最大内存量。
值为 `0` 表示无限制。

此设置不考虑可用内存量或机器上的总内存量。该限制仅适用于单个服务器内的单个查询。

可以使用 `SHOW PROCESSLIST` 查看每个查询的当前内存消耗。
系统会跟踪每个查询的峰值内存消耗并写入日志。

对于以下聚合函数使用 `String` 和 `Array` 参数时的状态,内存使用情况不会被完全跟踪:

- `min`
- `max`
- `any`
- `anyLast`
- `argMin`
- `argMax`

内存消耗还受参数 [`max_memory_usage_for_user`](/operations/settings/settings#max_memory_usage_for_user) 和 [`max_server_memory_usage`](/operations/server-configuration-parameters/settings#max_server_memory_usage) 的限制。


## max_memory_usage_for_user {#max_memory_usage_for_user}

<SettingsInfoBlock type='UInt64' default_value='0' />

单个服务器上运行用户查询时可使用的最大内存量。零表示无限制。

默认情况下,内存量不受限制(`max_memory_usage_for_user = 0`)。

另请参阅 [`max_memory_usage`](/operations/settings/settings#max_memory_usage) 的说明。

例如,如果要为名为 `clickhouse_read` 的用户将 `max_memory_usage_for_user` 设置为 1000 字节,可以使用以下语句

```sql
ALTER USER clickhouse_read SETTINGS max_memory_usage_for_user = 1000;
```

您可以通过退出客户端、重新登录,然后使用 `getSetting` 函数来验证设置是否生效:

```sql
SELECT getSetting('max_memory_usage_for_user');
```


## max_network_bandwidth {#max_network_bandwidth}

<SettingsInfoBlock type='UInt64' default_value='0' />

限制网络数据交换的速度,单位为字节/秒。此设置应用于每个查询。

可选值:

- 正整数。
- 0 — 禁用带宽控制。


## max_network_bandwidth_for_all_users {#max_network_bandwidth_for_all_users}

<SettingsInfoBlock type='UInt64' default_value='0' />

限制网络数据交换速度,单位为字节/秒。此设置应用于服务器上所有并发运行的查询。

可能的值:

- 正整数。
- 0 — 禁用数据速度控制。


## max_network_bandwidth_for_user {#max_network_bandwidth_for_user}

<SettingsInfoBlock type='UInt64' default_value='0' />

限制网络数据交换速度,单位为每秒字节数。此设置应用于单个用户并发执行的所有查询。

可能的值:

- 正整数。
- 0 — 禁用数据速度控制。


## max_network_bytes {#max_network_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

限制执行查询时通过网络接收或传输的数据量(以字节为单位)。此设置应用于每个查询。

可选值:

- 正整数。
- 0 — 禁用数据量控制。


## max_number_of_partitions_for_independent_aggregation {#max_number_of_partitions_for_independent_aggregation}

<SettingsInfoBlock type='UInt64' default_value='128' />

表中应用优化的最大分区数量


## max_os_cpu_wait_time_ratio_to_throw {#max_os_cpu_wait_time_ratio_to_throw}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "设置值已更改并回溯至 25.4 版本" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

操作系统 CPU 等待时间(OSCPUWaitMicroseconds 指标)与繁忙时间(OSCPUVirtualTimeMicroseconds 指标)之间的最大比率,用于决定是否拒绝查询。使用最小和最大比率之间的线性插值来计算拒绝概率,在此点概率为 1。


## max_parallel_replicas {#max_parallel_replicas}

<SettingsInfoBlock type='NonZeroUInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "1000" },
        { label: "默认最多使用 1000 个并行副本。" }
      ]
    }
  ]}
/>

执行查询时每个分片使用的最大副本数。

可能的值：

- 正整数。

**附加信息**

此选项会根据所使用的设置产生不同的结果。

:::note
当涉及连接或子查询，且所有表不满足特定要求时，此设置会产生不正确的结果。有关更多详细信息，请参阅[分布式子查询和 max_parallel_replicas](/operations/settings/settings#max_parallel_replicas)。
:::

### 使用 `SAMPLE` 键进行并行处理

如果在多个服务器上并行执行查询，查询处理速度可能会更快。但在以下情况下，查询性能可能会下降：

- 采样键在分区键中的位置不支持高效的范围扫描。
- 向表中添加采样键会降低按其他列进行过滤的效率。
- 采样键是一个计算开销较大的表达式。
- 集群延迟分布具有长尾特征，因此查询更多服务器会增加查询的整体延迟。

### 使用 [parallel_replicas_custom_key](#parallel_replicas_custom_key) 进行并行处理

此设置适用于任何复制表。


## max_parser_backtracks {#max_parser_backtracks}

<SettingsInfoBlock type='UInt64' default_value='1000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1000000" },
        { label: "限制解析复杂度" }
      ]
    }
  ]}
/>

解析器最大回溯次数(在递归下降解析过程中尝试不同备选方案的次数)。


## max_parser_depth {#max_parser_depth}

<SettingsInfoBlock type='UInt64' default_value='1000' />

限制递归下降解析器的最大递归深度。允许控制堆栈大小。

可能的值:

- 正整数。
- 0 — 递归深度无限制。


## max_parsing_threads {#max_parsing_threads}

<SettingsInfoBlock type='MaxThreads' default_value="'auto(N)'" />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "0" },
        {
          label:
            "添加独立设置项以控制文件并行解析的线程数"
        }
      ]
    }
  ]}
/>

用于解析支持并行解析的输入格式数据的最大线程数。默认情况下自动确定。


## max_partition_size_to_drop {#max_partition_size_to_drop}

<SettingsInfoBlock type='UInt64' default_value='50000000000' />

查询时删除分区的大小限制。值为 `0` 表示可以无限制地删除分区。

Cloud 默认值:1 TB。

:::note
此查询设置会覆盖其对应的服务器设置,请参阅 [max_partition_size_to_drop](/operations/server-configuration-parameters/settings#max_partition_size_to_drop)
:::


## max_partitions_per_insert_block {#max_partitions_per_insert_block}

<SettingsInfoBlock type='UInt64' default_value='100' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "19.5" },
        { label: "100" },
        { label: "为单个数据块的分区数量添加限制" }
      ]
    }
  ]}
/>

限制单个插入数据块中的最大分区数,
如果数据块包含的分区数过多,将抛出异常。

- 正整数。
- `0` — 不限制分区数量。

**详细信息**

插入数据时,ClickHouse 会计算插入数据块中的分区数量。如果分区数量超过
`max_partitions_per_insert_block`,ClickHouse 将根据
`throw_on_max_partitions_per_insert_block` 的设置记录警告或抛出异常。异常信息如下:

> "单个 INSERT 数据块的分区数过多(`partitions_count` 个分区,限制为 " + toString(max_partitions) + ")。
> 该限制由 'max_partitions_per_insert_block' 设置控制。
> 使用大量分区是一个常见的误区。这会导致严重的
> 性能问题,包括服务器启动缓慢、INSERT 查询缓慢
> 以及 SELECT 查询缓慢。建议单表的总分区数
> 控制在 1000 到 10000 以内。请注意,分区并非用于加速
> SELECT 查询(ORDER BY 键已足以实现快速的范围查询)。
> 分区的用途是数据管理操作(如 DROP PARTITION 等)。"

:::note
此设置是一个安全阈值,因为使用大量分区是一个常见的误区。
:::


## max_partitions_to_read {#max_partitions_to_read}

<SettingsInfoBlock type='Int64' default_value='-1' />

限制单个查询可访问的最大分区数。

表创建时指定的设置值可通过查询级设置覆盖。

可选值:

- 正整数
- `-1` - 无限制(默认)

:::note
您也可以在表设置中指定 MergeTree 设置 [`max_partitions_to_read`](/operations/settings/settings#max_partitions_to_read)。
:::


## max_parts_to_move {#max_parts_to_move}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "1000" }, { label: "新增设置" }]
    }
  ]}
/>

限制单次查询中可移动的数据分片数量。零表示不限制。


## max_projection_rows_to_use_projection_index {#max_projection_rows_to_use_projection_index}

<SettingsInfoBlock type='UInt64' default_value='1000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1000000" },
        { label: "新设置" }
      ]
    }
  ]}
/>

如果从投影索引中读取的行数小于或等于此阈值,ClickHouse 将在查询执行期间尝试应用该投影索引。


## max_query_size {#max_query_size}

<SettingsInfoBlock type='UInt64' default_value='262144' />

SQL 解析器可解析的查询字符串的最大字节数。
INSERT 查询中 VALUES 子句的数据由独立的流解析器处理(内存消耗为 O(1)),不受此限制的影响。

:::note
`max_query_size` 不能在 SQL 查询内部设置(例如 `SELECT now() SETTINGS max_query_size=10000`),因为 ClickHouse 需要分配缓冲区来解析查询,而缓冲区大小由 `max_query_size` 设置决定,该设置必须在执行查询之前进行配置。
:::


## max_read_buffer_size {#max_read_buffer_size}

<SettingsInfoBlock type='NonZeroUInt64' default_value='1048576' />

从文件系统读取时缓冲区的最大大小。


## max_read_buffer_size_local_fs {#max_read_buffer_size_local_fs}

<SettingsInfoBlock type='UInt64' default_value='131072' />

从本地文件系统读取数据的缓冲区最大大小。如果设置为 0,则使用 max_read_buffer_size。


## max_read_buffer_size_remote_fs {#max_read_buffer_size_remote_fs}

<SettingsInfoBlock type='UInt64' default_value='0' />

从远程文件系统读取数据的缓冲区最大大小。如果设置为 0,则使用 max_read_buffer_size。


## max_recursive_cte_evaluation_depth {#max_recursive_cte_evaluation_depth}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "1000" },
        { label: "递归 CTE 求值深度的最大限制" }
      ]
    }
  ]}
/>

递归 CTE 求值深度的最大限制


## max_remote_read_network_bandwidth {#max_remote_read_network_bandwidth}

<SettingsInfoBlock type='UInt64' default_value='0' />

读取操作通过网络进行数据交换的最大速度,单位为字节/秒。


## max_remote_write_network_bandwidth {#max_remote_write_network_bandwidth}

<SettingsInfoBlock type='UInt64' default_value='0' />

写入操作的网络数据传输最大速度(字节/秒)。


## max_replica_delay_for_distributed_queries {#max_replica_delay_for_distributed_queries}

<SettingsInfoBlock type='UInt64' default_value='300' />

在分布式查询中禁用滞后的副本。请参阅[复制](../../engines/table-engines/mergetree-family/replication.md)。

设置时间(以秒为单位)。如果副本的滞后时间大于或等于设置的值,则不使用该副本。

可能的值:

- 正整数。
- 0 — 不检查副本滞后。

要防止使用任何具有非零滞后的副本,请将此参数设置为 1。

在对指向复制表的分布式表执行 `SELECT` 查询时使用。


## max_result_bytes {#max_result_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

限制结果的字节大小(未压缩)。当达到阈值时,查询将在处理完一个数据块后停止,
但不会截断结果的最后一个数据块,因此结果大小可能会大于阈值。

**注意事项**

此阈值会考虑结果在内存中的大小。
即使结果大小很小,它也可能引用内存中更大的数据结构,
例如 LowCardinality 列的字典和 AggregateFunction 列的 Arena,
因此即使结果大小较小,也可能超过阈值。

:::warning
此设置属于较底层的配置,应谨慎使用
:::


## max_result_rows {#max_result_rows}

<SettingsInfoBlock type='UInt64' default_value='0' />

Cloud default value: `0`.

限制结果中的行数。该限制同样适用于子查询，以及在远程服务器上执行分布式查询的各个部分时。
当值为 `0` 时不应用限制。

当达到阈值时,查询会在处理完当前数据块后停止,但不会截断结果的最后一个数据块,因此结果大小可能会超过阈值。


## max_reverse_dictionary_lookup_cache_size_bytes {#max_reverse_dictionary_lookup_cache_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='104857600' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "104857600" },
        {
          label:
            "新设置。 函数 `dictGetKeys` 使用的单次查询反向字典查找缓存的最大字节数。该缓存为每个属性值存储序列化的键元组,以避免在同一查询中重复扫描字典。"
        }
      ]
    }
  ]}
/>

函数 `dictGetKeys` 使用的单次查询反向字典查找缓存的最大字节数。该缓存为每个属性值存储序列化的键元组,以避免在同一查询中重复扫描字典。 当达到限制时,将使用 LRU 算法淘汰条目。设置为 0 可禁用缓存。


## max_rows_in_distinct {#max_rows_in_distinct}

<SettingsInfoBlock type='UInt64' default_value='0' />

使用 DISTINCT 时不同行数的最大值。


## max_rows_in_join {#max_rows_in_join}

<SettingsInfoBlock type='UInt64' default_value='0' />

限制表连接时使用的哈希表中的行数。

此设置适用于 [SELECT ... JOIN](/sql-reference/statements/select/join)
操作和 [Join](/engines/table-engines/special/join) 表引擎。

如果查询包含多个连接,ClickHouse 会对每个中间结果检查此设置。

当达到限制时,ClickHouse 可以执行不同的操作。使用
[`join_overflow_mode`](/operations/settings/settings#join_overflow_mode) 设置来选择操作。

可能的值:

- 正整数。
- `0` — 不限制行数。


## max_rows_in_set {#max_rows_in_set}

<SettingsInfoBlock type='UInt64' default_value='0' />

由子查询创建的 IN 子句中数据集的最大行数。


## max_rows_in_set_to_optimize_join {#max_rows_in_set_to_optimize_join}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "0" },
        {
          label:
            "禁用连接优化,因为它会妨碍顺序读取优化"
        }
      ]
    }
  ]}
/>

在执行连接操作前,用于通过彼此的行集过滤连接表的集合的最大行数。

可能的值:

- 0 — 禁用。
- 任意正整数。


## max_rows_to_group_by {#max_rows_to_group_by}

<SettingsInfoBlock type='UInt64' default_value='0' />

聚合操作中接收的唯一键的最大数量。此设置用于限制聚合时的内存消耗。

如果 GROUP BY 聚合生成的行数(唯一 GROUP BY 键)超过指定数量,其行为将由 'group_by_overflow_mode' 参数决定,该参数默认值为 `throw`,也可以切换为近似 GROUP BY 模式。


## max_rows_to_read {#max_rows_to_read}

<SettingsInfoBlock type='UInt64' default_value='0' />

执行查询时可从表中读取的最大行数。
此限制在处理每个数据块时进行检查,仅应用于最深层的表表达式,且从远程服务器读取数据时,仅在远程服务器上进行检查。


## max_rows_to_read_leaf {#max_rows_to_read_leaf}

<SettingsInfoBlock type='UInt64' default_value='0' />

在运行分布式查询时,从叶节点本地表中可读取的最大行数。虽然分布式查询可以向每个分片(叶节点)发出多个子查询,但此限制仅在叶节点的读取阶段进行检查,而在根节点的结果合并阶段会被忽略。

例如,一个集群由 2 个分片组成,每个分片包含一个有 100 行的表。如果使用 `max_rows_to_read=150` 设置的分布式查询试图从两个表中读取所有数据,将会失败,因为总共有 200 行。而使用 `max_rows_to_read_leaf=150` 的查询将会成功,因为叶节点最多读取 100 行。

该限制针对每个处理的数据块进行检查。

:::note
当 `prefer_localhost_replica=1` 时,此设置不稳定。
:::


## max_rows_to_sort {#max_rows_to_sort}

<SettingsInfoBlock type='UInt64' default_value='0' />

排序前的最大行数。用于限制排序时的内存消耗。
如果 ORDER BY 操作需要处理的记录数超过指定值,
其行为将由 `sort_overflow_mode` 决定,默认值为 `throw`。


## max_rows_to_transfer {#max_rows_to_transfer}

<SettingsInfoBlock type='UInt64' default_value='0' />

执行 GLOBAL IN/JOIN 子句时，可传递到远程服务器或保存到临时表中的最大行数。


## max_sessions_for_user {#max_sessions_for_user}

<SettingsInfoBlock type='UInt64' default_value='0' />

每个已认证用户与 ClickHouse 服务器之间的最大并发会话数。

示例:

```xml
<profiles>
    <single_session_profile>
        <max_sessions_for_user>1</max_sessions_for_user>
    </single_session_profile>
    <two_sessions_profile>
        <max_sessions_for_user>2</max_sessions_for_user>
    </two_sessions_profile>
    <unlimited_sessions_profile>
        <max_sessions_for_user>0</max_sessions_for_user>
    </unlimited_sessions_profile>
</profiles>
<users>
    <!-- 用户 Alice 同一时间最多只能连接到 ClickHouse 服务器一次。 -->
    <Alice>
        <profile>single_session_user</profile>
    </Alice>
    <!-- 用户 Bob 可以同时使用 2 个会话。 -->
    <Bob>
        <profile>two_sessions_profile</profile>
    </Bob>
    <!-- 用户 Charles 可以同时使用任意数量的会话。 -->
    <Charles>
        <profile>unlimited_sessions_profile</profile>
    </Charles>
</users>
```

可能的值:

- 正整数
- `0` - 无限制并发会话数(默认)


## max_size_to_preallocate_for_aggregation {#max_size_to_preallocate_for_aggregation}

<SettingsInfoBlock type='UInt64' default_value='1000000000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "1000000000000" },
        { label: "为更大的表启用优化。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "22.12" },
        { label: "100000000" },
        { label: "优化性能" }
      ]
    }
  ]}
/>

在聚合之前允许在所有哈希表中总共为多少个元素预分配空间


## max_size_to_preallocate_for_joins {#max_size_to_preallocate_for_joins}

<SettingsInfoBlock type='UInt64' default_value='1000000000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "100000000" },
        { label: "新增设置。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.12" },
        { label: "1000000000000" },
        { label: "为更大的表启用优化。" }
      ]
    }
  ]}
/>

在执行连接操作前,允许在所有哈希表中预分配空间的元素总数上限


## max_streams_for_merge_tree_reading {#max_streams_for_merge_tree_reading}

<SettingsInfoBlock type='UInt64' default_value='0' />

如果不为零,则限制 MergeTree 表的读取流数量。


## max_streams_multiplier_for_merge_tables {#max_streams_multiplier_for_merge_tables}

<SettingsInfoBlock type='Float' default_value='5' />

从 Merge 表读取数据时请求更多的流。这些流将分布在 Merge 表所使用的各个表中。这样可以在线程之间实现更均匀的工作分配,在被合并的表大小不一致时尤其有用。


## max_streams_to_max_threads_ratio {#max_streams_to_max_threads_ratio}

<SettingsInfoBlock type='Float' default_value='1' />

允许使用比线程数更多的数据源,以便在线程之间更均匀地分配工作负载。这是一个临时解决方案,因为未来可以使数据源数量等于线程数量,并让每个数据源动态选择可用的工作任务。


## max_subquery_depth {#max_subquery_depth}

<SettingsInfoBlock type='UInt64' default_value='100' />

如果查询中嵌套子查询的数量超过指定值,将抛出异常。

:::tip
此设置可用于进行合理性检查,防止集群用户编写过于复杂的查询。
:::


## max_table_size_to_drop {#max_table_size_to_drop}

<SettingsInfoBlock type='UInt64' default_value='50000000000' />

对删除表操作的大小限制。值为 `0` 表示可以无限制地删除任意大小的表。

Cloud 默认值:1 TB。

:::note
此查询设置会覆盖其对应的服务器设置,请参阅 [max_table_size_to_drop](/operations/server-configuration-parameters/settings#max_table_size_to_drop)
:::


## max_temporary_columns {#max_temporary_columns}

<SettingsInfoBlock type='UInt64' default_value='0' />

运行查询时需要同时保存在 RAM 中的临时列的最大数量,包括常量列。如果查询在中间计算过程中生成的临时列数量超过指定值,则会抛出异常。

:::tip
此设置可用于防止过于复杂的查询。
:::

`0` 表示不限制。


## max_temporary_data_on_disk_size_for_query {#max_temporary_data_on_disk_size_for_query}

<SettingsInfoBlock type='UInt64' default_value='0' />

所有并发运行查询的临时文件在磁盘上消耗的最大数据量(以字节为单位)。

可能的值:

- 正整数。
- `0` — 无限制(默认)


## max_temporary_data_on_disk_size_for_user {#max_temporary_data_on_disk_size_for_user}

<SettingsInfoBlock type='UInt64' default_value='0' />

所有并发运行的用户查询在磁盘上临时文件所占用的最大数据量(以字节为单位)。

可能的值:

- 正整数。
- `0` — 无限制(默认)


## max_temporary_non_const_columns {#max_temporary_non_const_columns}

<SettingsInfoBlock type='UInt64' default_value='0' />

与 `max_temporary_columns` 类似,表示运行查询时必须同时保留在 RAM 中的临时列的最大数量,但不包括常量列。

:::note
运行查询时会频繁生成常量列,但它们几乎不消耗计算资源。
:::


## max_threads {#max_threads}

<SettingsInfoBlock type='MaxThreads' default_value="'auto(N)'" />

查询处理线程的最大数量,不包括从远程服务器获取数据的线程(参见 'max_distributed_connections' 参数)。

此参数适用于并行执行查询处理流水线中相同阶段的线程。
例如,从表中读取数据时,如果可以使用至少 'max_threads' 个线程并行执行函数表达式计算、WHERE 条件过滤和 GROUP BY 预聚合,则会使用 'max_threads' 个线程。

对于因 LIMIT 而快速完成的查询,可以设置较低的 'max_threads' 值。例如,如果每个数据块都包含所需数量的记录且 max_threads = 8,则会获取 8 个数据块,尽管实际上只需读取一个数据块即可。

`max_threads` 值越小,内存消耗越少。

Cloud 默认值:`auto(3)`


## max_threads_for_indexes {#max_threads_for_indexes}

<SettingsInfoBlock type='UInt64' default_value='0' />

用于处理索引的最大线程数。


## max_untracked_memory {#max_untracked_memory}

<SettingsInfoBlock type='UInt64' default_value='4194304' />

小型内存分配和释放操作会在线程局部变量中分组,仅当累积量(绝对值)超过指定值时才会被跟踪或分析。如果该值高于 'memory_profiler_step',则会被自动降低至 'memory_profiler_step'。


## memory_overcommit_ratio_denominator {#memory_overcommit_ratio_denominator}

<SettingsInfoBlock type='UInt64' default_value='1073741824' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.5" },
        { label: "1073741824" },
        { label: "默认启用内存超额使用功能" }
      ]
    }
  ]}
/>

表示在全局级别达到硬限制时的软内存限制。
此值用于计算查询的内存超额使用比率。
值为零表示跳过该查询。
了解更多信息,请参阅[内存超额使用](memory-overcommit.md)。


## memory_overcommit_ratio_denominator_for_user {#memory_overcommit_ratio_denominator_for_user}

<SettingsInfoBlock type='UInt64' default_value='1073741824' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.5" },
        { label: "1073741824" },
        { label: "默认启用内存超用功能" }
      ]
    }
  ]}
/>

它表示在用户级别达到硬限制时的软内存限制。
此值用于计算查询的内存超用比率。
零表示跳过查询。
阅读更多关于[内存超用](memory-overcommit.md)的信息。


## memory_profiler_sample_max_allocation_size {#memory_profiler_sample_max_allocation_size}

<SettingsInfoBlock type='UInt64' default_value='0' />

以 `memory_profiler_sample_probability` 的概率收集大小小于或等于指定值的随机内存分配。0 表示禁用。您可能需要将 'max_untracked_memory' 设置为 0,以使此阈值按预期工作。


## memory_profiler_sample_min_allocation_size {#memory_profiler_sample_min_allocation_size}

<SettingsInfoBlock type='UInt64' default_value='0' />

以等于 `memory_profiler_sample_probability` 的概率收集大小大于或等于指定值的随机内存分配。0 表示禁用。您可能需要将 'max_untracked_memory' 设置为 0，以使此阈值按预期工作。


## memory_profiler_sample_probability {#memory_profiler_sample_probability}

<SettingsInfoBlock type='Float' default_value='0' />

收集随机的内存分配和释放操作,并以 'MemorySample' 跟踪类型写入 system.trace_log。该概率应用于每次分配/释放操作,与分配大小无关(可通过 `memory_profiler_sample_min_allocation_size` 和 `memory_profiler_sample_max_allocation_size` 更改)。注意:仅当未跟踪内存量超过 'max_untracked_memory' 时才会进行采样。若需更精细的采样粒度,可将 'max_untracked_memory' 设置为 0。


## memory_profiler_step {#memory_profiler_step}

<SettingsInfoBlock type='UInt64' default_value='4194304' />

设置内存分析器的步长。每当查询内存使用量增加并超过下一个步长值(以字节为单位)时,内存分析器将收集内存分配的堆栈跟踪信息并将其写入 [trace_log](/operations/system-tables/trace_log)。

可选值:

- 正整数,表示字节数。

- 0 表示关闭内存分析器。


## memory_tracker_fault_probability {#memory_tracker_fault_probability}

<SettingsInfoBlock type='Float' default_value='0' />

用于测试`异常安全性` - 按指定概率在每次内存分配时抛出异常。


## memory_usage_overcommit_max_wait_microseconds {#memory_usage_overcommit_max_wait_microseconds}

<SettingsInfoBlock type='UInt64' default_value='5000000' />

在用户级别发生内存超用时,线程等待内存释放的最长时间。
如果超时且内存仍未释放,将抛出异常。
详见[内存超用](memory-overcommit.md)。


## merge_table_max_tables_to_look_for_schema_inference {#merge_table_max_tables_to_look_for_schema_inference}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "1000" }, { label: "新增设置" }]
    }
  ]}
/>

在创建未显式指定模式的 `Merge` 表或使用 `merge` 表函数时,将从不超过指定数量的匹配表中推断联合模式。
如果匹配的表数量超过此限制,则仅从前面指定数量的表中推断模式。


## merge_tree_coarse_index_granularity {#merge_tree_coarse_index_granularity}

<SettingsInfoBlock type='UInt64' default_value='8' />

在搜索数据时,ClickHouse 会检查索引文件中的数据标记。如果 ClickHouse 发现所需的键位于某个范围内,它会将该范围划分为 `merge_tree_coarse_index_granularity` 个子范围,并在这些子范围中递归搜索所需的键。

可能的值:

- 任意正偶数整数。


## merge_tree_compact_parts_min_granules_to_multibuffer_read {#merge_tree_compact_parts_min_granules_to_multibuffer_read}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='16' />

仅在 ClickHouse Cloud 中生效。MergeTree 表紧凑部分(compact part)条带中使用多缓冲区读取器的颗粒数阈值,该读取器支持并行读取和预取。从远程文件系统读取时,使用多缓冲区读取器会增加读取请求的数量。


## merge_tree_determine_task_size_by_prewhere_columns {#merge_tree_determine_task_size_by_prewhere_columns}

<SettingsInfoBlock type='Bool' default_value='1' />

是否仅使用 PREWHERE 列的大小来确定读取任务大小。


## merge_tree_max_bytes_to_use_cache {#merge_tree_max_bytes_to_use_cache}

<SettingsInfoBlock type='UInt64' default_value='2013265920' />

如果 ClickHouse 在单次查询中需要读取超过 `merge_tree_max_bytes_to_use_cache` 字节的数据,则不使用未压缩块缓存。

未压缩块缓存存储为查询提取的数据。ClickHouse 使用该缓存来加速重复小查询的响应速度。此设置可防止读取大量数据的查询污染缓存。[uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size) 服务器设置定义未压缩块缓存的大小。

可能的值:

- 任意正整数。


## merge_tree_max_rows_to_use_cache {#merge_tree_max_rows_to_use_cache}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

如果 ClickHouse 在单次查询中需要读取超过 `merge_tree_max_rows_to_use_cache` 行,则不使用未压缩块缓存。

未压缩块缓存存储为查询提取的数据。ClickHouse 使用此缓存来加速重复小查询的响应速度。此设置可防止读取大量数据的查询污染缓存。[uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size) 服务器设置定义未压缩块缓存的大小。

可选值:

- 任意正整数。


## merge_tree_min_bytes_for_concurrent_read {#merge_tree_min_bytes_for_concurrent_read}

<SettingsInfoBlock type='UInt64' default_value='251658240' />

如果从 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 引擎表的单个文件中读取的字节数超过 `merge_tree_min_bytes_for_concurrent_read`,则 ClickHouse 会尝试使用多个线程并发读取该文件。

可能的值:

- 正整数。


## merge_tree_min_bytes_for_concurrent_read_for_remote_filesystem {#merge_tree_min_bytes_for_concurrent_read_for_remote_filesystem}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "设置已弃用" }
      ]
    }
  ]}
/>

从远程文件系统读取时,在 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 引擎可以并行读取之前,从单个文件读取的最小字节数。不建议使用此设置。

可选值:

- 正整数。


## merge_tree_min_bytes_for_seek {#merge_tree_min_bytes_for_seek}

<SettingsInfoBlock type='UInt64' default_value='0' />

如果同一文件中需要读取的两个数据块之间的距离小于 `merge_tree_min_bytes_for_seek` 字节,ClickHouse 将顺序读取包含这两个数据块的文件区域,从而避免额外的磁盘寻址。

可能的值:

- 任意正整数。


## merge_tree_min_bytes_per_task_for_remote_reading {#merge_tree_min_bytes_per_task_for_remote_reading}

**别名**: `filesystem_prefetch_min_bytes_for_single_read_task`

<SettingsInfoBlock type='UInt64' default_value='2097152' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.8" },
        { label: "2097152" },
        {
          label:
            "该值已与 `filesystem_prefetch_min_bytes_for_single_read_task` 统一"
        }
      ]
    }
  ]}
/>

每个任务读取的最小字节数。


## merge_tree_min_read_task_size {#merge_tree_min_read_task_size}

<SettingsInfoBlock type='NonZeroUInt64' default_value='8' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "8" }, { label: "New setting" }]
    }
  ]}
/>

任务大小的硬性下限(即使颗粒数较少且可用线程数较多,也不会分配更小的任务


## merge_tree_min_rows_for_concurrent_read {#merge_tree_min_rows_for_concurrent_read}

<SettingsInfoBlock type='UInt64' default_value='163840' />

如果从 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 表的文件中需要读取的行数超过 `merge_tree_min_rows_for_concurrent_read`,则 ClickHouse 会尝试使用多个线程并发读取该文件。

可能的值:

- 正整数。


## merge_tree_min_rows_for_concurrent_read_for_remote_filesystem {#merge_tree_min_rows_for_concurrent_read_for_remote_filesystem}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "设置已弃用" }
      ]
    }
  ]}
/>

从远程文件系统读取时，[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 引擎在开始并行读取之前需要从单个文件读取的最小行数。不建议使用此设置。

可选值：

- 正整数。


## merge_tree_min_rows_for_seek {#merge_tree_min_rows_for_seek}

<SettingsInfoBlock type='UInt64' default_value='0' />

如果同一文件中需要读取的两个数据块之间的距离小于 `merge_tree_min_rows_for_seek` 行,则 ClickHouse 不会执行文件定位操作,而是按顺序读取数据。

可选值:

- 任意正整数。


## merge_tree_read_split_ranges_into_intersecting_and_non_intersecting_injection_probability {#merge_tree_read_split_ranges_into_intersecting_and_non_intersecting_injection_probability}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        {
          label:
            "用于测试 `PartsSplitter` - 每次从 MergeTree 读取时,按指定概率将读取范围拆分为相交和非相交范围。"
        }
      ]
    }
  ]}
/>

用于测试 `PartsSplitter` - 每次从 MergeTree 读取时,按指定概率将读取范围拆分为相交和非相交范围。


## merge_tree_storage_snapshot_sleep_ms {#merge_tree_storage_snapshot_sleep_ms}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "0" },
        {
          label: "用于调试查询中存储快照一致性的新配置项"
        }
      ]
    }
  ]}
/>

为 MergeTree 表创建存储快照时注入人工延迟(以毫秒为单位)。
仅用于测试和调试。

可选值:

- 0 - 无延迟(默认)
- N - 延迟毫秒数


## merge_tree_use_const_size_tasks_for_remote_reading {#merge_tree_use_const_size_tasks_for_remote_reading}

<SettingsInfoBlock type='Bool' default_value='1' />

是否对远程表读取使用固定大小的任务。


## merge_tree_use_deserialization_prefixes_cache {#merge_tree_use_deserialization_prefixes_cache}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.2" },
        { label: "1" },
        {
          label:
            "用于控制 MergeTree 反序列化前缀缓存使用的新设置"
        }
      ]
    }
  ]}
/>

在从远程磁盘读取 MergeTree 数据时,启用文件前缀中列元数据的缓存功能。


## merge_tree_use_prefixes_deserialization_thread_pool {#merge_tree_use_prefixes_deserialization_thread_pool}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.2" },
        { label: "1" },
        {
          label:
            "新增设置,用于控制 MergeTree 中并行前缀反序列化的线程池使用"
        }
      ]
    }
  ]}
/>

启用线程池以在 MergeTree 的 Wide 部分中并行读取前缀。该线程池的大小由服务器设置 `max_prefixes_deserialization_thread_pool_size` 控制。


## merge_tree_use_v1_object_and_dynamic_serialization {#merge_tree_use_v1_object_and_dynamic_serialization}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "0" },
        { label: "为 JSON 和 Dynamic 类型添加新的 V2 序列化版本" }
      ]
    }
  ]}
/>

启用后，MergeTree 将使用 JSON 和 Dynamic 类型的 V1 序列化版本，而非 V2 版本。更改此设置仅在服务器重启后生效。


## metrics_perf_events_enabled {#metrics_perf_events_enabled}

<SettingsInfoBlock type='Bool' default_value='0' />

启用后,将在查询执行过程中测量部分 perf 事件。


## metrics_perf_events_list {#metrics_perf_events_list}

以逗号分隔的性能指标列表,用于在查询执行过程中进行测量。留空表示测量所有事件。可用事件请参阅源代码中的 PerfEventInfo。


## min_bytes_to_use_direct_io {#min_bytes_to_use_direct_io}

<SettingsInfoBlock type='UInt64' default_value='0' />

使用直接 I/O 访问存储磁盘所需的最小数据量。

ClickHouse 在从表中读取数据时使用此设置。如果待读取数据的总存储量超过 `min_bytes_to_use_direct_io` 字节,则 ClickHouse 会使用 `O_DIRECT` 选项从存储磁盘读取数据。

可能的值:

- 0 — 禁用直接 I/O。
- 正整数。


## min_bytes_to_use_mmap_io {#min_bytes_to_use_mmap_io}

<SettingsInfoBlock type='UInt64' default_value='0' />

这是一个实验性设置。设置读取大文件时无需从内核复制数据到用户空间所需的最小内存量。建议的阈值约为 64 MB,因为 [mmap/munmap](https://en.wikipedia.org/wiki/Mmap) 速度较慢。此设置仅对大文件有意义,且仅在数据驻留在页面缓存中时才有效。

可能的值:

- 正整数。
- 0 — 读取大文件时仅使用从内核复制数据到用户空间的方式。


## min_chunk_bytes_for_parallel_parsing {#min_chunk_bytes_for_parallel_parsing}

<SettingsInfoBlock type='NonZeroUInt64' default_value='10485760' />

- 类型：无符号整数
- 默认值：1 MiB

每个线程在并行解析时处理的最小数据块大小（以字节为单位）。


## min_compress_block_size {#min_compress_block_size}

<SettingsInfoBlock type='UInt64' default_value='65536' />

适用于 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 表。为了降低查询处理延迟,在写入下一个标记时,如果数据块大小至少达到 `min_compress_block_size`,则会对该数据块进行压缩。默认值为 65,536。

如果未压缩数据小于 `max_compress_block_size`,则数据块的实际大小不小于此值,且不小于单个标记的数据量。

下面通过一个例子来说明。假设在创建表时将 `index_granularity` 设置为 8192。

写入一个 UInt32 类型的列(每个值 4 字节)。写入 8192 行时,总共有 32 KB 数据。由于 min_compress_block_size = 65,536,因此每两个标记会形成一个压缩块。

写入一个 String 类型的 URL 列(每个值平均大小为 60 字节)。写入 8192 行时,平均约有 500 KB 数据。由于超过了 65,536,因此每个标记会形成一个压缩块。在这种情况下,从磁盘读取单个标记范围内的数据时,不会解压缩额外的数据。

:::note
这是一个专家级设置,如果您刚开始使用 ClickHouse,不应修改此设置。
:::


## min_count_to_compile_aggregate_expression {#min_count_to_compile_aggregate_expression}

<SettingsInfoBlock type='UInt64' default_value='3' />

启动 JIT 编译所需的相同聚合表达式的最小数量。仅当启用 [compile_aggregate_expressions](#compile_aggregate_expressions) 设置时生效。

可选值:

- 正整数。
- 0 — 相同的聚合表达式总是进行 JIT 编译。


## min_count_to_compile_expression {#min_count_to_compile_expression}

<SettingsInfoBlock type='UInt64' default_value='3' />

相同表达式在被编译之前需要执行的最小次数。


## min_count_to_compile_sort_description {#min_count_to_compile_sort_description}

<SettingsInfoBlock type='UInt64' default_value='3' />

触发 JIT 编译前相同排序描述的数量阈值


## min_execution_speed {#min_execution_speed}

<SettingsInfoBlock type='UInt64' default_value='0' />

最小执行速度,以每秒处理行数为单位。当
[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)
超时后,将在每个数据块上进行检查。如果执行速度低于此值,则会抛出异常。


## min_execution_speed_bytes {#min_execution_speed_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

每秒执行的最小字节数。当
[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)
超时后,会对每个数据块进行检查。如果执行速度低于此值,则会抛出异常。


## min_external_table_block_size_bytes {#min_external_table_block_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='268402944' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "268402944" },
        {
          label:
            "当数据块不够大时,将传递给外部表的数据块合并到指定的字节大小。"
        }
      ]
    }
  ]}
/>

Squash blocks passed to the external table to a specified size in bytes, if blocks are not big enough.


## min_external_table_block_size_rows {#min_external_table_block_size_rows}

<SettingsInfoBlock type='UInt64' default_value='1048449' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1048449" },
        {
          label:
            "当数据块不够大时，将传递给外部表的数据块合并至指定的行数大小"
        }
      ]
    }
  ]}
/>

当数据块不够大时，将传递给外部表的数据块合并至指定的行数大小.


## min_free_disk_bytes_to_perform_insert {#min_free_disk_bytes_to_perform_insert}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        {
          label:
            "在插入数据时保留一定的可用磁盘空间,同时仍允许临时写入操作。"
        }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

执行插入操作所需的最小可用磁盘空间(以字节为单位)。


## min_free_disk_ratio_to_perform_insert {#min_free_disk_ratio_to_perform_insert}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        {
          label:
            "在允许临时写入的同时,保持一定的可用磁盘空间(以占总磁盘空间的比率表示),以防止插入操作占用过多空间。"
        }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

执行插入操作所需的最小可用磁盘空间比率。


## min_free_disk_space_for_temporary_data {#min_free_disk_space_for_temporary_data}

<SettingsInfoBlock type='UInt64' default_value='0' />

写入用于外部排序和聚合的临时数据时要保留的最小磁盘空间。


## min_hit_rate_to_use_consecutive_keys_optimization {#min_hit_rate_to_use_consecutive_keys_optimization}

<SettingsInfoBlock type='Float' default_value='0.5' />

用于聚合中连续键优化的缓存最小命中率，低于此值将禁用该优化


## min_insert_block_size_bytes {#min_insert_block_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='268402944' />

设置通过 `INSERT` 查询插入表中的数据块的最小字节数。较小的数据块将被合并为较大的数据块。

可能的值：

- 正整数。
- 0 — 禁用合并。


## min_insert_block_size_bytes_for_materialized_views {#min_insert_block_size_bytes_for_materialized_views}

<SettingsInfoBlock type='UInt64' default_value='0' />

设置通过 `INSERT` 查询插入表中的数据块的最小字节数。较小的数据块会被合并为较大的数据块。此设置仅适用于插入[物化视图](../../sql-reference/statements/create/view.md)的数据块。通过调整此设置,可以控制向物化视图推送数据时的数据块合并行为,避免过度的内存使用。

可能的值:

- 任意正整数。
- 0 — 禁用合并。

**另请参阅**

- [min_insert_block_size_bytes](#min_insert_block_size_bytes)


## min_insert_block_size_rows {#min_insert_block_size_rows}

<SettingsInfoBlock type='UInt64' default_value='1048449' />

设置通过 `INSERT` 查询插入表中的数据块的最小行数。较小的数据块会被合并为较大的数据块。

可能的值：

- 正整数。
- 0 — 禁用合并。


## min_insert_block_size_rows_for_materialized_views {#min_insert_block_size_rows_for_materialized_views}

<SettingsInfoBlock type='UInt64' default_value='0' />

设置通过 `INSERT` 查询插入表中的数据块的最小行数。较小的数据块会被合并为较大的数据块。此设置仅应用于插入[物化视图](../../sql-reference/statements/create/view.md)的数据块。通过调整此设置,可以控制向物化视图推送数据时的数据块合并行为,避免过度的内存使用。

可能的值:

- 任意正整数。
- 0 — 禁用合并。

**另请参阅**

- [min_insert_block_size_rows](#min_insert_block_size_rows)


## min_joined_block_size_bytes {#min_joined_block_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='524288' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "524288" },
        { label: "新增设置。" }
      ]
    }
  ]}
/>

JOIN 输入和输出数据块的最小字节大小(如果连接算法支持)。较小的数据块将被合并。0 表示无限制。


## min_joined_block_size_rows {#min_joined_block_size_rows}

<SettingsInfoBlock type='UInt64' default_value='65409' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.7" }, { label: "65409" }, { label: "新增设置。" }]
    }
  ]}
/>

JOIN 输入和输出块的最小行数(如果连接算法支持)。较小的块将被合并。0 表示无限制。


## min_os_cpu_wait_time_ratio_to_throw {#min_os_cpu_wait_time_ratio_to_throw}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "设置值已更改并回溯至 25.4 版本" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

操作系统 CPU 等待时间(OSCPUWaitMicroseconds 指标)与忙碌时间(OSCPUVirtualTimeMicroseconds 指标)之间的最小比率,用于判断是否拒绝查询。使用最小和最大比率之间的线性插值来计算概率,此时概率为 0。


## min_outstreams_per_resize_after_split {#min_outstreams_per_resize_after_split}

<SettingsInfoBlock type='UInt64' default_value='24' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.6" }, { label: "24" }, { label: "新设置。" }]
    }
  ]}
/>

指定在管道生成期间执行拆分后,`Resize` 或 `StrictResize` 处理器的最小输出流数量。如果拆分后的流数量少于此值,则不会执行拆分操作。

### 什么是 Resize 节点

`Resize` 节点是查询管道中的一个处理器,用于调整流经管道的数据流数量。它可以增加或减少流的数量,以在多个线程或处理器之间平衡工作负载。例如,如果查询需要更高的并行度,`Resize` 节点可以将单个流拆分为多个流。相反,它也可以将多个流合并为更少的流以整合数据处理。

`Resize` 节点确保数据在各个流之间均匀分布,同时保持数据块的结构。这有助于优化资源利用率并提高查询性能。

### 为什么需要拆分 Resize 节点

在管道执行期间,中心化 `Resize` 节点的 ExecutingGraph::Node::status_mutex 会产生严重的锁竞争,特别是在高核心数环境中,这种竞争会导致:

1. ExecutingGraph::updateNode 的延迟增加,直接影响查询性能。
2. 大量 CPU 周期浪费在自旋锁竞争(native_queued_spin_lock_slowpath)上,降低效率。
3. CPU 利用率降低,限制并行度和吞吐量。

### Resize 节点如何拆分

1. 检查输出流的数量以确保可以执行拆分:每个拆分后处理器的输出流需满足或超过 `min_outstreams_per_resize_after_split` 阈值。
2. 将 `Resize` 节点划分为具有相等端口数量的多个较小 `Resize` 节点,每个节点处理输入和输出流的一个子集。
3. 每个组独立处理,减少锁竞争。

### 拆分具有任意输入/输出的 Resize 节点

在某些情况下,当输入/输出无法被拆分后的 `Resize` 节点数量整除时,部分输入会连接到 `NullSource`,部分输出会连接到 `NullSink`。这样可以在不影响整体数据流的情况下完成拆分。

### 设置的目的

`min_outstreams_per_resize_after_split` 设置确保 `Resize` 节点的拆分是有意义的,避免创建过少的流而导致并行处理效率低下。通过强制要求最小输出流数量,此设置有助于在并行度和开销之间保持平衡,从而优化涉及流拆分和合并场景中的查询执行。

### 禁用设置

要禁用 `Resize` 节点的拆分,请将此设置设为 0。这将阻止在管道生成期间拆分 `Resize` 节点,使它们保持原始结构而不会被划分为更小的节点。


## min_table_rows_to_use_projection_index {#min_table_rows_to_use_projection_index}

<SettingsInfoBlock type='UInt64' default_value='1000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1000000" },
        { label: "新设置" }
      ]
    }
  ]}
/>

如果从表中读取的预估行数大于或等于此阈值,ClickHouse 将在查询执行时尝试使用投影索引。


## mongodb_throw_on_unsupported_query {#mongodb_throw_on_unsupported_query}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.9" }, { label: "1" }, { label: "新设置。" }]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "1" }, { label: "新设置。" }]
    }
  ]}
/>

启用后,当无法构建 MongoDB 查询时,MongoDB 表将返回错误。否则,ClickHouse 会读取完整表并在本地进行处理。当 'allow_experimental_analyzer=0' 时,此选项不适用。


## move_all_conditions_to_prewhere {#move_all_conditions_to_prewhere}

<SettingsInfoBlock type='Bool' default_value='1' />

将所有可行条件从 WHERE 移至 PREWHERE


## move_primary_key_columns_to_end_of_prewhere {#move_primary_key_columns_to_end_of_prewhere}

<SettingsInfoBlock type='Bool' default_value='1' />

将包含主键列的 PREWHERE 条件移至 AND 链的末尾。这些条件很可能已在主键分析阶段被考虑,因此对 PREWHERE 过滤的贡献不大。


## multiple_joins_try_to_keep_original_names {#multiple_joins_try_to_keep_original_names}

<SettingsInfoBlock type='Bool' default_value='0' />

在多表连接重写时不向顶层表达式列表添加别名


## mutations_execute_nondeterministic_on_initiator {#mutations_execute_nondeterministic_on_initiator}

<SettingsInfoBlock type='Bool' default_value='0' />

如果为 true,常量非确定性函数(例如 `now()` 函数)将在发起节点上执行,并在 `UPDATE` 和 `DELETE` 查询中被替换为字面量。这有助于在执行包含常量非确定性函数的 mutation 操作时保持副本间的数据同步。默认值:`false`。


## mutations_execute_subqueries_on_initiator {#mutations_execute_subqueries_on_initiator}

<SettingsInfoBlock type='Bool' default_value='0' />

如果设置为 true，标量子查询将在发起节点上执行，并在 `UPDATE` 和 `DELETE` 查询中被替换为字面量。默认值：`false`。


## mutations_max_literal_size_to_replace {#mutations_max_literal_size_to_replace}

<SettingsInfoBlock type='UInt64' default_value='16384' />

在 `UPDATE` 和 `DELETE` 查询中可替换的序列化字面量的最大字节大小。仅当上述两个设置中至少启用一个时生效。默认值:16384(16 KiB)。


## mutations_sync {#mutations_sync}

<SettingsInfoBlock type='UInt64' default_value='0' />

允许同步执行 `ALTER TABLE ... UPDATE|DELETE|MATERIALIZE INDEX|MATERIALIZE PROJECTION|MATERIALIZE COLUMN|MATERIALIZE STATISTICS` 查询（[变更操作](../../sql-reference/statements/alter/index.md/#mutations)）。

可能的值：

| 值 | 描述                                                                                                                                            |
| ----- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `0`   | 变更操作异步执行。                                                                                                                      |
| `1`   | 查询等待当前服务器上的所有变更操作完成。                                                                                   |
| `2`   | 查询等待所有副本（如果存在）上的所有变更操作完成。                                                                         |
| `3`   | 查询仅等待活跃副本完成。仅支持 `SharedMergeTree`。对于 `ReplicatedMergeTree`，其行为与 `mutations_sync = 2` 相同。 |


## mysql_datatypes_support_level {#mysql_datatypes_support_level}

定义 MySQL 类型如何转换为相应的 ClickHouse 类型。可以是 `decimal`、`datetime64`、`date2Date32` 或 `date2String` 的任意组合,以逗号分隔。

- `decimal`:当精度允许时,将 `NUMERIC` 和 `DECIMAL` 类型转换为 `Decimal`。
- `datetime64`:当精度不为 `0` 时,将 `DATETIME` 和 `TIMESTAMP` 类型转换为 `DateTime64` 而非 `DateTime`。
- `date2Date32`:将 `DATE` 转换为 `Date32` 而非 `Date`。优先级高于 `date2String`。
- `date2String`:将 `DATE` 转换为 `String` 而非 `Date`。会被 `datetime64` 覆盖。


## mysql_map_fixed_string_to_text_in_show_columns {#mysql_map_fixed_string_to_text_in_show_columns}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "降低 ClickHouse 与 BI 工具连接的配置复杂度。"
        }
      ]
    }
  ]}
/>

启用后,[FixedString](../../sql-reference/data-types/fixedstring.md) ClickHouse 数据类型将在 [SHOW COLUMNS](../../sql-reference/statements/show.md/#show_columns) 中显示为 `TEXT`。

仅在通过 MySQL wire 协议建立连接时生效。

- 0 - 使用 `BLOB`。
- 1 - 使用 `TEXT`。


## mysql_map_string_to_text_in_show_columns {#mysql_map_string_to_text_in_show_columns}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "降低 ClickHouse 与 BI 工具连接的配置工作量。"
        }
      ]
    }
  ]}
/>

启用后,ClickHouse 的 [String](../../sql-reference/data-types/string.md) 数据类型将在 [SHOW COLUMNS](../../sql-reference/statements/show.md/#show_columns) 中显示为 `TEXT`。

仅在通过 MySQL wire 协议建立连接时生效。

- 0 - 使用 `BLOB`。
- 1 - 使用 `TEXT`。


## mysql_max_rows_to_insert {#mysql_max_rows_to_insert}

<SettingsInfoBlock type='UInt64' default_value='65536' />

MySQL 存储引擎批量插入的最大行数


## network_compression_method {#network_compression_method}

<SettingsInfoBlock type='String' default_value='LZ4' />

用于压缩客户端/服务器及服务器/服务器通信的编解码器。

可选值：

- `NONE` — 无压缩。
- `LZ4` — 使用 LZ4 编解码器。
- `LZ4HC` — 使用 LZ4HC 编解码器。
- `ZSTD` — 使用 ZSTD 编解码器。

**另请参阅**

- [network_zstd_compression_level](#network_zstd_compression_level)


## network_zstd_compression_level {#network_zstd_compression_level}

<SettingsInfoBlock type='Int64' default_value='1' />

调整 ZSTD 压缩级别。仅当 [network_compression_method](#network_compression_method) 设置为 `ZSTD` 时使用。

可选值:

- 1 到 15 的正整数。


## normalize_function_names {#normalize_function_names}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.3" },
        { label: "1" },
        {
          label:
            "将函数名称规范化为其标准名称,投影查询路由需要此功能"
        }
      ]
    }
  ]}
/>

将函数名称规范化为其标准名称


## number_of_mutations_to_delay {#number_of_mutations_to_delay}

<SettingsInfoBlock type='UInt64' default_value='0' />

如果表中包含至少指定数量的未完成 mutation 操作,则人为降低该表的 mutation 执行速度。0 表示禁用


## number_of_mutations_to_throw {#number_of_mutations_to_throw}

<SettingsInfoBlock type='UInt64' default_value='0' />

如果变更表包含至少指定数量的未完成变更操作，则抛出 'Too many mutations ...' 异常。设置为 0 表示禁用此限制


## odbc_bridge_connection_pool_size {#odbc_bridge_connection_pool_size}

<SettingsInfoBlock type='UInt64' default_value='16' />

ODBC 桥接器中每个连接配置字符串的连接池大小。


## odbc_bridge_use_connection_pooling {#odbc_bridge_use_connection_pooling}

<SettingsInfoBlock type='Bool' default_value='1' />

在 ODBC 桥接中使用连接池。如果设置为 false,则每次都会创建新的连接。


## offset {#offset}

<SettingsInfoBlock type='UInt64' default_value='0' />

设置在开始返回查询结果之前要跳过的行数。它会调整 [OFFSET](/sql-reference/statements/select/offset) 子句设置的偏移量,这两个值会相加。

可能的值:

- 0 — 不跳过任何行。
- 正整数。

**示例**

输入表:

```sql
CREATE TABLE test (i UInt64) ENGINE = MergeTree() ORDER BY i;
INSERT INTO test SELECT number FROM numbers(500);
```

查询:

```sql
SET limit = 5;
SET offset = 7;
SELECT * FROM test LIMIT 10 OFFSET 100;
```

结果:

```text
┌───i─┐
│ 107 │
│ 108 │
│ 109 │
└─────┘
```


## opentelemetry_start_trace_probability {#opentelemetry_start_trace_probability}

<SettingsInfoBlock type='Float' default_value='0' />

设置 ClickHouse 为执行的查询启动追踪的概率(当未提供父级[追踪上下文](https://www.w3.org/TR/trace-context/)时)。

可能的值:

- 0 — 禁用所有执行查询的追踪(当未提供父级追踪上下文时)。
- [0..1] 范围内的正浮点数。例如,如果设置值为 `0.5`,ClickHouse 平均会为一半的查询启动追踪。
- 1 — 启用所有执行查询的追踪。


## opentelemetry_trace_cpu_scheduling {#opentelemetry_trace_cpu_scheduling}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "0" },
        { label: "用于追踪 `cpu_slot_preemption` 功能的新设置。" }
      ]
    }
  ]}
/>

收集工作负载抢占式 CPU 调度的 OpenTelemetry 跨度。


## opentelemetry_trace_processors {#opentelemetry_trace_processors}

<SettingsInfoBlock type='Bool' default_value='0' />

收集处理器的 OpenTelemetry 跨度信息。


## optimize_aggregation_in_order {#optimize_aggregation_in_order}

<SettingsInfoBlock type='Bool' default_value='0' />

在 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 表中,为 [SELECT](../../sql-reference/statements/select/index.md) 查询启用 [GROUP BY](/sql-reference/statements/select/group-by) 优化,以按相应顺序聚合数据。

可能的值:

- 0 — 禁用 `GROUP BY` 优化。
- 1 — 启用 `GROUP BY` 优化。

**另请参阅**

- [GROUP BY 优化](/sql-reference/statements/select/group-by#group-by-optimization-depending-on-table-sorting-key)


## optimize_aggregators_of_group_by_keys {#optimize_aggregators_of_group_by_keys}

<SettingsInfoBlock type='Bool' default_value='1' />

消除 SELECT 子句中 GROUP BY 键的 min/max/any/anyLast 聚合函数


## optimize_and_compare_chain {#optimize_and_compare_chain}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.2" }, { label: "1" }, { label: "新增设置" }]
    }
  ]}
/>

在 AND 链中填充常量比较以增强过滤能力。支持运算符 `<`、`<=`、`>`、`>=`、`=` 及其混合使用。例如,`(a < b) AND (b < c) AND (c < 5)` 将变为 `(a < b) AND (b < c) AND (c < 5) AND (b < 5) AND (a < 5)`。


## optimize_append_index {#optimize_append_index}

<SettingsInfoBlock type='Bool' default_value='0' />

使用[约束](../../sql-reference/statements/create/table.md/#constraints)来附加索引条件。默认值为 `false`。

可选值:

- true, false


## optimize_arithmetic_operations_in_aggregate_functions {#optimize_arithmetic_operations_in_aggregate_functions}

<SettingsInfoBlock type='Bool' default_value='1' />

将算术运算从聚合函数中移出


## optimize_const_name_size {#optimize_const_name_size}

<SettingsInfoBlock type='Int64' default_value='256' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "256" },
        {
          label:
            "对于大型常量，使用标量替换并以哈希值作为名称（大小根据名称长度估算）"
        }
      ]
    }
  ]}
/>

对于大型常量，使用标量替换并以哈希值作为名称（大小根据名称长度估算）。

可能的值：

- 正整数 — 名称的最大长度，
- 0 — 始终执行，
- 负整数 — 从不执行。


## optimize_count_from_files {#optimize_count_from_files}

<SettingsInfoBlock type='Bool' default_value='1' />

启用或禁用从不同输入格式的文件中统计行数的优化。适用于表函数/引擎 `file`/`s3`/`url`/`hdfs`/`azureBlobStorage`。

可选值:

- 0 — 禁用优化。
- 1 — 启用优化。


## optimize_distinct_in_order {#optimize_distinct_in_order}

<SettingsInfoBlock type='Bool' default_value='1' />

当 DISTINCT 中的某些列构成排序前缀时,启用 DISTINCT 优化。例如,MergeTree 表引擎中排序键的前缀或 ORDER BY 语句中的前缀


## optimize_distributed_group_by_sharding_key {#optimize_distributed_group_by_sharding_key}

<SettingsInfoBlock type='Bool' default_value='1' />

优化 `GROUP BY sharding_key` 查询,通过避免在发起服务器上执行代价高昂的聚合操作来减少发起服务器上查询的内存使用量。

支持以下类型的查询(及其所有组合):

- `SELECT DISTINCT [..., ]sharding_key[, ...] FROM dist`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...]`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] ORDER BY x`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] LIMIT 1`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] LIMIT 1 BY x`

不支持以下类型的查询(部分查询的支持可能会在后续版本中添加):

- `SELECT ... GROUP BY sharding_key[, ...] WITH TOTALS`
- `SELECT ... GROUP BY sharding_key[, ...] WITH ROLLUP`
- `SELECT ... GROUP BY sharding_key[, ...] WITH CUBE`
- `SELECT ... GROUP BY sharding_key[, ...] SETTINGS extremes=1`

可选值:

- 0 — 禁用。
- 1 — 启用。

另请参阅:

- [distributed_group_by_no_merge](#distributed_group_by_no_merge)
- [distributed_push_down_limit](#distributed_push_down_limit)
- [optimize_skip_unused_shards](#optimize_skip_unused_shards)

:::note
目前该设置需要启用 `optimize_skip_unused_shards`(这是因为该设置未来可能会默认启用,而只有当数据通过 Distributed 表插入时才能正常工作,即数据按照 sharding_key 进行分布)。
:::


## optimize_empty_string_comparisons {#optimize_empty_string_comparisons}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "1" }, { label: "新增设置。" }]
    }
  ]}
/>

当 col 为 String 或 FixedString 类型时,将形如 col = '' 或 '' = col 的表达式转换为 empty(col),将 col != '' 或 '' != col 转换为 notEmpty(col)。


## optimize_extract_common_expressions {#optimize_extract_common_expressions}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "1" },
        {
          label:
            "通过从析取合取式中提取公共表达式来优化 WHERE、PREWHERE、ON、HAVING 和 QUALIFY 表达式。"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.12" },
        { label: "0" },
        {
          label:
            "引入设置项,通过从析取合取式中提取公共表达式来优化 WHERE、PREWHERE、ON、HAVING 和 QUALIFY 表达式。"
        }
      ]
    }
  ]}
/>

允许从 WHERE、PREWHERE、ON、HAVING 和 QUALIFY 表达式的析取式中提取公共表达式。类似 `(A AND B) OR (A AND C)` 的逻辑表达式可以重写为 `A AND (B OR C)`,这有助于利用:

- 简单过滤表达式中的索引
- 交叉连接到内连接的优化


## optimize_functions_to_subcolumns {#optimize_functions_to_subcolumns}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.8" },
        { label: "1" },
        { label: "默认启用该设置" }
      ]
    }
  ]}
/>

启用或禁用通过将某些函数转换为读取子列的方式进行优化。这可以减少需要读取的数据量。

可以转换以下函数:

- [length](/sql-reference/functions/array-functions#length) 转换为读取 [size0](../../sql-reference/data-types/array.md/#array-size) 子列。
- [empty](/sql-reference/functions/array-functions#empty) 转换为读取 [size0](../../sql-reference/data-types/array.md/#array-size) 子列。
- [notEmpty](/sql-reference/functions/array-functions#notEmpty) 转换为读取 [size0](../../sql-reference/data-types/array.md/#array-size) 子列。
- [isNull](/sql-reference/functions/functions-for-nulls#isNull) 转换为读取 [null](../../sql-reference/data-types/nullable.md/#finding-null) 子列。
- [isNotNull](/sql-reference/functions/functions-for-nulls#isNotNull) 转换为读取 [null](../../sql-reference/data-types/nullable.md/#finding-null) 子列。
- [count](/sql-reference/aggregate-functions/reference/count) 转换为读取 [null](../../sql-reference/data-types/nullable.md/#finding-null) 子列。
- [mapKeys](/sql-reference/functions/tuple-map-functions#mapkeys) 转换为读取 [keys](/sql-reference/data-types/map#reading-subcolumns-of-map) 子列。
- [mapValues](/sql-reference/functions/tuple-map-functions#mapvalues) 转换为读取 [values](/sql-reference/data-types/map#reading-subcolumns-of-map) 子列。

可能的值:

- 0 — 禁用优化。
- 1 — 启用优化。


## optimize_group_by_constant_keys {#optimize_group_by_constant_keys}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.9" },
        { label: "1" },
        { label: "默认优化常量键的 GROUP BY" }
      ]
    }
  ]}
/>

当数据块中的所有键均为常量时优化 GROUP BY


## optimize_group_by_function_keys {#optimize_group_by_function_keys}

<SettingsInfoBlock type='Bool' default_value='1' />

消除 GROUP BY 子句中对其他键的函数调用


## optimize_if_chain_to_multiif {#optimize_if_chain_to_multiif}

<SettingsInfoBlock type='Bool' default_value='0' />

将 if(cond1, then1, if(cond2, ...)) 链式调用替换为 multiIf 函数。目前对数值类型不会带来性能提升。


## optimize_if_transform_strings_to_enum {#optimize_if_transform_strings_to_enum}

<SettingsInfoBlock type='Bool' default_value='0' />

将 If 和 Transform 函数中的字符串类型参数替换为枚举类型。默认禁用,因为在分布式查询中可能导致不一致的变更而引发查询失败。


## optimize_injective_functions_in_group_by {#optimize_injective_functions_in_group_by}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "1" },
        {
          label:
            "在分析器的 GROUP BY 子句中将单射函数替换为其参数"
        }
      ]
    }
  ]}
/>

在 GROUP BY 子句中将单射函数替换为其参数


## optimize_injective_functions_inside_uniq {#optimize_injective_functions_inside_uniq}

<SettingsInfoBlock type='Bool' default_value='1' />

删除 uniq\*() 函数内的单参数单射函数。


## optimize_min_equality_disjunction_chain_length {#optimize_min_equality_disjunction_chain_length}

<SettingsInfoBlock type='UInt64' default_value='3' />

对表达式 `expr = x1 OR ... expr = xN` 进行优化所需的最小长度


## optimize_min_inequality_conjunction_chain_length {#optimize_min_inequality_conjunction_chain_length}

<SettingsInfoBlock type='UInt64' default_value='3' />

表达式 `expr <> x1 AND ... expr <> xN` 进行优化的最小长度


## optimize_move_to_prewhere {#optimize_move_to_prewhere}

<SettingsInfoBlock type='Bool' default_value='1' />

启用或禁用 [SELECT](../../sql-reference/statements/select/index.md) 查询中的 [PREWHERE](../../sql-reference/statements/select/prewhere.md) 自动优化。

仅适用于 [\*MergeTree](../../engines/table-engines/mergetree-family/index.md) 表。

可选值:

- 0 — 禁用 `PREWHERE` 自动优化。
- 1 — 启用 `PREWHERE` 自动优化。


## optimize_move_to_prewhere_if_final {#optimize_move_to_prewhere_if_final}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在带有 [FINAL](/sql-reference/statements/select/from#final-modifier) 修饰符的 [SELECT](../../sql-reference/statements/select/index.md) 查询中自动进行 [PREWHERE](../../sql-reference/statements/select/prewhere.md) 优化。

仅适用于 [\*MergeTree](../../engines/table-engines/mergetree-family/index.md) 表。

可选值:

- 0 — 禁用在带有 `FINAL` 修饰符的 `SELECT` 查询中自动进行 `PREWHERE` 优化。
- 1 — 启用在带有 `FINAL` 修饰符的 `SELECT` 查询中自动进行 `PREWHERE` 优化。

**另请参阅**

- [optimize_move_to_prewhere](#optimize_move_to_prewhere) 设置


## optimize_multiif_to_if {#optimize_multiif_to_if}

<SettingsInfoBlock type='Bool' default_value='1' />

将仅包含单个条件的 'multiIf' 替换为 'if'。


## optimize_normalize_count_variants {#optimize_normalize_count_variants}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.3" },
        { label: "1" },
        {
          label:
            "默认将语义等同于 count() 的聚合函数重写为 count()"
        }
      ]
    }
  ]}
/>

将语义等同于 count() 的聚合函数重写为 count()。


## optimize_on_insert {#optimize_on_insert}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.1" },
        { label: "1" },
        {
          label:
            "默认启用 INSERT 数据优化以改善用户体验"
        }
      ]
    }
  ]}
/>

在插入数据之前启用或禁用数据转换,效果类似于对该数据块执行了合并操作(取决于表引擎)。

可选值:

- 0 — 禁用。
- 1 — 启用。

**示例**

启用与禁用的区别:

查询语句:

```sql
SET optimize_on_insert = 1;

CREATE TABLE test1 (`FirstTable` UInt32) ENGINE = ReplacingMergeTree ORDER BY FirstTable;

INSERT INTO test1 SELECT number % 2 FROM numbers(5);

SELECT * FROM test1;

SET optimize_on_insert = 0;

CREATE TABLE test2 (`SecondTable` UInt32) ENGINE = ReplacingMergeTree ORDER BY SecondTable;

INSERT INTO test2 SELECT number % 2 FROM numbers(5);

SELECT * FROM test2;
```

结果:

```text
┌─FirstTable─┐
│          0 │
│          1 │
└────────────┘

┌─SecondTable─┐
│           0 │
│           0 │
│           0 │
│           1 │
│           1 │
└─────────────┘
```

注意:此设置会影响[物化视图](/sql-reference/statements/create/view#materialized-view)的行为。


## optimize_or_like_chain {#optimize_or_like_chain}

<SettingsInfoBlock type='Bool' default_value='0' />

将多个 OR LIKE 优化为 multiMatchAny。默认情况下不应启用此优化,因为在某些场景下会影响索引分析。


## optimize_qbit_distance_function_reads {#optimize_qbit_distance_function_reads}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

将 `QBit` 数据类型上的距离函数替换为等效函数,仅从存储中读取计算所需的列。


## optimize_read_in_order {#optimize_read_in_order}

<SettingsInfoBlock type='Bool' default_value='1' />

在从 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 表读取数据的 [SELECT](../../sql-reference/statements/select/index.md) 查询中启用 [ORDER BY](/sql-reference/statements/select/order-by#optimization-of-data-reading) 优化。

可能的值：

- 0 — 禁用 `ORDER BY` 优化。
- 1 — 启用 `ORDER BY` 优化。

**另请参阅**

- [ORDER BY 子句](/sql-reference/statements/select/order-by#optimization-of-data-reading)


## optimize_read_in_window_order {#optimize_read_in_window_order}

<SettingsInfoBlock type='Bool' default_value='1' />

在 MergeTree 表中启用窗口子句的 ORDER BY 优化,以按相应顺序读取数据。


## optimize_redundant_functions_in_order_by {#optimize_redundant_functions_in_order_by}

<SettingsInfoBlock type='Bool' default_value='1' />

如果函数的参数也在 ORDER BY 中,则从 ORDER BY 中移除该函数


## optimize_respect_aliases {#optimize_respect_aliases}

<SettingsInfoBlock type='Bool' default_value='1' />

如果设置为 true,将在 WHERE/GROUP BY/ORDER BY 中识别别名,这有助于分区裁剪/二级索引/optimize_aggregation_in_order/optimize_read_in_order/optimize_trivial_count 优化


## optimize_rewrite_aggregate_function_with_if {#optimize_rewrite_aggregate_function_with_if}

<SettingsInfoBlock type='Bool' default_value='1' />

当逻辑等价时,将以 if 表达式作为参数的聚合函数进行重写。
例如,`avg(if(cond, col, null))` 可以重写为 `avgOrNullIf(cond, col)`。这可能会提升性能。

:::note
仅在启用分析器时支持(`enable_analyzer = 1`)。
:::


## optimize_rewrite_array_exists_to_has {#optimize_rewrite_array_exists_to_has}

<SettingsInfoBlock type='Bool' default_value='0' />

当逻辑等价时,将 arrayExists() 函数重写为 has() 函数。例如,arrayExists(x -> x = 1, arr) 可以重写为 has(arr, 1)


## optimize_rewrite_like_perfect_affix {#optimize_rewrite_like_perfect_affix}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

将带有完整前缀或后缀的 LIKE 表达式(例如 `col LIKE 'ClickHouse%'`)重写为 startsWith 或 endsWith 函数(例如 `startsWith(col, 'ClickHouse')`)。


## optimize_rewrite_regexp_functions {#optimize_rewrite_regexp_functions}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1" }, { label: "新增设置" }]
    }
  ]}
/>

将正则表达式相关函数重写为更简洁高效的形式


## optimize_rewrite_sum_if_to_count_if {#optimize_rewrite_sum_if_to_count_if}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "1" },
        { label: "仅在分析器中可用,且能正确工作" }
      ]
    }
  ]}
/>

当逻辑等价时,将 sumIf() 和 sum(if()) 函数重写为 countIf() 函数


## optimize_skip_merged_partitions {#optimize_skip_merged_partitions}

<SettingsInfoBlock type='Bool' default_value='0' />

当仅存在一个级别大于 0 且未过期 TTL 的数据部分时,启用或禁用 [OPTIMIZE TABLE ... FINAL](../../sql-reference/statements/optimize.md) 查询的优化。

- `OPTIMIZE TABLE ... FINAL SETTINGS optimize_skip_merged_partitions=1`

默认情况下,即使只有单个数据部分,`OPTIMIZE TABLE ... FINAL` 查询也会重写该部分。

可选值:

- 1 - 启用优化。
- 0 - 禁用优化。


## optimize_skip_unused_shards {#optimize_skip_unused_shards}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用对包含分片键条件的 [SELECT](../../sql-reference/statements/select/index.md) 查询跳过未使用的分片功能,其中分片键条件位于 `WHERE/PREWHERE` 子句中(前提是数据按分片键分布,否则查询将返回错误结果)。

可选值:

- 0 — 禁用。
- 1 — 启用。


## optimize_skip_unused_shards_limit {#optimize_skip_unused_shards_limit}

<SettingsInfoBlock type='UInt64' default_value='1000' />

分片键值数量的限制,达到该限制时将关闭 `optimize_skip_unused_shards`。

过多的值可能需要大量处理资源,但收益却不明显,因为如果 `IN (...)` 中包含大量值,查询很可能仍会被发送到所有分片。


## optimize_skip_unused_shards_nesting {#optimize_skip_unused_shards_nesting}

<SettingsInfoBlock type='UInt64' default_value='0' />

控制 [`optimize_skip_unused_shards`](#optimize_skip_unused_shards) 的行为(因此仍需启用 [`optimize_skip_unused_shards`](#optimize_skip_unused_shards)),具体取决于分布式查询的嵌套级别(即当一个 `Distributed` 表查询另一个 `Distributed` 表时的情况)。

可能的值:

- 0 — 禁用,`optimize_skip_unused_shards` 始终工作。
- 1 — 仅对第一层启用 `optimize_skip_unused_shards`。
- 2 — 对最多两层启用 `optimize_skip_unused_shards`。


## optimize_skip_unused_shards_rewrite_in {#optimize_skip_unused_shards_rewrite_in}

<SettingsInfoBlock type='Bool' default_value='1' />

重写远程分片查询中的 IN 子句,以排除不属于该分片的值(需要 optimize_skip_unused_shards)。

可能的值:

- 0 — 禁用。
- 1 — 启用。


## optimize_sorting_by_input_stream_properties {#optimize_sorting_by_input_stream_properties}

<SettingsInfoBlock type='Bool' default_value='1' />

根据输入流的排序属性来优化排序操作


## optimize_substitute_columns {#optimize_substitute_columns}

<SettingsInfoBlock type='Bool' default_value='0' />

使用[约束](../../sql-reference/statements/create/table.md/#constraints)进行列替换。默认值为 `false`。

可选值:

- true, false


## optimize_syntax_fuse_functions {#optimize_syntax_fuse_functions}

<SettingsInfoBlock type='Bool' default_value='0' />

启用对具有相同参数的聚合函数进行融合。当查询中包含至少两个参数相同的 [sum](/sql-reference/aggregate-functions/reference/sum)、[count](/sql-reference/aggregate-functions/reference/count) 或 [avg](/sql-reference/aggregate-functions/reference/avg) 聚合函数时,会将其重写为 [sumCount](/sql-reference/aggregate-functions/reference/sumcount)。

可选值:

- 0 — 不融合参数相同的函数。
- 1 — 融合参数相同的函数。

**示例**

查询:

```sql
CREATE TABLE fuse_tbl(a Int8, b Int8) Engine = Log;
SET optimize_syntax_fuse_functions = 1;
EXPLAIN SYNTAX SELECT sum(a), sum(b), count(b), avg(b) from fuse_tbl FORMAT TSV;
```

结果:

```text
SELECT
    sum(a),
    sumCount(b).1,
    sumCount(b).2,
    (sumCount(b).1) / (sumCount(b).2)
FROM fuse_tbl
```


## optimize_throw_if_noop {#optimize_throw_if_noop}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用当 [OPTIMIZE](../../sql-reference/statements/optimize.md) 查询未执行合并时抛出异常。

默认情况下,`OPTIMIZE` 即使未执行任何操作也会成功返回。此设置允许您区分这些情况,并在异常消息中获取具体原因。

可能的值:

- 1 — 启用抛出异常。
- 0 — 禁用抛出异常。


## optimize_time_filter_with_preimage {#optimize_time_filter_with_preimage}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "通过将函数转换为等效比较来优化 Date 和 DateTime 谓词,无需类型转换(例如 toYear(col) = 2023 -> col >= '2023-01-01' AND col <= '2023-12-31')"
        }
      ]
    }
  ]}
/>

Optimize Date and DateTime predicates by converting functions into equivalent comparisons without conversions (e.g. `toYear(col) = 2023 -> col >= '2023-01-01' AND col <= '2023-12-31'`)


## optimize_trivial_approximate_count_query {#optimize_trivial_approximate_count_query}

<SettingsInfoBlock type='Bool' default_value='0' />

对于支持此类估算的存储引擎(例如 EmbeddedRocksDB),在简单计数优化中使用近似值。

可能的值:

- 0 — 禁用优化。
- 1 — 启用优化。


## optimize_trivial_count_query {#optimize_trivial_count_query}

<SettingsInfoBlock type='Bool' default_value='1' />

启用或禁用对简单查询 `SELECT count() FROM table` 使用 MergeTree 元数据进行优化。如果需要使用行级安全功能,请禁用此设置。

可能的值:

- 0 — 禁用优化。
- 1 — 启用优化。

另请参阅:

- [optimize_functions_to_subcolumns](#optimize_functions_to_subcolumns)


## optimize_trivial_insert_select {#optimize_trivial_insert_select}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "0" },
        { label: "在许多情况下该优化并无实际意义。" }
      ]
    }
  ]}
/>

优化简单的 'INSERT INTO table SELECT ... FROM TABLES' 查询


## optimize_uniq_to_count {#optimize_uniq_to_count}

<SettingsInfoBlock type='Bool' default_value='1' />

当子查询包含 DISTINCT 或 GROUP BY 子句时,将 uniq 及其变体(uniqUpTo 除外)重写为 count。


## optimize_use_implicit_projections {#optimize_use_implicit_projections}

<SettingsInfoBlock type='Bool' default_value='1' />

自动选择隐式投影以执行 SELECT 查询


## optimize_use_projection_filtering {#optimize_use_projection_filtering}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.6" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

启用使用投影过滤数据分片范围,即使在执行 SELECT 查询时未选择投影。


## optimize_use_projections {#optimize_use_projections}

**别名**: `allow_experimental_projection_optimization`

<SettingsInfoBlock type='Bool' default_value='1' />

启用或禁用处理 `SELECT` 查询时的[投影](../../engines/table-engines/mergetree-family/mergetree.md/#projections)优化。

可能的值：

- 0 — 禁用投影优化。
- 1 — 启用投影优化。


## optimize_using_constraints {#optimize_using_constraints}

<SettingsInfoBlock type='Bool' default_value='0' />

使用[约束](../../sql-reference/statements/create/table.md/#constraints)进行查询优化。默认值为 `false`。

可选值:

- true, false


## os_threads_nice_value_materialized_view {#os_threads_nice_value_materialized_view}

<SettingsInfoBlock type='Int32' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

物化视图线程的 Linux nice 值。值越小,CPU 优先级越高。

需要 CAP_SYS_NICE 权限,否则无效。

可选值:-20 至 19。


## os_threads_nice_value_query {#os_threads_nice_value_query}

**别名**: `os_thread_priority`

<SettingsInfoBlock type='Int32' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

查询处理线程的 Linux nice 值。值越低,CPU 优先级越高。

需要 CAP_SYS_NICE 权限,否则不生效。

可选值:-20 至 19。


## output_format_compression_level {#output_format_compression_level}

<SettingsInfoBlock type='UInt64' default_value='3' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "3" },
        { label: "允许更改查询输出的压缩级别" }
      ]
    }
  ]}
/>

查询输出压缩时的默认压缩级别。当 `SELECT` 查询包含 `INTO OUTFILE` 或写入表函数 `file`、`url`、`hdfs`、`s3` 或 `azureBlobStorage` 时应用此设置。

可能的值:从 `1` 到 `22`


## output_format_compression_zstd_window_log {#output_format_compression_zstd_window_log}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "0" },
        {
          label:
            "允许在使用 zstd 压缩时更改查询输出的 zstd 窗口对数值"
        }
      ]
    }
  ]}
/>

当输出压缩方法为 `zstd` 时可使用此设置。如果大于 `0`,此设置将显式设置压缩窗口大小(`2` 的幂)并启用 zstd 压缩的长距离模式。这有助于获得更好的压缩比。

可能的值:非负数。请注意,如果值过小或过大,`zstdlib` 将抛出异常。典型值范围为 `20`(窗口大小 = `1MB`)至 `30`(窗口大小 = `1GB`)。


## output_format_parallel_formatting {#output_format_parallel_formatting}

<SettingsInfoBlock type='Bool' default_value='1' />

启用或禁用数据格式的并行格式化。仅支持 [TSV](/interfaces/formats/TabSeparated)、[TSKV](/interfaces/formats/TSKV)、[CSV](/interfaces/formats/CSV) 和 [JSONEachRow](/interfaces/formats/JSONEachRow) 格式。

可选值:

- 1 — 启用。
- 0 — 禁用。


## page_cache_block_size {#page_cache_block_size}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "1048576" },
        { label: "使该设置可按查询级别进行调整。" }
      ]
    }
  ]}
/>

存储在用户空间页缓存中的文件块大小，以字节为单位。所有通过缓存的读取操作都会向上取整为该大小的倍数。

该设置可以按查询级别进行调整，但不同块大小的缓存条目无法重用。更改该设置会使缓存中的现有条目失效。

较大的值（如 1 MiB）适合高吞吐量查询，较小的值（如 64 KiB）适合低延迟点查询。


## page_cache_inject_eviction {#page_cache_inject_eviction}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        { label: "新增用户空间页面缓存" }
      ]
    }
  ]}
/>

用户空间页面缓存会随机使部分页面失效。此功能用于测试。


## page_cache_lookahead_blocks {#page_cache_lookahead_blocks}

<SettingsInfoBlock type='UInt64' default_value='16' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "16" },
        { label: "使此设置可在单个查询级别进行调整。" }
      ]
    }
  ]}
/>

当用户空间页面缓存未命中时,如果底层存储中的连续块也不在缓存中,则一次性从底层存储读取最多指定数量的连续块。每个块的大小为 page_cache_block_size 字节。

较高的值适用于高吞吐量查询,而低延迟的点查询在不使用预读时效果更好。


## parallel_distributed_insert_select {#parallel_distributed_insert_select}

<SettingsInfoBlock type='UInt64' default_value='2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "2" },
        { label: "默认启用并行分布式 INSERT SELECT" }
      ]
    }
  ]}
/>

启用并行分布式 `INSERT ... SELECT` 查询。

如果执行 `INSERT INTO distributed_table_a SELECT ... FROM distributed_table_b` 查询,且两个表使用相同的集群,并且两个表均为[复制表](../../engines/table-engines/mergetree-family/replication.md)或均为非复制表,则该查询将在每个分片上本地处理。

可选值:

- `0` — 禁用。
- `1` — 在分布式引擎底层表的每个分片上执行 `SELECT`。
- `2` — 在分布式引擎底层表的每个分片上执行 `SELECT` 和 `INSERT`。

使用此设置时需要设置 `enable_parallel_replicas = 1`。


## parallel_hash_join_threshold {#parallel_hash_join_threshold}

<SettingsInfoBlock type='UInt64' default_value='100000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "100000" }, { label: "新设置" }]
    },
    {
      id: "row-2",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新设置" }]
    },
    {
      id: "row-3",
      items: [{ label: "25.3" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

当应用基于哈希的连接算法时,此阈值用于决定使用 `hash` 还是 `parallel_hash`(仅在右表大小估算值可用时)。
当右表大小低于该阈值时,将使用前者。


## parallel_replica_offset {#parallel_replica_offset}

<BetaBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

这是一个内部设置,不应直接使用,它代表了"并行副本"模式的实现细节。在分布式查询中,此设置将由发起服务器自动设置,用于标识参与查询处理的并行副本的索引位置。


## parallel_replicas_allow_in_with_subquery {#parallel_replicas_allow_in_with_subquery}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1" },
        {
          label:
            "如果为 true,则 IN 子查询将在每个从副本上执行"
        }
      ]
    }
  ]}
/>

如果为 true,则 IN 子查询将在每个从副本上执行.


## parallel_replicas_connect_timeout_ms {#parallel_replicas_connect_timeout_ms}

<BetaBadge />

<SettingsInfoBlock type='毫秒' default_value='300' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "300" },
        { label: "并行副本查询的独立连接超时" }
      ]
    }
  ]}
/>

在使用并行副本执行查询时,连接到远程副本的超时时间(以毫秒为单位)。如果连接超时,相应的副本将不会用于查询执行


## parallel_replicas_count {#parallel_replicas_count}

<BetaBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

这是一个内部设置,不应直接使用,它表示"并行副本"模式的实现细节。在分布式查询中,此设置将由发起服务器自动设置为参与查询处理的并行副本数量。


## parallel_replicas_custom_key {#parallel_replicas_custom_key}

<BetaBadge />

用于在特定表的副本之间分配工作负载的任意整数表达式。
该值可以是任何整数表达式。

建议使用基于主键的简单表达式。

如果在由单个分片和多个副本组成的集群上使用此设置,这些副本将被转换为虚拟分片。
否则,其行为将与 `SAMPLE` 键相同,即使用每个分片的多个副本。


## parallel_replicas_custom_key_range_lower {#parallel_replicas_custom_key_range_lower}

<BetaBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "添加设置以控制使用动态分片并行副本时的范围过滤器"
        }
      ]
    }
  ]}
/>

允许 `range` 过滤器类型基于自定义范围 `[parallel_replicas_custom_key_range_lower, INT_MAX]` 在副本之间均匀分配工作负载。

当与 [parallel_replicas_custom_key_range_upper](#parallel_replicas_custom_key_range_upper) 结合使用时,过滤器将针对范围 `[parallel_replicas_custom_key_range_lower, parallel_replicas_custom_key_range_upper]` 在副本之间均匀分配工作负载。

注意:此设置不会在查询处理期间过滤任何额外数据,而是改变范围过滤器将范围 `[0, INT_MAX]` 拆分用于并行处理的分割点。


## parallel_replicas_custom_key_range_upper {#parallel_replicas_custom_key_range_upper}

<BetaBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "添加设置以在使用动态分片的并行副本时控制范围过滤器。值为 0 时禁用上限。"
        }
      ]
    }
  ]}
/>

允许 `range` 过滤器类型基于自定义范围 `[0, parallel_replicas_custom_key_range_upper]` 在副本之间均匀分配工作负载。值为 0 时禁用上限,并将其设置为自定义键表达式的最大值。

当与 [parallel_replicas_custom_key_range_lower](#parallel_replicas_custom_key_range_lower) 结合使用时,过滤器将在范围 `[parallel_replicas_custom_key_range_lower, parallel_replicas_custom_key_range_upper]` 内均匀地在副本之间分配工作负载。

注意:此设置不会在查询处理期间过滤任何额外数据,而是改变范围过滤器将范围 `[0, INT_MAX]` 拆分用于并行处理的分割点。


## parallel_replicas_for_cluster_engines {#parallel_replicas_for_cluster_engines}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.3" }, { label: "1" }, { label: "新增设置。" }]
    }
  ]}
/>

将表函数引擎替换为其 -Cluster 替代版本


## parallel_replicas_for_non_replicated_merge_tree {#parallel_replicas_for_non_replicated_merge_tree}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

如果为 true，ClickHouse 也会对非复制 MergeTree 表使用并行副本算法


## parallel_replicas_index_analysis_only_on_coordinator {#parallel_replicas_index_analysis_only_on_coordinator}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "1" },
        {
          label:
            "索引分析仅在副本协调器上执行,在其他副本上跳过。仅在启用 parallel_replicas_local_plan 时生效"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.10" },
        { label: "1" },
        {
          label:
            "索引分析仅在副本协调器上执行,在其他副本上跳过。仅在启用 parallel_replicas_local_plan 时生效"
        }
      ]
    }
  ]}
/>

Index analysis done only on replica-coordinator and skipped on other replicas. Effective only with enabled parallel_replicas_local_pla


## parallel_replicas_insert_select_local_pipeline {#parallel_replicas_insert_select_local_pipeline}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "1" },
        {
          label:
            "在使用并行副本的分布式 INSERT SELECT 操作中使用本地管道。由于性能问题目前已禁用"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.4" },
        { label: "0" },
        {
          label:
            "在使用并行副本的分布式 INSERT SELECT 操作中使用本地管道。由于性能问题目前已禁用"
        }
      ]
    }
  ]}
/>

在使用并行副本的分布式 INSERT SELECT 操作中使用本地管道


## parallel_replicas_local_plan {#parallel_replicas_local_plan}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        {
          label:
            "在并行副本查询中为本地副本使用本地执行计划"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.11" },
        { label: "1" },
        {
          label:
            "在并行副本查询中为本地副本使用本地执行计划"
        }
      ]
    },
    {
      id: "row-3",
      items: [
        { label: "24.10" },
        { label: "1" },
        {
          label:
            "在并行副本查询中为本地副本使用本地执行计划"
        }
      ]
    }
  ]}
/>

为本地副本构建本地执行计划


## parallel_replicas_mark_segment_size {#parallel_replicas_mark_segment_size}

<BetaBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        { label: "此设置的值现在由系统自动确定" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.1" },
        { label: "128" },
        {
          label:
            "新增设置以控制新并行副本协调器实现中的段大小"
        }
      ]
    }
  ]}
/>

数据分片被虚拟划分为多个段，以便在副本之间分配进行并行读取。此设置控制这些段的大小。除非您完全确定自己在做什么,否则不建议更改。取值范围应为 [128; 16384]


## parallel_replicas_min_number_of_rows_per_replica {#parallel_replicas_min_number_of_rows_per_replica}

<BetaBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

将查询中使用的副本数量限制为(预估读取行数 / min_number_of_rows_per_replica)。最大值仍受 'max_parallel_replicas' 限制


## parallel_replicas_mode {#parallel_replicas_mode}

<BetaBadge />

<SettingsInfoBlock type='ParallelReplicasMode' default_value='read_tasks' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "read_tasks" },
        {
          label:
            "此设置作为并行副本功能 Beta 版本的一部分引入"
        }
      ]
    }
  ]}
/>

用于并行副本的自定义键过滤器类型。default - 对自定义键使用取模运算;range - 对自定义键使用范围过滤器,使用该自定义键值类型的所有可能值。


## parallel_replicas_only_with_analyzer {#parallel_replicas_only_with_analyzer}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.2" },
        { label: "1" },
        { label: "仅在启用分析器时支持并行副本" }
      ]
    }
  ]}
/>

使用并行副本功能需要启用分析器。当分析器被禁用时,即使启用了从副本并行读取,查询执行也会回退到本地执行。不支持在未启用分析器的情况下使用并行副本


## parallel_replicas_prefer_local_join {#parallel_replicas_prefer_local_join}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "若为 true,且 JOIN 可通过并行副本算法执行,且 JOIN 右表的所有存储引擎均为 *MergeTree,则使用本地 JOIN 代替 GLOBAL JOIN。"
        }
      ]
    }
  ]}
/>

If true, and JOIN can be executed with parallel replicas algorithm, and all storages of right JOIN part are \*MergeTree, local JOIN will be used instead of GLOBAL JOIN.


## parallel_replicas_support_projection {#parallel_replicas_support_projection}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "1" },
        {
          label:
            "新增设置。可在并行副本中应用投影优化。仅在启用 parallel_replicas_local_plan 且 aggregation_in_order 处于非激活状态时生效。"
        }
      ]
    }
  ]}
/>

可在并行副本中应用投影优化。仅在启用 parallel_replicas_local_plan 且 aggregation_in_order 处于非激活状态时生效。


## parallel_view_processing {#parallel_view_processing}

<SettingsInfoBlock type='Bool' default_value='0' />

启用并发推送到附加视图，而不是顺序推送。


## parallelize_output_from_storages {#parallelize_output_from_storages}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.5" },
        { label: "1" },
        {
          label:
            "允许在执行从 file/url/s3 等读取数据的查询时进行并行处理。这可能会导致行的顺序发生变化。"
        }
      ]
    }
  ]}
/>

并行化存储读取步骤的输出。如果可能,允许在从存储读取后立即对查询处理进行并行化


## parsedatetime_e_requires_space_padding {#parsedatetime_e_requires_space_padding}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "改进了与 MySQL DATE_FORMAT/STR_TO_DATE 的兼容性" }
      ]
    }
  ]}
/>

函数 `parseDateTime` 中的格式化符 `%e` 要求单位数的日期使用空格填充,例如:` 2` 可以被接受,但 `2` 会引发错误。


## parsedatetime_parse_without_leading_zeros {#parsedatetime_parse_without_leading_zeros}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.11" },
        { label: "1" },
        { label: "改进了与 MySQL DATE_FORMAT/STR_TO_DATE 的兼容性" }
      ]
    }
  ]}
/>

函数 'parseDateTime' 中的格式化符 '%c'、'%l' 和 '%k' 在解析月份和小时时不要求前导零。


## partial_merge_join_left_table_buffer_bytes {#partial_merge_join_left_table_buffer_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

如果不为 0，则在部分合并连接中将左表的数据块组合成更大的块。每个连接线程最多使用指定内存的 2 倍。


## partial_merge_join_rows_in_right_blocks {#partial_merge_join_rows_in_right_blocks}

<SettingsInfoBlock type='UInt64' default_value='65536' />

限制 [JOIN](../../sql-reference/statements/select/join.md) 查询中部分合并连接算法的右表数据块大小。

ClickHouse 服务器执行以下操作:

1.  将右表连接数据拆分为包含不超过指定行数的数据块。
2.  使用最小值和最大值为每个数据块建立索引。
3.  如果可能,将准备好的数据块卸载到磁盘。

可能的值:

- 任意正整数。推荐值范围:\[1000, 100000\]。


## partial_result_on_first_cancel {#partial_result_on_first_cancel}

<SettingsInfoBlock type='Bool' default_value='0' />

允许查询在取消后返回部分结果。


## parts_to_delay_insert {#parts_to_delay_insert}

<SettingsInfoBlock type='UInt64' default_value='0' />

如果目标表的单个分区中包含至少指定数量的活跃数据部分，则会人为降低向该表插入数据的速度。


## parts_to_throw_insert {#parts_to_throw_insert}

<SettingsInfoBlock type='UInt64' default_value='0' />

如果目标表的单个分区中活跃数据部分的数量超过此值,则抛出 'Too many parts ...' 异常。


## per_part_index_stats {#per_part_index_stats}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "New setting." }]
    }
  ]}
/>

        记录每个数据分区的索引统计信息


## poll_interval {#poll_interval}

<SettingsInfoBlock type='UInt64' default_value='10' />

在服务器的查询等待循环中阻塞指定秒数。


## postgresql_connection_attempt_timeout {#postgresql_connection_attempt_timeout}

<SettingsInfoBlock type='UInt64' default_value='2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "2" },
        {
          label:
            "允许控制 PostgreSQL 连接的 'connect_timeout' 参数。"
        }
      ]
    }
  ]}
/>

单次尝试连接 PostgreSQL 端点的超时时间(以秒为单位)。
该值作为连接 URL 的 `connect_timeout` 参数传递。


## postgresql_connection_pool_auto_close_connection {#postgresql_connection_pool_auto_close_connection}

<SettingsInfoBlock type='Bool' default_value='0' />

在将连接返回连接池之前关闭连接。


## postgresql_connection_pool_retries {#postgresql_connection_pool_retries}

<SettingsInfoBlock type='UInt64' default_value='2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "2" },
        {
          label:
            "允许控制 PostgreSQL 连接池的重试次数。"
        }
      ]
    }
  ]}
/>

PostgreSQL 表引擎和数据库引擎的连接池推入/弹出操作的重试次数。


## postgresql_connection_pool_size {#postgresql_connection_pool_size}

<SettingsInfoBlock type='UInt64' default_value='16' />

PostgreSQL 表引擎和数据库引擎的连接池大小。


## postgresql_connection_pool_wait_timeout {#postgresql_connection_pool_wait_timeout}

<SettingsInfoBlock type='UInt64' default_value='5000' />

PostgreSQL 表引擎和数据库引擎在连接池为空时的推入/弹出操作超时时间。默认情况下,当连接池为空时将会阻塞。


## postgresql_fault_injection_probability {#postgresql_fault_injection_probability}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.2" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

内部（用于复制）PostgreSQL 查询失败的近似概率。有效值区间为 [0.0f, 1.0f]


## prefer_column_name_to_alias {#prefer_column_name_to_alias}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在查询表达式和子句中使用原始列名而非别名。当别名与列名相同时,此设置尤为重要,请参阅[表达式别名](/sql-reference/syntax#notes-on-usage)。启用此设置可使 ClickHouse 中的别名语法规则与大多数其他数据库引擎更加兼容。

可选值:

- 0 — 列名被别名替换。
- 1 — 列名不被别名替换。

**示例**

启用和禁用之间的区别:

查询:

```sql
SET prefer_column_name_to_alias = 0;
SELECT avg(number) AS number, max(number) FROM numbers(10);
```

结果:

```text
Received exception from server (version 21.5.1):
Code: 184. DB::Exception: Received from localhost:9000. DB::Exception: Aggregate function avg(number) is found inside another aggregate function in query: While processing avg(number) AS number.
```

查询:

```sql
SET prefer_column_name_to_alias = 1;
SELECT avg(number) AS number, max(number) FROM numbers(10);
```

结果:

```text
┌─number─┬─max(number)─┐
│    4.5 │           9 │
└────────┴─────────────┘
```


## prefer_external_sort_block_bytes {#prefer_external_sort_block_bytes}

<SettingsInfoBlock type='UInt64' default_value='16744704' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.5" },
        { label: "16744704" },
        {
          label:
            "外部排序的首选最大块字节数,减少合并期间的内存使用量。"
        }
      ]
    }
  ]}
/>

外部排序的首选最大块字节数,减少合并期间的内存使用量。


## prefer_global_in_and_join {#prefer_global_in_and_join}

<SettingsInfoBlock type='Bool' default_value='0' />

启用将 `IN`/`JOIN` 操作符替换为 `GLOBAL IN`/`GLOBAL JOIN`。

可能的值:

- 0 — 禁用。`IN`/`JOIN` 操作符不会被替换为 `GLOBAL IN`/`GLOBAL JOIN`。
- 1 — 启用。`IN`/`JOIN` 操作符会被替换为 `GLOBAL IN`/`GLOBAL JOIN`。

**用法**

虽然 `SET distributed_product_mode=global` 可以改变分布式表的查询行为,但它不适用于本地表或外部资源表。此时 `prefer_global_in_and_join` 设置就派上用场了。

例如,我们有包含本地表的查询服务节点,这些表不适合分布式处理。我们需要在分布式处理期间使用 `GLOBAL` 关键字动态分散它们的数据 — `GLOBAL IN`/`GLOBAL JOIN`。

`prefer_global_in_and_join` 的另一个用例是访问由外部引擎创建的表。此设置有助于在连接此类表时减少对外部源的调用次数:每个查询仅调用一次。

**另请参阅:**

- [分布式子查询](/sql-reference/operators/in#distributed-subqueries) 了解有关如何使用 `GLOBAL IN`/`GLOBAL JOIN` 的更多信息


## prefer_localhost_replica {#prefer_localhost_replica}

<SettingsInfoBlock type='Bool' default_value='1' />

启用/禁用在处理分布式查询时优先使用本地副本。

可能的值:

- 1 — 如果本地副本存在,ClickHouse 始终将查询发送到本地副本。
- 0 — ClickHouse 使用 [load_balancing](#load_balancing) 设置指定的负载均衡策略。

:::note
如果使用 [max_parallel_replicas](#max_parallel_replicas) 时未设置 [parallel_replicas_custom_key](#parallel_replicas_custom_key),请禁用此设置。
如果已设置 [parallel_replicas_custom_key](#parallel_replicas_custom_key),则仅在包含多个副本的多分片集群上使用时才禁用此设置。
如果在单分片多副本集群上使用,禁用此设置会产生负面影响。
:::


## prefer_warmed_unmerged_parts_seconds {#prefer_warmed_unmerged_parts_seconds}

<CloudOnlyBadge />

<SettingsInfoBlock type='Int64' default_value='0' />

仅在 ClickHouse Cloud 中生效。如果合并后的数据分区创建时间少于指定秒数且未经预热(参见 [cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch)),但其所有源分区均可用且已预热,则 SELECT 查询将改为从这些源分区读取数据。仅适用于 Replicated-/SharedMergeTree 表引擎。注意:此设置仅检查 CacheWarmer 是否已处理该分区;若分区通过其他方式被加载到缓存中,在 CacheWarmer 处理之前仍被视为冷数据;若分区已预热但随后被从缓存中驱逐,仍被视为已预热状态。


## preferred_block_size_bytes {#preferred_block_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='1000000' />

此设置用于调整查询处理时的数据块大小,是对粒度较粗的 'max_block_size' 设置的进一步精细调优。当列数据较大且按 'max_block_size' 行数计算的块大小可能超过指定字节数时,系统会降低块大小以提高 CPU 缓存局部性。


## preferred_max_column_in_block_size_bytes {#preferred_max_column_in_block_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

读取数据块时对列最大大小的限制。有助于降低缓存未命中次数。该值应接近 L2 缓存大小。


## preferred_optimize_projection_name {#preferred_optimize_projection_name}

如果设置为非空字符串,ClickHouse 将尝试在查询中应用指定的投影。

可能的值:

- string:首选投影的名称


## prefetch_buffer_size {#prefetch_buffer_size}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

从文件系统读取数据时预取缓冲区的最大大小。


## print_pretty_type_names {#print_pretty_type_names}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "1" },
        { label: "改进用户体验。" }
      ]
    }
  ]}
/>

允许在 `DESCRIBE` 查询和 `toTypeName()` 函数中以带缩进的格式化方式打印深层嵌套的类型名称。

示例:

```sql
CREATE TABLE test (a Tuple(b String, c Tuple(d Nullable(UInt64), e Array(UInt32), f Array(Tuple(g String, h Map(String, Array(Tuple(i String, j UInt64))))), k Date), l Nullable(String))) ENGINE=Memory;
DESCRIBE TABLE test FORMAT TSVRaw SETTINGS print_pretty_type_names=1;
```

```
a   Tuple(
    b String,
    c Tuple(
        d Nullable(UInt64),
        e Array(UInt32),
        f Array(Tuple(
            g String,
            h Map(
                String,
                Array(Tuple(
                    i String,
                    j UInt64
                ))
            )
        )),
        k Date
    ),
    l Nullable(String)
)
```


## priority {#priority}

<SettingsInfoBlock type='UInt64' default_value='0' />

查询的优先级。1 表示最高优先级,数值越大优先级越低;0 表示不使用优先级。


## promql_database {#promql_database}

<ExperimentalBadge />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "" },
        { label: "新增实验性设置" }
      ]
    }
  ]}
/>

指定 'promql' 方言所使用的数据库名称。空字符串表示使用当前数据库。


## promql_evaluation_time {#promql_evaluation_time}

<ExperimentalBadge />

**别名**: `evaluation_time`

<SettingsInfoBlock type='FloatAuto' default_value='auto' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.9" },
        { label: "auto" },
        {
          label:
            "此设置已重命名。原名称为 `evaluation_time`。"
        }
      ]
    }
  ]}
/>

设置用于 promql 方言的评估时间。'auto' 表示使用当前时间。


## promql_table {#promql_table}

<ExperimentalBadge />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "" },
        { label: "新增实验性设置" }
      ]
    }
  ]}
/>

指定 'promql' 方言所使用的 TimeSeries 表名称。


## push_external_roles_in_interserver_queries {#push_external_roles_in_interserver_queries}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "1" }, { label: "新增设置。" }]
    }
  ]}
/>

启用在执行查询时将用户角色从发起节点推送到其他节点。


## query_cache_compress_entries {#query_cache_compress_entries}

<SettingsInfoBlock type='Bool' default_value='1' />

压缩[查询缓存](../query-cache.md)中的条目。以较慢的插入和读取速度为代价，降低查询缓存的内存消耗。

可能的值：

- 0 - 禁用
- 1 - 启用


## query_cache_max_entries {#query_cache_max_entries}

<SettingsInfoBlock type='UInt64' default_value='0' />

当前用户可在[查询缓存](../query-cache.md)中存储的查询结果的最大数量。0 表示无限制。

可选值:

- 大于或等于 0 的正整数。


## query_cache_max_size_in_bytes {#query_cache_max_size_in_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

当前用户可在[查询缓存](../query-cache.md)中分配的最大内存量(以字节为单位)。0 表示无限制。

可能的值:

- 大于或等于 0 的正整数。


## query_cache_min_query_duration {#query_cache_min_query_duration}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

查询结果存储到[查询缓存](../query-cache.md)所需的最小运行时长(毫秒)。

可选值:

- 大于等于 0 的正整数。


## query_cache_min_query_runs {#query_cache_min_query_runs}

<SettingsInfoBlock type='UInt64' default_value='0' />

`SELECT` 查询结果被存储到[查询缓存](../query-cache.md)之前必须运行的最小次数。

可选值:

- 大于或等于 0 的正整数。


## query_cache_nondeterministic_function_handling {#query_cache_nondeterministic_function_handling}

<SettingsInfoBlock
  type='QueryResultCacheNondeterministicFunctionHandling'
  default_value='throw'
/>

控制[查询缓存](../query-cache.md)如何处理包含非确定性函数(如 `rand()` 或 `now()`)的 `SELECT` 查询。

可能的值:

- `'throw'` - 抛出异常并且不缓存查询结果。
- `'save'` - 缓存查询结果。
- `'ignore'` - 不缓存查询结果并且不抛出异常。


## query_cache_share_between_users {#query_cache_share_between_users}

<SettingsInfoBlock type='Bool' default_value='0' />

启用后,[查询缓存](../query-cache.md)中缓存的 `SELECT` 查询结果可被其他用户读取。
出于安全考虑,不建议启用此设置。

可选值:

- 0 - 禁用
- 1 - 启用


## query_cache_squash_partial_results {#query_cache_squash_partial_results}

<SettingsInfoBlock type='Bool' default_value='1' />

将部分结果块合并为大小为 [max_block_size](#max_block_size) 的块。会降低插入[查询缓存](../query-cache.md)的性能,但可以提高缓存条目的压缩率(参见 [query_cache_compress-entries](#query_cache_compress_entries))。

可选值:

- 0 - 禁用
- 1 - 启用


## query_cache_system_table_handling {#query_cache_system_table_handling}

<SettingsInfoBlock
  type='QueryResultCacheSystemTableHandling'
  default_value='throw'
/>

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "throw" },
        {
          label:
            "查询缓存不再缓存针对系统表的查询结果"
        }
      ]
    }
  ]}
/>

控制[查询缓存](../query-cache.md)如何处理针对系统表的 `SELECT` 查询,即 `system.*` 和 `information_schema.*` 数据库中的表。

可能的值:

- `'throw'` - 抛出异常并且不缓存查询结果。
- `'save'` - 缓存查询结果。
- `'ignore'` - 不缓存查询结果并且不抛出异常。


## query_cache_tag {#query_cache_tag}

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.8" },
        { label: "" },
        { label: "用于标记查询缓存条目的新设置。" }
      ]
    }
  ]}
/>

用于为[查询缓存](../query-cache.md)条目添加标签的字符串。
查询缓存会将标签不同的相同查询视为不同的查询。

可选值:

- 任意字符串


## query_cache_ttl {#query_cache_ttl}

<SettingsInfoBlock type='Seconds' default_value='60' />

超过此时间(以秒为单位)后,[查询缓存](../query-cache.md)中的条目将过期。

可选值:

- 大于或等于 0 的正整数。


## query_condition_cache_store_conditions_as_plaintext {#query_condition_cache_store_conditions_as_plaintext}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

以明文形式存储[查询条件缓存](/operations/query-condition-cache)的过滤条件。
启用后,system.query_condition_cache 会显示完整的过滤条件,便于调试缓存相关问题。
默认禁用,因为明文过滤条件可能暴露敏感信息。

可能的值:

- 0 - 禁用
- 1 - 启用


## query_metric_log_interval {#query_metric_log_interval}

<SettingsInfoBlock type='Int64' default_value='-1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "-1" }, { label: "新增设置。" }]
    }
  ]}
/>

收集单个查询的 [query_metric_log](../../operations/system-tables/query_metric_log.md) 的时间间隔,以毫秒为单位。

如果设置为任何负值,将使用 [query_metric_log 设置](/operations/server-configuration-parameters/settings#query_metric_log) 中的 `collect_interval_milliseconds` 值,若该值不存在则默认为 1000。

要禁用单个查询的收集,请将 `query_metric_log_interval` 设置为 0。

默认值:-1


## query_plan_aggregation_in_order {#query_plan_aggregation_in_order}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.12" },
        { label: "1" },
        { label: "启用查询计划相关的部分重构" }
      ]
    }
  ]}
/>

切换查询计划级别的按序聚合优化。
仅在设置 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是专家级设置,仅应由开发人员用于调试。该设置未来可能以不向后兼容的方式更改或被移除。
:::

可能的值:

- 0 - 禁用
- 1 - 启用


## query_plan_convert_any_join_to_semi_or_anti_join {#query_plan_convert_any_join_to_semi_or_anti_join}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "1" }, { label: "新增设置。" }]
    }
  ]}
/>

允许将 ANY JOIN 转换为 SEMI 或 ANTI JOIN,当 JOIN 后的过滤器对未匹配或已匹配的行始终求值为 false 时


## query_plan_convert_join_to_in {#query_plan_convert_join_to_in}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

当输出列仅绑定到左表时,允许将 `JOIN` 转换为使用 `IN` 的子查询。使用非 ANY JOIN(例如默认的 ALL JOIN)时可能会产生错误结果。


## query_plan_convert_outer_join_to_inner_join {#query_plan_convert_outer_join_to_inner_join}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "1" },
        {
          label:
            "当 JOIN 后的过滤器始终过滤默认值时,允许将 OUTER JOIN 转换为 INNER JOIN"
        }
      ]
    }
  ]}
/>

当 `JOIN` 后的过滤器始终过滤默认值时,允许将 `OUTER JOIN` 转换为 `INNER JOIN`


## query_plan_direct_read_from_text_index {#query_plan_direct_read_from_text_index}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "1" }, { label: "新增设置。" }]
    }
  ]}
/>

允许在查询计划中仅使用倒排索引进行全文搜索过滤。


## query_plan_display_internal_aliases {#query_plan_display_internal_aliases}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

在 EXPLAIN PLAN 中显示内部别名(如 \_\_table1),而非原始查询中指定的别名。


## query_plan_enable_multithreading_after_window_functions {#query_plan_enable_multithreading_after_window_functions}

<SettingsInfoBlock type='Bool' default_value='1' />

在窗口函数计算完成后启用多线程处理，以支持并行流处理


## query_plan_enable_optimizations {#query_plan_enable_optimizations}

<SettingsInfoBlock type='Bool' default_value='1' />

控制是否在查询计划级别启用查询优化。

:::note
这是一个专家级设置,仅供开发人员用于调试。此设置在未来可能会以不向后兼容的方式更改或被移除。
:::

可选值:

- 0 - 禁用查询计划级别的所有优化
- 1 - 启用查询计划级别的优化(但仍可通过各个优化项的独立设置来禁用特定优化)


## query_plan_execute_functions_after_sorting {#query_plan_execute_functions_after_sorting}

<SettingsInfoBlock type='Bool' default_value='1' />

切换查询计划级别的优化,将表达式移至排序步骤之后执行。
仅在设置 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是专家级设置,仅应由开发人员用于调试。该设置可能在未来以不向后兼容的方式更改或被移除。
:::

可能的值:

- 0 - 禁用
- 1 - 启用


## query_plan_filter_push_down {#query_plan_filter_push_down}

<SettingsInfoBlock type='Bool' default_value='1' />

启用或禁用查询计划级别的优化,该优化将过滤器下推到执行计划中。
仅当设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是专家级设置,仅应由开发人员用于调试。该设置在未来可能会以不向后兼容的方式更改或被移除。
:::

可选值:

- 0 - 禁用
- 1 - 启用


## query_plan_join_shard_by_pk_ranges {#query_plan_join_shard_by_pk_ranges}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

当连接键包含两个表主键的前缀时,对 JOIN 应用分片。支持 hash、parallel_hash 和 full_sorting_merge 算法。通常不会提升查询速度,但可能降低内存消耗。


## query_plan_join_swap_table {#query_plan_join_swap_table}

<SettingsInfoBlock type='BoolAuto' default_value='auto' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "auto" },
        { label: "新增设置。此前始终选择右表。" }
      ]
    }
  ]}
/>

    确定在查询计划中连接操作的哪一侧应作为构建表(也称为内表,即在哈希连接中插入到哈希表的表)。此设置仅支持使用 `JOIN ON` 子句的 `ALL` 连接严格性。可能的值为:
    - 'auto': 由规划器决定使用哪个表作为构建表。
    - 'false': 不交换表(右表为构建表)。
    - 'true': 始终交换表(左表为构建表)。


## query_plan_lift_up_array_join {#query_plan_lift_up_array_join}

<SettingsInfoBlock type='Bool' default_value='1' />

切换查询计划级别的优化,该优化会在执行计划中将 ARRAY JOIN 操作上移。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置,仅应由开发人员用于调试。该设置可能在未来以不向后兼容的方式更改或被移除。
:::

可能的值:

- 0 - 禁用
- 1 - 启用


## query_plan_lift_up_union {#query_plan_lift_up_union}

<SettingsInfoBlock type='Bool' default_value='1' />

切换查询计划级别的优化,将查询计划中较大的子树移入 union 以启用进一步的优化。
仅在设置 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是专家级设置,仅应由开发人员用于调试。该设置可能在未来以向后不兼容的方式更改或被移除。
:::

可能的值:

- 0 - 禁用
- 1 - 启用


## query_plan_max_limit_for_lazy_materialization {#query_plan_max_limit_for_lazy_materialization}

<SettingsInfoBlock type='UInt64' default_value='100' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.4" },
        { label: "10" },
        {
          label:
            "新增设置项,用于控制允许使用查询计划进行延迟物化优化的最大限制值。如果为零,则无限制"
        }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "25.11" }, { label: "100" }, { label: "更优" }]
    }
  ]}
/>

控制允许使用查询计划进行延迟物化优化的最大限制值。如果为零,则无限制。


## query_plan_max_optimizations_to_apply {#query_plan_max_optimizations_to_apply}

<SettingsInfoBlock type='UInt64' default_value='10000' />

限制应用于查询计划的优化总数,详见设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations)。
用于避免复杂查询的优化时间过长。
在 EXPLAIN PLAN 查询中,达到此限制后将停止应用优化并按原样返回计划。
对于常规查询执行,如果实际优化数量超过此设置,则会抛出异常。

:::note
这是一个专家级设置,仅应由开发人员用于调试。该设置在未来可能以不向后兼容的方式更改或被移除。
:::


## query_plan_max_step_description_length {#query_plan_max_step_description_length}

<SettingsInfoBlock type='UInt64' default_value='500' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "500" }, { label: "New setting" }]
    }
  ]}
/>

EXPLAIN PLAN 中步骤描述的最大长度。


## query_plan_merge_expressions {#query_plan_merge_expressions}

<SettingsInfoBlock type='Bool' default_value='1' />

控制是否启用查询计划级别的优化，该优化会合并连续的过滤器。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅应由开发人员用于调试。该设置可能在未来以不向后兼容的方式更改或被移除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用


## query_plan_merge_filter_into_join_condition {#query_plan_merge_filter_into_join_condition}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.4" },
        { label: "1" },
        { label: "新增设置,用于将过滤条件合并到连接条件中" }
      ]
    }
  ]}
/>

允许将过滤条件合并到 `JOIN` 条件中,并将 `CROSS JOIN` 转换为 `INNER JOIN`。


## query_plan_merge_filters {#query_plan_merge_filters}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "0" },
        { label: "允许在查询计划中合并过滤器" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.11" },
        { label: "1" },
        {
          label:
            "允许在查询计划中合并过滤器。新分析器正确支持过滤器下推需要启用此选项。"
        }
      ]
    }
  ]}
/>

允许在查询计划中合并过滤器。


## query_plan_optimize_join_order_limit {#query_plan_optimize_join_order_limit}

<SettingsInfoBlock type='UInt64' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

    优化同一子查询内的连接顺序。目前仅支持极少数情况。
    该值为可优化的最大表数量。


## query_plan_optimize_lazy_materialization {#query_plan_optimize_lazy_materialization}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.4" },
        { label: "1" },
        {
          label:
            "新增设置项,用于启用基于查询计划的延迟物化优化"
        }
      ]
    }
  ]}
/>

使用查询计划进行延迟物化优化。


## query_plan_optimize_prewhere {#query_plan_optimize_prewhere}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "允许将过滤条件下推到支持的存储引擎的 PREWHERE 表达式"
        }
      ]
    }
  ]}
/>

允许将过滤条件下推到支持的存储引擎的 PREWHERE 表达式


## query_plan_push_down_limit {#query_plan_push_down_limit}

<SettingsInfoBlock type='Bool' default_value='1' />

切换查询计划级别的优化,该优化将 LIMIT 操作下推到执行计划中。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置,仅应由开发人员用于调试。该设置可能在未来以不向后兼容的方式更改或被移除。
:::

可能的值:

- 0 - 禁用
- 1 - 启用


## query_plan_read_in_order {#query_plan_read_in_order}

<SettingsInfoBlock type='Bool' default_value='1' />

切换查询计划级别的按序读取优化。
仅在设置 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是专家级设置,仅应由开发人员用于调试。该设置在未来可能以不向后兼容的方式更改或被移除。
:::

可能的值:

- 0 - 禁用
- 1 - 启用


## query_plan_remove_redundant_distinct {#query_plan_remove_redundant_distinct}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.2" },
        { label: "1" },
        { label: "移除查询计划中的冗余 Distinct 步骤" }
      ]
    }
  ]}
/>

启用或禁用查询计划级别的优化,用于移除冗余的 DISTINCT 步骤。
仅在设置 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置,仅应由开发人员用于调试。该设置可能在未来以不向后兼容的方式更改或被移除。
:::

可能的值:

- 0 - 禁用
- 1 - 启用


## query_plan_remove_redundant_sorting {#query_plan_remove_redundant_sorting}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.1" },
        { label: "1" },
        {
          label:
            "移除查询计划中的冗余排序。例如,子查询中与 ORDER BY 子句相关的排序步骤"
        }
      ]
    }
  ]}
/>

启用或禁用查询计划级别的优化,用于移除冗余的排序步骤,例如子查询中的排序步骤。
仅在设置 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置,仅应由开发人员用于调试。该设置可能在未来以不向后兼容的方式更改或被移除。
:::

可能的值:

- 0 - 禁用
- 1 - 启用


## query_plan_remove_unused_columns {#query_plan_remove_unused_columns}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1" },
        {
          label:
            "新增设置。添加优化以移除查询计划中未使用的列。"
        }
      ]
    }
  ]}
/>

启用或禁用查询计划级别的优化,该优化会尝试从查询计划步骤中移除未使用的列(包括输入列和输出列)。
仅当设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置,仅应由开发人员用于调试。该设置在未来可能会以不向后兼容的方式更改或被移除。
:::

可选值:

- 0 - 禁用
- 1 - 启用


## query_plan_reuse_storage_ordering_for_window_functions {#query_plan_reuse_storage_ordering_for_window_functions}

<SettingsInfoBlock type='Bool' default_value='1' />

控制查询计划级别的优化，在对窗口函数进行排序时复用存储排序。
仅在设置 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是专家级设置,仅供开发人员用于调试。该设置可能在未来以不向后兼容的方式更改或被移除。
:::

可能的值:

- 0 - 禁用
- 1 - 启用


## query_plan_split_filter {#query_plan_split_filter}

<SettingsInfoBlock type='Bool' default_value='1' />

:::note
这是专家级设置,仅供开发人员用于调试。此设置未来可能会以不向后兼容的方式更改或被移除。
:::

切换查询计划级别的优化,将过滤器拆分为表达式。
仅当设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

可能的值:

- 0 - 禁用
- 1 - 启用


## query_plan_try_use_vector_search {#query_plan_try_use_vector_search}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "1" }, { label: "新增设置。" }]
    }
  ]}
/>

切换查询计划级别的优化,尝试使用向量相似度索引。
仅当设置 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是专家级设置,仅应由开发人员用于调试。该设置可能在未来以不向后兼容的方式更改或被移除。
:::

可能的值:

- 0 - 禁用
- 1 - 启用


## query_plan_use_new_logical_join_step {#query_plan_use_new_logical_join_step}

**别名**: `query_plan_use_logical_join_step`

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.2" }, { label: "1" }, { label: "启用新步骤" }]
    },
    {
      id: "row-2",
      items: [
        { label: "25.1" },
        { label: "0" },
        { label: "新连接步骤,内部变更" }
      ]
    }
  ]}
/>

在查询计划中使用逻辑连接步骤。
注意:设置 `query_plan_use_new_logical_join_step` 已弃用,请改用 `query_plan_use_logical_join_step`。


## query_profiler_cpu_time_period_ns {#query_profiler_cpu_time_period_ns}

<SettingsInfoBlock type='UInt64' default_value='1000000000' />

设置[查询分析器](../../operations/optimizing-performance/sampling-query-profiler.md)的 CPU 时钟计时器周期。此计时器仅统计 CPU 时间。

可能的值:

- 正整数,单位为纳秒。

  推荐值:

            - 10000000(每秒 100 次)纳秒或更大,用于单个查询。
            - 1000000000(每秒一次),用于集群级分析。

- 0 表示关闭计时器。

**在 ClickHouse Cloud 中暂时禁用。**

另请参阅:

- 系统表 [trace_log](/operations/system-tables/trace_log)


## query_profiler_real_time_period_ns {#query_profiler_real_time_period_ns}

<SettingsInfoBlock type='UInt64' default_value='1000000000' />

设置[查询分析器](../../operations/optimizing-performance/sampling-query-profiler.md)的实时时钟计时器周期。实时时钟计时器统计实际运行时间(wall-clock time)。

可能的值:

- 正整数,单位为纳秒。

  推荐值:

            - 10000000(每秒 100 次)纳秒或更小,适用于单个查询。
            - 1000000000(每秒一次),适用于集群级分析。

- 0 表示关闭计时器。

**在 ClickHouse Cloud 中暂时禁用。**

另请参阅:

- 系统表 [trace_log](/operations/system-tables/trace_log)


## queue_max_wait_ms {#queue_max_wait_ms}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

当并发请求数超过最大值时,请求在队列中的等待时间。


## rabbitmq_max_wait_ms {#rabbitmq_max_wait_ms}

<SettingsInfoBlock type='Milliseconds' default_value='5000' />

从 RabbitMQ 读取数据重试前的等待时间。


## read_backoff_max_throughput {#read_backoff_max_throughput}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

用于在读取速度较慢时减少线程数量的设置。当读取带宽低于此值（每秒字节数）时统计事件。


## read_backoff_min_concurrency {#read_backoff_min_concurrency}

<SettingsInfoBlock type='UInt64' default_value='1' />

用于在读取速度较慢时尝试保持的最小线程数设置。


## read_backoff_min_events {#read_backoff_min_events}

<SettingsInfoBlock type='UInt64' default_value='2' />

用于在读取速度较慢时减少线程数的设置。达到此事件数后将减少线程数。


## read_backoff_min_interval_between_events_ms {#read_backoff_min_interval_between_events_ms}

<SettingsInfoBlock type='Milliseconds' default_value='1000' />

用于在读取速度较慢时减少线程数量的设置。如果距离上一个事件的时间间隔小于指定时长,则忽略当前事件。


## read_backoff_min_latency_ms {#read_backoff_min_latency_ms}

<SettingsInfoBlock type='Milliseconds' default_value='1000' />

当读取速度较慢时用于减少线程数量的设置。仅关注耗时至少达到此值的读取操作。


## read_from_distributed_cache_if_exists_otherwise_bypass_cache {#read_from_distributed_cache_if_exists_otherwise_bypass_cache}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。与 read_from_filesystem_cache_if_exists_otherwise_bypass_cache 相同,但适用于分布式缓存。


## read_from_filesystem_cache_if_exists_otherwise_bypass_cache {#read_from_filesystem_cache_if_exists_otherwise_bypass_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

允许以被动模式使用文件系统缓存——从现有缓存条目中获益,但不向缓存中添加新条目。如果为重型即席查询启用此设置,同时为短时实时查询保持禁用状态,这将有助于避免过重查询导致的缓存颠簸,从而提高整体系统效率。


## read_from_page_cache_if_exists_otherwise_bypass_cache {#read_from_page_cache_if_exists_otherwise_bypass_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        { label: "新增用户空间页缓存" }
      ]
    }
  ]}
/>

以被动模式使用用户空间页缓存,类似于 read_from_filesystem_cache_if_exists_otherwise_bypass_cache。


## read_in_order_two_level_merge_threshold {#read_in_order_two_level_merge_threshold}

<SettingsInfoBlock type='UInt64' default_value='100' />

在按主键顺序进行多线程读取时,执行初步合并步骤所需读取的最小数据分片数。


## read_in_order_use_buffering {#read_in_order_use_buffering}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "1" },
        {
          label:
            "按主键顺序读取时在合并前使用缓冲"
        }
      ]
    }
  ]}
/>

按主键顺序读取时在合并前使用缓冲。可提高查询执行的并行度


## read_in_order_use_virtual_row {#read_in_order_use_virtual_row}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "0" },
        {
          label:
            "按主键或其单调函数的顺序读取时使用虚拟行。在跨多个数据部分进行查询时非常有用,因为只会访问相关的部分。"
        }
      ]
    }
  ]}
/>

按主键或其单调函数的顺序读取时使用虚拟行。在跨多个数据部分进行查询时非常有用,因为只会访问相关的部分。


## read_overflow_mode {#read_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

超出限制时的处理方式。


## read_overflow_mode_leaf {#read_overflow_mode_leaf}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

设置当读取的数据量超过叶子节点限制时的处理方式。

可选项：

- `throw`：抛出异常（默认）。
- `break`：停止执行查询并返回部分结果。


## read_priority {#read_priority}

<SettingsInfoBlock type='Int64' default_value='0' />

用于设置从本地文件系统或远程文件系统读取数据的优先级。仅在本地文件系统使用 'pread_threadpool' 方法和远程文件系统使用 `threadpool` 方法时支持。


## read_through_distributed_cache {#read_through_distributed_cache}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "ClickHouse Cloud 专用设置" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。允许从分布式缓存读取数据


## readonly {#readonly}

<SettingsInfoBlock type='UInt64' default_value='0' />

0 - 无只读限制。1 - 仅允许读取请求以及更改明确允许的设置。2 - 仅允许读取请求以及更改设置,但 'readonly' 设置除外。


## receive_data_timeout_ms {#receive_data_timeout_ms}

<SettingsInfoBlock type='Milliseconds' default_value='2000' />

从副本接收第一个数据包或包含正向进度信息的数据包时的连接超时时间


## receive_timeout {#receive_timeout}

<SettingsInfoBlock type='Seconds' default_value='300' />

从网络接收数据的超时时间,单位为秒。如果在此时间间隔内未接收到任何字节,将抛出异常。如果在客户端设置此参数,服务器端相应连接的套接字 'send_timeout' 也将被设置。


## regexp_max_matches_per_row {#regexp_max_matches_per_row}

<SettingsInfoBlock type='UInt64' default_value='1000' />

设置每行中单个正则表达式的最大匹配次数。在 [extractAllGroupsHorizontal](/sql-reference/functions/string-search-functions#extractAllGroupsHorizontal) 函数中使用贪婪正则表达式时,使用此设置可防止内存溢出。

可能的值:

- 正整数。


## reject_expensive_hyperscan_regexps {#reject_expensive_hyperscan_regexps}

<SettingsInfoBlock type='Bool' default_value='1' />

拒绝可能导致 hyperscan 评估开销过大的模式(由于 NFA 状态爆炸)


## remerge_sort_lowered_memory_bytes_ratio {#remerge_sort_lowered_memory_bytes_ratio}

<SettingsInfoBlock type='Float' default_value='2' />

如果重新合并后的内存使用量未降低到此比率,则将禁用重新合并。


## remote_filesystem_read_method {#remote_filesystem_read_method}

<SettingsInfoBlock type='String' default_value='threadpool' />

从远程文件系统读取数据的方法,可选值:read、threadpool。


## remote_filesystem_read_prefetch {#remote_filesystem_read_prefetch}

<SettingsInfoBlock type='Bool' default_value='1' />

从远程文件系统读取数据时是否使用预取功能。


## remote_fs_read_backoff_max_tries {#remote_fs_read_backoff_max_tries}

<SettingsInfoBlock type='UInt64' default_value='5' />

使用退避重试策略的最大读取尝试次数


## remote_fs_read_max_backoff_ms {#remote_fs_read_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='10000' />

从远程磁盘读取数据时的最大等待时间


## remote_read_min_bytes_for_seek {#remote_read_min_bytes_for_seek}

<SettingsInfoBlock type='UInt64' default_value='4194304' />

远程读取(url、s3)执行 seek 操作(而非忽略式读取)所需的最小字节数。


## rename_files_after_processing {#rename_files_after_processing}

- **类型：** String

- **默认值：** 空字符串

此设置用于指定 `file` 表函数处理文件后的重命名模式。启用此选项后,`file` 表函数读取的所有文件将按照指定的占位符模式进行重命名,仅在文件处理成功时执行。

### 占位符

- `%a` — 完整的原始文件名(例如 "sample.csv")。
- `%f` — 不含扩展名的原始文件名(例如 "sample")。
- `%e` — 带点号的原始文件扩展名(例如 ".csv")。
- `%t` — 时间戳(微秒)。
- `%%` — 百分号("%")。

### 示例

- 选项:`--rename_files_after_processing="processed_%f_%t%e"`

- 查询:`SELECT * FROM file('sample.csv')`

如果成功读取 `sample.csv`,该文件将被重命名为 `processed_sample_1683473210851438.csv`


## replace_running_query {#replace_running_query}

<SettingsInfoBlock type='Bool' default_value='0' />

使用 HTTP 接口时,可以传递 'query_id' 参数。该参数是一个任意字符串,用作查询标识符。
如果此时同一用户已有相同 'query_id' 的查询正在执行,则行为取决于 'replace_running_query' 参数。

`0`(默认值)– 抛出异常(如果具有相同 'query_id' 的查询正在运行,则不允许执行新查询)。

`1` – 取消旧查询并开始执行新查询。

将此参数设置为 1 可实现分段条件的建议功能。输入下一个字符后,如果旧查询尚未完成,则应取消该查询。


## replace_running_query_max_wait_ms {#replace_running_query_max_wait_ms}

<SettingsInfoBlock type='Milliseconds' default_value='5000' />

当 [replace_running_query](#replace_running_query) 设置启用时,等待具有相同 `query_id` 的运行中查询结束的等待时间。

可能的值:

- 正整数。
- 0 — 如果服务器已在执行具有相同 `query_id` 的查询,则抛出异常,不允许运行新查询。


## replication_wait_for_inactive_replica_timeout {#replication_wait_for_inactive_replica_timeout}

<SettingsInfoBlock type='Int64' default_value='120' />

指定等待非活动副本执行 [`ALTER`](../../sql-reference/statements/alter/index.md)、[`OPTIMIZE`](../../sql-reference/statements/optimize.md) 或 [`TRUNCATE`](../../sql-reference/statements/truncate.md) 查询的等待时长(以秒为单位)。

可能的值:

- `0` — 不等待。
- 负整数 — 无限等待。
- 正整数 — 等待的秒数。


## restore_replace_external_dictionary_source_to_null {#restore_replace_external_dictionary_source_to_null}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

在恢复时将外部字典源替换为 Null。用于测试目的


## restore_replace_external_engines_to_null {#restore_replace_external_engines_to_null}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.8" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

用于测试目的。将所有外部引擎替换为 Null，以避免建立外部连接。


## restore_replace_external_table_functions_to_null {#restore_replace_external_table_functions_to_null}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.8" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

用于测试目的。将所有外部表函数替换为 Null,以避免发起外部连接。


## restore_replicated_merge_tree_to_shared_merge_tree {#restore_replicated_merge_tree_to_shared_merge_tree}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.2" }, { label: "0" }, { label: "新设置。" }]
    }
  ]}
/>

在 RESTORE 过程中将表引擎从 Replicated*MergeTree 替换为 Shared*MergeTree。


## result_overflow_mode {#result_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

Cloud default value: `throw`

设置当结果数据量超过某个限制时的处理方式。

可选值:

- `throw`: 抛出异常(默认值)。
- `break`: 停止执行查询并返回部分结果,如同源数据已耗尽。

使用 'break' 类似于使用 LIMIT。`Break` 仅在数据块级别中断执行。这意味着返回的行数会大于
[`max_result_rows`](/operations/settings/settings#max_result_rows),是 [`max_block_size`](/operations/settings/settings#max_block_size) 的倍数,
并且取决于 [`max_threads`](/operations/settings/settings#max_threads)。

**示例**

```sql title="查询"
SET max_threads = 3, max_block_size = 3333;
SET max_result_rows = 3334, result_overflow_mode = 'break';

SELECT *
FROM numbers_mt(100000)
FORMAT Null;
```

```text title="结果"
6666 rows in set. ...
```


## rewrite_count_distinct_if_with_count_distinct_implementation {#rewrite_count_distinct_if_with_count_distinct_implementation}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.8" },
        { label: "1" },
        {
          label:
            "使用 count_distinct_implementation 配置重写 countDistinctIf"
        }
      ]
    }
  ]}
/>

允许使用 [count_distinct_implementation](#count_distinct_implementation) 设置重写 `countDistcintIf`。

可能的值:

- true — 允许。
- false — 不允许。


## rewrite_in_to_join {#rewrite_in_to_join}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.10" },
        { label: "0" },
        { label: "新增实验性设置" }
      ]
    }
  ]}
/>

将 'x IN subquery' 形式的表达式重写为 JOIN。这有助于通过连接重排序来优化整个查询。


## s3_allow_multipart_copy {#s3_allow_multipart_copy}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.2" }, { label: "1" }, { label: "新增设置。" }]
    }
  ]}
/>

允许在 S3 中使用分段复制。


## s3_allow_parallel_part_upload {#s3_allow_parallel_part_upload}

<SettingsInfoBlock type='Bool' default_value='1' />

对 S3 分段上传使用多线程。可能会导致内存使用量略有增加


## s3_check_objects_after_upload {#s3_check_objects_after_upload}

<SettingsInfoBlock type='Bool' default_value='0' />

通过 HEAD 请求检查每个上传到 S3 的对象，以确保上传成功


## s3_connect_timeout_ms {#s3_connect_timeout_ms}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1000" },
        { label: "引入 S3 连接超时专用设置" }
      ]
    }
  ]}
/>

S3 磁盘的主机连接超时时间。


## s3_create_new_file_on_insert {#s3_create_new_file_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在 s3 引擎表中每次插入时创建新文件。启用后,每次插入都会创建一个新的 S3 对象,其键名遵循类似以下的模式:

初始:`data.Parquet.gz` -> `data.1.Parquet.gz` -> `data.2.Parquet.gz`,依此类推。

可能的值:

- 0 — `INSERT` 查询创建新文件,如果文件已存在且未设置 s3_truncate_on_insert 则失败。
- 1 — 如果未设置 s3_truncate_on_insert,`INSERT` 查询在每次插入时使用后缀(从第二次开始)创建新文件。

更多详情请参见[此处](/integrations/s3#inserting-data)。


## s3_disable_checksum {#s3_disable_checksum}

<SettingsInfoBlock type='Bool' default_value='0' />

向 S3 发送文件时不计算校验和。通过避免对文件进行多次处理遍历,可以加快写入速度。这在大多数情况下是安全的,因为 MergeTree 表的数据本身就会由 ClickHouse 进行校验和计算,而且当通过 HTTPS 访问 S3 时,TLS 层已经在网络传输过程中提供了完整性保障。不过,S3 上的额外校验和可以提供深度防御。


## s3_ignore_file_doesnt_exist {#s3_ignore_file_doesnt_exist}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "允许在 S3 表引擎中当请求的文件不存在时返回 0 行,而不是抛出异常"
        }
      ]
    }
  ]}
/>

读取特定键时,如果文件不存在则忽略文件缺失。

可能的值:

- 1 — `SELECT` 返回空结果。
- 0 — `SELECT` 抛出异常。


## s3_list_object_keys_size {#s3_list_object_keys_size}

<SettingsInfoBlock type='UInt64' default_value='1000' />

ListObject 请求批量返回的最大文件数


## s3_max_connections {#s3_max_connections}

<SettingsInfoBlock type='UInt64' default_value='1024' />

每台服务器的最大连接数。


## s3_max_get_burst {#s3_max_get_burst}

<SettingsInfoBlock type='UInt64' default_value='0' />

在达到每秒请求限制之前可同时发出的最大请求数。默认值为 0,等同于 `s3_max_get_rps`


## s3_max_get_rps {#s3_max_get_rps}

<SettingsInfoBlock type='UInt64' default_value='0' />

S3 GET 请求每秒速率限制，超过此限制后将进行限流。设置为 0 表示不限制。


## s3_max_inflight_parts_for_one_file {#s3_max_inflight_parts_for_one_file}

<SettingsInfoBlock type='UInt64' default_value='20' />

多部分上传请求中并发加载的分片的最大数量。0 表示无限制。


## s3_max_part_number {#s3_max_part_number}

<SettingsInfoBlock type='UInt64' default_value='10000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "10000" },
        { label: "S3 分段上传的最大分段编号" }
      ]
    }
  ]}
/>

S3 分段上传的最大分段编号.


## s3_max_put_burst {#s3_max_put_burst}

<SettingsInfoBlock type='UInt64' default_value='0' />

在达到每秒请求限制之前可同时发出的最大请求数。默认值为 0,等同于 `s3_max_put_rps`


## s3_max_put_rps {#s3_max_put_rps}

<SettingsInfoBlock type='UInt64' default_value='0' />

S3 PUT 请求每秒速率限制，超过此限制后将进行限流。设置为 0 表示不限制。


## s3_max_single_operation_copy_size {#s3_max_single_operation_copy_size}

<SettingsInfoBlock type='UInt64' default_value='33554432' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "33554432" },
        { label: "S3 中单次复制操作的最大大小" }
      ]
    }
  ]}
/>

S3 中单次复制操作的最大大小。此设置仅在 s3_allow_multipart_copy 为 true 时使用。


## s3_max_single_part_upload_size {#s3_max_single_part_upload_size}

<SettingsInfoBlock type='UInt64' default_value='33554432' />

使用单部分上传到 S3 的对象的最大大小。


## s3_max_single_read_retries {#s3_max_single_read_retries}

<SettingsInfoBlock type='UInt64' default_value='4' />

单次 S3 读取期间的最大重试次数。


## s3_max_unexpected_write_error_retries {#s3_max_unexpected_write_error_retries}

<SettingsInfoBlock type='UInt64' default_value='4' />

S3 写入过程中遇到意外错误时的最大重试次数。


## s3_max_upload_part_size {#s3_max_upload_part_size}

<SettingsInfoBlock type='UInt64' default_value='5368709120' />

S3 分段上传时单个分段的最大大小。


## s3_min_upload_part_size {#s3_min_upload_part_size}

<SettingsInfoBlock type='UInt64' default_value='16777216' />

分段上传到 S3 时每个分段的最小大小。


## s3_request_timeout_ms {#s3_request_timeout_ms}

<SettingsInfoBlock type='UInt64' default_value='30000' />

与 S3 之间发送和接收数据的空闲超时时间。如果单次 TCP 读取或写入调用的阻塞时间超过此值,则操作失败。


## s3_skip_empty_files {#s3_skip_empty_files}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "1" },
        { label: "我们希望这能提供更好的用户体验" }
      ]
    }
  ]}
/>

启用或禁用在 [S3](../../engines/table-engines/integrations/s3.md) 引擎表中跳过空文件。

可能的值：

- 0 — 如果空文件与请求的格式不兼容，`SELECT` 会抛出异常。
- 1 — 对于空文件，`SELECT` 返回空结果。


## s3_slow_all_threads_after_network_error {#s3_slow_all_threads_after_network_error}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "1" }, { label: "新设置" }]
    }
  ]}
/>

当设置为 `true` 时,如果任何单个 S3 请求遇到可重试的网络错误(如套接字超时),则所有向同一备份端点执行 S3 请求的线程都会被减速。
当设置为 `false` 时,每个线程独立处理 S3 请求退避,互不影响。


## s3_strict_upload_part_size {#s3_strict_upload_part_size}

<SettingsInfoBlock type='UInt64' default_value='0' />

在分段上传到 S3 时每个分段的精确大小(某些实现不支持可变大小的分段)。


## s3_throw_on_zero_files_match {#s3_throw_on_zero_files_match}

<SettingsInfoBlock type='Bool' default_value='0' />

当 ListObjects 请求无法匹配到任何文件时抛出错误


## s3_truncate_on_insert {#s3_truncate_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用 s3 引擎表在插入数据前的截断操作。如果禁用,当 S3 对象已存在时,尝试插入将抛出异常。

可能的值:

- 0 — `INSERT` 查询创建新文件,如果文件已存在且未设置 s3_create_new_file_on_insert,则失败。
- 1 — `INSERT` 查询用新数据替换文件的现有内容。

更多详细信息请参见[此处](/integrations/s3#inserting-data)。


## s3_upload_part_size_multiply_factor {#s3_upload_part_size_multiply_factor}

<SettingsInfoBlock type='UInt64' default_value='2' />

每当单次写入 S3 上传的分片数量达到 s3_multiply_parts_count_threshold 时,将 s3_min_upload_part_size 乘以此系数。


## s3_upload_part_size_multiply_parts_count_threshold {#s3_upload_part_size_multiply_parts_count_threshold}

<SettingsInfoBlock type='UInt64' default_value='500' />

每当上传到 S3 的分片数达到此阈值时,s3_min_upload_part_size 会乘以 s3_upload_part_size_multiply_factor。


## s3_use_adaptive_timeouts {#s3_use_adaptive_timeouts}

<SettingsInfoBlock type='Bool' default_value='1' />

当设置为 `true` 时,所有 S3 请求的前两次尝试将使用较低的发送和接收超时时间。
当设置为 `false` 时,所有尝试将使用相同的超时时间。


## s3_validate_request_settings {#s3_validate_request_settings}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "1" },
        { label: "允许禁用 S3 请求设置验证" }
      ]
    }
  ]}
/>

启用 S3 请求设置验证。
可选值：

- 1 — 验证设置。
- 0 — 不验证设置。


## s3queue_default_zookeeper_path {#s3queue_default_zookeeper_path}

<SettingsInfoBlock type='String' default_value='/clickhouse/s3queue/' />

S3Queue 引擎的默认 ZooKeeper 路径前缀


## s3queue_enable_logging_to_s3queue_log {#s3queue_enable_logging_to_s3queue_log}

<SettingsInfoBlock type='Bool' default_value='0' />

启用写入 system.s3queue_log。该值可通过表设置在每个表级别覆盖


## s3queue_keeper_fault_injection_probability {#s3queue_keeper_fault_injection_probability}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

S3Queue 的 Keeper 故障注入概率。


## s3queue_migrate_old_metadata_to_buckets {#s3queue_migrate_old_metadata_to_buckets}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

将 S3Queue 表的旧元数据结构迁移至新结构


## schema_inference_cache_require_modification_time_for_url {#schema_inference_cache_require_modification_time_for_url}

<SettingsInfoBlock type='Bool' default_value='1' />

对带有 Last-Modified 头的 URL,使用缓存中的模式并验证最后修改时间


## schema_inference_use_cache_for_azure {#schema_inference_use_cache_for_azure}

<SettingsInfoBlock type='Bool' default_value='1' />

在使用 Azure 表函数时,在架构推断中使用缓存


## schema_inference_use_cache_for_file {#schema_inference_use_cache_for_file}

<SettingsInfoBlock type='Bool' default_value='1' />

使用文件表函数时在模式推断中使用缓存


## schema_inference_use_cache_for_hdfs {#schema_inference_use_cache_for_hdfs}

<SettingsInfoBlock type='Bool' default_value='1' />

使用 hdfs 表函数时在模式推断中使用缓存


## schema_inference_use_cache_for_s3 {#schema_inference_use_cache_for_s3}

<SettingsInfoBlock type='Bool' default_value='1' />

使用 s3 表函数时在模式推断中使用缓存


## schema_inference_use_cache_for_url {#schema_inference_use_cache_for_url}

<SettingsInfoBlock type='Bool' default_value='1' />

使用 url 表函数时在模式推断中使用缓存


## secondary_indices_enable_bulk_filtering {#secondary_indices_enable_bulk_filtering}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "1" },
        { label: "基于数据跳过索引的新过滤算法" }
      ]
    }
  ]}
/>

启用索引的批量过滤算法。该算法预期始终具有更好的性能,但我们保留此设置以保证兼容性和可控性。


## select_sequential_consistency {#select_sequential_consistency}

<SettingsInfoBlock type='UInt64' default_value='0' />

:::note
此设置在 SharedMergeTree 和 ReplicatedMergeTree 之间的行为有所不同,有关 `select_sequential_consistency` 在 SharedMergeTree 中的行为详情,请参阅 [SharedMergeTree 一致性](/cloud/reference/shared-merge-tree#consistency)。
:::

启用或禁用 `SELECT` 查询的顺序一致性。要求禁用 `insert_quorum_parallel`(默认启用)。

可能的值:

- 0 — 禁用。
- 1 — 启用。

使用说明

启用顺序一致性后,ClickHouse 仅允许客户端在包含所有先前使用 `insert_quorum` 执行的 `INSERT` 查询数据的副本上执行 `SELECT` 查询。如果客户端引用的是部分副本,ClickHouse 将抛出异常。SELECT 查询不会包含尚未写入副本仲裁数的数据。

当 `insert_quorum_parallel` 启用时(默认启用),`select_sequential_consistency` 不生效。这是因为并行 `INSERT` 查询可能写入不同的仲裁副本集,因此无法保证单个副本已接收所有写入操作。

另请参阅:

- [insert_quorum](#insert_quorum)
- [insert_quorum_timeout](#insert_quorum_timeout)
- [insert_quorum_parallel](#insert_quorum_parallel)


## send_logs_level {#send_logs_level}

<SettingsInfoBlock type='LogsLevel' default_value='fatal' />

将达到指定最低级别的服务器文本日志发送到客户端。有效值:'trace'、'debug'、'information'、'warning'、'error'、'fatal'、'none'


## send_logs_source_regexp {#send_logs_source_regexp}

发送服务器文本日志,使用指定的正则表达式匹配日志源名称。为空表示所有来源。


## send_profile_events {#send_profile_events}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1" },
        { label: "新增设置。是否向客户端发送性能分析事件。" }
      ]
    }
  ]}
/>

启用或禁用向客户端发送 [ProfileEvents](/native-protocol/server.md#profile-events) 数据包。

对于不需要性能分析事件的客户端,可以禁用此设置以减少网络流量。

可能的值:

- 0 — 禁用。
- 1 — 启用。


## send_progress_in_http_headers {#send_progress_in_http_headers}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用 `clickhouse-server` 响应中的 `X-ClickHouse-Progress` HTTP 响应头。

更多信息请参阅 [HTTP 接口说明](../../interfaces/http.md)。

可选值:

- 0 — 禁用。
- 1 — 启用。


## send_timeout {#send_timeout}

<SettingsInfoBlock type='Seconds' default_value='300' />

向网络发送数据的超时时间,单位为秒。如果客户端需要发送数据,但在此时间间隔内无法发送任何字节,则会抛出异常。如果在客户端设置此参数,服务器端相应连接的套接字 'receive_timeout' 也将被设置。


## serialize_query_plan {#serialize_query_plan}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "0" }, { label: "NewSetting" }]
    }
  ]}
/>

序列化分布式处理的查询计划


## session_timezone {#session_timezone}

<BetaBadge />

设置当前会话或查询的隐式时区。
隐式时区是应用于未明确指定时区的 DateTime/DateTime64 类型值的时区。
该设置优先于全局配置的(服务器级别)隐式时区。
值为 ''(空字符串)表示当前会话或查询的隐式时区等于[服务器时区](../server-configuration-parameters/settings.md/#timezone)。

您可以使用函数 `timeZone()` 和 `serverTimeZone()` 来获取会话时区和服务器时区。

可能的值:

- `system.time_zones` 中的任何时区名称,例如 `Europe/Berlin`、`UTC` 或 `Zulu`

示例:

```sql
SELECT timeZone(), serverTimeZone() FORMAT CSV

"Europe/Berlin","Europe/Berlin"
```

```sql
SELECT timeZone(), serverTimeZone() SETTINGS session_timezone = 'Asia/Novosibirsk' FORMAT CSV

"Asia/Novosibirsk","Europe/Berlin"
```

将会话时区 'America/Denver' 分配给未明确指定时区的内部 DateTime:

```sql
SELECT toDateTime64(toDateTime64('1999-12-12 23:23:23.123', 3), 3, 'Europe/Zurich') SETTINGS session_timezone = 'America/Denver' FORMAT TSV

1999-12-13 07:23:23.123
```

:::warning
并非所有解析 DateTime/DateTime64 的函数都遵循 `session_timezone`。这可能导致难以察觉的错误。
请参阅以下示例和说明。
:::

```sql
CREATE TABLE test_tz (`d` DateTime('UTC')) ENGINE = Memory AS SELECT toDateTime('2000-01-01 00:00:00', 'UTC');

SELECT *, timeZone() FROM test_tz WHERE d = toDateTime('2000-01-01 00:00:00') SETTINGS session_timezone = 'Asia/Novosibirsk'
0 rows in set.

SELECT *, timeZone() FROM test_tz WHERE d = '2000-01-01 00:00:00' SETTINGS session_timezone = 'Asia/Novosibirsk'
┌───────────────────d─┬─timeZone()───────┐
│ 2000-01-01 00:00:00 │ Asia/Novosibirsk │
└─────────────────────┴──────────────────┘
```

这是由于不同的解析流程导致的:

- 第一个 `SELECT` 查询中使用的未明确指定时区的 `toDateTime()` 遵循 `session_timezone` 设置和全局时区。
- 在第二个查询中,DateTime 从字符串解析而来,并继承现有列 `d` 的类型和时区。因此,`session_timezone` 设置和全局时区不会被遵循。

**另请参阅**

- [timezone](../server-configuration-parameters/settings.md/#timezone)


## set_overflow_mode {#set_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

设置当数据量超过其中一个限制时的处理方式。

可能的值:

- `throw`: 抛出异常(默认)。
- `break`: 停止执行查询并返回部分结果,如同源数据已耗尽。


## shared_merge_tree_sync_parts_on_partition_operations {#shared_merge_tree_sync_parts_on_partition_operations}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "1" },
        { label: "新增设置。默认情况下数据部分始终同步" }
      ]
    }
  ]}
/>

在 SMT 表中执行 MOVE|REPLACE|ATTACH 分区操作后自动同步数据部分集。仅适用于 ClickHouse Cloud


## short_circuit_function_evaluation {#short_circuit_function_evaluation}

<SettingsInfoBlock
  type='ShortCircuitFunctionEvaluation'
  default_value='enable'
/>

允许按照[短路求值](https://en.wikipedia.org/wiki/Short-circuit_evaluation)方式计算 [if](../../sql-reference/functions/conditional-functions.md/#if)、[multiIf](../../sql-reference/functions/conditional-functions.md/#multiIf)、[and](/sql-reference/functions/logical-functions#and) 和 [or](/sql-reference/functions/logical-functions#or) 函数。这有助于优化这些函数中复杂表达式的执行,并防止可能的异常(例如在不应发生时的除零错误)。

可能的值:

- `enable` — 对适用的函数启用短路求值(可能抛出异常或计算开销较大的函数)。
- `force_enable` — 对所有函数启用短路求值。
- `disable` — 禁用短路求值。


## short_circuit_function_evaluation_for_nulls {#short_circuit_function_evaluation_for_nulls}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "1" },
        {
          label:
            "允许仅对所有参数均为非 NULL 值的行执行带有 Nullable 参数的函数"
        }
      ]
    }
  ]}
/>

优化当任意参数为 NULL 时返回 NULL 的函数的求值过程。当函数参数中 NULL 值的百分比超过 short_circuit_function_evaluation_for_nulls_threshold 时,系统将跳过逐行求值。而是直接为所有行返回 NULL,避免不必要的计算。


## short_circuit_function_evaluation_for_nulls_threshold {#short_circuit_function_evaluation_for_nulls_threshold}

<SettingsInfoBlock type='Double' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "1" },
        {
          label:
            "NULL 值比率阈值,用于仅在所有参数均为非 NULL 值的行上执行带有 Nullable 参数的函数。当启用 short_circuit_function_evaluation_for_nulls 设置时生效。"
        }
      ]
    }
  ]}
/>

NULL 值比率阈值,用于仅在所有参数均为非 NULL 值的行上执行带有 Nullable 参数的函数。当启用 short_circuit_function_evaluation_for_nulls 设置时生效。
当包含 NULL 值的行数占总行数的比率超过此阈值时,将跳过对这些包含 NULL 值的行的计算。


## show_data_lake_catalogs_in_system_tables {#show_data_lake_catalogs_in_system_tables}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1" }, { label: "新增设置" }]
    },
    {
      id: "row-2",
      items: [
        { label: "25.10" },
        { label: "0" },
        { label: "默认禁用在系统表中显示目录" }
      ]
    }
  ]}
/>

启用在系统表中显示数据湖目录。


## show_processlist_include_internal {#show_processlist_include_internal}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "1" }, { label: "新增设置。" }]
    }
  ]}
/>

在 `SHOW PROCESSLIST` 查询输出中显示内部辅助进程。

内部进程包括字典重新加载、可刷新物化视图重新加载、在 `SHOW ...` 查询中执行的辅助 `SELECT` 语句、为适配损坏表而在内部执行的辅助 `CREATE DATABASE ...` 查询等。


## show_table_uuid_in_table_create_query_if_not_nil {#show_table_uuid_in_table_create_query_if_not_nil}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "20.7" },
        { label: "0" },
        {
          label:
            "对于 Engine=Atomic,在 CREATE 查询中停止显示表的 UUID"
        }
      ]
    }
  ]}
/>

设置 `SHOW TABLE` 查询的显示方式。

可能的值:

- 0 — 查询结果中不显示表的 UUID。
- 1 — 查询结果中显示表的 UUID。


## single_join_prefer_left_table {#single_join_prefer_left_table}

<SettingsInfoBlock type='Bool' default_value='1' />

对于单个 JOIN,当标识符存在歧义时优先选择左表


## skip_redundant_aliases_in_udf {#skip_redundant_aliases_in_udf}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "0" },
        {
          label:
            "启用后,允许在同一表的多个物化列中多次使用同一个用户定义函数。"
        }
      ]
    }
  ]}
/>

为简化使用,用户定义函数中不使用(替换)冗余别名。

可能的值:

- 1 — 在 UDF 中跳过(替换)别名。
- 0 — 在 UDF 中不跳过(替换)别名。

**示例**

启用和禁用的区别:

查询:

```sql
SET skip_redundant_aliases_in_udf = 0;
CREATE FUNCTION IF NOT EXISTS test_03274 AS ( x ) -> ((x + 1 as y, y + 2));

EXPLAIN SYNTAX SELECT test_03274(4 + 2);
```

结果:

```text
SELECT ((4 + 2) + 1 AS y, y + 2)
```

查询:

```sql
SET skip_redundant_aliases_in_udf = 1;
CREATE FUNCTION IF NOT EXISTS test_03274 AS ( x ) -> ((x + 1 as y, y + 2));

EXPLAIN SYNTAX SELECT test_03274(4 + 2);
```

结果:

```text
SELECT ((4 + 2) + 1, ((4 + 2) + 1) + 2)
```


## skip_unavailable_shards {#skip_unavailable_shards}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用静默跳过不可用的分片。

如果分片的所有副本都不可用,则该分片被视为不可用。副本在以下情况下不可用:

- ClickHouse 因任何原因无法连接到副本。

  连接副本时,ClickHouse 会执行多次尝试。如果所有尝试均失败,则该副本被视为不可用。

- 副本无法通过 DNS 解析。

  如果副本的主机名无法通过 DNS 解析,可能表示以下情况:
  - 副本的主机没有 DNS 记录。这可能发生在具有动态 DNS 的系统中,例如 [Kubernetes](https://kubernetes.io),其中节点在停机期间可能无法解析,这并非错误。

  - 配置错误。ClickHouse 配置文件包含错误的主机名。

可能的值:

- 1 — 启用跳过。

  如果分片不可用,ClickHouse 将基于部分数据返回结果,且不报告节点可用性问题。

- 0 — 禁用跳过。

  如果分片不可用,ClickHouse 将抛出异常。


## sleep_after_receiving_query_ms {#sleep_after_receiving_query_ms}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

TCPHandler 接收查询后的休眠时间


## sleep_in_send_data_ms {#sleep_in_send_data_ms}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

TCPHandler 发送数据时的休眠时间


## sleep_in_send_tables_status_ms {#sleep_in_send_tables_status_ms}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

在 TCPHandler 中发送表状态响应时的休眠时间


## sort_overflow_mode {#sort_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

设置当排序前接收的行数超过其中一个限制时的处理方式。

可选值:

- `throw`: 抛出异常。
- `break`: 停止执行查询并返回部分结果。


## split_intersecting_parts_ranges_into_layers_final {#split_intersecting_parts_ranges_into_layers_final}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "允许在 FINAL 优化过程中将重叠的数据分区范围拆分为多层"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.1" },
        { label: "1" },
        {
          label:
            "允许在 FINAL 优化过程中将重叠的数据分区范围拆分为多层"
        }
      ]
    }
  ]}
/>

在 FINAL 优化过程中将重叠的数据分区范围拆分为多层


## split_parts_ranges_into_intersecting_and_non_intersecting_final {#split_parts_ranges_into_intersecting_and_non_intersecting_final}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "允许在 FINAL 优化过程中将数据分片范围拆分为相交和不相交部分"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.1" },
        { label: "1" },
        {
          label:
            "允许在 FINAL 优化过程中将数据分片范围拆分为相交和不相交部分"
        }
      ]
    }
  ]}
/>

在 FINAL 优化过程中将数据分片范围拆分为相交和不相交部分


## splitby_max_substrings_includes_remaining_string {#splitby_max_substrings_includes_remaining_string}

<SettingsInfoBlock type='Bool' default_value='0' />

控制当函数 [splitBy\*()](../../sql-reference/functions/splitting-merging-functions.md) 的参数 `max_substrings` > 0 时,是否将剩余字符串包含在结果数组的最后一个元素中。

可能的值:

- `0` - 剩余字符串不会包含在结果数组的最后一个元素中。
- `1` - 剩余字符串会包含在结果数组的最后一个元素中。此行为与 Spark 的 [`split()`](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.split.html) 函数和 Python 的 ['string.split()'](https://docs.python.org/3/library/stdtypes.html#str.split) 方法一致。


## stop_refreshable_materialized_views_on_startup {#stop_refreshable_materialized_views_on_startup}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

在服务器启动时,阻止可刷新物化视图的调度,效果等同于执行 SYSTEM STOP VIEWS 命令。之后可以使用 `SYSTEM START VIEWS` 或 `SYSTEM START VIEW <name>` 手动启动这些视图。此设置同样适用于新创建的视图。对不可刷新的物化视图无影响。


## storage_file_read_method {#storage_file_read_method}

<SettingsInfoBlock type='LocalFSReadMethod' default_value='pread' />

从存储文件读取数据的方法,可选值:`read`、`pread`、`mmap`。mmap 方法不适用于 clickhouse-server(仅适用于 clickhouse-local)。


## storage_system_stack_trace_pipe_read_timeout_ms {#storage_system_stack_trace_pipe_read_timeout_ms}

<SettingsInfoBlock type='Milliseconds' default_value='100' />

查询 `system.stack_trace` 表时,从管道读取线程信息的最大超时时间。此设置仅用于测试目的,不应由用户修改。


## stream_flush_interval_ms {#stream_flush_interval_ms}

<SettingsInfoBlock type='Milliseconds' default_value='7500' />

适用于流式表,在发生超时或线程生成 [max_insert_block_size](#max_insert_block_size) 行数据时触发刷新。

默认值为 7500。

该值越小,数据刷新到表的频率越高。将该值设置得过低会导致性能下降。


## stream_like_engine_allow_direct_select {#stream_like_engine_allow_direct_select}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.12" },
        { label: "0" },
        {
          label:
            "默认不允许对 Kafka/RabbitMQ/FileLog 直接执行 SELECT 查询"
        }
      ]
    }
  ]}
/>

允许对 Kafka、RabbitMQ、FileLog、Redis Streams 和 NATS 引擎直接执行 SELECT 查询。如果已附加物化视图,即使启用此设置,也不允许执行 SELECT 查询。


## stream_like_engine_insert_queue {#stream_like_engine_insert_queue}

当流式引擎从多个队列读取数据时,用户在写入数据时需要选择要插入的目标队列。适用于 Redis Streams 和 NATS。


## stream_poll_timeout_ms {#stream_poll_timeout_ms}

<SettingsInfoBlock type='Milliseconds' default_value='500' />

从流式存储轮询数据或向流式存储写入数据的超时时间。


## system_events_show_zero_values {#system_events_show_zero_values}

<SettingsInfoBlock type='Bool' default_value='0' />

允许从 [`system.events`](../../operations/system-tables/events.md) 中查询值为零的事件。

某些监控系统要求在每个检查点传递所有指标值,即使指标值为零也不例外。

可选值:

- 0 — 禁用。
- 1 — 启用。

**示例**

查询

```sql
SELECT * FROM system.events WHERE event='QueryMemoryLimitExceeded';
```

结果

```text
Ok.
```

查询

```sql
SET system_events_show_zero_values = 1;
SELECT * FROM system.events WHERE event='QueryMemoryLimitExceeded';
```

结果

```text
┌─event────────────────────┬─value─┬─description───────────────────────────────────────────┐
│ QueryMemoryLimitExceeded │     0 │ 查询超出内存限制的次数。 │
└──────────────────────────┴───────┴───────────────────────────────────────────────────────┘
```


## table_engine_read_through_distributed_cache {#table_engine_read_through_distributed_cache}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.7" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。允许通过表引擎/表函数（s3、azure 等）从分布式缓存读取数据


## table_function_remote_max_addresses {#table_function_remote_max_addresses}

<SettingsInfoBlock type='UInt64' default_value='1000' />

设置 [remote](../../sql-reference/table-functions/remote.md) 函数从模式生成的地址的最大数量。

可选值:

- 正整数。


## tcp_keep_alive_timeout {#tcp_keep_alive_timeout}

<SettingsInfoBlock type='Seconds' default_value='290' />

连接在 TCP 开始发送 keepalive 探测包之前需要保持空闲的时间(以秒为单位)


## temporary_data_in_cache_reserve_space_wait_lock_timeout_milliseconds {#temporary_data_in_cache_reserve_space_wait_lock_timeout_milliseconds}

<SettingsInfoBlock type='UInt64' default_value='600000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "600000" },
        {
          label:
            "为文件系统缓存中的临时数据预留空间时锁定缓存的等待时间"
        }
      ]
    }
  ]}
/>

为文件系统缓存中的临时数据预留空间时锁定缓存的等待时间


## temporary_files_buffer_size {#temporary_files_buffer_size}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.10" },
        { label: "1048576" },
        { label: "新设置" }
      ]
    }
  ]}
/>

临时文件写入器的缓冲区大小。缓冲区越大,系统调用次数越少,但内存消耗越多。


## temporary_files_codec {#temporary_files_codec}

<SettingsInfoBlock type='String' default_value='LZ4' />

设置磁盘上排序和连接操作所使用的临时文件的压缩编解码器。

可选值：

- LZ4 — 应用 [LZ4](<https://en.wikipedia.org/wiki/LZ4_(compression_algorithm)>) 压缩算法。
- NONE — 不应用压缩。


## text_index_use_bloom_filter {#text_index_use_bloom_filter}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "1" }, { label: "新增设置。" }]
    }
  ]}
/>

用于测试目的，启用或禁用文本索引中布隆过滤器的使用。


## throw_if_deduplication_in_dependent_materialized_views_enabled_with_async_insert {#throw_if_deduplication_in_dependent_materialized_views_enabled_with_async_insert}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1" },
        {
          label:
            "依赖物化视图中的去重功能无法与异步插入同时使用。"
        }
      ]
    }
  ]}
/>

当同时启用 `deduplicate_blocks_in_dependent_materialized_views` 和 `async_insert` 设置时,在执行 INSERT 查询时抛出异常。这可以保证正确性,因为这两个功能无法同时使用。


## throw_if_no_data_to_insert {#throw_if_no_data_to_insert}

<SettingsInfoBlock type='Bool' default_value='1' />

允许或禁止空 INSERT 操作,默认启用(空插入时会抛出错误)。仅适用于通过 [`clickhouse-client`](/interfaces/cli) 或 [gRPC 接口](/interfaces/grpc)执行的 INSERT 操作。


## throw_on_error_from_cache_on_write_operations {#throw_on_error_from_cache_on_write_operations}

<SettingsInfoBlock type='Bool' default_value='0' />

在写入操作(INSERT、合并)的缓存过程中忽略缓存错误


## throw_on_max_partitions_per_insert_block {#throw_on_max_partitions_per_insert_block}

<SettingsInfoBlock type='Bool' default_value='1' />

控制达到 `max_partitions_per_insert_block` 限制时的行为。

可选值:

- `true` - 当插入块达到 `max_partitions_per_insert_block` 限制时,抛出异常。
- `false` - 当达到 `max_partitions_per_insert_block` 限制时,记录警告日志。

:::tip
当您需要了解修改 [`max_partitions_per_insert_block`](/operations/settings/settings#max_partitions_per_insert_block) 参数对用户的影响时,此设置会很有用。
:::


## throw_on_unsupported_query_inside_transaction {#throw_on_unsupported_query_inside_transaction}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

在事务内使用不支持的查询时抛出异常


## timeout_before_checking_execution_speed {#timeout_before_checking_execution_speed}

<SettingsInfoBlock type='Seconds' default_value='10' />

在指定的秒数过期后,检查执行速度是否不会过慢(不低于 `min_execution_speed`)。


## timeout_overflow_mode {#timeout_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

设置当查询运行时间超过 `max_execution_time` 或预估运行时间超过 `max_estimated_execution_time` 时的处理方式。

可选值:

- `throw`: 抛出异常(默认)。
- `break`: 停止执行查询并返回部分结果,如同源数据已用尽。


## timeout_overflow_mode_leaf {#timeout_overflow_mode_leaf}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

设置当叶节点中的查询运行时间超过 `max_execution_time_leaf` 时会发生什么。

可选值:

- `throw`: 抛出异常(默认值)。
- `break`: 停止执行查询并返回部分结果,就像源数据已用尽一样。


## totals_auto_threshold {#totals_auto_threshold}

<SettingsInfoBlock type='Float' default_value='0.5' />

`totals_mode = 'auto'` 的阈值。
参见"WITH TOTALS 修饰符"章节。


## totals_mode {#totals_mode}

<SettingsInfoBlock type='TotalsMode' default_value='after_having_exclusive' />

当存在 HAVING 子句以及 max_rows_to_group_by 和 group_by_overflow_mode = 'any' 时,如何计算 TOTALS。
请参阅"WITH TOTALS 修饰符"章节。


## trace_profile_events {#trace_profile_events}

<SettingsInfoBlock type='Bool' default_value='0' />

启用或禁用在每次性能事件更新时收集堆栈跟踪，包括性能事件名称和增量值，并将其发送到 [trace_log](/operations/system-tables/trace_log)。

可能的值：

- 1 — 启用性能事件跟踪。
- 0 — 禁用性能事件跟踪。


## transfer_overflow_mode {#transfer_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

设置当数据量超过其中一个限制时的处理方式。

可选值：

- `throw`：抛出异常（默认值）。
- `break`：停止执行查询并返回部分结果，如同源数据已耗尽。


## transform_null_in {#transform_null_in}

<SettingsInfoBlock type='Bool' default_value='0' />

启用 [IN](../../sql-reference/operators/in.md) 运算符对 [NULL](/sql-reference/syntax#null) 值的相等性判断。

默认情况下,`NULL` 值无法进行比较,因为 `NULL` 表示未定义的值。因此,比较表达式 `expr = NULL` 必须始终返回 `false`。启用此设置后,在 `IN` 运算符中 `NULL = NULL` 将返回 `true`。

可能的值:

- 0 — `IN` 运算符中 `NULL` 值的比较返回 `false`。
- 1 — `IN` 运算符中 `NULL` 值的比较返回 `true`。

**示例**

考虑 `null_in` 表:

```text
┌──idx─┬─────i─┐
│    1 │     1 │
│    2 │  NULL │
│    3 │     3 │
└──────┴───────┘
```

查询:

```sql
SELECT idx, i FROM null_in WHERE i IN (1, NULL) SETTINGS transform_null_in = 0;
```

结果:

```text
┌──idx─┬────i─┐
│    1 │    1 │
└──────┴──────┘
```

查询:

```sql
SELECT idx, i FROM null_in WHERE i IN (1, NULL) SETTINGS transform_null_in = 1;
```

结果:

```text
┌──idx─┬─────i─┐
│    1 │     1 │
│    2 │  NULL │
└──────┴───────┘
```

**另请参阅**

- [IN 运算符中的 NULL 处理](/sql-reference/operators/in#null-processing)


## traverse_shadow_remote_data_paths {#traverse_shadow_remote_data_paths}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        {
          label:
            "查询 system.remote_data_paths 时遍历 shadow 目录。"
        }
      ]
    }
  ]}
/>

查询 system.remote_data_paths 时,除实际表数据外,还遍历冻结数据(shadow 目录)


## union_default_mode {#union_default_mode}

设置组合 `SELECT` 查询结果的模式。该设置仅在与 [UNION](../../sql-reference/statements/select/union.md) 一起使用且未显式指定 `UNION ALL` 或 `UNION DISTINCT` 时生效。

可能的值:

- `'DISTINCT'` — ClickHouse 输出组合查询的结果行,并去除重复行。
- `'ALL'` — ClickHouse 输出组合查询的所有结果行,包括重复行。
- `''` — 与 `UNION` 一起使用时,ClickHouse 将抛出异常。

参见 [UNION](../../sql-reference/statements/select/union.md) 中的示例。


## unknown_packet_in_send_data {#unknown_packet_in_send_data}

<SettingsInfoBlock type='UInt64' default_value='0' />

发送未知数据包以替代第 N 个数据包


## update_parallel_mode {#update_parallel_mode}

<SettingsInfoBlock type='UpdateParallelMode' default_value='auto' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "auto" }, { label: "新增设置" }]
    }
  ]}
/>

决定并发更新查询的执行行为。

可选值：

- `sync` - 按顺序执行所有 `UPDATE` 查询。
- `auto` - 仅对存在依赖关系的 `UPDATE` 查询按顺序执行，即当一个查询更新的列被另一个查询的表达式所使用时。
- `async` - 不对更新查询进行同步。


## update_sequential_consistency {#update_sequential_consistency}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "1" }, { label: "新增设置" }]
    }
  ]}
/>

如果为 true，则在执行更新操作之前，会将数据分片集合更新到最新版本。


## use_async_executor_for_materialized_views {#use_async_executor_for_materialized_views}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.12" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

对物化视图查询使用异步且可能的多线程执行方式,可以加快 INSERT 期间的视图处理速度,但也会消耗更多内存。


## use_cache_for_count_from_files {#use_cache_for_count_from_files}

<SettingsInfoBlock type='Bool' default_value='1' />

在表函数 `file`/`s3`/`url`/`hdfs`/`azureBlobStorage` 中对文件进行计数时启用行数缓存。

默认启用。


## use_client_time_zone {#use_client_time_zone}

<SettingsInfoBlock type='Bool' default_value='0' />

使用客户端时区解释 DateTime 字符串值,而不是使用服务器时区。


## use_compact_format_in_distributed_parts_names {#use_compact_format_in_distributed_parts_names}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.1" },
        { label: "1" },
        {
          label:
            "默认对 Distributed 表的异步 INSERT 使用紧凑格式"
        }
      ]
    }
  ]}
/>

对使用 `Distributed` 引擎的表执行后台（`distributed_foreground_insert`）INSERT 操作时，使用紧凑格式存储数据块。

可选值：

- 0 — 使用 `user[:password]@host:port#default_database` 目录格式。
- 1 — 使用 `[shard{shard_index}[_replica{replica_index}]]` 目录格式。

:::note

- 当 `use_compact_format_in_distributed_parts_names=0` 时，集群定义的变更不会应用于后台 INSERT 操作。
- 当 `use_compact_format_in_distributed_parts_names=1` 时，更改集群定义中节点的顺序会改变 `shard_index`/`replica_index`，请注意此影响。
  :::


## use_concurrency_control {#use_concurrency_control}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "1" },
        { label: "默认启用并发控制" }
      ]
    }
  ]}
/>

遵循服务器的并发控制(参见全局服务器设置 `concurrent_threads_soft_limit_num` 和 `concurrent_threads_soft_limit_ratio_to_cores`)。如果禁用此设置,即使服务器过载也允许使用更多线程(不建议在正常使用中禁用,主要用于测试场景)。


## use_hedged_requests {#use_hedged_requests}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.9" },
        { label: "1" },
        { label: "默认启用对冲请求功能" }
      ]
    }
  ]}
/>

为远程查询启用对冲请求逻辑。允许为查询与不同副本建立多个连接。
当现有副本连接在 `hedged_connection_timeout` 时间内未能建立,或在 `receive_data_timeout` 时间内未接收到数据时,将启用新连接。查询使用第一个发送非空进度包(或数据包,若启用了 `allow_changing_replica_until_first_data_packet`)的连接;
其他连接将被取消。支持 `max_parallel_replicas > 1` 的查询。

默认启用。

Cloud 默认值:`1`


## use_hive_partitioning {#use_hive_partitioning}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "1" },
        { label: "默认启用此设置。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.8" },
        { label: "0" },
        {
          label:
            "允许在 File、URL、S3、AzureBlobStorage 和 HDFS 引擎中使用 Hive 分区。"
        }
      ]
    }
  ]}
/>

启用后,ClickHouse 将在类文件表引擎 [File](/sql-reference/table-functions/file#hive-style-partitioning)/[S3](/sql-reference/table-functions/s3#hive-style-partitioning)/[URL](/sql-reference/table-functions/url#hive-style-partitioning)/[HDFS](/sql-reference/table-functions/hdfs#hive-style-partitioning)/[AzureBlobStorage](/sql-reference/table-functions/azureBlobStorage#hive-style-partitioning) 的路径中检测 Hive 风格的分区(`/name=value/`),并允许在查询中将分区列作为虚拟列使用。这些虚拟列的名称与分区路径中的名称相同,但以 `_` 开头。


## use_iceberg_metadata_files_cache {#use_iceberg_metadata_files_cache}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "1" }, { label: "新增设置" }]
    }
  ]}
/>

启用后,iceberg 表函数和 iceberg 存储可以利用 iceberg 元数据文件缓存。

可能的值:

- 0 - 禁用
- 1 - 启用


## use_iceberg_partition_pruning {#use_iceberg_partition_pruning}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "1" },
        { label: "默认启用 Iceberg 分区修剪。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.1" },
        { label: "0" },
        { label: "用于 Iceberg 分区修剪的新设置。" }
      ]
    }
  ]}
/>

对 Iceberg 表使用 Iceberg 分区修剪


## use_index_for_in_with_subqueries {#use_index_for_in_with_subqueries}

<SettingsInfoBlock type='Bool' default_value='1' />

当 IN 运算符的右侧为子查询或表表达式时,尝试使用索引。


## use_index_for_in_with_subqueries_max_values {#use_index_for_in_with_subqueries_max_values}

<SettingsInfoBlock type='UInt64' default_value='0' />

IN 运算符右侧集合的最大大小,用于使用表索引进行过滤。该设置可以避免因大型查询准备额外数据结构而导致的性能下降和内存使用增加。设置为零表示无限制。


## use_join_disjunctions_push_down {#use_join_disjunctions_push_down}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

启用将 JOIN 条件中通过 OR 连接的部分下推到相应的输入侧("部分下推")。
这使得存储引擎能够更早地进行过滤,从而减少数据读取量。
该优化保持语义不变,仅在每个顶层 OR 分支为目标侧至少贡献一个确定性谓词时才会应用。


## use_legacy_to_time {#use_legacy_to_time}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "1" },
        {
          label:
            "新增设置。允许用户使用 toTime 的旧版函数逻辑,其工作方式与 toTimeWithFixedDate 相同。"
        }
      ]
    }
  ]}
/>

启用时,允许使用旧版 toTime 函数,该函数将日期时间转换为固定日期,同时保留时间部分。
禁用时,使用新版 toTime 函数,该函数将不同类型的数据转换为 Time 类型。
旧版函数也可以通过 toTimeWithFixedDate 无条件访问。


## use_page_cache_for_disks_without_file_cache {#use_page_cache_for_disks_without_file_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        { label: "新增用户空间页缓存" }
      ]
    }
  ]}
/>

对未启用文件系统缓存的远程磁盘使用用户空间页缓存。


## use_page_cache_with_distributed_cache {#use_page_cache_with_distributed_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.3" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

使用分布式缓存时启用用户空间页面缓存。


## use_paimon_partition_pruning {#use_paimon_partition_pruning}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "New setting." }]
    }
  ]}
/>

为 Paimon 表函数启用 Paimon 分区裁剪


## use_query_cache {#use_query_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

启用后，`SELECT` 查询可以利用[查询缓存](../query-cache.md)。参数 [enable_reads_from_query_cache](#enable_reads_from_query_cache) 和 [enable_writes_to_query_cache](#enable_writes_to_query_cache) 可更详细地控制缓存的使用方式。

可选值：

- 0 - 禁用
- 1 - 启用


## use_query_condition_cache {#use_query_condition_cache}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.4" },
        { label: "1" },
        { label: "新增优化" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "25.3" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

启用[查询条件缓存](/operations/query-condition-cache)。该缓存会存储数据部分中不满足 `WHERE` 子句条件的颗粒范围,
并将此信息作为临时索引用于后续查询。

可能的值:

- 0 - 禁用
- 1 - 启用


## use_roaring_bitmap_iceberg_positional_deletes {#use_roaring_bitmap_iceberg_positional_deletes}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "New setting" }]
    }
  ]}
/>

对 Iceberg 位置删除使用 Roaring Bitmap。


## use_skip_indexes {#use_skip_indexes}

<SettingsInfoBlock type='Bool' default_value='1' />

在查询执行期间使用数据跳过索引。

可能的值：

- 0 — 禁用。
- 1 — 启用。


## use_skip_indexes_if_final {#use_skip_indexes_if_final}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "1" },
        { label: "设置默认值变更" }
      ]
    }
  ]}
/>

控制在执行带有 FINAL 修饰符的查询时是否使用跳数索引。

跳数索引可能会排除包含最新数据的行(颗粒),从而导致带有 FINAL 修饰符的查询返回不正确的结果。启用此设置后,即使使用 FINAL 修饰符也会应用跳数索引,这可能会提高性能,但存在遗漏最近更新数据的风险。此设置应与 use_skip_indexes_if_final_exact_mode 设置同步启用(默认已启用)。

可能的值:

- 0 — 禁用。
- 1 — 启用。


## use_skip_indexes_if_final_exact_mode {#use_skip_indexes_if_final_exact_mode}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "1" },
        { label: "设置默认值变更" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.5" },
        { label: "0" },
        {
          label:
            "引入此设置以帮助 FINAL 查询在使用跳过索引时返回正确结果"
        }
      ]
    }
  ]}
/>

控制在执行带有 FINAL 修饰符的查询时,是否在较新的数据分片中扩展跳过索引返回的颗粒,以确保返回正确的结果。

使用跳过索引可能会排除包含最新数据的行(颗粒),从而导致结果不正确。此设置通过扫描与跳过索引返回范围存在重叠的较新数据分片,来确保返回正确的结果。仅当应用程序可以接受基于跳过索引查找的近似结果时,才应禁用此设置。

可能的值:

- 0 — 禁用。
- 1 — 启用。


## use_skip_indexes_on_data_read {#use_skip_indexes_on_data_read}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

在数据读取过程中启用数据跳过索引。

启用后,跳过索引将在读取每个数据颗粒时动态评估,而不是在查询执行开始前预先分析。这可以降低查询启动延迟。

可选值:

- 0 — 禁用。
- 1 — 启用。


## use_statistics_cache {#use_statistics_cache}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "New setting" }]
    }
  ]}
/>

在查询中使用统计信息缓存,以避免加载每个数据分区的统计信息所产生的开销


## use_structure_from_insertion_table_in_table_functions {#use_structure_from_insertion_table_in_table_functions}

<SettingsInfoBlock type='UInt64' default_value='2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.11" },
        { label: "2" },
        {
          label:
            "改进表函数中使用插入表结构的方式"
        }
      ]
    }
  ]}
/>

使用插入表的结构,而非从数据推断架构。可选值:0 - 禁用,1 - 启用,2 - 自动


## use_text_index_dictionary_cache {#use_text_index_dictionary_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

是否使用反序列化文本索引字典块的缓存。
在处理大量文本索引查询时,使用文本索引字典块缓存可以显著降低延迟并提高吞吐量。


## use_text_index_header_cache {#use_text_index_header_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

是否使用反序列化的文本索引头缓存。
使用文本索引头缓存可以在处理大量文本索引查询时显著降低延迟并提高吞吐量。


## use_text_index_postings_cache {#use_text_index_postings_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "新设置" }]
    }
  ]}
/>

是否使用反序列化文本索引倒排表的缓存。
使用文本索引倒排表缓存可以在处理大量文本索引查询时显著降低延迟并提高吞吐量。


## use_uncompressed_cache {#use_uncompressed_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

是否使用未压缩数据块的缓存。可设置为 0 或 1。默认值为 0（禁用）。
使用未压缩缓存（仅适用于 MergeTree 系列表）可以在处理大量短查询时显著降低延迟并提高吞吐量。对于频繁发送短请求的用户，建议启用此设置。同时需要注意 [uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size) 配置参数（仅可在配置文件中设置）——未压缩缓存块的大小。默认值为 8 GiB。未压缩缓存会按需填充,最少使用的数据会被自动删除。

对于读取较大数据量（一百万行或更多）的查询，未压缩缓存会自动禁用，以便为真正的小查询节省空间。这意味着您可以始终将 'use_uncompressed_cache' 设置保持为 1。


## use_variant_as_common_type {#use_variant_as_common_type}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "0" },
        {
          label: "当不存在公共类型时,允许在 if/multiIf 中使用 Variant"
        }
      ]
    }
  ]}
/>

当参数类型之间不存在公共类型时,允许将 `Variant` 类型用作 [if](../../sql-reference/functions/conditional-functions.md/#if)/[multiIf](../../sql-reference/functions/conditional-functions.md/#multiIf)/[array](../../sql-reference/functions/array-functions.md)/[map](../../sql-reference/functions/tuple-map-functions.md) 函数的结果类型。

示例:

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(if(number % 2, number, range(number))) as variant_type FROM numbers(1);
SELECT if(number % 2, number, range(number)) as variant FROM numbers(5);
```

```text
┌─variant_type───────────────────┐
│ Variant(Array(UInt64), UInt64) │
└────────────────────────────────┘
┌─variant───┐
│ []        │
│ 1         │
│ [0,1]     │
│ 3         │
│ [0,1,2,3] │
└───────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(multiIf((number % 4) = 0, 42, (number % 4) = 1, [1, 2, 3], (number % 4) = 2, 'Hello, World!', NULL)) AS variant_type FROM numbers(1);
SELECT multiIf((number % 4) = 0, 42, (number % 4) = 1, [1, 2, 3], (number % 4) = 2, 'Hello, World!', NULL) AS variant FROM numbers(4);
```

```text
─variant_type─────────────────────────┐
│ Variant(Array(UInt8), String, UInt8) │
└──────────────────────────────────────┘

┌─variant───────┐
│ 42            │
│ [1,2,3]       │
│ Hello, World! │
│ ᴺᵁᴸᴸ          │
└───────────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(array(range(number), number, 'str_' || toString(number))) as array_of_variants_type from numbers(1);
SELECT array(range(number), number, 'str_' || toString(number)) as array_of_variants FROM numbers(3);
```

```text
┌─array_of_variants_type────────────────────────┐
│ Array(Variant(Array(UInt64), String, UInt64)) │
└───────────────────────────────────────────────┘

┌─array_of_variants─┐
│ [[],0,'str_0']    │
│ [[0],1,'str_1']   │
│ [[0,1],2,'str_2'] │
└───────────────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(map('a', range(number), 'b', number, 'c', 'str_' || toString(number))) as map_of_variants_type from numbers(1);
SELECT map('a', range(number), 'b', number, 'c', 'str_' || toString(number)) as map_of_variants FROM numbers(3);
```

```text
┌─map_of_variants_type────────────────────────────────┐
│ Map(String, Variant(Array(UInt64), String, UInt64)) │
└─────────────────────────────────────────────────────┘

┌─map_of_variants───────────────┐
│ {'a':[],'b':0,'c':'str_0'}    │
│ {'a':[0],'b':1,'c':'str_1'}   │
│ {'a':[0,1],'b':2,'c':'str_2'} │
└───────────────────────────────┘
```


## use_with_fill_by_sorting_prefix {#use_with_fill_by_sorting_prefix}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.5" },
        { label: "1" },
        {
          label:
            "ORDER BY 子句中位于 WITH FILL 列之前的列构成排序前缀。排序前缀值不同的行将分别独立填充"
        }
      ]
    }
  ]}
/>

ORDER BY 子句中位于 WITH FILL 列之前的列构成排序前缀。排序前缀值不同的行将分别独立填充


## validate_enum_literals_in_operators {#validate_enum_literals_in_operators}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "0" }, { label: "新增设置" }]
    }
  ]}
/>

启用后,将在 `IN`、`NOT IN`、`==`、`!=` 等操作符中验证枚举字面量是否与枚举类型匹配,若字面量不是有效的枚举值则抛出异常。


## validate_mutation_query {#validate_mutation_query}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "1" },
        { label: "新增设置:默认验证变更查询。" }
      ]
    }
  ]}
/>

在接受变更查询之前对其进行验证。变更操作在后台执行,运行无效查询会导致变更操作卡住,需要手动干预。

仅在遇到向后不兼容的错误时更改此设置。


## validate_polygons {#validate_polygons}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "20.4" },
        { label: "1" },
        {
          label:
            "默认情况下,如果 pointInPolygon 函数中的多边形无效则抛出异常,而不是返回可能错误的结果"
        }
      ]
    }
  ]}
/>

启用或禁用 [pointInPolygon](/sql-reference/functions/geo/coordinates#pointinpolygon) 函数在多边形自相交或自相切时抛出异常。

可能的值:

- 0 — 禁用抛出异常。`pointInPolygon` 接受无效多边形并可能返回不正确的结果。
- 1 — 启用抛出异常。


## vector_search_filter_strategy {#vector_search_filter_strategy}

<SettingsInfoBlock type='VectorSearchFilterStrategy' default_value='auto' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "auto" }, { label: "新设置" }]
    }
  ]}
/>

如果向量搜索查询包含 WHERE 子句,此设置决定是先评估该子句(预过滤)还是先检查向量相似度索引(后过滤)。可选值:

- 'auto' - 后过滤(具体语义未来可能会变更)。
- 'postfilter' - 使用向量相似度索引识别最近邻,然后应用其他过滤条件
- 'prefilter' - 先评估其他过滤条件,然后执行暴力搜索以识别最近邻。


## vector_search_index_fetch_multiplier {#vector_search_index_fetch_multiplier}

**别名**: `vector_search_postfilter_multiplier`

<SettingsInfoBlock type='Float' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "1" },
        { label: "设置 'vector_search_postfilter_multiplier' 的别名" }
      ]
    }
  ]}
/>

将从向量相似度索引中获取的最近邻居数量乘以此数值。仅在与其他谓词进行后置过滤时应用,或当设置 'vector_search_with_rescoring = 1' 时应用。


## vector_search_with_rescoring {#vector_search_with_rescoring}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

控制 ClickHouse 是否对使用向量相似度索引的查询执行重新评分。
不启用重新评分时,向量相似度索引直接返回包含最佳匹配的行。
启用重新评分后,会将结果行外推至颗粒级别,并重新检查颗粒中的所有行。
在大多数情况下,重新评分对准确性的提升微乎其微,但会显著降低向量搜索查询的性能。
注意:未启用重新评分但启用了并行副本时运行查询,可能会回退至重新评分模式。


## wait_changes_become_visible_after_commit_mode {#wait_changes_become_visible_after_commit_mode}

<ExperimentalBadge />

<SettingsInfoBlock
  type='TransactionsWaitCSNMode'
  default_value='wait_unknown'
/>

等待已提交的更改在最新快照中变为实际可见


## wait_for_async_insert {#wait_for_async_insert}

<SettingsInfoBlock type='Bool' default_value='1' />

如果为 true,则等待异步插入处理完成


## wait_for_async_insert_timeout {#wait_for_async_insert_timeout}

<SettingsInfoBlock type='Seconds' default_value='120' />

等待异步插入处理的超时时间


## wait_for_window_view_fire_signal_timeout {#wait_for_window_view_fire_signal_timeout}

<ExperimentalBadge />

<SettingsInfoBlock type='Seconds' default_value='10' />

事件时间处理中等待窗口视图触发信号的超时时间


## window_view_clean_interval {#window_view_clean_interval}

<ExperimentalBadge />

<SettingsInfoBlock type='Seconds' default_value='60' />

窗口视图的清理间隔（秒），用于释放过期数据。


## window_view_heartbeat_interval {#window_view_heartbeat_interval}

<ExperimentalBadge />

<SettingsInfoBlock type='Seconds' default_value='15' />

心跳间隔(以秒为单位),用于指示监视查询是否存活。


## workload {#workload}

<SettingsInfoBlock type='String' default_value='default' />

用于访问资源的工作负载名称


## write_full_path_in_iceberg_metadata {#write_full_path_in_iceberg_metadata}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新增设置。" }]
    }
  ]}
/>

将完整路径(包括 s3://)写入 Iceberg 元数据文件。


## write_through_distributed_cache {#write_through_distributed_cache}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "ClickHouse Cloud 配置项" }
      ]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。允许写入分布式缓存(写入 S3 也将通过分布式缓存完成)


## write_through_distributed_cache_buffer_size {#write_through_distributed_cache_buffer_size}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.7" }, { label: "0" }, { label: "新增云设置" }]
    }
  ]}
/>

仅在 ClickHouse Cloud 中生效。设置直写式分布式缓存的缓冲区大小。如果设置为 0，将使用不存在分布式缓存时所使用的缓冲区大小。


## zstd_window_log_max {#zstd_window_log_max}

<SettingsInfoBlock type='Int64' default_value='0' />

允许您选择 ZSTD 的最大窗口日志大小（不适用于 MergeTree 系列表引擎）
