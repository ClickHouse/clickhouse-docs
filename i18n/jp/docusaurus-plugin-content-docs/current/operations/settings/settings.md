---
'title': 'セッション設定'
'sidebar_label': 'セッション設定'
'slug': '/operations/settings/settings'
'toc_max_heading_level': 2
'description': '``system.settings`` テーブルにある設定です。'
---

import ExperimentalBadge from '@theme/badges/ExperimentalBadge';
import BetaBadge from '@theme/badges/BetaBadge';
import CloudOnlyBadge from '@theme/badges/CloudOnlyBadge';
import SettingsInfoBlock from '@theme/SettingsInfoBlock/SettingsInfoBlock';
import VersionHistory from '@theme/VersionHistory/VersionHistory';


<!-- Autogenerated -->
すべての設定は、テーブル [system.settings](/operations/system-tables/settings) にも利用可能です。これらの設定は、[source](https://github.com/ClickHouse/ClickHouse/blob/master/src/Core/Settings.cpp) から自動生成されています。
## add_http_cors_header {#add_http_cors_header} 

<SettingsInfoBlock type="Bool" default_value="0" />

HTTP CORS ヘッダーを追加します。
## additional_result_filter {#additional_result_filter} 

`SELECT` クエリの結果に適用する追加のフィルター式です。
この設定は、いかなるサブクエリにも適用されません。

**例**

```sql
INSERT INTO table_1 VALUES (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');
SElECT * FROM table_1;

```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 2 │ bb   │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘

```sql
SELECT *
FROM table_1
SETTINGS additional_result_filter = 'x != 2'

```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘

## additional_table_filters {#additional_table_filters} 

<SettingsInfoBlock type="Map" default_value="{}" />

指定されたテーブルからの読み込み後に適用される追加のフィルター式です。

**例**

```sql
INSERT INTO table_1 VALUES (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');
SELECT * FROM table_1;

```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 2 │ bb   │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘

```sql
SELECT *
FROM table_1
SETTINGS additional_table_filters = {'table_1': 'x != 2'}

```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘

## aggregate_functions_null_for_empty {#aggregate_functions_null_for_empty} 

<SettingsInfoBlock type="Bool" default_value="0" />

クエリ内のすべての集計関数を書き換え、[-OrNull](/sql-reference/aggregate-functions/combinators#-ornull) サフィックスを追加するかどうかを有効または無効にします。SQL 標準の互換性のために有効にします。
これは、分散クエリに対して一貫した結果を得るために、[count_distinct_implementation](#count_distinct_implementation) 設定と同様にクエリリライトを介して実装されます。

可能な値：

- 0 — 無効。
- 1 — 有効。

**例**

次のクエリを考えてみてください：
```sql
SELECT SUM(-1), MAX(0) FROM system.one WHERE 0;

`aggregate_functions_null_for_empty = 0` の場合、結果は以下のようになります：
```text
┌─SUM(-1)─┬─MAX(0)─┐
│       0 │      0 │
└─────────┴────────┘

`aggregate_functions_null_for_empty = 1` の場合、結果は以下のようになります：
```text
┌─SUMOrNull(-1)─┬─MAXOrNull(0)─┐
│          NULL │         NULL │
└───────────────┴──────────────┘

## aggregation_in_order_max_block_bytes {#aggregation_in_order_max_block_bytes} 

<SettingsInfoBlock type="UInt64" default_value="50000000" />

主キーの順序で集計中に蓄積されたブロックの最大サイズ（バイト）です。ブロックサイズが小さいほど、集計の最終マージステージがより多く平行化されます。
## aggregation_memory_efficient_merge_threads {#aggregation_memory_efficient_merge_threads} 

<SettingsInfoBlock type="UInt64" default_value="0" />

メモリ効率の良いモードで中間の集計結果をマージするために使用するスレッドの数。大きくなるほど、より多くのメモリが消費されます。0 は「max_threads」と同じです。
## allow_aggregate_partitions_independently {#allow_aggregate_partitions_independently} 

<SettingsInfoBlock type="Bool" default_value="0" />

パーティションキーがグループ化キーに適合する場合に、別々のスレッドでパーティションの独立した集計を有効にします。パーティションの数がコアの数に近く、パーティションのサイズがほぼ同じ場合に有益です。
## allow_archive_path_syntax {#allow_archive_path_syntax} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "1"},{"label": "アーカイブパス構文の無効化を許可する新しい設定を追加しました。"}]}, {"id": "row-2","items": [{"label": "24.5"},{"label": "1"},{"label": "アーカイブパス構文の無効化を許可する新しい設定を追加しました。"}]}]}/>

ファイル/S3 エンジン/テーブル関数は、アーカイブが正しい拡張子を持っている場合、'::' を <archive> :: <file> としてパスを解析します。
## allow_asynchronous_read_from_io_pool_for_merge_tree {#allow_asynchronous_read_from_io_pool_for_merge_tree} 

<SettingsInfoBlock type="Bool" default_value="0" />

MergeTree テーブルから読み取るためにバックグラウンド I/O プールを使用します。この設定は、I/O に依存するクエリのパフォーマンスを向上させる可能性があります。
## allow_changing_replica_until_first_data_packet {#allow_changing_replica_until_first_data_packet} 

<SettingsInfoBlock type="Bool" default_value="0" />

有効な場合、ヘッジリクエストで最初のデータパケットを受信するまで新しい接続を開始できます。進行状況がある場合でも、進行が `receive_data_timeout` タイムアウトのために更新されていない場合、そうでなければ最初に進行した後でレプリカの変更を無効にします。
## allow_create_index_without_type {#allow_create_index_without_type} 

<SettingsInfoBlock type="Bool" default_value="0" />

TYPE なしで CREATE INDEX クエリを許可します。このクエリは無視されます。SQL 互換性テスト用に作成されました。
## allow_custom_error_code_in_throwif {#allow_custom_error_code_in_throwif} 

<SettingsInfoBlock type="Bool" default_value="0" />

関数 throwIf() でカスタムエラーコードを有効にします。これが真の場合、スローされた例外は予期しないエラーコードを持つ可能性があります。
## allow_ddl {#allow_ddl} 

<SettingsInfoBlock type="Bool" default_value="1" />

true に設定されている場合、ユーザーは DDL クエリを実行できます。
## allow_deprecated_database_ordinary {#allow_deprecated_database_ordinary} 

<SettingsInfoBlock type="Bool" default_value="0" />

非推奨の Ordinary エンジンを持つデータベースの作成を許可します。
## allow_deprecated_error_prone_window_functions {#allow_deprecated_error_prone_window_functions} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "0"},{"label": "エラーの発生しやすい非推奨ウィンドウ関数 (neighbor, runningAccumulate, runningDifferenceStartingWithFirstValue, runningDifference) の使用を許可する。"}]}]}/>

エラーの発生しやすい非推奨のウィンドウ関数 (neighbor, runningAccumulate, runningDifferenceStartingWithFirstValue, runningDifference) の使用を許可します。
## allow_deprecated_snowflake_conversion_functions {#allow_deprecated_snowflake_conversion_functions} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "非推奨関数 snowflakeToDateTime[64] および dateTime[64]ToSnowflake を無効にしました。"}]}]}/>

関数 `snowflakeToDateTime`, `snowflakeToDateTime64`, `dateTimeToSnowflake`, および `dateTime64ToSnowflake` は非推奨であり、デフォルトで無効です。
代わりに関数 `snowflakeIDToDateTime`, `snowflakeIDToDateTime64`, `dateTimeToSnowflakeID`, および `dateTime64ToSnowflakeID` を使用してください。

非推奨の関数を再び有効にするには (例えば、移行期間中)、この設定を `true` に設定してください。
## allow_deprecated_syntax_for_merge_tree {#allow_deprecated_syntax_for_merge_tree} 

<SettingsInfoBlock type="Bool" default_value="0" />

非推奨のエンジン定義構文を持つ *MergeTree テーブルの作成を許可します。
## allow_distributed_ddl {#allow_distributed_ddl} 

<SettingsInfoBlock type="Bool" default_value="1" />

true に設定されている場合、ユーザーは分散 DDL クエリを実行できます。
## allow_drop_detached {#allow_drop_detached} 

<SettingsInfoBlock type="Bool" default_value="0" />

ALTER TABLE ... DROP DETACHED PART[ITION] ... クエリを許可します。
## allow_execute_multiif_columnar {#allow_execute_multiif_columnar} 

<SettingsInfoBlock type="Bool" default_value="1" />

multiIf 関数を列指向で実行することを許可します。
## allow_experimental_analyzer {#allow_experimental_analyzer} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "デフォルトでアナライザーとプランナーを有効にします。"}]}]}/>

新しいクエリアナライザーを許可します。
## allow_experimental_codecs {#allow_experimental_codecs} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

true に設定されている場合、実験的な圧縮コーデックを指定することができます（ただし、現在は利用できないため、このオプションは何もしません）。
## allow_experimental_correlated_subqueries {#allow_experimental_correlated_subqueries} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "相関サブクエリの実行を許可する新しい設定を追加しました。"}]}]}/>

相関サブクエリの実行を許可します。
## allow_experimental_database_glue_catalog {#allow_experimental_database_glue_catalog} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "0"},{"label": "カタログの種類を 'glue' に設定した実験的データベースエンジン DataLakeCatalog を許可します。"}]}]}/>

カタログの種類を 'glue' に設定した実験的データベースエンジン DataLakeCatalog を許可します。
## allow_experimental_database_hms_catalog {#allow_experimental_database_hms_catalog} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "カタログの種類を 'hive' に設定した実験的データベースエンジン DataLakeCatalog を許可します。"}]}]}/>

カタログの種類を 'hms' に設定した実験的データベースエンジン DataLakeCatalog を許可します。
## allow_experimental_database_iceberg {#allow_experimental_database_iceberg} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "0"},{"label": "新しい設定です。"}]}]}/>

カタログの種類を 'iceberg' に設定した実験的データベースエンジン DataLakeCatalog を許可します。
## allow_experimental_database_materialized_postgresql {#allow_experimental_database_materialized_postgresql} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

Engine=MaterializedPostgreSQL(...) でデータベースを作成することを許可します。
## allow_experimental_database_unity_catalog {#allow_experimental_database_unity_catalog} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "0"},{"label": "カタログの種類を 'unity' に設定した実験的データベースエンジン DataLakeCatalog を許可します。"}]}]}/>

カタログの種類を 'unity' に設定した実験的データベースエンジン DataLakeCatalog を許可します。
## allow_experimental_delta_kernel_rs {#allow_experimental_delta_kernel_rs} 

<BetaBadge/>

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "新しい設定です。"}]}]}/>

実験的な delta-kernel-rs 実装を許可します。
## allow_experimental_dynamic_type {#allow_experimental_dynamic_type} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "1"},{"label": "動的データ型が生産準備完了です。"}]}, {"id": "row-2","items": [{"label": "24.5"},{"label": "0"},{"label": "新しい実験的動的型を追加します。"}]}]}/>

[Dynamic](../../sql-reference/data-types/dynamic.md) データ型の作成を許可します。
## allow_experimental_full_text_index {#allow_experimental_full_text_index} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "実験的な全文インデックスを有効にします。"}]}]}/>

true に設定されている場合、実験的な全文インデックスを使用することを許可します。
## allow_experimental_funnel_functions {#allow_experimental_funnel_functions} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

ファネル分析用の実験的な関数を有効にします。
## allow_experimental_hash_functions {#allow_experimental_hash_functions} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

実験的なハッシュ関数を有効にします。
## allow_experimental_inverted_index {#allow_experimental_inverted_index} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

true に設定されている場合、実験的な逆インデックスを使用することを許可します。
## allow_experimental_join_condition {#allow_experimental_join_condition} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "0"},{"label": "両方の左および右テーブルのカラムを含む非等号条件による結合をサポートします。例えば `t1.y < t2.y`。"}]}]}/>

両方の左および右テーブルのカラムを含む非等号条件による結合をサポートします。例えば `t1.y < t2.y`。
## allow_experimental_join_right_table_sorting {#allow_experimental_join_right_table_sorting} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "true に設定されており、かつ、`join_to_sort_minimum_perkey_rows` および `join_to_sort_maximum_table_rows` の条件が満たされている場合、右テーブルをキーで再範囲指定して左または内部ハッシュ結合のパフォーマンスを向上させます。"}]}]}/>

true に設定されており、かつ、`join_to_sort_minimum_perkey_rows` および `join_to_sort_maximum_table_rows` の条件が満たされている場合、右テーブルをキーで再範囲指定して左または内部ハッシュ結合のパフォーマンスを向上させます。
## allow_experimental_json_type {#allow_experimental_json_type} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "1"},{"label": "JSON データ型が生産準備完了です。"}]}, {"id": "row-2","items": [{"label": "24.8"},{"label": "0"},{"label": "新しい実験的 JSON 型を追加します。"}]}]}/>

[JSON](../../sql-reference/data-types/newjson.md) データ型の作成を許可します。
## allow_experimental_kafka_offsets_storage_in_keeper {#allow_experimental_kafka_offsets_storage_in_keeper} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "Kafka のコミットオフセットを ClickHouse Keeper に保存する実験的な Kafka ストレージエンジンの使用を許可します。"}]}]}/>

Kafka 関連のオフセットを ClickHouse Keeper に保存する実験的な機能を許可します。これを有効にすると、Kafka テーブルエンジンに ClickHouse Keeper パスとレプリカ名を指定できます。その結果、通常の Kafka エンジンの代わりに、主に ClickHouse Keeper にコミットオフセットを保存する新しいタイプのストレージエンジンが使用されます。
## allow_experimental_kusto_dialect {#allow_experimental_kusto_dialect} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "新しい設定です。"}]}]}/>

Kusto Query Language (KQL) - SQL の代替を有効にします。
## allow_experimental_lightweight_update {#allow_experimental_lightweight_update} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "新しい設定です。"}]}]}/>

軽量更新を使用することを許可します。
## allow_experimental_live_view {#allow_experimental_live_view} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

非推奨の LIVE VIEW の作成を許可します。

可能な値：

- 0 — ライブビューの操作が無効になっています。
- 1 — ライブビューの操作が有効になっています。
## allow_experimental_materialized_postgresql_table {#allow_experimental_materialized_postgresql_table} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

MaterializedPostgreSQL テーブルエンジンを使用することを許可します。デフォルトでは無効です。なぜなら、この機能は実験的だからです。
## allow_experimental_nlp_functions {#allow_experimental_nlp_functions} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

自然言語処理のための実験的な関数を有効にします。
## allow_experimental_object_type {#allow_experimental_object_type} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

廃止された Object データ型を許可します。
## allow_experimental_parallel_reading_from_replicas {#allow_experimental_parallel_reading_from_replicas} 

<BetaBadge/>

<SettingsInfoBlock type="UInt64" default_value="0" />

SELECT クエリの実行に対してシャードごとに最大 `max_parallel_replicas` の数のレプリカを使用します。読み取りは動的に並列化され、調整されます。0 - 無効、1 - 有効、障害時に静かに無効にします、2 - 有効、障害時に例外をスローします。
## allow_experimental_prql_dialect {#allow_experimental_prql_dialect} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "新しい設定です。"}]}]}/>

PRQL - SQL の代替を有効にします。
## allow_experimental_query_deduplication {#allow_experimental_query_deduplication} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

パート UUID に基づく SELECT クエリのための実験的なデータ重複排除を有効にします。
## allow_experimental_statistics {#allow_experimental_statistics} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "設定名が変更されました。旧名は `allow_experimental_statistic` です。"}]}]}/>

[統計](../../engines/table-engines/mergetree-family/mergetree.md/#table_engine-mergetree-creating-a-table) を持つカラムを定義し、[統計を操作](../../engines/table-engines/mergetree-family/mergetree.md/#column-statistics) することを許可します。
## allow_experimental_time_series_table {#allow_experimental_time_series_table} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "TimeSeries テーブルエンジンを許可する新しい設定を追加しました。"}]}]}/>

[TimeSeries](../../engines/table-engines/integrations/time-series.md) テーブルエンジンを持つテーブルを作成することを許可します。可能な値：
- 0 — [TimeSeries](../../engines/table-engines/integrations/time-series.md) テーブルエンジンは無効です。
- 1 — [TimeSeries](../../engines/table-engines/integrations/time-series.md) テーブルエンジンは有効です。
## allow_experimental_ts_to_grid_aggregate_function {#allow_experimental_ts_to_grid_aggregate_function} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "クラウド専用です。"}]}]}/>

Prometheus のようなタイムシリーズの再サンプリングのための実験的な tsToGrid 集約関数。
## allow_experimental_variant_type {#allow_experimental_variant_type} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "1"},{"label": "Variant データ型が生産準備完了です。"}]}, {"id": "row-2","items": [{"label": "24.1"},{"label": "0"},{"label": "新しい実験的 Variant 型を追加します。"}]}]}/>

[Variant](../../sql-reference/data-types/variant.md) データ型の作成を許可します。
## allow_experimental_vector_similarity_index {#allow_experimental_vector_similarity_index} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "実験的なベクトル類似性インデックスを許可する新しい設定を追加しました。"}]}]}/>

実験的なベクトル類似性インデックスを許可します。
## allow_experimental_window_view {#allow_experimental_window_view} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

WINDOW VIEW を有効にします。十分に成熟していません。
## allow_general_join_planning {#allow_general_join_planning} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "ハッシュ結合アルゴリズムが有効な場合、より一般的な結合プランニングアルゴリズムを許可します。"}]}]}/>

より複雑な条件を扱うことができる一般的な結合プランニングアルゴリズムを許可しますが、ハッシュ結合にのみ機能します。ハッシュ結合が有効でない場合は、この設定の値に関係なく、通常の結合プランニングアルゴリズムが使用されます。
## allow_get_client_http_header {#allow_get_client_http_header} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "新しい関数を導入しました。"}]}]}/>

現在の HTTP リクエストのヘッダーの値を取得する `getClientHTTPHeader` 関数を使用することを許可します。セキュリティ上の理由から、デフォルトでは有効になっていません。なぜなら `Cookie` などの一部のヘッダーは、機密情報を含む可能性があるからです。`X-ClickHouse-*` および `Authentication` ヘッダーは常に制限されており、この関数で取得することはできません。
## allow_hyperscan {#allow_hyperscan} 

<SettingsInfoBlock type="Bool" default_value="1" />

Hyperscan ライブラリを使用する関数を許可します。潜在的に長いコンパイル時間や過剰なリソース使用を避けるために無効にします。
## allow_introspection_functions {#allow_introspection_functions} 

<SettingsInfoBlock type="Bool" default_value="0" />

クエリプロファイリングのための [インストロスペクション関数](../../sql-reference/functions/introspection.md) を有効または無効にします。

可能な値：

- 1 — インストロスペクション関数が有効。
- 0 — インストロスペクション関数が無効。

**関連情報**

- [Sampling Query Profiler](../../operations/optimizing-performance/sampling-query-profiler.md)
- システムテーブル [trace_log](/operations/system-tables/trace_log)
## allow_materialized_view_with_bad_select {#allow_materialized_view_with_bad_select} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "存在しないカラムやテーブルを参照する MV の作成を許可しない。"}]}, {"id": "row-2","items": [{"label": "24.9"},{"label": "1"},{"label": "CREATE MATERIALIZED VIEW における厳格な検証をサポート（ただし、まだ有効化はしません）。"}]}]}/>

存在しないテーブルやカラムを参照する SELECT クエリで CREATE MATERIALIZED VIEW を許可します。文法的には有効でなければなりません。リフレッシュ可能な MV には適用されません。SELECT クエリから MV スキーマが推測される必要がある場合（つまり、CREATE にカラムリストがなく、TO テーブルがない場合）には適用されません。MV のソーステーブルが作成される前に MV を作成するために使用できます。
## allow_named_collection_override_by_default {#allow_named_collection_override_by_default} 

<SettingsInfoBlock type="Bool" default_value="1" />

デフォルトで命名コレクションのフィールドのオーバーライドを許可します。
## allow_non_metadata_alters {#allow_non_metadata_alters} 

<SettingsInfoBlock type="Bool" default_value="1" />

テーブルメタデータにのみ影響を与えるのではなく、ディスク上のデータにも影響を与える ALTER を実行することを許可します。
## allow_nonconst_timezone_arguments {#allow_nonconst_timezone_arguments} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "0"},{"label": "toTimeZone(), fromUnixTimestamp*(), snowflakeToDateTime*() などの特定の時間関連関数に非定数のタイムゾーン引数を許可します。"}]}]}/>

toTimeZone(), fromUnixTimestamp*(), snowflakeToDateTime*() などの特定の時間関連関数に非定数のタイムゾーン引数を許可します。
## allow_nondeterministic_mutations {#allow_nondeterministic_mutations} 

<SettingsInfoBlock type="Bool" default_value="0" />

ユーザーレベルの設定で、レプリケートされたテーブルで `dictGet` のような非決定的関数を使用した変更を可能にします。

たとえば、辞書などはノード間で同期されていない可能性があるため、レプリケートされたテーブルでは、これから値を取得する変更はデフォルトで禁止されています。この設定を有効にすると、この動作を許可しますが、使用されるデータがすべてのノードで同期されていることを確認するのはユーザーの責任です。

**例**

```xml
<profiles>
    <default>
        <allow_nondeterministic_mutations>1</allow_nondeterministic_mutations>

        <!-- ... -->
    </default>

    <!-- ... -->

</profiles>

## allow_nondeterministic_optimize_skip_unused_shards {#allow_nondeterministic_optimize_skip_unused_shards} 

<SettingsInfoBlock type="Bool" default_value="0" />

シャーディングキー内の非決定的（`rand` や `dictGet` のような、後者は更新に関してのいくつかの注意が必要です）関数を許可します。

可能な値：

- 0 — 禁止。
- 1 — 許可。
## allow_not_comparable_types_in_comparison_functions {#allow_not_comparable_types_in_comparison_functions} 

<SettingsInfoBlock type="Bool" default_value="0" />

特に比較関数 `equal/less/greater/etc.` 内で比較できない型（JSON/Object/AggregateFunction など）を使用できるかどうかを許可または制限します。
## allow_not_comparable_types_in_order_by {#allow_not_comparable_types_in_order_by} 

<SettingsInfoBlock type="Bool" default_value="0" />

ORDER BY キー内で比較できない型を（JSON/Object/AggregateFunction など）使用できるかどうかを許可または制限します。
## allow_prefetched_read_pool_for_local_filesystem {#allow_prefetched_read_pool_for_local_filesystem} 

<SettingsInfoBlock type="Bool" default_value="0" />

すべてのパーツがローカルファイルシステムにある場合、予め取得したスレッドプールを優先します。
## allow_prefetched_read_pool_for_remote_filesystem {#allow_prefetched_read_pool_for_remote_filesystem} 

<SettingsInfoBlock type="Bool" default_value="1" />

すべてのパーツがリモートファイルシステムにある場合、予め取得したスレッドプールを優先します。
## allow_push_predicate_ast_for_distributed_subqueries {#allow_push_predicate_ast_for_distributed_subqueries} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "新しい設定です。"}]}]}/>

アナライザーが有効な分散サブクエリのASTレベルでのプッシュ条件を許可します。
## allow_push_predicate_when_subquery_contains_with {#allow_push_predicate_when_subquery_contains_with} 

<SettingsInfoBlock type="Bool" default_value="1" />

サブクエリに WITH 句が含まれている場合のプッシュ条件を許可します。
## allow_reorder_prewhere_conditions {#allow_reorder_prewhere_conditions} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1"},{"label": "新しい設定です。"}]}]}/>

WHERE から PREWHERE に条件を移動する際に、フィルタリングを最適化するためにそれらを並べ替えることを許可します。
## allow_settings_after_format_in_insert {#allow_settings_after_format_in_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.4"},{"label": "0"},{"label": "INSERT クエリの FORMAT 後に SETTINGS を許可しない。なぜなら ClickHouse は SETTINGS をいくつかの値として解釈し、誤解を招く恐れがあるからです。"}]}]}/>

INSERT クエリの FORMAT 後に `SETTINGS` が許可されるかどうかを制御します。これは非常に推奨されません。なぜなら、`SETTINGS` の一部が値として解釈される可能性があるからです。

例：

```sql
INSERT INTO FUNCTION null('foo String') SETTINGS max_threads=1 VALUES ('bar');

ただし、次のクエリは `allow_settings_after_format_in_insert` が必要です：

```sql
SET allow_settings_after_format_in_insert=1;
INSERT INTO FUNCTION null('foo String') VALUES ('bar') SETTINGS max_threads=1;

可能な値：

- 0 — 禁止。
- 1 — 許可。

:::note
この設定は、古い構文に依存するユースケースの場合のみ、後方互換性のために使用してください。
:::
## allow_simdjson {#allow_simdjson} 

<SettingsInfoBlock type="Bool" default_value="1" />

AVX2 命令が利用可能な場合、'JSON*' 関数で simdjson ライブラリの使用を許可します。無効にすると rapidjson が使用されます。
## allow_statistics_optimize {#allow_statistics_optimize} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "設定名が変更されました。旧名は `allow_statistic_optimize` です。"}]}]}/>

クエリを最適化するために統計を使用することを許可します。
## allow_suspicious_codecs {#allow_suspicious_codecs} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "20.5"},{"label": "0"},{"label": "意味のない圧縮コーデックの指定を許可しない。"}]}]}/>

true に設定されている場合、意味のない圧縮コーデックを指定することを許可します。
## allow_suspicious_fixed_string_types {#allow_suspicious_fixed_string_types} 

<SettingsInfoBlock type="Bool" default_value="0" />

CREATE TABLE ステートメントで、n > 256 のタイプ FixedString(n) のカラムを作成することを許可します。長さが 256 以上の FixedString は疑わしく、誤用の兆候である可能性が高いです。
## allow_suspicious_indices {#allow_suspicious_indices} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "0"},{"label": "true の場合、同一の式でインデックスを定義することを拒否します。"}]}]}/>

同一の式を持つプライマリ/セカンダリインデックスおよびソートキーを拒否します。

## allow_suspicious_low_cardinality_types {#allow_suspicious_low_cardinality_types} 

<SettingsInfoBlock type="Bool" default_value="0" />

8バイト以下の固定サイズのデータ型とともに [LowCardinality](../../sql-reference/data-types/lowcardinality.md) の使用を許可または制限します：数値データ型および `FixedString(8_bytes_or_less)`。

小さい固定値に対して `LowCardinality` を使用するのは、通常は非効率的です。なぜなら ClickHouse は各行に対して数値インデックスを格納するためです。その結果：

- ディスクスペースの使用量が増加する可能性があります。
- 辞書のサイズに応じて RAM の消費量が増える場合があります。
- いくつかの関数は、追加のコーディング/エンコーディング操作のために動作が遅くなる可能性があります。

[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) エンジンのテーブルにおけるマージ時間は、上記のすべての理由により増加する可能性があります。

可能な値：

- 1 — `LowCardinality` の使用が制限されません。
- 0 — `LowCardinality` の使用が制限されます。

## allow_suspicious_primary_key {#allow_suspicious_primary_key} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "MergeTree 用の疑わしい PRIMARY KEY/ORDER BY を禁止します (例：SimpleAggregateFunction)"}]}]}/>

MergeTree 用の疑わしい `PRIMARY KEY`/`ORDER BY` を許可します（例：SimpleAggregateFunction）。

## allow_suspicious_ttl_expressions {#allow_suspicious_ttl_expressions} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.12"},{"label": "0"},{"label": "これは新しい設定であり、以前のバージョンでは動作が許可されているのと同じでした。"}]}]}/>

テーブルのカラムに依存しないTTL式を拒否します。これはほとんどの場合、ユーザーエラーを示します。

## allow_suspicious_types_in_group_by {#allow_suspicious_types_in_group_by} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "デフォルトで GROUP BY において Variant/Dynamic タイプを許可しない"}]}]}/>

GROUP BY キーで [Variant](../../sql-reference/data-types/variant.md) と [Dynamic](../../sql-reference/data-types/dynamic.md) タイプの使用を許可または制限します。

## allow_suspicious_types_in_order_by {#allow_suspicious_types_in_order_by} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "デフォルトで ORDER BY において Variant/Dynamic タイプを許可しない"}]}]}/>

ORDER BY キーで [Variant](../../sql-reference/data-types/variant.md) と [Dynamic](../../sql-reference/data-types/dynamic.md) タイプの使用を許可または制限します。

## allow_suspicious_variant_types {#allow_suspicious_variant_types} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "0"},{"label": "デフォルトで疑わしいバリアントを持つ Variant タイプの作成を許可しない"}]}]}/>

CREATE TABLE 文で類似したバリアントタイプを持つ Variant タイプを指定することを許可します（例えば、異なる数値または日付タイプを持つもの）。この設定を有効にすると、類似したタイプの値を扱う際にいくつかの曖昧さが生じる可能性があります。

## allow_unrestricted_reads_from_keeper {#allow_unrestricted_reads_from_keeper} 

<SettingsInfoBlock type="Bool" default_value="0" />

システムの zookeeper テーブルからの制限のない（パスに条件なし）読み取りを許可しますが、zookeeper にとっては安全ではありません。

## alter_move_to_space_execute_async {#alter_move_to_space_execute_async} 

<SettingsInfoBlock type="Bool" default_value="0" />

ALTER TABLE MOVE ... TO [DISK|VOLUME] を非同期に実行します。

## alter_partition_verbose_result {#alter_partition_verbose_result} 

<SettingsInfoBlock type="Bool" default_value="0" />

パーティションおよびパーツとの操作が正常に適用された情報を表示するかどうかを有効または無効にします。
これは [ATTACH PARTITION|PART](/sql-reference/statements/alter/partition#attach-partitionpart) と [FREEZE PARTITION](/sql-reference/statements/alter/partition#freeze-partition) に適用されます。

可能な値：

- 0 — 詳細を無効にします。
- 1 — 詳細を有効にします。

**例**

```sql
CREATE TABLE test(a Int64, d Date, s String) ENGINE = MergeTree PARTITION BY toYYYYMDECLARE(d) ORDER BY a;
INSERT INTO test VALUES(1, '2021-01-01', '');
INSERT INTO test VALUES(1, '2021-01-01', '');
ALTER TABLE test DETACH PARTITION ID '202101';

ALTER TABLE test ATTACH PARTITION ID '202101' SETTINGS alter_partition_verbose_result = 1;

┌─command_type─────┬─partition_id─┬─part_name────┬─old_part_name─┐
│ ATTACH PARTITION │ 202101       │ 202101_7_7_0 │ 202101_5_5_0  │
│ ATTACH PARTITION │ 202101       │ 202101_8_8_0 │ 202101_6_6_0  │
└──────────────────┴──────────────┴──────────────┴───────────────┘

ALTER TABLE test FREEZE SETTINGS alter_partition_verbose_result = 1;

┌─command_type─┬─partition_id─┬─part_name────┬─backup_name─┬─backup_path───────────────────┬─part_backup_path────────────────────────────────────────────┐
│ FREEZE ALL   │ 202101       │ 202101_7_7_0 │ 8           │ /var/lib/clickhouse/shadow/8/ │ /var/lib/clickhouse/shadow/8/data/default/test/202101_7_7_0 │
│ FREEZE ALL   │ 202101       │ 202101_8_8_0 │ 8           │ /var/lib/clickhouse/shadow/8/ │ /var/lib/clickhouse/shadow/8/data/default/test/202101_8_8_0 │
└──────────────┴──────────────┴──────────────┴─────────────┴───────────────────────────────┴─────────────────────────────────────────────────────────────┘

## alter_sync {#alter_sync} 

<SettingsInfoBlock type="UInt64" default_value="1" />

レプリカによって実行されるアクションを待機するように設定し、[ALTER](../../sql-reference/statements/alter/index.md)、[OPTIMIZE](../../sql-reference/statements/optimize.md)、または [TRUNCATE](../../sql-reference/statements/truncate.md) クエリです。

可能な値：

- 0 — 待機しない。
- 1 — 自分の実行を待つ。
- 2 — みんなを待つ。

クラウドのデフォルト値：`0`。

:::note
`alter_sync` は `Replicated` テーブルにのみ適用され、`Replicated` でないテーブルの ALTER には影響しません。
:::

## alter_update_mode {#alter_update_mode} 

<SettingsInfoBlock type="AlterUpdateMode" default_value="heavy" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "heavy"},{"label": "新しい設定"}]}]}/>

`UPDATE` コマンドを含む `ALTER` クエリのモード。

可能な値：
- `heavy` - 通常の変更を実行します。
- `lightweight` - 可能な場合は軽量更新を実行し、それ以外は通常の変更を実行します。
- `lightweight_force` - 可能な場合は軽量更新を実行し、それ以外はエラーをスローします。

## analyze_index_with_space_filling_curves {#analyze_index_with_space_filling_curves} 

<SettingsInfoBlock type="Bool" default_value="1" />

テーブルのインデックスにスペースフィリング曲線（例： `ORDER BY mortonEncode(x, y)` または `ORDER BY hilbertEncode(x, y)`）があり、クエリがその引数に条件を持つ場合（例： `x >= 10 AND x <= 20 AND y >= 20 AND y <= 30`）、インデックス分析にスペースフィリング曲線を使用します。

## analyzer_compatibility_join_using_top_level_identifier {#analyzer_compatibility_join_using_top_level_identifier} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "JOIN USING からプロジェクションに識別子を解決することを強制します"}]}]}/>

プロジェクションから JOIN USING の識別子を解決することを強制します（例えば、`SELECT a + 1 AS b FROM t1 JOIN t2 USING (b)` の場合、`t1.b = t2.b` ではなく `t1.a + 1 = t2.b` で結合が行われます）。

## any_join_distinct_right_table_keys {#any_join_distinct_right_table_keys} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "19.14"},{"label": "0"},{"label": "不整合を避けるためにデフォルトで ANY RIGHT および ANY FULL JOIN を無効にします"}]}]}/>

`ANY INNER|LEFT JOIN` 操作における従来の ClickHouse サーバーの動作を有効にします。

:::note
レガシーの `JOIN` 動作に依存するユースケースがある場合にのみ、この設定を使用してください。
:::

レガシー動作が有効な場合：

- `t1 ANY LEFT JOIN t2` と `t2 ANY RIGHT JOIN t1` の結果は等しくありません。なぜなら ClickHouse は左から右へのテーブルキーのマッピングが多対一のロジックを使用するからです。
- `ANY INNER JOIN` 操作の結果は、`SEMI LEFT JOIN` 操作と同様に左テーブルからのすべての行を含みます。

レガシー動作が無効な場合：

- `t1 ANY LEFT JOIN t2` と `t2 ANY RIGHT JOIN t1` の結果は等しくなります。なぜなら ClickHouse は `ANY RIGHT JOIN` 操作において一対多のキーのマッピングを提供するロジックを使用するからです。
- `ANY INNER JOIN` 操作の結果は、左テーブルと右テーブルの各キーごとに1行を含みます。

可能な値：

- 0 — レガシー動作が無効です。
- 1 — レガシー動作が有効です。

参考：

- [JOIN の厳密さ](/sql-reference/statements/select/join#settings)

## apply_deleted_mask {#apply_deleted_mask} 

<SettingsInfoBlock type="Bool" default_value="1" />

軽量 DELETE で削除された行のフィルタリングを有効にします。無効にすると、クエリがそれらの行を読み取ることができるようになります。これはデバッグや「復元」シナリオに有用です。

## apply_mutations_on_fly {#apply_mutations_on_fly} 

<SettingsInfoBlock type="Bool" default_value="0" />

true の場合、データ部分に現物化されていない変更（UPDATE と DELETE）が SELECT 時に適用されます。

## apply_patch_parts {#apply_patch_parts} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "新しい設定"}]}]}/>

true の場合、パッチパーツ（軽量更新を表す）が SELECT 時に適用されます。

## apply_settings_from_server {#apply_settings_from_server} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "クライアント側のコード（例：INSERT 入力解析とクエリ出力フォーマット）は、サーバーと同じ設定を使用します。サーバー構成からの設定を含めます。"}]}]}/>

クライアントがサーバーから設定を受け入れるべきかどうか。

これは、クライアント側での操作にのみ影響し、特に INSERT 入力データの解析やクエリ結果のフォーマットに影響します。クエリの実行の大部分はサーバーで行われ、この設定には影響しません。

通常、この設定はユーザープロファイル（users.xml または `ALTER USER` のようなクエリ）で設定されるべきであり、クライアント経由（クライアントコマンドライン引数、`SET` クエリ、または `SELECT` クエリの `SETTINGS` セクション）で設定されるべきではありません。クライアント経由では false に変更できますが、true に変更することはできません（ユーザープロファイルに `apply_settings_from_server = false` が設定されている場合、サーバーは設定を送信しません）。

最初は（24.12）サーバー設定（`send_settings_to_client`）がありましたが、その後使いやすさのためにこのクライアント設定に置き換えられました。

## asterisk_include_alias_columns {#asterisk_include_alias_columns} 

<SettingsInfoBlock type="Bool" default_value="0" />

ワイルドカードクエリ（`SELECT *`）のために [ALIAS](../../sql-reference/statements/create/table.md/#alias) カラムを含めます。

可能な値：

- 0 - 無効
- 1 - 有効

## asterisk_include_materialized_columns {#asterisk_include_materialized_columns} 

<SettingsInfoBlock type="Bool" default_value="0" />

ワイルドカードクエリ（`SELECT *`）のために [MATERIALIZED](/sql-reference/statements/create/view#materialized-view) カラムを含めます。

可能な値：

- 0 - 無効
- 1 - 有効

## async_insert {#async_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

true の場合、INSERT クエリのデータがキューに保存され、後でバックグラウンドでテーブルにフラッシュされます。wait_for_async_insert が false の場合、INSERT クエリはほぼ即座に処理されます。そうでない場合、クライアントはデータがテーブルにフラッシュされるまで待機します。

## async_insert_busy_timeout_decrease_rate {#async_insert_busy_timeout_decrease_rate} 

<SettingsInfoBlock type="Double" default_value="0.2" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "0.2"},{"label": "適応型非同期挿入タイムアウトが減少する指数成長率"}]}]}/>

適応型非同期挿入タイムアウトが減少する指数成長率。

## async_insert_busy_timeout_increase_rate {#async_insert_busy_timeout_increase_rate} 

<SettingsInfoBlock type="Double" default_value="0.2" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "0.2"},{"label": "適応型非同期挿入タイムアウトが増加する指数成長率"}]}]}/>

適応型非同期挿入タイムアウトが増加する指数成長率。

## async_insert_busy_timeout_max_ms {#async_insert_busy_timeout_max_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="200" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "200"},{"label": "非同期挿入タイムアウトの最小値（ミリ秒単位）。async_insert_busy_timeout_ms は async_insert_busy_timeout_max_ms にエイリアスされる"}]}]}/>

クエリごとに集めたデータをダンプする前に待機する最大時間。

## async_insert_busy_timeout_min_ms {#async_insert_busy_timeout_min_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="50" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "50"},{"label": "適応アルゴリズムによって後に増加される可能性のある非同期挿入タイムアウトの初期値（ミリ秒単位）"}]}]}/>

auto-adjusting が async_insert_use_adaptive_busy_timeout で有効になっている場合、クエリごとに集めたデータをダンプする前に待機する最小時間。適応アルゴリズムの初期値としても機能します。

## async_insert_deduplicate {#async_insert_deduplicate} 

<SettingsInfoBlock type="Bool" default_value="0" />

レプリケートされたテーブルの非同期 INSERT クエリの場合、挿入ブロックの重複排除を行うかどうかを指定します。

## async_insert_max_data_size {#async_insert_max_data_size} 

<SettingsInfoBlock type="UInt64" default_value="10485760" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "10485760"},{"label": "以前の値は小さすぎるようでした。"}]}]}/>

挿入される前にクエリごとに収集された未解析のデータの最大サイズ（バイト単位）。

## async_insert_max_query_number {#async_insert_max_query_number} 

<SettingsInfoBlock type="UInt64" default_value="450" />

挿入される前の最大INSERTクエリ数。

## async_insert_poll_timeout_ms {#async_insert_poll_timeout_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="10" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "10"},{"label": "非同期挿入キューからデータをポーリングするタイムアウト（ミリ秒単位）"}]}]}/>

非同期挿入キューからデータをポーリングするタイムアウト。

## async_insert_use_adaptive_busy_timeout {#async_insert_use_adaptive_busy_timeout} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "適応型非同期挿入タイムアウトを使用する"}]}]}/>

true に設定されている場合、非同期挿入に適応型バジータイムアウトを使用します。

## async_query_sending_for_remote {#async_query_sending_for_remote} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.3"},{"label": "1"},{"label": "シャード間で非同期に接続を作成し、クエリを送信します"}]}]}/>

リモートクエリの実行中に非同期接続の作成とクエリの送信を有効にします。

デフォルトで有効です。

## async_socket_for_remote {#async_socket_for_remote} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.5"},{"label": "1"},{"label": "すべての問題を修正し、リモートクエリのソケットからの非同期リードを再びデフォルトで有効にします"}]}, {"id": "row-2","items": [{"label": "21.3"},{"label": "0"},{"label": "いくつかの問題のため、リモートクエリからのソケットからの非同期リードを無効にします"}]}]}/>

リモートクエリの実行中にソケットからの非同期リードを有効にします。

デフォルトで有効です。

## azure_allow_parallel_part_upload {#azure_allow_parallel_part_upload} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "true"},{"label": "Azure マルチパートアップロードのために複数のスレッドを使用します。"}]}]}/>

Azure のマルチパートアップロードのために複数のスレッドを使用します。

## azure_check_objects_after_upload {#azure_check_objects_after_upload} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "アップロードが成功したことを確認するために、Azure Blob ストレージ内の各アップロードオブジェクトをチェックします。"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "0"},{"label": "アップロードが成功したことを確認するために、Azure Blob ストレージ内の各アップロードオブジェクトをチェックします。"}]}]}/>

アップロードが成功したことを確認するために、Azure Blob ストレージ内の各アップロードオブジェクトをチェックします。

## azure_create_new_file_on_insert {#azure_create_new_file_on_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

Azure エンジンテーブルで各挿入時に新しいファイルを作成するかどうかを有効または無効にします。

## azure_ignore_file_doesnt_exist {#azure_ignore_file_doesnt_exist} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "AzureBlobStorage テーブルエンジンでファイルが存在しない場合に 0 行を返すことを許可します。例外をスローするのではなく。"}]}]}/>

特定のキーを読み取る際にファイルが存在しない場合は無視します。

可能な値：
- 1 — `SELECT` は空の結果を返します。
- 0 — `SELECT` は例外をスローします。

## azure_list_object_keys_size {#azure_list_object_keys_size} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

ListObject リクエストでバッチで返される可能性のある最大ファイル数。

## azure_max_blocks_in_multipart_upload {#azure_max_blocks_in_multipart_upload} 

<SettingsInfoBlock type="UInt64" default_value="50000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "50000"},{"label": "Azure でのマルチパートアップロードの最大ブロック数。"}]}]}/>

Azure でのマルチパートアップロードの最大ブロック数。

## azure_max_inflight_parts_for_one_file {#azure_max_inflight_parts_for_one_file} 

<SettingsInfoBlock type="UInt64" default_value="20" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "20"},{"label": "マルチパートアップロードリクエストで同時に読み込まれるパーツの最大数。0 は無制限。"}]}]}/>

マルチパートアップロードリクエストで同時に読み込まれるパーツの最大数。0 は無制限です。

## azure_max_single_part_copy_size {#azure_max_single_part_copy_size} 

<SettingsInfoBlock type="UInt64" default_value="268435456" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "268435456"},{"label": "Azure Blob ストレージへの単一パートコピーを使用してコピーするオブジェクトの最大サイズ。"}]}]}/>

Azure Blob ストレージへの単一パートコピーを使用してコピーするオブジェクトの最大サイズ。

## azure_max_single_part_upload_size {#azure_max_single_part_upload_size} 

<SettingsInfoBlock type="UInt64" default_value="104857600" />

単一パートアップロードを使用して Azure Blob ストレージにアップロードするオブジェクトの最大サイズ。

## azure_max_single_read_retries {#azure_max_single_read_retries} 

<SettingsInfoBlock type="UInt64" default_value="4" />

単一の Azure Blob ストレージ読み取り中の最大リトライ回数。

## azure_max_unexpected_write_error_retries {#azure_max_unexpected_write_error_retries} 

<SettingsInfoBlock type="UInt64" default_value="4" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "4"},{"label": "Azure Blob ストレージ書き込み中の予期しないエラーが発生した場合の最大リトライ数。"}]}]}/>

Azure Blob ストレージ書き込み中の予期しないエラーが発生した場合の最大リトライ数。

## azure_max_upload_part_size {#azure_max_upload_part_size} 

<SettingsInfoBlock type="UInt64" default_value="5368709120" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "5368709120"},{"label": "Azure Blob ストレージへのマルチパートアップロード中のパートの最大サイズ。"}]}]}/>

Azure Blob ストレージへのマルチパートアップロード中のパートの最大サイズ。

## azure_min_upload_part_size {#azure_min_upload_part_size} 

<SettingsInfoBlock type="UInt64" default_value="16777216" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "16777216"},{"label": "Azure Blob ストレージへのマルチパートアップロード中のパートの最小サイズ。"}]}]}/>

Azure Blob ストレージへのマルチパートアップロード中のパートの最小サイズ。

## azure_sdk_max_retries {#azure_sdk_max_retries} 

<SettingsInfoBlock type="UInt64" default_value="10" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "10"},{"label": "Azure SDK における最大リトライ回数。"}]}]}/>

Azure SDK における最大リトライ回数。

## azure_sdk_retry_initial_backoff_ms {#azure_sdk_retry_initial_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="10" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "10"},{"label": "Azure SDK におけるリトライ間の最小バックオフ。"}]}]}/>

Azure SDK におけるリトライ間の最小バックオフ。

## azure_sdk_retry_max_backoff_ms {#azure_sdk_retry_max_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "1000"},{"label": "Azure SDK におけるリトライ間の最大バックオフ。"}]}]}/>

Azure SDK におけるリトライ間の最大バックオフ。

## azure_skip_empty_files {#azure_skip_empty_files} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "Azure テーブルエンジンで空のファイルをスキップすることを許可します。"}]}]}/>

S3 エンジンで空のファイルをスキップすることを有効または無効にします。

可能な値：
- 0 — 空のファイルがリクエストされた形式と互換性がない場合、 `SELECT` が例外をスローします。
- 1 — 空のファイルに対して `SELECT` が空の結果を返します。

## azure_strict_upload_part_size {#azure_strict_upload_part_size} 

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "Azure Blob ストレージへのマルチパートアップロード中のパートの正確なサイズ。"}]}]}/>

Azure Blob ストレージへのマルチパートアップロード中のパートの正確なサイズ。

## azure_throw_on_zero_files_match {#azure_throw_on_zero_files_match} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "AzureBlobStorage エンジンにおいて ListObjects リクエストがファイルに一致しない場合、空のクエリ結果の代わりにエラーをスローすることを許可します。"}]}]}/>

glob 拡張ルールに従って一致するファイルがゼロの場合、エラーをスローします。

可能な値：
- 1 — `SELECT` は例外をスローします。
- 0 — `SELECT` は空の結果を返します。

## azure_truncate_on_insert {#azure_truncate_on_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

Azure エンジンテーブルでの挿入前にトランケートを有効または無効にします。

## azure_upload_part_size_multiply_factor {#azure_upload_part_size_multiply_factor} 

<SettingsInfoBlock type="UInt64" default_value="2" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "2"},{"label": "単一の書き込みから Azure Blob ストレージにアップロードされた部分の数が azure_multiply_parts_count_threshold に達するたびに azure_min_upload_part_size にこの因子を掛けます。"}]}]}/>

単一の書き込みから Azure Blob ストレージにアップロードされた部分の数が azure_multiply_parts_count_threshold に達するたびに azure_min_upload_part_size にこの因子を掛けます。

## azure_upload_part_size_multiply_parts_count_threshold {#azure_upload_part_size_multiply_parts_count_threshold} 

<SettingsInfoBlock type="UInt64" default_value="500" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "500"},{"label": "この数のパーツが Azure Blob ストレージにアップロードされるたびに、azure_min_upload_part_size が azure_upload_part_size_multiply_factor によって掛け算されます。"}]}]}/>

この数のパーツが Azure Blob ストレージにアップロードされるたびに、azure_min_upload_part_size が azure_upload_part_size_multiply_factor によって掛け算されます。

## backup_restore_batch_size_for_keeper_multi {#backup_restore_batch_size_for_keeper_multi} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

バックアップまたは復元中の [Zoo]Keeper へのマルチリクエストのためのバッチの最大サイズ。

## backup_restore_batch_size_for_keeper_multiread {#backup_restore_batch_size_for_keeper_multiread} 

<SettingsInfoBlock type="UInt64" default_value="10000" />

バックアップまたは復元中の [Zoo]Keeper へのマルチリードリクエストのためのバッチの最大サイズ。

## backup_restore_failure_after_host_disconnected_for_seconds {#backup_restore_failure_after_host_disconnected_for_seconds} 

<SettingsInfoBlock type="UInt64" default_value="3600" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "3600"},{"label": "新しい設定。"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "3600"},{"label": "新しい設定。"}]}]}/>

BACKUP ON CLUSTER または RESTORE ON CLUSTER 操作中にホストがこの時間の間に ZooKeeper における一時的な 'alive' ノードを再作成しないと、全体のバックアップまたは復元は失敗したと見なされます。
この値は、ホストが障害後に ZooKeeper に再接続するための合理的な時間よりも長くする必要があります。
ゼロは無制限を意味します。

## backup_restore_finish_timeout_after_error_sec {#backup_restore_finish_timeout_after_error_sec} 

<SettingsInfoBlock type="UInt64" default_value="180" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "180"},{"label": "新しい設定。"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "180"},{"label": "新しい設定。"}]}]}/>

その他のホストが "エラー" ノードに反応して現在の BACKUP ON CLUSTER または RESTORE ON CLUSTER 操作の作業を停止するまで、発信者がどのくらい待機するか。

## backup_restore_keeper_fault_injection_probability {#backup_restore_keeper_fault_injection_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

バックアップまたは復元中の keeper リクエストの失敗確率の近似値。有効な値の範囲は [0.0f, 1.0f] です。

## backup_restore_keeper_fault_injection_seed {#backup_restore_keeper_fault_injection_seed} 

<SettingsInfoBlock type="UInt64" default_value="0" />

0 - ランダムシード、さもなくばこの設定値。

## backup_restore_keeper_max_retries {#backup_restore_keeper_max_retries} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1000"},{"label": "一時的な [Zoo]Keeper の障害で、全体のバックアップまたは復元操作が失敗しないように十分な大きさにする必要があります。"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "1000"},{"label": "一時的な [Zoo]Keeper の障害で、全体のバックアップまたは復元操作が失敗しないように十分な大きさにする必要があります。"}]}]}/>

バックアップまたは復元操作中の [Zoo]Keeper 操作の最大リトライ数。
一時的な [Zoo]Keeper] の障害の中で全体の操作が失敗しないようにするために十分な大きさにする必要があります。

## backup_restore_keeper_max_retries_while_handling_error {#backup_restore_keeper_max_retries_while_handling_error} 

<SettingsInfoBlock type="UInt64" default_value="20" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "20"},{"label": "新しい設定。"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "20"},{"label": "新しい設定。"}]}]}/>

バックアップ ON CLUSTER または RESTORE ON CLUSTER 操作のエラー処理中に、 [Zoo]Keeper 操作の最大リトライ数。

## backup_restore_keeper_max_retries_while_initializing {#backup_restore_keeper_max_retries_while_initializing} 

<SettingsInfoBlock type="UInt64" default_value="20" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "20"},{"label": "新しい設定。"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "20"},{"label": "新しい設定。"}]}]}/>

BACKUP ON CLUSTER または RESTORE ON CLUSTER 操作の初期化中の [Zoo]Keeper 操作の最大リトライ数。

## backup_restore_keeper_retry_initial_backoff_ms {#backup_restore_keeper_retry_initial_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="100" />

バックアップまたは復元中の [Zoo]Keeper 操作の初期バックオフタイムアウト。

## backup_restore_keeper_retry_max_backoff_ms {#backup_restore_keeper_retry_max_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="5000" />

バックアップまたは復元中の [Zoo]Keeper 操作の最大バックオフタイムアウト。

## backup_restore_keeper_value_max_size {#backup_restore_keeper_value_max_size} 

<SettingsInfoBlock type="UInt64" default_value="1048576" />

バックアップ中の [Zoo]Keeper ノードのデータの最大サイズ。

## backup_restore_s3_retry_attempts {#backup_restore_s3_retry_attempts} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "1000"},{"label": "Aws::Client::RetryStrategy の設定。Aws::Client は自動的にリトライします。0 はリトライしないことを意味します。バックアップ/復元のみに適用されます。"}]}]}/>

Aws::Client::RetryStrategy の設定。Aws::Client は自動的にリトライします。0 はリトライしないことを意味します。バックアップ/復元のみに適用されます。
## cache_warmer_threads {#cache_warmer_threads} 

<CloudOnlyBadge/>

<SettingsInfoBlock type="UInt64" default_value="4" />

ClickHouse Cloud のみで効果があります。 [cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch) が有効な場合、新しいデータパーツをファイルキャッシュに予測的にダウンロードするためのバックグラウンドスレッドの数。ゼロに設定すると無効になります。

## calculate_text_stack_trace {#calculate_text_stack_trace} 

<SettingsInfoBlock type="Bool" default_value="1" />

クエリ実行中に例外が発生した場合にテキストスタックトレースを計算します。これがデフォルトです。シンボルのルックアップが必要で、多数の無効なクエリが実行される場合、ファジングテストが遅くなる可能性があります。通常の場合は、このオプションを無効にしない方がよいです。

## cancel_http_readonly_queries_on_client_close {#cancel_http_readonly_queries_on_client_close} 

<SettingsInfoBlock type="Bool" default_value="0" />

クライアントが応答を待たずに接続を閉じると、HTTP の読み取り専用クエリ（例： SELECT）をキャンセルします。

クラウドのデフォルト値: `1`。

## cast_ipv4_ipv6_default_on_conversion_error {#cast_ipv4_ipv6_default_on_conversion_error} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.3"},{"label": "0"},{"label": "Make functions cast(value, 'IPv4') and cast(value, 'IPv6') behave same as toIPv4 and toIPv6 functions"}]}]}/>

CAST 演算子を IPv4 と IPv6 型にキャストする際、CAST 演算子で toIPv4 および toIPv6 関数が変換エラーで例外をスローするのではなく、デフォルト値を返します。

## cast_keep_nullable {#cast_keep_nullable} 

<SettingsInfoBlock type="Bool" default_value="0" />

[CAST](/sql-reference/functions/type-conversion-functions#cast) 演算において `Nullable` データ型を保持するかどうかを有効または無効にします。

設定が有効な場合、`CAST` 関数の引数が `Nullable` の場合、結果も `Nullable` 型に変換されます。設定が無効な場合、結果は常に正確に指定された宛先型になります。

可能な値:

- 0 — `CAST` の結果は、正確に指定された宛先型になります。
- 1 — 引数の型が `Nullable` の場合、`CAST` の結果は `Nullable(DestinationDataType)` に変換されます。

**例**

次のクエリは、宛先データ型が正確に得られます：

```sql
SET cast_keep_nullable = 0;
SELECT CAST(toNullable(toInt32(0)) AS Int32) as x, toTypeName(x);

結果：

```text
┌─x─┬─toTypeName(CAST(toNullable(toInt32(0)), 'Int32'))─┐
│ 0 │ Int32                                             │
└───┴───────────────────────────────────────────────────┘

次のクエリは、宛先データ型に `Nullable` 修飾が加わります：

```sql
SET cast_keep_nullable = 1;
SELECT CAST(toNullable(toInt32(0)) AS Int32) as x, toTypeName(x);

結果：

```text
┌─x─┬─toTypeName(CAST(toNullable(toInt32(0)), 'Int32'))─┐
│ 0 │ Nullable(Int32)                                   │
└───┴───────────────────────────────────────────────────┘

**関連情報**

- [CAST](/sql-reference/functions/type-conversion-functions#cast) 関数  

## cast_string_to_dynamic_use_inference {#cast_string_to_dynamic_use_inference} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "0"},{"label": "Add setting to allow converting String to Dynamic through parsing"}]}]}/>

文字列から動的型への変換時に型推論を使用します。

## cast_string_to_variant_use_inference {#cast_string_to_variant_use_inference} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "New setting to enable/disable types inference during CAST from String to Variant"}]}]}/>

文字列からバリアント型への変換時に型推論を使用します。

## check_query_single_value_result {#check_query_single_value_result} 

<SettingsInfoBlock type="Bool" default_value="1" />

`MergeTree` ファミリーエンジンに対する [CHECK TABLE](/sql-reference/statements/check-table) クエリ結果の詳細レベルを定義します。

可能な値:

- 0 — クエリはテーブルの個々のデータパーツごとのチェック状態を表示します。
- 1 — クエリは全体のテーブルチェック状態を表示します。

## check_referential_table_dependencies {#check_referential_table_dependencies} 

<SettingsInfoBlock type="Bool" default_value="0" />

DDL クエリ（DROP TABLE や RENAME など）が参照依存関係を壊さないことを確認します。

## check_table_dependencies {#check_table_dependencies} 

<SettingsInfoBlock type="Bool" default_value="1" />

DDL クエリ（DROP TABLE や RENAME など）が依存関係を壊さないことを確認します。

## checksum_on_read {#checksum_on_read} 

<SettingsInfoBlock type="Bool" default_value="1" />

読み取り時にチェックサムを検証します。デフォルトで有効化されており、本番環境では常に有効にする必要があります。この設定を無効にすることによる利点は期待できません。この設定は、MergeTree ファミリーのテーブルにのみ適用されます。他のテーブルエンジンやネットワーク経由でデータを受信する際、チェックサムは常に検証されます。

## cloud_mode {#cloud_mode} 

<SettingsInfoBlock type="Bool" default_value="0" />

クラウドモード。 

## cloud_mode_database_engine {#cloud_mode_database_engine} 

<SettingsInfoBlock type="UInt64" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

クラウドで許可されるデータベースエンジン。 1 - DDL を Replicated データベースを使用するように書き換えます。 2 - DDL を Shared データベースを使用するように書き換えます。

## cloud_mode_engine {#cloud_mode_engine} 

<SettingsInfoBlock type="UInt64" default_value="1" />

クラウドで許可されるエンジンファミリー。

- 0 - すべてを許可する
- 1 - DDL を *ReplicatedMergeTree を使用するように書き換える
- 2 - DDL を SharedMergeTree を使用するように書き換える
- 3 - DDL を SharedMergeTree を使用するように書き換えますが、明示的に指定されたリモートディスクがある場合を除く

UInt64 により公開部分を最小化します。

## cluster_for_parallel_replicas {#cluster_for_parallel_replicas} 

<BetaBadge/>

現在のサーバがあるシャードのクラスタ。

## collect_hash_table_stats_during_aggregation {#collect_hash_table_stats_during_aggregation} 

<SettingsInfoBlock type="Bool" default_value="1" />

メモリの最適化のためにハッシュテーブルの統計を収集することを有効にします。

## collect_hash_table_stats_during_joins {#collect_hash_table_stats_during_joins} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "1"},{"label": "New setting."}]}]}/>

メモリの最適化のためにハッシュテーブルの統計を収集することを有効にします。

## compatibility {#compatibility} 

`compatibility` 設定により、ClickHouse は以前のバージョンのデフォルト設定を使用します。以前のバージョンは設定として提供されます。

設定がデフォルト値以外に設定された場合、それらの設定は尊重されます（変更されていない設定にのみ `compatibility` 設定が影響します）。

この設定は、`22.3`、`22.8` のように文字列として ClickHouse バージョン番号を取ります。空の値は、この設定が無効であることを意味します。

デフォルトでは無効です。

:::note
ClickHouse Cloud では、互換性設定は ClickHouse Cloud サポートによって設定される必要があります。設定してもらうには、[ケースを開いてください](https://clickhouse.cloud/support)。
:::

## compatibility_ignore_auto_increment_in_create_table {#compatibility_ignore_auto_increment_in_create_table} 

<SettingsInfoBlock type="Bool" default_value="0" />

真の場合、列宣言で AUTO_INCREMENT キーワードを無視し、そうでなければエラーを返します。MySQL からのマイグレーションを簡素化します。

## compatibility_ignore_collation_in_create_table {#compatibility_ignore_collation_in_create_table} 

<SettingsInfoBlock type="Bool" default_value="1" />

テーブル作成時の照合を無視して互換性を持たせます。

## compile_aggregate_expressions {#compile_aggregate_expressions} 

<SettingsInfoBlock type="Bool" default_value="1" />

集約関数をネイティブコードに JIT コンパイルすることを有効または無効にします。この設定を有効にすると、パフォーマンスが向上する可能性があります。

可能な値：

- 0 — 集約は JIT コンパイルなしで行われます。
- 1 — 集約は JIT コンパイルを使用して行われます。

**関連情報**

- [min_count_to_compile_aggregate_expression](#min_count_to_compile_aggregate_expression)

## compile_expressions {#compile_expressions} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "We believe that the LLVM infrastructure behind the JIT compiler is stable enough to enable this setting by default."}]}]}/>

一部のスカラー関数と演算子をネイティブコードにコンパイルします。

## compile_sort_description {#compile_sort_description} 

<SettingsInfoBlock type="Bool" default_value="1" />

ソート説明をネイティブコードにコンパイルします。

## connect_timeout {#connect_timeout} 

<SettingsInfoBlock type="Seconds" default_value="10" />

レプリカがない場合の接続タイムアウト。

## connect_timeout_with_failover_ms {#connect_timeout_with_failover_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "1000"},{"label": "Increase default connect timeout because of async connect"}]}]}/>

分散テーブルエンジンに対してリモートサーバに接続する際のタイムアウト（クラスター定義に 'shard' および 'replica' セクションを使用する場合）。失敗した場合、さまざまなレプリカに接続するための複数の試行が行われます。

## connect_timeout_with_failover_secure_ms {#connect_timeout_with_failover_secure_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "1000"},{"label": "Increase default secure connect timeout because of async connect"}]}]}/>

最初の正常なレプリカを選択する際の接続タイムアウト（安全な接続用）。

## connection_pool_max_wait_ms {#connection_pool_max_wait_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

接続プールが満杯の際に接続を待つ時間（ミリ秒単位）。

可能な値：

- 正の整数。
- 0 — 無限のタイムアウト。

## connections_with_failover_max_tries {#connections_with_failover_max_tries} 

<SettingsInfoBlock type="UInt64" default_value="3" />

分散テーブルエンジンに対する各レプリカの接続試行の最大回数。

## convert_query_to_cnf {#convert_query_to_cnf} 

<SettingsInfoBlock type="Bool" default_value="0" />

`true` に設定すると、 `SELECT` クエリは結合標準形（CNF）に変換されます。クエリを CNF に書き換えることで、実行が速くなるシナリオがあります（この [GitHub の問題](https://github.com/ClickHouse/ClickHouse/issues/11749) を参照して説明をご覧ください）。

例えば、次の `SELECT` クエリは修正されません（デフォルトの動作）：

```sql
EXPLAIN SYNTAX
SELECT *
FROM
(
    SELECT number AS x
    FROM numbers(20)
) AS a
WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))
SETTINGS convert_query_to_cnf = false;

結果は：

```response
┌─explain────────────────────────────────────────────────────────┐
│ SELECT x                                                       │
│ FROM                                                           │
│ (                                                              │
│     SELECT number AS x                                         │
│     FROM numbers(20)                                           │
│     WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15)) │
│ ) AS a                                                         │
│ WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))     │
│ SETTINGS convert_query_to_cnf = 0                              │
└────────────────────────────────────────────────────────────────┘

`convert_query_to_cnf` を `true` に設定して、何が変わるか見てみましょう：

```sql
EXPLAIN SYNTAX
SELECT *
FROM
(
    SELECT number AS x
    FROM numbers(20)
) AS a
WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))
SETTINGS convert_query_to_cnf = true;

`WHERE` 条件が CNF に書き換えられていることに注意してくださいが、結果セットは同じで、ブール論理は変更されていません：

```response
┌─explain───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SELECT x                                                                                                              │
│ FROM                                                                                                                  │
│ (                                                                                                                     │
│     SELECT number AS x                                                                                                │
│     FROM numbers(20)                                                                                                  │
│     WHERE ((x <= 15) OR (x <= 5)) AND ((x <= 15) OR (x >= 1)) AND ((x >= 10) OR (x <= 5)) AND ((x >= 10) OR (x >= 1)) │
│ ) AS a                                                                                                                │
│ WHERE ((x >= 10) OR (x >= 1)) AND ((x >= 10) OR (x <= 5)) AND ((x <= 15) OR (x >= 1)) AND ((x <= 15) OR (x <= 5))     │
│ SETTINGS convert_query_to_cnf = 1                                                                                     │
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

可能な値：true, false

## count_distinct_implementation {#count_distinct_implementation} 

<SettingsInfoBlock type="String" default_value="uniqExact" />

[COUNT(DISTINCT ...)](/sql-reference/aggregate-functions/reference/count) 構文を実行するために使用される `uniq*` 関数を指定します。

可能な値：

- [uniq](/sql-reference/aggregate-functions/reference/uniq)
- [uniqCombined](/sql-reference/aggregate-functions/reference/uniqcombined)
- [uniqCombined64](/sql-reference/aggregate-functions/reference/uniqcombined64)
- [uniqHLL12](/sql-reference/aggregate-functions/reference/uniqhll12)
- [uniqExact](/sql-reference/aggregate-functions/reference/uniqexact)

## count_distinct_optimization {#count_distinct_optimization} 

<SettingsInfoBlock type="Bool" default_value="0" />

重複のない数をサブクエリに書き換えます。

## create_if_not_exists {#create_if_not_exists} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "New setting."}]}]}/>

デフォルトで `CREATE` ステートメントに `IF NOT EXISTS` を有効にします。この設定または `IF NOT EXISTS` が指定され、提供された名前のテーブルがすでに存在する場合、例外はスローされません。

## create_index_ignore_unique {#create_index_ignore_unique} 

<SettingsInfoBlock type="Bool" default_value="0" />

作成される UNIQUE INDEX 内の UNIQUE キーワードを無視します。SQL の互換性テストのために作られました。

## create_replicated_merge_tree_fault_injection_probability {#create_replicated_merge_tree_fault_injection_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

メタデータを ZooKeeper に作成した後に、テーブル作成中の障害注入の確率です。

## create_table_empty_primary_key_by_default {#create_table_empty_primary_key_by_default} 

<SettingsInfoBlock type="Bool" default_value="0" />

ORDER BY と PRIMARY KEY が指定されていない場合に空の主キーを持つ *MergeTree テーブルを作成できるようにします。

## cross_join_min_bytes_to_compress {#cross_join_min_bytes_to_compress} 

<SettingsInfoBlock type="UInt64" default_value="1073741824" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "1073741824"},{"label": "Minimal size of block to compress in CROSS JOIN. Zero value means - disable this threshold. This block is compressed when any of the two thresholds (by rows or by bytes) are reached."}]}]}/>

CROSS JOIN で圧縮するための最小ブロックサイズ。ゼロの値はこの閾値を無効にします。このブロックは、2 つの閾値（行数またはバイト数）のいずれかに達した場合に圧縮されます。

## cross_join_min_rows_to_compress {#cross_join_min_rows_to_compress} 

<SettingsInfoBlock type="UInt64" default_value="10000000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "10000000"},{"label": "Minimal count of rows to compress block in CROSS JOIN. Zero value means - disable this threshold. This block is compressed when any of the two thresholds (by rows or by bytes) are reached."}]}]}/>

CROSS JOIN で圧縮するための最小行数。ゼロの値はこの閾値を無効にします。このブロックは、2 つの閾値（行数またはバイト数）のいずれかに達した場合に圧縮されます。

## data_type_default_nullable {#data_type_default_nullable} 

<SettingsInfoBlock type="Bool" default_value="0" />

明示的修飾子 [NULL または NOT NULL](/sql-reference/statements/create/table#null-or-not-null-modifiers) のないデータ型を [Nullable](/sql-reference/data-types/nullable) として許可します。

可能な値：

- 1 — 列定義内のデータ型がデフォルトで `Nullable` に設定されます。
- 0 — 列定義内のデータ型がデフォルトで `Nullable` ではないように設定されます。

## database_atomic_wait_for_drop_and_detach_synchronously {#database_atomic_wait_for_drop_and_detach_synchronously} 

<SettingsInfoBlock type="Bool" default_value="0" />

すべての `DROP` および `DETACH` クエリに `SYNC` 修飾子を追加します。

可能な値：

- 0 — クエリは遅延実行されます。
- 1 — クエリは遅延なしで実行されます。

## database_replicated_allow_explicit_uuid {#database_replicated_allow_explicit_uuid} 

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "Added a new setting to disallow explicitly specifying table UUID"}]}]}/>

0 - 複製されたデータベースのテーブルに UUID を明示的に指定することを許可しません。1 - 許可します。2 - 許可しますが、指定された UUID を無視してランダムな UUID を生成します。

## distributed_background_insert_split_batch_on_failure {#distributed_background_insert_split_batch_on_failure} 



<SettingsInfoBlock type="Bool" default_value="0" />

バッチ分割の有効/無効を設定します。

特定のバッチをリモートシャードに送信する際に、`Memory limit exceeded`などのエラーが発生するため、失敗することがあります。この場合、再試行しても効果がなく（テーブルの分散送信が停止します）、そのバッチからファイルを1つずつ送信することでINSERTが成功することがあります。

したがって、この設定を`1`にすると、そのようなバッチのバッチ処理が無効になります（失敗したバッチに対して`distributed_background_insert_batch`が一時的に無効化されます）。

可能な値：

- 1 — 有効。
- 0 — 無効。

:::note
この設定は、サーバー（マシン）の異常終了によって発生する可能性のある破損したバッチにも影響します（及び`fsync_after_insert`/`fsync_directories`が`Distributed`テーブルエンジンに対してない場合）。
:::

:::note
自動バッチ分割に依存しないでください。これはパフォーマンスを損なう可能性があります。
:::
## distributed_background_insert_timeout {#distributed_background_insert_timeout} 



<SettingsInfoBlock type="UInt64" default_value="0" />

分散テーブルへのINSERTクエリのタイムアウト。これは、insert_distributed_syncが有効な場合にのみ使用されます。ゼロ値はタイムアウトなしを意味します。
## distributed_cache_bypass_connection_pool {#distributed_cache_bypass_connection_pool} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。分散キャッシュ接続プールをバイパスすることを許可します。
## distributed_cache_connect_max_tries {#distributed_cache_connect_max_tries} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="20" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "20"},{"label": "Cloud のみ"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "20"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。接続が失敗した場合に分散キャッシュに接続する試行の回数。
## distributed_cache_data_packet_ack_window {#distributed_cache_data_packet_ack_window} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="5" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "5"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。単一の分散キャッシュ読み取りリクエストにおけるDataPacketシーケンスのACKを送信するためのウィンドウ。
## distributed_cache_discard_connection_if_unread_data {#distributed_cache_discard_connection_if_unread_data} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "新しい設定"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "1"},{"label": "新しい設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。一部のデータが未読の場合、接続を破棄します。
## distributed_cache_fetch_metrics_only_from_current_az {#distributed_cache_fetch_metrics_only_from_current_az} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。system.distributed_cache_metrics、system.distributed_cache_eventsから現在のアベイラビリティゾーンのみからメトリクスを取得します。
## distributed_cache_log_mode {#distributed_cache_log_mode} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="DistributedCacheLogMode" default_value="on_error" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "on_error"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。system.distributed_cache_logへの書き込みモード。
## distributed_cache_max_unacked_inflight_packets {#distributed_cache_max_unacked_inflight_packets} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="10" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "10"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。単一の分散キャッシュ読み取りリクエストにおける未確認のフライトパケットの最大数。
## distributed_cache_min_bytes_for_seek {#distributed_cache_min_bytes_for_seek} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "新しいプライベート設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。分散キャッシュでシークを行うための最小バイト数。
## distributed_cache_pool_behaviour_on_limit {#distributed_cache_pool_behaviour_on_limit} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="DistributedCachePoolBehaviourOnLimit" default_value="wait" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "wait"},{"label": "Cloud のみ"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "allocate_bypassing_pool"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。プールの制限に達した場合の分散キャッシュ接続の動作を特定します。
## distributed_cache_read_alignment {#distributed_cache_read_alignment} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。テスト目的の設定です。変更しないでください。
## distributed_cache_read_only_from_current_az {#distributed_cache_read_only_from_current_az} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "新しい設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。現在のアベイラビリティゾーンからのみ読み取ることを許可します。無効にすると、すべてのアベイラビリティゾーンのすべてのキャッシュサーバーから読み取ります。
## distributed_cache_read_request_max_tries {#distributed_cache_read_request_max_tries} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="20" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "20"},{"label": "新しい設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。分散キャッシュ要求が失敗した場合の試行回数。
## distributed_cache_receive_response_wait_milliseconds {#distributed_cache_receive_response_wait_milliseconds} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="60000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "60000"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。分散キャッシュから要求のデータを受信するために待機する時間（ミリ秒）。
## distributed_cache_receive_timeout_milliseconds {#distributed_cache_receive_timeout_milliseconds} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="10000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "10000"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。分散キャッシュからの応答を受信するための待機時間（ミリ秒）。
## distributed_cache_throw_on_error {#distributed_cache_throw_on_error} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。分散キャッシュとの通信中に発生した例外または分散キャッシュから受信した例外を再スローします。それ以外は、エラー時に分散キャッシュをスキップします。
## distributed_cache_wait_connection_from_pool_milliseconds {#distributed_cache_wait_connection_from_pool_milliseconds} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="100" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "100"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud でのみ効果があります。分散_cache_pool_behaviour_on_limit が wait の場合に接続プールから接続を受信するまでの待機時間（ミリ秒）。
## distributed_connections_pool_size {#distributed_connections_pool_size} 



<SettingsInfoBlock type="UInt64" default_value="1024" />

分散テーブルへのすべてのクエリのためにリモートサーバーとの同時接続の最大数。クラスター内のサーバーの数以下には設定しないことを推奨します。
## distributed_ddl_entry_format_version {#distributed_ddl_entry_format_version} 



<SettingsInfoBlock type="UInt64" default_value="5" />

分散DDL（ON CLUSTER）クエリの互換性バージョン。
## distributed_ddl_output_mode {#distributed_ddl_output_mode} 



<SettingsInfoBlock type="DistributedDDLOutputMode" default_value="throw" />

分散DDLクエリ結果の形式を設定します。

可能な値：

- `throw` — クエリが完了したすべてのホストに対してクエリ実行ステータスを持つ結果セットを返します。クエリが一部のホストで失敗した場合は、最初の例外を再スローします。クエリがまだ一部のホストで完了しておらず、[distributed_ddl_task_timeout](#distributed_ddl_task_timeout) が超過した場合、`TIMEOUT_EXCEEDED`例外をスローします。
- `none` — `throw`に似ていますが、分散DDLクエリは結果セットを返しません。
- `null_status_on_timeout` — 結果セットの一部の行において、該当ホストでクエリが完了していない場合に`TIMEOUT_EXCEEDED`をスローする代わりに、実行ステータスとして`NULL`を返します。
- `never_throw` — `TIMEOUT_EXCEEDED`をスローせず、クエリが一部のホストで失敗した場合に例外を再スローしません。
- `none_only_active` - `none`に似ていますが、`Replicated`データベースの非アクティブなレプリカを待ちません。注：このモードでは、クエリが一部のレプリカで実行されなかったことを特定することはできず、バックグラウンドで実行されることになります。
- `null_status_on_timeout_only_active` — `null_status_on_timeout`に似ていますが、`Replicated`データベースの非アクティブなレプリカを待ちません。
- `throw_only_active` — `throw`に似ていますが、`Replicated`データベースの非アクティブなレプリカを待ちません。

クラウドのデフォルト値：`none`。
## distributed_ddl_task_timeout {#distributed_ddl_task_timeout} 



<SettingsInfoBlock type="Int64" default_value="180" />

クラスター内のすべてのホストからのDDLクエリ応答のタイムアウトを設定します。DDLリクエストがすべてのホストで実行されていない場合、応答はタイムアウトエラーを含み、リクエストは非同期モードで実行されます。負の値は無限を意味します。

可能な値：

- 正の整数。
- 0 — 非同期モード。
- 負の整数 — 無限のタイムアウト。
## distributed_foreground_insert {#distributed_foreground_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

[Distributed](/engines/table-engines/special/distributed)テーブルへの同期データ挿入を有効または無効にします。

デフォルトでは、`Distributed`テーブルにデータを挿入する際に、ClickHouseサーバーはバックグラウンドモードでクラスターのノードにデータを送信します。`distributed_foreground_insert=1`のとき、データは同期的に処理され、すべてのシャード（`internal_replication` が真の場合は各シャードの少なくとも1つのレプリカ）にデータが保存されるまで`INSERT`操作は成功しません。

可能な値：

- 0 — データはバックグラウンドモードで挿入されます。
- 1 — データは同期モードで挿入されます。

クラウドのデフォルト値：`1`。

**関連情報**

- [Distributed Table Engine](/engines/table-engines/special/distributed)
- [Managing Distributed Tables](/sql-reference/statements/system#managing-distributed-tables)
## distributed_group_by_no_merge {#distributed_group_by_no_merge} 



<SettingsInfoBlock type="UInt64" default_value="0" />

分散クエリ処理のために異なるサーバーからの集約状態をマージしないようにします。異なるシャードに異なるキーが存在することが確実な場合に使用できます。

可能な値：

- `0` — 無効（初期ノードで最終クエリ処理が行われます）。
- `1` - 分散クエリ処理のために異なるサーバーからの集約状態をマージしない（クエリはシャードで完全に処理され、イニシエーターはデータを単にプロキシするだけです）。異なるシャードに異なるキーが存在することが確実な場合に使用できます。
- `2` - `1`と同様ですが、`ORDER BY`と`LIMIT`を適用します（これは、クエリがリモートノードで完全に処理される場合（例えば、`distributed_group_by_no_merge=1`の場合）には不可能です）。`ORDER BY`及び/または`LIMIT`を伴うクエリに使用できます。

**例**

```sql
SELECT *
FROM remote('127.0.0.{2,3}', system.one)
GROUP BY dummy
LIMIT 1
SETTINGS distributed_group_by_no_merge = 1
FORMAT PrettyCompactMonoBlock

┌─dummy─┐
│     0 │
│     0 │
└───────┘

```sql
SELECT *
FROM remote('127.0.0.{2,3}', system.one)
GROUP BY dummy
LIMIT 1
SETTINGS distributed_group_by_no_merge = 2
FORMAT PrettyCompactMonoBlock

┌─dummy─┐
│     0 │
└───────┘

## distributed_insert_skip_read_only_replicas {#distributed_insert_skip_read_only_replicas} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "true の場合、Distributed に対する INSERT は読み取り専用レプリカをスキップします"}]}]}/>

分散先のINSERTクエリで読み取り専用レプリカをスキップすることを有効にします。

可能な値：

- 0 — 通常通りINSERTを行い、読み取り専用レプリカに行く場合は失敗します。
- 1 — イニシエーターは、シャードにデータを送信する前に読み取り専用レプリカをスキップします。
## distributed_plan_default_reader_bucket_count {#distributed_plan_default_reader_bucket_count} 

<ExperimentalBadge/>



<SettingsInfoBlock type="UInt64" default_value="8" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "8"},{"label": "新しい実験的設定"}]}]}/>

分散クエリでの並列読み取りのデフォルトタスク数。タスクはレプリカ間に分配されます。
## distributed_plan_default_shuffle_join_bucket_count {#distributed_plan_default_shuffle_join_bucket_count} 

<ExperimentalBadge/>



<SettingsInfoBlock type="UInt64" default_value="8" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "8"},{"label": "新しい実験的設定"}]}]}/>

分散シャッフルハッシュジョインのデフォルトバケット数。
## distributed_plan_execute_locally {#distributed_plan_execute_locally} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "新しい実験的設定"}]}]}/>

分散クエリプランのすべてのタスクをローカルで実行します。テストやデバッグに便利です。
## distributed_plan_force_exchange_kind {#distributed_plan_force_exchange_kind} 

<ExperimentalBadge/>



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": ""},{"label": "新しい実験的設定"}]}]}/>

分散クエリのステージ間での交換演算子の種類を強制します。

可能な値：

 - '' - 交換演算子の種類を強制せず、オプティマイザーに選択させます。
 - 'Persisted' - オブジェクトストレージに一時ファイルを使用します。
 - 'Streaming' - ネットワーク経由でデータをストリームします。
## distributed_plan_optimize_exchanges {#distributed_plan_optimize_exchanges} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "新しい実験的設定"}]}]}/>

分散クエリプランから不要な交換を削除します。デバッグのために無効にしてください。
## distributed_product_mode {#distributed_product_mode} 



<SettingsInfoBlock type="DistributedProductMode" default_value="deny" />

[分散サブクエリ](../../sql-reference/operators/in.md)の動作を変更します。

ClickHouseは、この設定をクエリが分散テーブルの積を含む場合、すなわち、分散テーブルへのクエリが分散テーブルに対する非GLOBALサブクエリを含む場合に適用します。

制限：

- INおよびJOINサブクエリにのみ適用されます。
- FROMセクションが1つ以上のシャードを含む分散テーブルを使用する場合にのみ。
- サブクエリが1つ以上のシャードを含む分散テーブルに関連する場合。
- テーブル値の[remote](../../sql-reference/table-functions/remote.md)関数には使用されません。

可能な値：

- `deny` — デフォルト値。これらのタイプのサブクエリ（"Double-distributed in/JOIN subqueries is denied"という例外を返す）を使用することを禁止します。
- `local` — サブクエリ内のデータベースとテーブルを目的のサーバー（シャード）のローカルなものに置き換え、通常の`IN`/`JOIN`を残します。
- `global` — `IN`/`JOIN`クエリを`GLOBAL IN`/`GLOBAL JOIN`に置き換えます。
- `allow` — これらのタイプのサブクエリを使用することを許可します。
## distributed_push_down_limit {#distributed_push_down_limit} 



<SettingsInfoBlock type="UInt64" default_value="1" />

各シャードにおける[LIMIT](#limit)の適用を有効または無効にします。

これにより、次のことを回避できます：
- ネットワーク経由での余分な行の送信；
- イニシエーターで制限の背後にある行の処理。

21.9バージョン以降、次の条件が満たされる場合にのみ`distributed_push_down_limit`がクエリの実行を変更するため、不正確な結果は得られなくなります：
- [distributed_group_by_no_merge](#distributed_group_by_no_merge) > 0。
- クエリが`GROUP BY`/`DISTINCT`/`LIMIT BY`を含まず、`ORDER BY`/`LIMIT`を含む場合。
- クエリが`GROUP BY`/`DISTINCT`/`LIMIT BY`を含み、かつ`ORDER BY`/`LIMIT`を伴い、以下の条件を満たす場合：
    - [optimize_skip_unused_shards](#optimize_skip_unused_shards) が有効である。
    - [optimize_distributed_group_by_sharding_key](#optimize_distributed_group_by_sharding_key) が有効である。

可能な値：

- 0 — 無効。
- 1 — 有効。

参照：

- [distributed_group_by_no_merge](#distributed_group_by_no_merge)
- [optimize_skip_unused_shards](#optimize_skip_unused_shards)
- [optimize_distributed_group_by_sharding_key](#optimize_distributed_group_by_sharding_key)
## distributed_replica_error_cap {#distributed_replica_error_cap} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

- 種類：unsigned int
- デフォルト値：1000

各レプリカのエラー数はこの値に制限され、単一のレプリカがあまりにも多くのエラーを蓄積するのを防ぎます。

参照：

- [load_balancing](#load_balancing-round_robin)
- [テーブルエンジン 分散](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_half_life](#distributed_replica_error_half_life)
- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)
## distributed_replica_error_half_life {#distributed_replica_error_half_life} 



<SettingsInfoBlock type="Seconds" default_value="60" />

- 種類：秒
- デフォルト値：60秒

分散テーブルのエラーがゼロになる速さを制御します。レプリカが一定時間利用できない場合、5つのエラーが蓄積し、`distributed_replica_error_half_life`が1秒に設定されている場合、最後のエラーの3秒後にレプリカは正常と見なされます。

参照：

- [load_balancing](#load_balancing-round_robin)
- [テーブルエンジン 分散](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_cap](#distributed_replica_error_cap)
- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)
## distributed_replica_max_ignored_errors {#distributed_replica_max_ignored_errors} 



<SettingsInfoBlock type="UInt64" default_value="0" />

- 種類：unsigned int
- デフォルト値：0

レプリカの選択中に無視されるエラーの数（`load_balancing`アルゴリズムに従って）です。

参照：

- [load_balancing](#load_balancing-round_robin)
- [テーブルエンジン 分散](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_cap](#distributed_replica_error_cap)
- [distributed_replica_error_half_life](#distributed_replica_error_half_life)
## do_not_merge_across_partitions_select_final {#do_not_merge_across_partitions_select_final} 



<SettingsInfoBlock type="Bool" default_value="0" />

選択最終でパーティション内のパーツのみをマージします。
## empty_result_for_aggregation_by_constant_keys_on_empty_set {#empty_result_for_aggregation_by_constant_keys_on_empty_set} 



<SettingsInfoBlock type="Bool" default_value="1" />

空のセットでの定数キーによる集約時に空の結果を返します。
## empty_result_for_aggregation_by_empty_set {#empty_result_for_aggregation_by_empty_set} 



<SettingsInfoBlock type="Bool" default_value="0" />

空のセットでキーなしの集約時に空の結果を返します。
## enable_adaptive_memory_spill_scheduler {#enable_adaptive_memory_spill_scheduler} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "0"},{"label": "新しい設定。外部ストレージにデータを適応的にスピルすることを有効にします。"}]}]}/>

プロセッサにデータを外部ストレージに適応的にスピルさせるトリガーです。現在、グレースジョインがサポートされています。
## enable_blob_storage_log {#enable_blob_storage_log} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "blob ストレージ操作に関する情報を system.blob_storage_log テーブルに書き込む"}]}]}/>

blob ストレージ操作に関する情報を system.blob_storage_log テーブルに書き込みます。
## enable_deflate_qpl_codec {#enable_deflate_qpl_codec} 



<SettingsInfoBlock type="Bool" default_value="0" />

有効にすると、DEFLATE_QPL コーデックを使用してカラムを圧縮できます。
## enable_early_constant_folding {#enable_early_constant_folding} 



<SettingsInfoBlock type="Bool" default_value="1" />

定数の分析に基づき、関数およびサブクエリの結果を分析し、定数が存在する場合はクエリを書き直します。
## enable_extended_results_for_datetime_functions {#enable_extended_results_for_datetime_functions} 



<SettingsInfoBlock type="Bool" default_value="0" />

次のタイプの結果を返すことを有効または無効にします：
- `Date32` の拡張範囲（`Date` タイプと比較して）に対して、以下の関数 [toStartOfYear](../../sql-reference/functions/date-time-functions.md/#tostartofyear)、[toStartOfISOYear](../../sql-reference/functions/date-time-functions.md/#tostartofisoyear)、[toStartOfQuarter](../../sql-reference/functions/date-time-functions.md/#tostartofquarter)、[toStartOfMonth](../../sql-reference/functions/date-time-functions.md/#tostartofmonth)、[toLastDayOfMonth](../../sql-reference/functions/date-time-functions.md/#tolastdayofmonth)、[toStartOfWeek](../../sql-reference/functions/date-time-functions.md/#tostartofweek)、[toLastDayOfWeek](../../sql-reference/functions/date-time-functions.md/#tolastdayofweek)、[toMonday](../../sql-reference/functions/date-time-functions.md/#tomonday)。
- `DateTime64` の拡張範囲（`DateTime` タイプと比較して）に対して、以下の関数 [toStartOfDay](../../sql-reference/functions/date-time-functions.md/#tostartofday)、[toStartOfHour](../../sql-reference/functions/date-time-functions.md/#tostartofhour)、[toStartOfMinute](../../sql-reference/functions/date-time-functions.md/#tostartofminute)、[toStartOfFiveMinutes](../../sql-reference/functions/date-time-functions.md/#tostartoffiveminutes)、[toStartOfTenMinutes](../../sql-reference/functions/date-time-functions.md/#tostartoftenminutes)、[toStartOfFifteenMinutes](../../sql-reference/functions/date-time-functions.md/#tostartoffifteenminutes)、[timeSlot](../../sql-reference/functions/date-time-functions.md/#timeslot)。

可能な値：

- 0 — 関数はすべての型の引数に対して `Date` または `DateTime` を返します。
- 1 — 関数は、`Date32` または `DateTime64` 引数に対して `Date32` または `DateTime64` を返し、それ以外は `Date` または `DateTime` を返します。
## enable_filesystem_cache {#enable_filesystem_cache} 



<SettingsInfoBlock type="Bool" default_value="1" />

リモートファイルシステム用のキャッシュを使用します。この設定はディスクのキャッシュをオン/オフにするものではなく（それはディスク構成を通じて行う必要があります）、意図した場合にはいくつかのクエリに対してキャッシュをバイパスすることができます。
## enable_filesystem_cache_log {#enable_filesystem_cache_log} 



<SettingsInfoBlock type="Bool" default_value="0" />

各クエリのファイルシステムキャッシュログを記録することを許可します。
## enable_filesystem_cache_on_write_operations {#enable_filesystem_cache_on_write_operations} 



<SettingsInfoBlock type="Bool" default_value="0" />

書き込み操作でキャッシュに書き込む。実際にこの設定が機能するには、ディスク構成にも追加する必要があります。
## enable_filesystem_read_prefetches_log {#enable_filesystem_read_prefetches_log} 



<SettingsInfoBlock type="Bool" default_value="0" />

クエリ中にシステム.filesystemのprefetch_logにログを記録します。テストやデバッグのためのみ使用すべきであり、デフォルトでオンにすることは推奨されません。
## enable_global_with_statement {#enable_global_with_statement} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.2"},{"label": "1"},{"label": "デフォルトでWITHステートメントをUNIONクエリやすべてのサブクエリに伝播します"}]}]}/>

WITHステートメントをUNIONクエリおよびすべてのサブクエリに伝播します。
## enable_hdfs_pread {#enable_hdfs_pread} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "新しい設定"}]}]}/>

HDFSファイルのためのpreadを有効または無効にします。デフォルトでは、`hdfsPread`が使用されます。無効にすると、`hdfsRead`および`hdfsSeek`が使用されます。
## enable_http_compression {#enable_http_compression} 



<SettingsInfoBlock type="Bool" default_value="0" />

HTTPリクエストへの応答でのデータ圧縮を有効または無効にします。

詳細については、[HTTPインターフェース説明](../../interfaces/http.md)を参照してください。

可能な値：

- 0 — 無効。
- 1 — 有効。
## enable_job_stack_trace {#enable_job_stack_trace} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "デフォルトでジョブのスケジューリングからスタックトレースを収集することを有効にします。"}]}]}/>

ジョブの作成者のスタックトレースを出力します。
## enable_lightweight_delete {#enable_lightweight_delete} 



<SettingsInfoBlock type="Bool" default_value="1" />

MergeTreeテーブルのための軽量DELETEミューテーションを有効にします。
## enable_memory_bound_merging_of_aggregation_results {#enable_memory_bound_merging_of_aggregation_results} 



<SettingsInfoBlock type="Bool" default_value="1" />

集約のためのメモリ制約付きマージ戦略を有効にします。
## enable_multiple_prewhere_read_steps {#enable_multiple_prewhere_read_steps} 



<SettingsInfoBlock type="Bool" default_value="1" />

WHEREからPREWHEREにより多くの条件を移動し、ANDで結合された複数の条件がある場合にディスクから読み込みおよびフィルタリングを複数のステップで行います。
## enable_named_columns_in_function_tuple {#enable_named_columns_in_function_tuple} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "すべての名前が一意であり、クオートされていない識別子として扱える場合に、関数tuple() で名前付きタプルを生成します。"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "0"},{"label": "使いやすさの改善を待って無効"}]}]}/>

すべての名前が一意であり、クオートされていない識別子として扱える場合に、関数tuple() で名前付きタプルを生成します。
## enable_optimize_predicate_expression {#enable_optimize_predicate_expression} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "18.12.17"},{"label": "1"},{"label": "デフォルトでサブクエリの述語を最適化します。"}]}]}/>

`SELECT`クエリ内での述語プッシュダウンを有効にします。

述語プッシュダウンは、分散クエリにおけるネットワークトラフィックを大幅に削減する可能性があります。

可能な値：

- 0 — 無効。
- 1 — 有効。

使用法

次のクエリを考慮してください。

1.  `SELECT count() FROM test_table WHERE date = '2018-10-10'`
2.  `SELECT count() FROM (SELECT * FROM test_table) WHERE date = '2018-10-10'`

`enable_optimize_predicate_expression = 1`の場合、これらのクエリの実行時間は同じになります。ClickHouseはサブクエリを処理する際に`WHERE`を適用します。

`enable_optimize_predicate_expression = 0`の場合、２番目のクエリの実行時間が大幅に長くなります。なぜなら、`WHERE`句はサブクエリが終了した後にすべてのデータに適用されるからです。
## enable_optimize_predicate_expression_to_final_subquery {#enable_optimize_predicate_expression_to_final_subquery} 



<SettingsInfoBlock type="Bool" default_value="1" />

述語を最終サブクエリにプッシュダウン可能にします。
## enable_order_by_all {#enable_order_by_all} 



<SettingsInfoBlock type="Bool" default_value="1" />

`ORDER BY ALL`構文によるソートを有効または無効にします。詳細は[ORDER BY](../../sql-reference/statements/select/order-by.md)を参照してください。

可能な値：

- 0 — ORDER BY ALLを無効にします。
- 1 — ORDER BY ALLを有効にします。

**例**

クエリ：

```sql
CREATE TABLE TAB(C1 Int, C2 Int, ALL Int) ENGINE=Memory();

INSERT INTO TAB VALUES (10, 20, 30), (20, 20, 10), (30, 10, 20);

SELECT * FROM TAB ORDER BY ALL; -- ALLがあいまいであるためエラーを返します。

SELECT * FROM TAB ORDER BY ALL SETTINGS enable_order_by_all = 0;

結果：

```text
┌─C1─┬─C2─┬─ALL─┐
│ 20 │ 20 │  10 │
│ 30 │ 10 │  20 │
│ 10 │ 20 │  30 │
└────┴────┴─────┘

## enable_parsing_to_custom_serialization {#enable_parsing_to_custom_serialization} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1"},{"label": "新しい設定"}]}]}/>

真であれば、データはテーブルから得たシリアル化のヒントに基づいて、カスタムシリアル化（例：スパース）を持つカラムに直接解析されることが可能です。

## enable_positional_arguments {#enable_positional_arguments} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.7"},{"label": "1"},{"label": "位置引数機能をデフォルトで有効にする"}]}]}/>

[GROUP BY](/sql-reference/statements/select/group-by)、[LIMIT BY](../../sql-reference/statements/select/limit-by.md)、[ORDER BY](../../sql-reference/statements/select/order-by.md) ステートメントの位置引数のサポートを有効または無効にします。

可能な値:

- 0 — 位置引数はサポートされていません。
- 1 — 位置引数がサポートされています: カラム番号がカラム名の代わりに使用できます。

**例**

クエリ:

```sql
CREATE TABLE positional_arguments(one Int, two Int, three Int) ENGINE=Memory();

INSERT INTO positional_arguments VALUES (10, 20, 30), (20, 20, 10), (30, 10, 20);

SELECT * FROM positional_arguments ORDER BY 2,3;

結果:

```text
┌─one─┬─two─┬─three─┐
│  30 │  10 │   20  │
│  20 │  20 │   10  │
│  10 │  20 │   30  │
└─────┴─────┴───────┘

## enable_reads_from_query_cache {#enable_reads_from_query_cache} 



<SettingsInfoBlock type="Bool" default_value="1" />

`SELECT` クエリの結果が [クエリキャッシュ](../query-cache.md) から取得されるようにします。

可能な値:

- 0 - 無効
- 1 - 有効
## enable_s3_requests_logging {#enable_s3_requests_logging} 



<SettingsInfoBlock type="Bool" default_value="0" />

S3 リクエストの非常に詳細なログを有効にします。デバッグ専用の意味があります。
## enable_scalar_subquery_optimization {#enable_scalar_subquery_optimization} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "19.18"},{"label": "1"},{"label": "大きなスカラ値の (デシリアライズ) を防ぎ、同じサブクエリを複数回実行しないようにする"}]}]}/>

真に設定されている場合、大きなスカラ値の (デシリアライズ) を防ぎ、同じサブクエリを複数回実行しないようにします。
## enable_sharing_sets_for_mutations {#enable_sharing_sets_for_mutations} 



<SettingsInfoBlock type="Bool" default_value="1" />

IN サブクエリのためにビルドしたセットオブジェクトを同じ変異の異なるタスク間で共有できるようにします。これにより、メモリ使用量と CPU 消費が削減されます。
## enable_software_prefetch_in_aggregation {#enable_software_prefetch_in_aggregation} 



<SettingsInfoBlock type="Bool" default_value="1" />

集約時にソフトウェアプリフェッチの使用を有効にします。
## enable_unaligned_array_join {#enable_unaligned_array_join} 



<SettingsInfoBlock type="Bool" default_value="0" />

異なるサイズの複数の配列を持つ ARRAY JOIN を許可します。この設定が有効な場合、配列は最も長いものにリサイズされます。
## enable_url_encoding {#enable_url_encoding} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "既存の設定のデフォルト値を変更しました"}]}]}/>

[URL](../../engines/table-engines/special/url.md) エンジンテーブルの URI 内のパスのデコード/エンコードを有効または無効にします。

デフォルトで無効です。
## enable_vertical_final {#enable_vertical_final} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "バグを修正した後に再びデフォルトで垂直最終を有効にする"}]}, {"id": "row-2","items": [{"label": "24.1"},{"label": "1"},{"label": "デフォルトで垂直最終を使用する"}]}]}/>

有効にすると、FINAL の際に行を削除としてマークし、後でフィルタリングすることで重複した行を削除します。
## enable_writes_to_query_cache {#enable_writes_to_query_cache} 



<SettingsInfoBlock type="Bool" default_value="1" />

`SELECT` クエリの結果を [クエリキャッシュ](../query-cache.md) に保存します。

可能な値:

- 0 - 無効
- 1 - 有効
## enable_zstd_qat_codec {#enable_zstd_qat_codec} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "新しい ZSTD_QAT コーデックを追加"}]}]}/>

有効にされていると、ZSTD_QAT コーデックを使用してカラムを圧縮することができます。
## enforce_strict_identifier_format {#enforce_strict_identifier_format} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "新しい設定。"}]}]}/>

有効にすると、英数字とアンダースコアを含む識別子のみを許可します。
## engine_file_allow_create_multiple_files {#engine_file_allow_create_multiple_files} 



<SettingsInfoBlock type="Bool" default_value="0" />

ファイルエンジンテーブルで挿入のたびに新しいファイルを作成することを許可または禁止します (フォーマットがサフィックス (`JSON`, `ORC`, `Parquet`, など) を持つ場合)。有効にすると、各挿入時に次のパターンに従った名前の新しいファイルが作成されます:

`data.Parquet` -> `data.1.Parquet` -> `data.2.Parquet`, など。

可能な値:
- 0 — `INSERT` クエリがファイルの末尾に新しいデータを追加します。
- 1 — `INSERT` クエリが新しいファイルを作成します。
## engine_file_empty_if_not_exists {#engine_file_empty_if_not_exists} 



<SettingsInfoBlock type="Bool" default_value="0" />

ファイルなしでファイルエンジンテーブルからデータを選択できるようにします。

可能な値:
- 0 — `SELECT` が例外をスローします。
- 1 — `SELECT` が空の結果を返します。
## engine_file_skip_empty_files {#engine_file_skip_empty_files} 



<SettingsInfoBlock type="Bool" default_value="0" />

[File](../../engines/table-engines/special/file.md)エンジンテーブルで空のファイルをスキップすることを有効または無効にします。

可能な値:
- 0 — 空のファイルが要求されたフォーマットと互換性がない場合、`SELECT` が例外をスローします。
- 1 — 空のファイルに対して `SELECT` が空の結果を返します。
## engine_file_truncate_on_insert {#engine_file_truncate_on_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

[File](../../engines/table-engines/special/file.md) エンジンテーブルで挿入前にトランケートを有効または無効にします。

可能な値:
- 0 — `INSERT` クエリがファイルの末尾に新しいデータを追加します。
- 1 — `INSERT` クエリがファイルの既存内容を新しいデータで置き換えます。
## engine_url_skip_empty_files {#engine_url_skip_empty_files} 



<SettingsInfoBlock type="Bool" default_value="0" />

[URL](../../engines/table-engines/special/url.md)エンジンテーブルで空のファイルをスキップすることを有効または無効にします。

可能な値:
- 0 — 空のファイルが要求されたフォーマットと互換性がない場合、`SELECT` が例外をスローします。
- 1 — 空のファイルに対して `SELECT` が空の結果を返します。
## except_default_mode {#except_default_mode} 



<SettingsInfoBlock type="SetOperationMode" default_value="ALL" />

EXCEPT クエリのデフォルトモードを設定します。可能な値: 空文字列、'ALL'、'DISTINCT'。空の場合、モードなしのクエリは例外をスローします。
## external_storage_connect_timeout_sec {#external_storage_connect_timeout_sec} 



<SettingsInfoBlock type="UInt64" default_value="10" />

接続タイムアウト（秒単位）。現在、MySQL のみに対応しています。
## external_storage_max_read_bytes {#external_storage_max_read_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

外部エンジンのテーブルが履歴データをフラッシュする際の最大バイト数の制限。現在、MySQL テーブルエンジン、データベースエンジン、および辞書のみに対応しています。0 に等しい場合、この設定は無効です。
## external_storage_max_read_rows {#external_storage_max_read_rows} 



<SettingsInfoBlock type="UInt64" default_value="0" />

外部エンジンのテーブルが履歴データをフラッシュする際の最大行数の制限。現在、MySQL テーブルエンジン、データベースエンジン、および辞書のみに対応しています。0 に等しい場合、この設定は無効です。
## external_storage_rw_timeout_sec {#external_storage_rw_timeout_sec} 



<SettingsInfoBlock type="UInt64" default_value="300" />

読み取り/書き込みタイムアウト（秒単位）。現在、MySQL のみに対応しています。
## external_table_functions_use_nulls {#external_table_functions_use_nulls} 



<SettingsInfoBlock type="Bool" default_value="1" />

[mysql](../../sql-reference/table-functions/mysql.md)、[postgresql](../../sql-reference/table-functions/postgresql.md)、および [odbc](../../sql-reference/table-functions/odbc.md) テーブル関数が Nullable カラムを使用する方法を定義します。

可能な値:

- 0 — テーブル関数が明示的に Nullable カラムを使用します。
- 1 — テーブル関数が暗黙的に Nullable カラムを使用します。

**使用例**

設定が `0` に設定されている場合、テーブル関数は Nullable カラムを作成せず、NULL の代わりにデフォルト値を挿入します。これは、配列内の NULL 値にも適用されます。
## external_table_strict_query {#external_table_strict_query} 



<SettingsInfoBlock type="Bool" default_value="0" />

それが真に設定されている場合、外部テーブルへのクエリの変換式をローカルフィルターに変換することは禁止されます。
## extract_key_value_pairs_max_pairs_per_row {#extract_key_value_pairs_max_pairs_per_row} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "0"},{"label": "extractKeyValuePairs 関数によって生成される最大ペア数。メモリの消費が過剰になるのを防ぐための保護を提供します。"}]}]}/>

extractKeyValuePairs 関数によって生成される最大ペア数。メモリの消費が過剰になるのを防ぐための保護を提供します。
## extremes {#extremes} 



<SettingsInfoBlock type="Bool" default_value="0" />

クエリ結果のカラムでの極端な値（最小値および最大値）をカウントするかどうか。0 または 1 を受け入れます。デフォルトは 0（無効）。
「極端な値」セクションでの詳細情報をご覧ください。
## fallback_to_stale_replicas_for_distributed_queries {#fallback_to_stale_replicas_for_distributed_queries} 



<SettingsInfoBlock type="Bool" default_value="1" />

更新データが利用できない場合に、古いレプリカにクエリを強制します。[レプリケーション](../../engines/table-engines/mergetree-family/replication.md) を参照してください。

ClickHouse は、テーブルの古いレプリカから最も関連性の高いものを選択します。

複製されたテーブルを指す分散テーブルから `SELECT` を実行する際に使用されます。

デフォルトは 1（有効）。
## filesystem_cache_boundary_alignment {#filesystem_cache_boundary_alignment} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "新しい設定"}]}]}/>

ファイルシステムキャッシュの境界アラインメント。この設定は、非ディスクの読み取り（リモートテーブルエンジン/テーブル関数のキャッシュ用）のみで適用されますが、MergeTree テーブルのストレージ構成には適用されません。値が 0 の場合、アラインメントはありません。
## filesystem_cache_enable_background_download_during_fetch {#filesystem_cache_enable_background_download_during_fetch} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "新しい設定"}]}]}/>

ClickHouse Cloud のみで効果があります。ファイルシステムキャッシュ内のスペース予約のためにキャッシュをロックするまでの待機時間。
## filesystem_cache_enable_background_download_for_metadata_files_in_packed_storage {#filesystem_cache_enable_background_download_for_metadata_files_in_packed_storage} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "新しい設定"}]}]}/>

ClickHouse Cloud のみで効果があります。ファイルシステムキャッシュ内のスペース予約のためにキャッシュをロックするまでの待機時間。
## filesystem_cache_max_download_size {#filesystem_cache_max_download_size} 



<SettingsInfoBlock type="UInt64" default_value="137438953472" />

単一のクエリによってダウンロード可能な最大リモートファイルシステムキャッシュサイズ。
## filesystem_cache_name {#filesystem_cache_name} 



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": ""},{"label": "ステートレステーブルエンジンまたはデータレイクに使用するファイルシステムキャッシュ名"}]}]}/>

ステートレステーブルエンジンまたはデータレイクに使用するファイルシステムキャッシュ名。
## filesystem_cache_prefer_bigger_buffer_size {#filesystem_cache_prefer_bigger_buffer_size} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "新しい設定"}]}]}/>

ファイルシステムキャッシュが有効な場合、キャッシュのパフォーマンスが低下する小さなファイルセグメントの書き込みを避けるために、大きなバッファサイズを優先して選択します。一方で、この設定を有効にすると、メモリ使用量が増加する可能性があります。
## filesystem_cache_reserve_space_wait_lock_timeout_milliseconds {#filesystem_cache_reserve_space_wait_lock_timeout_milliseconds} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1000"},{"label": "ファイルシステムキャッシュでのスペース予約のためのキャッシュをロックするまでの待機時間"}]}]}/>

ファイルシステムキャッシュでのスペース予約のためのキャッシュをロックするまでの待機時間。
## filesystem_cache_segments_batch_size {#filesystem_cache_segments_batch_size} 



<SettingsInfoBlock type="UInt64" default_value="20" />

読み込みバッファがキャッシュから要求できるファイルセグメントの単一バッチのサイズに関する制限。値が低すぎるとキャッシュへの過剰なリクエストが発生し、値が大きすぎるとキャッシュからの排出が遅くなります。
## filesystem_cache_skip_download_if_exceeds_per_query_cache_write_limit {#filesystem_cache_skip_download_if_exceeds_per_query_cache_write_limit} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "設定skip_download_if_exceeds_query_cache_limit の名前を変更"}]}]}/>

クエリキャッシュサイズを超える場合、リモートファイルシステムからのダウンロードをスキップします。
## filesystem_prefetch_max_memory_usage {#filesystem_prefetch_max_memory_usage} 



<SettingsInfoBlock type="NonZeroUInt64" default_value="1073741824" />

プレフェッチに使用される最大メモリ使用量。
## filesystem_prefetch_step_bytes {#filesystem_prefetch_step_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

バイト単位のプレフェッチステップ。ゼロは「自動」を意味し、もっとも適切なプレフェッチステップが自動的に推測されますが、必ずしも100％最適とは限りません。実際の値は、filesystem_prefetch_min_bytes_for_single_read_task 設定によって異なる可能性があります。
## filesystem_prefetch_step_marks {#filesystem_prefetch_step_marks} 



<SettingsInfoBlock type="UInt64" default_value="0" />

マーク単位のプレフェッチステップ。ゼロは「自動」を意味し、もっとも適切なプレフェッチステップが自動的に推測されますが、必ずしも100％最適とは限りません。実際の値は、filesystem_prefetch_min_bytes_for_single_read_task 設定によって異なる可能性があります。
## filesystem_prefetches_limit {#filesystem_prefetches_limit} 



<SettingsInfoBlock type="UInt64" default_value="200" />

最大プレフェッチ数。ゼロは無制限を意味します。プレフェッチ数を制限したい場合は、設定 `filesystem_prefetches_max_memory_usage` が推奨されます。
## final {#final} 



<SettingsInfoBlock type="Bool" default_value="0" />

クエリ内のすべてのテーブルに自動的に [FINAL](../../sql-reference/statements/select/from.md/#final-modifier) 修飾子を適用し、[FINAL](../../sql-reference/statements/select/from.md/#final-modifier) が適用できるテーブル、結合テーブル、サブクエリのテーブル、および分散テーブルに適用します。

可能な値:

- 0 - 無効
- 1 - 有効

例:

```sql
CREATE TABLE test
(
    key Int64,
    some String
)
ENGINE = ReplacingMergeTree
ORDER BY key;

INSERT INTO test FORMAT Values (1, 'first');
INSERT INTO test FORMAT Values (1, 'second');

SELECT * FROM test;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘
┌─key─┬─some──┐
│   1 │ first │
└─────┴───────┘

SELECT * FROM test SETTINGS final = 1;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘

SET final = 1;
SELECT * FROM test;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘

## flatten_nested {#flatten_nested} 



<SettingsInfoBlock type="Bool" default_value="1" />

[ネストされた](../../sql-reference/data-types/nested-data-structures/index.md) カラムのデータ形式を設定します。

可能な値:

- 1 — ネストされたカラムが別々の配列にフラット化されます。
- 0 — ネストされたカラムはタプルの単一配列のままです。

**使用例**

設定が `0` に設定されている場合、任意のネストレベルを使用することができます。

**例**

クエリ:

```sql
SET flatten_nested = 1;
CREATE TABLE t_nest (`n` Nested(a UInt32, b UInt32)) ENGINE = MergeTree ORDER BY tuple();

SHOW CREATE TABLE t_nest;

結果:

```text
┌─statement───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.t_nest
(
    `n.a` Array(UInt32),
    `n.b` Array(UInt32)
)
ENGINE = MergeTree
ORDER BY tuple()
SETTINGS index_granularity = 8192 │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

クエリ:

```sql
SET flatten_nested = 0;

CREATE TABLE t_nest (`n` Nested(a UInt32, b UInt32)) ENGINE = MergeTree ORDER BY tuple();

SHOW CREATE TABLE t_nest;

結果:

```text
┌─statement──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.t_nest
(
    `n` Nested(a UInt32, b UInt32)
)
ENGINE = MergeTree
ORDER BY tuple()
SETTINGS index_granularity = 8192 │
└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

## force_aggregate_partitions_independently {#force_aggregate_partitions_independently} 



<SettingsInfoBlock type="Bool" default_value="0" />

適用可能な場合に最適化の使用を強制しますが、ヒューリスティクスが使用しないと判断した場合。
## force_aggregation_in_order {#force_aggregation_in_order} 



<SettingsInfoBlock type="Bool" default_value="0" />

この設定は、サーバ自体によって分散クエリのサポートに使用されます。通常の操作を中断するため、手動で変更しないでください。（分散集計中にリモートノードでの順序での集計使用を強制します）。
## force_data_skipping_indices {#force_data_skipping_indices} 

指定されたデータスキッピングインデックスが使用されていない場合、クエリの実行を無効にします。

以下の例を考えてみましょう:

```sql
CREATE TABLE data
(
    key Int,
    d1 Int,
    d1_null Nullable(Int),
    INDEX d1_idx d1 TYPE minmax GRANULARITY 1,
    INDEX d1_null_idx assumeNotNull(d1_null) TYPE minmax GRANULARITY 1
)
Engine=MergeTree()
ORDER BY key;

SELECT * FROM data_01515;
SELECT * FROM data_01515 SETTINGS force_data_skipping_indices=''; -- クエリは CANNOT_PARSE_TEXT エラーを生成します。
SELECT * FROM data_01515 SETTINGS force_data_skipping_indices='d1_idx'; -- クエリは INDEX_NOT_USED エラーを生成します。
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='d1_idx'; -- OK。
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='`d1_idx`'; -- OK（フルフィーチャーパーサーの例）。
SELECT * FROM data_01515 WHERE d1 = 0 AND assumeNotNull(d1_null) = 0 SETTINGS force_data_skipping_indices='`d1_idx`, d1_null_idx'; -- OK。

## force_grouping_standard_compatibility {#force_grouping_standard_compatibility} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.9"},{"label": "1"},{"label": "GROUPING 関数の出力を SQL 標準および他の DBMS と同じにする"}]}]}/>

GROUPING 関数が引数が集計キーとして使用されていない場合、1 を返すようにします。
## force_index_by_date {#force_index_by_date} 



<SettingsInfoBlock type="Bool" default_value="0" />

日付によってインデックスを使用できない場合、クエリの実行を無効にします。

MergeTree ファミリーのテーブルで動作します。

`force_index_by_date=1` の場合、ClickHouse は、データ範囲を制限するために使用できる日付キー条件がクエリにあるかどうかを確認します。適切な条件がない場合、例外がスローされます。ただし、条件が読み取るデータ量を制限するかどうかはチェックされません。たとえば、条件 `Date != ' 2000-01-01 '` は、テーブル内のすべてのデータと一致する場合でも受け入れられます（つまり、クエリを実行するには完全なスキャンが必要です）。MergeTree テーブルのデータ範囲の詳細については、[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) を参照してください。
## force_optimize_projection {#force_optimize_projection} 



<SettingsInfoBlock type="Bool" default_value="0" />

集計最適化が有効な場合、`SELECT` クエリでの [プロジェクション](../../engines/table-engines/mergetree-family/mergetree.md/#projections) の必須使用を有効または無効にします。

可能な値:

- 0 — プロジェクション最適化は必須ではありません。
- 1 — プロジェクション最適化は必須です。
## force_optimize_projection_name {#force_optimize_projection_name} 

非空の文字列に設定されている場合、このプロジェクションがクエリ内で少なくとも一度使用されていることを確認します。

可能な値:

- 文字列: クエリで使用されるプロジェクションの名前。
## force_optimize_skip_unused_shards {#force_optimize_skip_unused_shards} 



<SettingsInfoBlock type="UInt64" default_value="0" />

[optimize_skip_unused_shards](#optimize_skip_unused_shards)が有効で、未使用のシャードのスキップが不可能な場合、クエリの実行を無効にします。スキップが不可能で、設定が有効な場合、例外がスローされます。

可能な値:

- 0 — 無効。ClickHouse は例外をスローしません。
- 1 — 有効。テーブルにシャーディングキーがある場合のみクエリの実行が無効になります。
- 2 — 有効。テーブルにシャーディングキーが定義されているか否かに関わらず、クエリの実行が無効になります。
## force_optimize_skip_unused_shards_nesting {#force_optimize_skip_unused_shards_nesting} 



<SettingsInfoBlock type="UInt64" default_value="0" />

[`force_optimize_skip_unused_shards`](#force_optimize_skip_unused_shards) の制御（そのため、[`force_optimize_skip_unused_shards`](#force_optimize_skip_unused_shards) も必要です）。分散クエリのネストレベルによって制御されます（たとえば、別の `Distributed` テーブルを参照する `Distributed` テーブルの場合）。

可能な値:

- 0 - 無効。`force_optimize_skip_unused_shards` は常に機能します。
- 1 — `force_optimize_skip_unused_shards` を最初のレベルのみに有効にします。
- 2 — `force_optimize_skip_unused_shards` を2階層目まで有効にします。
## force_primary_key {#force_primary_key} 



<SettingsInfoBlock type="Bool" default_value="0" />

プライマリキーによるインデックス作成が不可能な場合、クエリの実行を無効にします。

MergeTree ファミリーのテーブルで動作します。

`force_primary_key=1` の場合、ClickHouse は、データ範囲を制限するために使用できるプライマリキー条件がクエリにあるかどうかを確認します。適切な条件がない場合、例外がスローされます。ただし、条件が読み取るデータ量を制限するかどうかはチェックされません。MergeTree テーブルのデータ範囲については、[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) を参照してください。
## force_remove_data_recursively_on_drop {#force_remove_data_recursively_on_drop} 



<SettingsInfoBlock type="Bool" default_value="0" />

DROP クエリでデータを再帰的に削除します。 'Directory not empty' エラーを回避しますが、デタッチされたデータを静かに削除する可能性があります。
## formatdatetime_e_with_space_padding {#formatdatetime_e_with_space_padding} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "MySQL DATE_FORMAT/STR_TO_DATE との互換性の向上"}]}]}/>

関数 'formatDateTime' におけるフォーマッタ '%e' は、一桁の日を前スペース付きで表示します。例えば、' 2' のように。
## formatdatetime_f_prints_scale_number_of_digits {#formatdatetime_f_prints_scale_number_of_digits} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "新しい設定。"}]}]}/>

関数 'formatDateTime' のフォーマッタ '%f' は、固定の6桁ではなく、DateTime64 のスケール量の桁数を表示します。
## formatdatetime_f_prints_single_zero {#formatdatetime_f_prints_single_zero} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "0"},{"label": "MySQL DATE_FORMAT()/STR_TO_DATE() との互換性の向上"}]}]}/>

関数 'formatDateTime' のフォーマッタ '%f' は、整形された値に小数秒がない場合、6つの0の代わりに1つの0を表示します。
## formatdatetime_format_without_leading_zeros {#formatdatetime_format_without_leading_zeros} 



<SettingsInfoBlock type="Bool" default_value="0" />

関数 'formatDateTime' のフォーマッタ '%c', '%l' および '%k' は、前ゼロなしで月と時間を表示します。
## formatdatetime_parsedatetime_m_is_month_name {#formatdatetime_parsedatetime_m_is_month_name} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "1"},{"label": "MySQL DATE_FORMAT/STR_TO_DATE との互換性の向上"}]}]}/>

関数 'formatDateTime' および 'parseDateTime' におけるフォーマッタ '%M' は、分ではなく月名を表示/解析します。
## fsync_metadata {#fsync_metadata} 



<SettingsInfoBlock type="Bool" default_value="1" />

.sql ファイルを書き込む際に [fsync](http://pubs.opengroup.org/onlinepubs/9699919799/functions/fsync.html) を有効または無効にします。デフォルトで有効です。

サーバーに数百万の小さなテーブルがあり、常に作成および削除される場合は、無効にする意義があります。
## function_implementation {#function_implementation} 

特定のターゲットやバリアント（実験的）用の関数実装を選択します。空の場合は、すべてを有効にします。
## function_json_value_return_type_allow_complex {#function_json_value_return_type_allow_complex} 



<SettingsInfoBlock type="Bool" default_value="0" />

json_value 関数で複雑な型（構造体、配列、マップなど）を返すかどうかを制御します。

```sql
SELECT JSON_VALUE('{"hello":{"world":"!"}}', '$.hello') settings function_json_value_return_type_allow_complex=true

┌─JSON_VALUE('{"hello":{"world":"!"}}', '$.hello')─┐
│ {"world":"!"}                                    │
└──────────────────────────────────────────────────┘

1 row in set. Elapsed: 0.001 sec.

可能な値:

- true — 許可。
- false — 拒否。
## function_json_value_return_type_allow_nullable {#function_json_value_return_type_allow_nullable} 



<SettingsInfoBlock type="Bool" default_value="0" />

値が存在しない場合、JSON_VALUE 関数に対して `NULL` を返すかどうかを制御します。

```sql
SELECT JSON_VALUE('{"hello":"world"}', '$.b') settings function_json_value_return_type_allow_nullable=true;

┌─JSON_VALUE('{"hello":"world"}', '$.b')─┐
│ ᴺᵁᴸᴸ                                   │
└────────────────────────────────────────┘

1 row in set. Elapsed: 0.001 sec.

可能な値:

- true — 許可。
- false — 拒否。
## function_locate_has_mysql_compatible_argument_order {#function_locate_has_mysql_compatible_argument_order} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "MySQL の locate 関数との互換性を高めます。"}]}]}/>

[locate](../../sql-reference/functions/string-search-functions.md/#locate) 関数の引数の順序を制御します。

可能な値:

- 0 — 関数 `locate` は引数 `(haystack, needle[, start_pos])` を受け入れます。
- 1 — 関数 `locate` は引数 `(needle, haystack, [, start_pos])` を受け入れます（MySQL 互換の動作）。
## function_range_max_elements_in_block {#function_range_max_elements_in_block} 



<SettingsInfoBlock type="UInt64" default_value="500000000" />

関数 [range](/sql-reference/functions/array-functions#rangeend-rangestart--end--step) によって生成されるデータボリュームの安全しきい値を設定します。データの各ブロックの値が生成される最大数を定義します（ブロック内の各行の配列サイズの合計）。

可能な値:

- 正の整数。

**関連項目**

- [max_block_size](#max_block_size)
- [min_insert_block_size_rows](#min_insert_block_size_rows)
## function_sleep_max_microseconds_per_block {#function_sleep_max_microseconds_per_block} 



<SettingsInfoBlock type="UInt64" default_value="3000000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.7"},{"label": "3000000"},{"label": "以前のバージョンでは、sleep の最大スリープ時間は 3 秒のみが適用されていましたが、sleepEachRow 関数には適用されていませんでした。この新しいバージョンでは、この設定を導入しました。前のバージョンとの互換性を持たせるために、制限を完全に無効にします。"}]}]}/>

関数 `sleep` が各ブロックでスリープすることが許可される最大マイクロ秒数。ユーザーがそれをより大きな値で呼び出した場合、例外がスローされます。これは安全しきい値です。
## function_visible_width_behavior {#function_visible_width_behavior} 



<SettingsInfoBlock type="UInt64" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "1"},{"label": "visibleWidth のデフォルト動作をより正確に変更しました"}]}]}/>

`visibleWidth` 動作のバージョン。 0 - コードポイントの数だけをカウントします; 1 - ゼロ幅と合成文字を正しくカウントし、全幅文字を2としてカウントし、タブ幅を推定し、削除文字をカウントします。
## geo_distance_returns_float64_on_float64_arguments {#geo_distance_returns_float64_on_float64_arguments} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "デフォルトの精度を高めます。"}]}]}/>

すべての4つの引数が Float64 の場合、`geoDistance`、`greatCircleDistance`、`greatCircleAngle` 関数は Float64 を返し、内部計算にダブル精度を使用します。以前の ClickHouse バージョンでは、関数は常に Float32 を返しました。
## geotoh3_argument_order {#geotoh3_argument_order} 

<BetaBadge/>



<SettingsInfoBlock type="GeoToH3ArgumentOrder" default_value="lat_lon" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "lat_lon"},{"label": "レガシー動作のための新しい設定で、lonとlatの引数順序を設定する"}]}]}/>

geoToH3 関数は、'lon_lat' に設定されている場合は (lon, lat) を、'lat_lon' に設定されている場合は (lat, lon) を受け入れます。
## glob_expansion_max_elements {#glob_expansion_max_elements} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

許可される最大アドレス数（外部ストレージ、テーブル関数など）。
## grace_hash_join_initial_buckets {#grace_hash_join_initial_buckets} 

<ExperimentalBadge/>



<SettingsInfoBlock type="NonZeroUInt64" default_value="1" />

初期のグレースハッシュジョインバケット数
## grace_hash_join_max_buckets {#grace_hash_join_max_buckets} 

<ExperimentalBadge/>



<SettingsInfoBlock type="NonZeroUInt64" default_value="1024" />

グレースハッシュジョインバケット数の制限
## group_by_overflow_mode {#group_by_overflow_mode} 



<SettingsInfoBlock type="OverflowModeGroupBy" default_value="throw" />

集計のためのユニークなキーの数が制限を超えたときに何が起こるかを設定します：
- `throw`: 例外をスローします
- `break`: クエリの実行を停止し、部分結果を返します
- `any`: セットに含まれるキーの集計を続けますが、新しいキーはセットに追加しません。

'any' 値を使用すると、GROUP BY の近似が実行できます。この近似の品質は、データの統計的性質に依存します。
## group_by_two_level_threshold {#group_by_two_level_threshold} 



<SettingsInfoBlock type="UInt64" default_value="100000" />

2レベルの集計が始まるキーの数。 0 - 制限は設定されていません。
## group_by_two_level_threshold_bytes {#group_by_two_level_threshold_bytes} 



<SettingsInfoBlock type="UInt64" default_value="50000000" />

バイト単位の集計状態のサイズから、2レベルの集計が使用され始めます。 0 - 制限は設定されていません。少なくとも 1 つの制限がトリガーされた場合、2レベルの集計が使用されます。
## group_by_use_nulls {#group_by_use_nulls} 



<SettingsInfoBlock type="Bool" default_value="0" />

[GROUP BY句](/sql-reference/statements/select/group-by)が集計キーのタイプを扱う方法を変更します。
`ROLLUP`、`CUBE`、または `GROUPING SETS` の指定子が使用されると、一部の集計キーは結果行を生成するために使用されない場合があります。
これらのキーに対応するカラムは、この設定に応じて、対応する行にデフォルト値または `NULL` で埋められます。

可能な値：

- 0 — 集計キータイプに対するデフォルト値が欠落している場合に使用されます。
- 1 — ClickHouse は SQL 標準が言う通りに `GROUP BY` を実行します。集計キーのタイプは [Nullable](/sql-reference/data-types/nullable) に変換され、使用されなかった行の対応する集計キーに対して [NULL](/sql-reference/syntax#null) で埋められます。

参照：

- [GROUP BY句](/sql-reference/statements/select/group-by)
## h3togeo_lon_lat_result_order {#h3togeo_lon_lat_result_order} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "新しい設定"}]}]}/>

関数 'h3ToGeo' は、true の場合は (lon, lat) を返し、そうでない場合は (lat, lon) を返します。
## handshake_timeout_ms {#handshake_timeout_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="10000" />

ハンドシェイク中にレプリカから Hello パケットを受信するためのタイムアウト（ミリ秒）。
## hdfs_create_new_file_on_insert {#hdfs_create_new_file_on_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

HDFS エンジンテーブルでの各挿入時に新しいファイルを作成するかどうかを有効または無効にします。有効にした場合、各挿入時に、次のようなパターンに似た名前の新しい HDFS ファイルが作成されます：

最初: `data.Parquet.gz` -> `data.1.Parquet.gz` -> `data.2.Parquet.gz` など。

可能な値：
- 0 — `INSERT` クエリは、新しいデータをファイルの末尾に追加します。
- 1 — `INSERT` クエリは、新しいファイルを作成します。
## hdfs_ignore_file_doesnt_exist {#hdfs_ignore_file_doesnt_exist} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "HDFSテーブルエンジンで、要求されたファイルが存在しないときに0行を返すことを許可します。例外をスローするのではなく。"}]}]}/>

特定のキーの読み込みの際に、ファイルの不在を無視します。

可能な値：
- 1 — `SELECT` は結果が空を返します。
- 0 — `SELECT` は例外をスローします。
## hdfs_replication {#hdfs_replication} 



<SettingsInfoBlock type="UInt64" default_value="0" />

hdfs ファイルを作成する際に、実際のレプリケーション数を指定できます。
## hdfs_skip_empty_files {#hdfs_skip_empty_files} 



<SettingsInfoBlock type="Bool" default_value="0" />

[HDFS](../../engines/table-engines/integrations/hdfs.md) エンジンテーブルで空のファイルをスキップすることを有効または無効にします。

可能な値：
- 0 — 空のファイルが要求された形式と互換性がない場合、`SELECT` は例外をスローします。
- 1 — 空のファイルに対して `SELECT` は空の結果を返します。
## hdfs_throw_on_zero_files_match {#hdfs_throw_on_zero_files_match} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "HDFSエンジンでListObjectsリクエストがファイルに一致しない場合にエラーをスローします。出力は空のクエリ結果になります。"}]}]}/>

グロブ展開ルールに従い、ゼロファイルが一致した場合にエラーをスローします。

可能な値：
- 1 — `SELECT` は例外をスローします。
- 0 — `SELECT` は空の結果を返します。
## hdfs_truncate_on_insert {#hdfs_truncate_on_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

HDFS エンジンテーブルでの挿入前に切り捨てを有効または無効にします。無効のときは、HDFS に既にファイルが存在する場合に挿入を試みると例外がスローされます。

可能な値：
- 0 — `INSERT` クエリは、新しいデータをファイルの末尾に追加します。
- 1 — `INSERT` クエリは、ファイルの既存の内容を新しいデータで置き換えます。
## hedged_connection_timeout_ms {#hedged_connection_timeout_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="50" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "50"},{"label": "ヘッジリクエストのためのレプリカとの接続を確立するための接続タイムアウトをご確認ください。"}]}]}/>

ヘッジリクエスト時のレプリカとの接続を確立するための接続タイムアウト
## hnsw_candidate_list_size_for_search {#hnsw_candidate_list_size_for_search} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="256" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "256"},{"label": "新しい設定。以前は、値は CREATE INDEX でオプションで指定され、デフォルトは 64でした。"}]}]}/>

ベクトル類似性インデックス検索時の動的候補リストのサイズ。これを 'ef_search' と呼びます。
## hsts_max_age {#hsts_max_age} 



<SettingsInfoBlock type="UInt64" default_value="0" />

HSTS の有効期限。 0 は HSTS を無効にします。
## http_connection_timeout {#http_connection_timeout} 



<SettingsInfoBlock type="Seconds" default_value="1" />

HTTP接続のタイムアウト（秒単位）。

可能な値：

- 任意の正の整数。
- 0 - 無効（無限のタイムアウト）。
## http_headers_progress_interval_ms {#http_headers_progress_interval_ms} 



<SettingsInfoBlock type="UInt64" default_value="100" />

指定された間隔ごとに X-ClickHouse-Progress HTTP ヘッダーを送信する頻度を制限します。
## http_make_head_request {#http_make_head_request} 



<SettingsInfoBlock type="Bool" default_value="1" />

`http_make_head_request` 設定は、データを HTTP から読み取る際に `HEAD` リクエストを実行し、読み取るファイルに関する情報（サイズなど）を取得できるようにします。デフォルトで有効になっているため、サーバーが `HEAD` リクエストをサポートしていない場合は、この設定を無効にすることが望ましい場合があります。
## http_max_field_name_size {#http_max_field_name_size} 



<SettingsInfoBlock type="UInt64" default_value="131072" />

HTTP ヘッダー内のフィールド名の最大長
## http_max_field_value_size {#http_max_field_value_size} 



<SettingsInfoBlock type="UInt64" default_value="131072" />

HTTP ヘッダー内のフィールド値の最大長
## http_max_fields {#http_max_fields} 



<SettingsInfoBlock type="UInt64" default_value="1000000" />

HTTP ヘッダー内のフィールドの最大数
## http_max_multipart_form_data_size {#http_max_multipart_form_data_size} 



<SettingsInfoBlock type="UInt64" default_value="1073741824" />

multipart/form-data コンテンツのサイズに対する制限。この設定は URL パラメータから解析できず、ユーザープロファイルで設定する必要があります。データはクエリ実行の開始前にメモリ内で解析され、外部テーブルが作成されます。この段階で影響を与える唯一の制限です（最大メモリ使用量および最大実行時間の制限は、HTTP フォームデータを読み込む際に影響を及ぼしません）。
## http_max_request_param_data_size {#http_max_request_param_data_size} 



<SettingsInfoBlock type="UInt64" default_value="10485760" />

あらかじめ定義された HTTP リクエストでクエリパラメータとして使用されるリクエストデータのサイズに対する制限。
## http_max_tries {#http_max_tries} 



<SettingsInfoBlock type="UInt64" default_value="10" />

HTTP 経由で読み取るための最大試行回数。
## http_max_uri_size {#http_max_uri_size} 



<SettingsInfoBlock type="UInt64" default_value="1048576" />

HTTP リクエストの最大 URI 長を設定します。

可能な値：

- 正の整数。
## http_native_compression_disable_checksumming_on_decompress {#http_native_compression_disable_checksumming_on_decompress} 



<SettingsInfoBlock type="Bool" default_value="0" />

クライアントからの HTTP POST データの解凍時にチェックサム検証を有効または無効にします。ClickHouse ネイティブ圧縮形式でのみ使用されます（`gzip` または `deflate` では使用されません）。

詳細については、[HTTPインターフェースの説明](../../interfaces/http.md)を参照してください。

可能な値：

- 0 — 無効。
- 1 — 有効。
## http_receive_timeout {#http_receive_timeout} 



<SettingsInfoBlock type="Seconds" default_value="30" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.6"},{"label": "30"},{"label": "http_send_timeoutをご確認ください。"}]}]}/>

HTTP 受信タイムアウト（秒単位）。

可能な値：

- 任意の正の整数。
- 0 - 無効（無限のタイムアウト）。
## http_response_buffer_size {#http_response_buffer_size} 



<SettingsInfoBlock type="UInt64" default_value="0" />

クライアントに HTTP 応答を送信する前にサーバーメモリ内でバッファリングするバイト数、またはディスクにフラッシュ時（http_wait_end_of_query が有効な場合）。
## http_response_headers {#http_response_headers} 



<SettingsInfoBlock type="Map" default_value="{}" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": ""},{"label": "新しい設定。"}]}]}/>

サーバーが成功したクエリ結果とともに返す HTTP ヘッダーを追加または上書きすることができます。
これは HTTP インターフェースにのみ影響します。

ヘッダーがデフォルトで既に設定されている場合、提供された値が上書きされます。
デフォルトで設定されていなかったヘッダーは、ヘッダーのリストに追加されます。
サーバーによってデフォルトで設定されたヘッダーで、この設定によって上書きされていないものは、そのまま残ります。

この設定は、ヘッダーを一定の値に設定できることを可能にします。現在、動的に計算された値にヘッダーを設定する方法はありません。

名前や値には ASCII 制御文字を含めることはできません。

ユーザーが設定を変更できる UI アプリケーションを実装しつつ、返されたヘッダーに基づいて決定を行う場合、この設定を読み取り専用に制限することをお勧めします。

例: `SET http_response_headers = '{"Content-Type": "image/png"}'`
## http_retry_initial_backoff_ms {#http_retry_initial_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="100" />

最大ミリ秒数のバックオフ、HTTP 経由での読み取りを再試行する際に
## http_retry_max_backoff_ms {#http_retry_max_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="10000" />

最大ミリ秒数のバックオフ、HTTP 経由での読み取りを再試行する際に
## http_send_timeout {#http_send_timeout} 



<SettingsInfoBlock type="Seconds" default_value="30" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.6"},{"label": "30"},{"label": "3 分は非常に長すぎるようです。これは単一のネットワーク書き込み呼び出しのタイムアウトであり、全体のアップロード操作のためではないことに注意してください。"}]}]}/>

HTTP 送信タイムアウト（秒単位）。

可能な値：

- 任意の正の整数。
- 0 - 無効（無限のタイムアウト）。

:::note
これはデフォルトプロファイルにのみ適用されます。変更を有効にするにはサーバーの再起動が必要です。
:::
## http_skip_not_found_url_for_globs {#http_skip_not_found_url_for_globs} 



<SettingsInfoBlock type="Bool" default_value="1" />

HTTP_NOT_FOUNDエラーのあるグロブ用のURLをスキップします
## http_wait_end_of_query {#http_wait_end_of_query} 



<SettingsInfoBlock type="Bool" default_value="0" />

サーバー側での HTTP 応答バッファリングを有効にします。
## http_write_exception_in_output_format {#http_write_exception_in_output_format} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.9"},{"label": "1"},{"label": "HTTP ストリーミングで例外を出力フォーマットに書き込みます。"}]}]}/>

有効な出力を生成するために出力フォーマットに例外を書き込みます。JSONおよびXMLフォーマットで機能します。
## http_zlib_compression_level {#http_zlib_compression_level} 



<SettingsInfoBlock type="Int64" default_value="3" />

[enable_http_compression = 1](#enable_http_compression)の場合、HTTP リクエストに対する応答のデータ圧縮のレベルを設定します。

可能な値: 1 から 9 までの数字。
## iceberg_snapshot_id {#iceberg_snapshot_id} 



<SettingsInfoBlock type="Int64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "新しい設定。"}]}]}/>

特定のスナップショットIDを使用して Iceberg テーブルにクエリします。
## iceberg_timestamp_ms {#iceberg_timestamp_ms} 



<SettingsInfoBlock type="Int64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "新しい設定。"}]}]}/>

特定のタイムスタンプで現在のスナップショットを使用して Iceberg テーブルにクエリします。
## idle_connection_timeout {#idle_connection_timeout} 



<SettingsInfoBlock type="UInt64" default_value="3600" />

指定された秒数の後にアイドル TCP 接続を閉じるためのタイムアウト。

可能な値：

- 正の整数（0 - 直ちに閉じる、0 秒後）。
## ignore_cold_parts_seconds {#ignore_cold_parts_seconds} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Int64" default_value="0" />

ClickHouse Cloud のみで効果があります。新しいデータパーツを SELECT クエリから除外します。プリウォームされるか、指定された秒数が経過するまで除外します。Replicated-/SharedMergeTree のみ。
## ignore_data_skipping_indices {#ignore_data_skipping_indices} 

クエリで使用されているスキッピングインデックスを無視します。

次の例を考えてみましょう：

```sql
CREATE TABLE data
(
    key Int,
    x Int,
    y Int,
    INDEX x_idx x TYPE minmax GRANULARITY 1,
    INDEX y_idx y TYPE minmax GRANULARITY 1,
    INDEX xy_idx (x,y) TYPE minmax GRANULARITY 1
)
Engine=MergeTree()
ORDER BY key;

INSERT INTO data VALUES (1, 2, 3);

SELECT * FROM data;
SELECT * FROM data SETTINGS ignore_data_skipping_indices=''; -- クエリは CANNOT_PARSE_TEXT エラーを生成します。
SELECT * FROM data SETTINGS ignore_data_skipping_indices='x_idx'; -- OK。
SELECT * FROM data SETTINGS ignore_data_skipping_indices='na_idx'; -- OK。

SELECT * FROM data WHERE x = 1 AND y = 1 SETTINGS ignore_data_skipping_indices='xy_idx',force_data_skipping_indices='xy_idx' ; -- クエリは INDEX_NOT_USED エラーを生成します。xy_idx は明示的に無視されているためです。
SELECT * FROM data WHERE x = 1 AND y = 2 SETTINGS ignore_data_skipping_indices='xy_idx';

いかなるインデックスも無視しないクエリ：
```sql
EXPLAIN indexes = 1 SELECT * FROM data WHERE x = 1 AND y = 2;

Expression ((Projection + Before ORDER BY))
  Filter (WHERE)
    ReadFromMergeTree (default.data)
    Indexes:
      PrimaryKey
        Condition: true
        Parts: 1/1
        Granules: 1/1
      Skip
        Name: x_idx
        Description: minmax GRANULARITY 1
        Parts: 0/1
        Granules: 0/1
      Skip
        Name: y_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
      Skip
        Name: xy_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0

`xy_idx` インデックスを無視した場合：
```sql
EXPLAIN indexes = 1 SELECT * FROM data WHERE x = 1 AND y = 2 SETTINGS ignore_data_skipping_indices='xy_idx';

Expression ((Projection + Before ORDER BY))
  Filter (WHERE)
    ReadFromMergeTree (default.data)
    Indexes:
      PrimaryKey
        Condition: true
        Parts: 1/1
        Granules: 1/1
      Skip
        Name: x_idx
        Description: minmax GRANULARITY 1
        Parts: 0/1
        Granules: 0/1
      Skip
        Name: y_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0

MergeTreeファミリーのテーブルで動作します。
## ignore_drop_queries_probability {#ignore_drop_queries_probability} 



<SettingsInfoBlock type="Float" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "0"},{"label": "テスト目的で指定された確率でDROPクエリを無視することを許可します。"}]}]}/>

有効にすると、サーバーは指定された確率ですべての DROP テーブルクエリを無視します（Memory と JOIN エンジンには DROP を TRUNCATE に置き換えます）。テスト目的で使用されます
## ignore_materialized_views_with_dropped_target_table {#ignore_materialized_views_with_dropped_target_table} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "削除されたターゲットテーブルを持つマテリアライズドビューを無視することを許可する新しい設定を追加しました。"}]}]}/>

ビューにプッシュするときに、削除されたターゲットテーブルを持つ MV を無視します。
## ignore_on_cluster_for_replicated_access_entities_queries {#ignore_on_cluster_for_replicated_access_entities_queries} 



<SettingsInfoBlock type="Bool" default_value="0" />

レプリケートされたアクセシビリティ管理クエリのための ON CLUSTER 句を無視します。
## ignore_on_cluster_for_replicated_named_collections_queries {#ignore_on_cluster_for_replicated_named_collections_queries} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "レプリケートされた名前付きコレクション管理クエリのための ON CLUSTER 句を無視します。"}]}]}/>

レプリケートされた名前付きコレクション管理クエリのための ON CLUSTER 句を無視します。
## ignore_on_cluster_for_replicated_udf_queries {#ignore_on_cluster_for_replicated_udf_queries} 



<SettingsInfoBlock type="Bool" default_value="0" />

レプリケートされた UDF 管理クエリのための ON CLUSTER 句を無視します。
## implicit_select {#implicit_select} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "新しい設定。" }]}]}/>

先頭に SELECT キーワードのない単純な SELECT クエリを書くことを許可します。これにより、計算機のような使用法が容易になります。例えば、`1 + 2` は有効なクエリになります。

`clickhouse-local` ではデフォルトで有効になっており、明示的に無効にすることができます。
## implicit_table_at_top_level {#implicit_table_at_top_level} 



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": ""},{"label": "新しい設定。clickhouse-localで使用されます。"}]}]}/>

空でない場合、最上位レベルで FROM なしのクエリは、system.oneの代わりにこのテーブルから読み取ります。

これは、clickhouse-local で入力データ処理に使用されます。
この設定はユーザーによって明示的に設定できますが、このタイプの使用を目的とはしていません。

サブクエリには、この設定の影響はありません（スカラ、FROM、IN サブクエリのいずれか）。
UNION、INTERSECT、EXCEPT チェーンの最上位レベルの SELECT は、この設定の影響を受け、括弧内のグループ化に関係なく均一に扱われます。
この設定がビューおよび分散クエリにどのように影響するかは不明です。

この設定は、テーブル名を受け入れます（この場合、テーブルは現在のデータベースから解決されます）または 'database.table' の形式の修飾名を受け入れます。
データベースおよびテーブル名は引用符を付けずに指定する必要があります。単純な識別子のみが許可されます。
## implicit_transaction {#implicit_transaction} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

有効にし、まだトランザクション内でない場合、クエリをフルトランザクション内にラップします（開始 + コミットまたはロールバック）。
## input_format_parallel_parsing {#input_format_parallel_parsing} 



<SettingsInfoBlock type="Bool" default_value="1" />

データ形式の順序保存並列解析を有効または無効にします。[TSV](../../interfaces/formats.md/#tabseparated)、[TSKV](../../interfaces/formats.md/#tskv)、[CSV](../../interfaces/formats.md/#csv)、および[JSONEachRow](../../interfaces/formats.md/#jsoneachrow)形式に対してのみサポートされています。

可能な値：

- 1 — 有効。
- 0 — 無効。
## insert_allow_materialized_columns {#insert_allow_materialized_columns} 



<SettingsInfoBlock type="Bool" default_value="0" />

この設定が有効な場合、INSERT にマテリアライズ列を許可します。
## insert_deduplicate {#insert_deduplicate} 



<SettingsInfoBlock type="Bool" default_value="1" />

`INSERT` に対するブロック重複削除を有効または無効にします（Replicated* テーブル用）。

可能な値：

- 0 — 無効。
- 1 — 有効。

デフォルトでは、`INSERT` ステートメントによってレプリケートテーブルに挿入されたブロックは重複削除されます（[データレプリケーション](../../engines/table-engines/mergetree-family/replication.md)を参照）。
レプリケートされたテーブルのデフォルトでは、各パーティションに対して最新の 100 ブロックのみが重複削除されます（[replicated_deduplication_window](merge-tree-settings.md/#replicated_deduplication_window)、[replicated_deduplication_window_seconds](merge-tree-settings.md/#replicated_deduplication_window_seconds)を参照）。
重複削除されていないテーブルの場合は、[non_replicated_deduplication_window](merge-tree-settings.md/#non_replicated_deduplication_window)を参照してください。
## insert_deduplication_token {#insert_deduplication_token} 

この設定により、ユーザーは MergeTree/ReplicatedMergeTree で独自の重複排除セマンティクスを提供できます。
例えば、各 INSERT ステートメントで設定に対してユニークな値を提供することにより、
ユーザーは同じ挿入データが重複排除されることを回避できます。

可能な値：

- 任意の文字列

`insert_deduplication_token` は、空でないときにのみ重複排除に使用されます。

レプリケートされたテーブルのデフォルトでは、各パーティションに対して最新の 100 の挿入のみが重複排除されます（[replicated_deduplication_window](merge-tree-settings.md/#replicated_deduplication_window)、[replicated_deduplication_window_seconds](merge-tree-settings.md/#replicated_deduplication_window_seconds)を参照）。
重複削除されていないテーブルの場合は、[non_replicated_deduplication_window](merge-tree-settings.md/#non_replicated_deduplication_window)を参照してください。

:::note
`insert_deduplication_token` はパーティションレベルで動作します（`insert_deduplication` チェックサムと同じです）。複数のパーティションが同じ `insert_deduplication_token` を持つことができます。
:::

例：

```sql
CREATE TABLE test_table
( A Int64 )
ENGINE = MergeTree
ORDER BY A
SETTINGS non_replicated_deduplication_window = 100;

INSERT INTO test_table SETTINGS insert_deduplication_token = 'test' VALUES (1);

-- 次の挿入は、insert_deduplication_token が異なるため、重複排除されません
INSERT INTO test_table SETTINGS insert_deduplication_token = 'test1' VALUES (1);

-- 次の挿入は、insert_deduplication_token が以前のものの1つと同じであるため、重複排除されます
INSERT INTO test_table SETTINGS insert_deduplication_token = 'test' VALUES (2);

SELECT * FROM test_table

┌─A─┐
│ 1 │
└───┘
┌─A─┐
│ 1 │
└───┘

## insert_keeper_fault_injection_probability {#insert_keeper_fault_injection_probability} 



<SettingsInfoBlock type="Float" default_value="0" />

INSERT 中の keeper リクエストの故障の近似確率。有効な値は [0.0f, 1.0f] の範囲です。
## insert_keeper_fault_injection_seed {#insert_keeper_fault_injection_seed} 



<SettingsInfoBlock type="UInt64" default_value="0" />

0 - ランダムシード、そうでなければ、設定値
## insert_keeper_max_retries {#insert_keeper_max_retries} 



<SettingsInfoBlock type="UInt64" default_value="20" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.2"},{"label": "20"},{"label": "INSERT 時に Keeper に再接続を有効にして、信頼性を向上させます。"}]}]}/>

この設定は、レプリケートされた MergeTree に挿入中の ClickHouse Keeper (または ZooKeeper) リクエストの最大再試行回数を設定します。ネットワークエラー、Keeper セッションタイムアウト、またはリクエストタイムアウトのために失敗した Keeper リクエストのみが再試行の対象となります。

可能な値：

- 正の整数。
- 0 — 再試行は無効

クラウドデフォルト値: `20`。

Keeper リクエストの再試行は、いくつかのタイムアウトの後に行われます。このタイムアウトは次の設定によって制御されます：`insert_keeper_retry_initial_backoff_ms`、`insert_keeper_retry_max_backoff_ms`。
最初の再試行は `insert_keeper_retry_initial_backoff_ms` タイムアウトの後に行われます。次のタイムアウトは次のように計算されます：

timeout = min(insert_keeper_retry_max_backoff_ms, latest_timeout * 2)

例えば、`insert_keeper_retry_initial_backoff_ms=100`、`insert_keeper_retry_max_backoff_ms=10000` および `insert_keeper_max_retries=8` の場合、タイムアウトは `100, 200, 400, 800, 1600, 3200, 6400, 10000` になります。

障害耐性の他に、再試行はユーザーエクスペリエンスを向上させることを目的としています。これにより、Keeper が再起動している間に INSERT 実行中にエラーを返さないようにできます（例：アップグレードによるもの）。
## insert_keeper_retry_initial_backoff_ms {#insert_keeper_retry_initial_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="100" />

INSERT クエリ実行中に失敗した Keeper リクエストを再試行するための初期タイムアウト（ミリ秒単位）

可能な値：

- 正の整数。
- 0 — タイムアウトなし
## insert_keeper_retry_max_backoff_ms {#insert_keeper_retry_max_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="10000" />

INSERT クエリ実行中に失敗した Keeper リクエストを再試行するための最大タイムアウト（ミリ秒単位）

可能な値：

- 正の整数。
- 0 — 最大タイムアウトに制限はありません
## insert_null_as_default {#insert_null_as_default} 



<SettingsInfoBlock type="Bool" default_value="1" />

非 [nullable](/sql-reference/data-types/nullable) データ型のカラムに [NULL](/sql-reference/syntax#null) の代わりに [default values](/sql-reference/statements/create/table#default_values) を挿入することを有効または無効にします。
カラムのタイプが非nullableであり、この設定が無効な場合、`NULL` を挿入すると例外が発生します。カラムのタイプが nullable の場合、`NULL` 値は、この設定に関係なくそのまま挿入されます。

この設定は、[INSERT ... SELECT](../../sql-reference/statements/insert-into.md/#inserting-the-results-of-select) クエリに適用されます。`SELECT` サブクエリは、`UNION ALL` 句で連結できることに注意してください。

可能な値：

- 0 — 非 nullable カラムに `NULL` を挿入すると例外が発生します。
- 1 — デフォルトのカラム値が `NULL` の代わりに挿入されます。
## insert_quorum {#insert_quorum} 



<SettingsInfoBlock type="UInt64Auto" default_value="0" />

:::note
この設定は SharedMergeTree には適用されません。詳細については、[SharedMergeTree の整合性](/cloud/reference/shared-merge-tree#consistency)を参照してください。
:::

クオラム書き込みを有効にします。

- `insert_quorum < 2` の場合、クオラム書き込みは無効になります。
- `insert_quorum >= 2` の場合、クオラム書き込みは有効になります。
- `insert_quorum = 'auto'` の場合、過半数の数（`number_of_replicas / 2 + 1`）をクオラム番号として使用します。

クオラム書き込み

`INSERT` は、ClickHouse が `insert_quorum_timeout` の間に `insert_quorum` のレプリカにデータを書き込むことに成功しない限り成功しません。理由の如何にかかわらず、成功した書き込みのレプリカの数が `insert_quorum` に到達しない場合、書き込みは失敗と見なされ、ClickHouse はすでに書き込まれたすべてのレプリカから挿入されたブロックを削除します。

`insert_quorum_parallel` が無効な場合、クオラム内のすべてのレプリカは一貫性があります。つまり、すべての以前の `INSERT` クエリからのデータを含みます（`INSERT` シーケンスは線形化されます）。`insert_quorum` および `insert_quorum_parallel` が無効な場合に書き込まれたデータを読み取るときは、[select_sequential_consistency](#select_sequential_consistency)を使用して `SELECT` クエリに対して逐次的一貫性をオンにすることができます。

ClickHouse は例外を生成します：

- クエリの時点で使用可能なレプリカの数が `insert_quorum` より少ない場合。
- `insert_quorum_parallel` が無効で、前のブロックがまだ `insert_quorum` のレプリカに挿入されていない状態でデータを書き込もうとする試みが行われた場合。この状況は、ユーザーが前の `INSERT` クエリが完了する前に同じテーブルに別の `INSERT` クエリを実行しようとした場合に発生する可能性があります。

参照：

- [insert_quorum_timeout](#insert_quorum_timeout)
- [insert_quorum_parallel](#insert_quorum_parallel)
- [select_sequential_consistency](#select_sequential_consistency)
## insert_quorum_parallel {#insert_quorum_parallel} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.1"},{"label": "1"},{"label": "デフォルトで並列クオーラム挿入を使用します。これはシーケンシャルクオーラム挿入よりもずっと便利です。"}]}]}/>

:::note
この設定はSharedMergeTreeには適用されません。詳細については[SharedMergeTreeの一貫性](/cloud/reference/shared-merge-tree#consistency)を参照してください。
:::

クオーラム `INSERT` クエリの並列処理を有効または無効にします。これを有効にすると、前のクエリがまだ終了していない間に追加の `INSERT` クエリを送信できます。無効にすると、同じテーブルへの追加の書き込みは拒否されます。

可能な値：

- 0 — 無効。
- 1 — 有効。

参照：

- [insert_quorum](#insert_quorum)
- [insert_quorum_timeout](#insert_quorum_timeout)
- [select_sequential_consistency](#select_sequential_consistency)

## insert_quorum_timeout {#insert_quorum_timeout} 

<SettingsInfoBlock type="Milliseconds" default_value="600000" />

クオーラムへの書き込みタイムアウトをミリ秒単位で指定します。タイムアウトが経過し、書き込みがまだ行われていない場合、ClickHouseは例外を生成し、クライアントは同じブロックを同じまたは他のレプリカに書き込むためにクエリを再実行する必要があります。

参照：

- [insert_quorum](#insert_quorum)
- [insert_quorum_parallel](#insert_quorum_parallel)
- [select_sequential_consistency](#select_sequential_consistency)

## insert_shard_id {#insert_shard_id} 

<SettingsInfoBlock type="UInt64" default_value="0" />

`0` 以外の場合、データが同期的に挿入される[Distributed](/engines/table-engines/special/distributed)テーブルのシャードを指定します。

`insert_shard_id` の値が不正な場合、サーバーは例外を投げます。

`requested_cluster`におけるシャードの数を取得するには、サーバー設定を確認するか、以下のクエリを使用できます。

```sql
SELECT uniq(shard_num) FROM system.clusters WHERE cluster = 'requested_cluster';

可能な値：

- 0 — 無効。
- 対応する[Distributed](/engines/table-engines/special/distributed)テーブルの`1`から`shards_num`の間の任意の数字。

**例**

クエリ：

```sql
CREATE TABLE x AS system.numbers ENGINE = MergeTree ORDER BY number;
CREATE TABLE x_dist AS x ENGINE = Distributed('test_cluster_two_shards_localhost', currentDatabase(), x);
INSERT INTO x_dist SELECT * FROM numbers(5) SETTINGS insert_shard_id = 1;
SELECT * FROM x_dist ORDER BY number ASC;

結果：

```text
┌─number─┐
│      0 │
│      0 │
│      1 │
│      1 │
│      2 │
│      2 │
│      3 │
│      3 │
│      4 │
│      4 │
└────────┘

## interactive_delay {#interactive_delay} 

<SettingsInfoBlock type="UInt64" default_value="100000" />

リクエストの実行がキャンセルされたかどうかを確認し、進行状況を送信するためのマイクロ秒単位のインターバル。

## intersect_default_mode {#intersect_default_mode} 

<SettingsInfoBlock type="SetOperationMode" default_value="ALL" />

INTERSECTクエリにおけるデフォルトモードを設定します。可能な値：空文字列、'ALL'、'DISTINCT'。空の場合、モードなしのクエリは例外を投げます。

## join_algorithm {#join_algorithm} 

<SettingsInfoBlock type="JoinAlgorithm" default_value="direct,parallel_hash,hash" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "direct,parallel_hash,hash"},{"label": "'default'は明示的に指定された結合アルゴリズムのために非推奨となり、またparallel_hashはhashより好まれるようになりました。"}]}]}/>

使用する[JOIN](../../sql-reference/statements/select/join.md)アルゴリズムを指定します。

いくつかのアルゴリズムを指定でき、特定のクエリに対してはタイプ/厳密さとテーブルエンジンに基づいて利用可能なものが選択されます。

可能な値：

- grace_hash

 [Grace hash join](https://en.wikipedia.org/wiki/Hash_join#Grace_hash_join)が使用されます。Grace hashは、メモリ使用を制限しながら、高性能な複雑な結合を提供するアルゴリズムオプションを提供します。

1段階目のグレース結合は、右テーブルを読み取り、キー列のハッシュ値に基づいてNバケツに分割します（初期的にはNは`grace_hash_join_initial_buckets`です）。この過程は、各バケツが独立に処理できることを確保するために行われます。最初のバケツの行はメモリ内のハッシュテーブルに追加され、他はディスクに保存されます。ハッシュテーブルがメモリ制限（例：[`max_bytes_in_join`](/operations/settings/settings#max_bytes_in_join)で設定されたもの）を超えた場合、バケツの数が増加し、各行に割り当てられたバケツも変更されます。現在のバケツに属さない行はフラッシュされ、再割り当てされます。

 `INNER/LEFT/RIGHT/FULL ALL/ANY JOIN`をサポートしています。

- hash

 [Hash joinアルゴリズム](https://en.wikipedia.org/wiki/Hash_join)が使用されます。すべての組み合わせの種類と厳密さ、`JOIN ON`セクションで`OR`と結合された複数の結合キーをサポートする最も一般的な実装です。

 `hash`アルゴリズムを使用する場合、結合の右部分がRAMにアップロードされます。

- parallel_hash

 データをバケツに分割し、プロセスを高速化するために同時に複数のハッシュテーブルを構築する`hash`結合の変種です。

 `parallel_hash`アルゴリズムを使用する場合、結合の右部分がRAMにアップロードされます。

- partial_merge

 [ソートマージアルゴリズム](https://en.wikipedia.org/wiki/Sort-merge_join)の変種で、右テーブルのみが完全にソートされます。

 `RIGHT JOIN`および`FULL JOIN`は`ALL`厳密性（`SEMI`、`ANTI`、`ANY`、および`ASOF`はサポートされていません）でのみサポートされます。

 `partial_merge`アルゴリズムを使用する場合、ClickHouseはデータをソートし、ディスクにダンプします。ClickHouse内の`partial_merge`アルゴリズムは、古典的な実装とは若干異なります。最初に、ClickHouseは結合キーで右テーブルをブロックごとにソートし、ソートされたブロックの最小・最大インデックスを作成します。次に、左テーブルの部分を`join key`でソートし、右テーブルに対してそれらを結合します。最小・最大インデックスも使用して、不要な右テーブルブロックをスキップします。

- direct

 このアルゴリズムは、右テーブルのストレージがキー・バリューリクエストをサポートしている場合に適用できます。

 `direct`アルゴリズムは、左テーブルからの行をキーとして使用して、右テーブルでルックアップを実行します。これは[Dictionary](/engines/table-engines/special/dictionary)または[EmbeddedRocksDB](../../engines/table-engines/integrations/embedded-rocksdb.md)などの特別なストレージのみでサポートされ、`LEFT`および`INNER` JOINのみが対象です。

- auto

 `auto`に設定されている場合、最初に`hash`結合が試みられ、メモリ制限が違反されると、アルゴリズムが動的に別のアルゴリズムに切り替わります。

- full_sorting_merge

 [ソートマージアルゴリズム](https://en.wikipedia.org/wiki/Sort-merge_join)で、結合前にテーブルを完全にソートします。

- prefer_partial_merge

 ClickHouseは可能な場合、常に`partial_merge`結合を使用しようとし、それ以外の場合は`hash`を使用します。*非推奨*、`partial_merge,hash`と同等です。

- default (非推奨)

 レガシー値であり、もう使用しないでください。`direct,hash`と同じで、すなわち直結合とハッシュ結合を使用しようとします（この順序で）。

## join_any_take_last_row {#join_any_take_last_row} 

<SettingsInfoBlock type="Bool" default_value="0" />

`ANY`厳密性のある結合操作の動作を変更します。

:::note
この設定は、[Join](../../engines/table-engines/special/join.md)エンジンテーブルとの`JOIN`操作のみに適用されます。
:::

可能な値：

- 0 — 右テーブルに一致する行が複数ある場合、最初に見つかった行のみが結合されます。
- 1 — 右テーブルに一致する行が複数ある場合、最後に見つかった行のみが結合されます。

参照：

- [JOIN句](/sql-reference/statements/select/join)
- [Joinテーブルエンジン](../../engines/table-engines/special/join.md)
- [join_default_strictness](#join_default_strictness)

## join_default_strictness {#join_default_strictness} 

<SettingsInfoBlock type="JoinStrictness" default_value="ALL" />

[JOIN句](/sql-reference/statements/select/join)のデフォルト厳密性を設定します。

可能な値：

- `ALL` — 右テーブルに一致する行が複数ある場合、ClickHouseは一致する行からの[直積](https://en.wikipedia.org/wiki/Cartesian_product)を作成します。これは標準SQLからの通常の`JOIN`動作です。
- `ANY` — 右テーブルに一致する行が複数ある場合、最初に見つかった行のみが結合されます。右テーブルに一致する行が1つだけある場合、`ANY`と`ALL`の結果は同じです。
- `ASOF` — 一致が不確実なシーケンスを結合するために使用します。
- 空文字列 — クエリ内に`ALL`または`ANY`が指定されていない場合、ClickHouseは例外を投げます。

## join_on_disk_max_files_to_merge {#join_on_disk_max_files_to_merge} 

<SettingsInfoBlock type="UInt64" default_value="64" />

ディスク上で実行されるMergeJoin操作において、並列ソートに許可されるファイルの数を制限します。

設定の値が大きいほど、より多くのRAMが使用され、ディスクI/Oが減少します。

可能な値：

- 2から始まる任意の正の整数。

## join_output_by_rowlist_perkey_rows_threshold {#join_output_by_rowlist_perkey_rows_threshold} 

<SettingsInfoBlock type="UInt64" default_value="5" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "5"},{"label": "ハッシュ結合における行リストを出力するか否かを決定するための右テーブルのキーごとの平均行数の下限。"}]}]}/>

ハッシュ結合における行リストを出力するか否かを決定するための右テーブルのキーごとの平均行数の下限。

## join_overflow_mode {#join_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

次のいずれかの結合制限が達成されたときにClickHouseが実行するアクションを定義します：

- [max_bytes_in_join](/operations/settings/settings#max_bytes_in_join)
- [max_rows_in_join](/operations/settings/settings#max_rows_in_join)

可能な値：

- `THROW` — ClickHouseは例外を投げて操作を中断します。
- `BREAK` — ClickHouseは操作を中断し、例外を投げません。

デフォルト値：`THROW`。

**関連情報**

- [JOIN句](/sql-reference/statements/select/join)
- [Joinテーブルエンジン](/engines/table-engines/special/join)

## join_to_sort_maximum_table_rows {#join_to_sort_maximum_table_rows} 

<ExperimentalBadge/>

<SettingsInfoBlock type="UInt64" default_value="10000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "10000"},{"label": "左または内結合でキーによって右テーブルを再範囲するかどうかを決定するための右テーブルの最大行数。"}]}]}/>

左または内結合でキーによって右テーブルを再範囲するかどうかを決定するための右テーブルの最大行数。

## join_to_sort_minimum_perkey_rows {#join_to_sort_minimum_perkey_rows} 

<ExperimentalBadge/>

<SettingsInfoBlock type="UInt64" default_value="40" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "40"},{"label": "左または内結合でキーによって右テーブルを再範囲するかどうかを決定するための右テーブルのキーごとの平均行数の下限。この設定は、スパーステーブルキーに対して最適化が適用されないことを保証します。"}]}]}/>

左または内結合でキーによって右テーブルを再範囲するかどうかを決定するための右テーブルのキーごとの平均行数の下限。この設定は、スパーステーブルキーに対して最適化が適用されないことを保証します。

## join_use_nulls {#join_use_nulls} 

<SettingsInfoBlock type="Bool" default_value="0" />

[JOIN](../../sql-reference/statements/select/join.md)の動作タイプを設定します。テーブルをマージする際に、空のセルが出現する場合があります。この設定に基づいてClickHouseはそれらを異なって埋めます。

可能な値：

- 0 — 空のセルは対応するフィールドタイプのデフォルト値で埋められます。
- 1 — `JOIN`は標準SQLと同じように行動します。対応するフィールドタイプは[Nullable](/sql-reference/data-types/nullable)に変換され、空のセルは[NULL](/sql-reference/syntax)で埋められます。

## joined_subquery_requires_alias {#joined_subquery_requires_alias} 

<SettingsInfoBlock type="Bool" default_value="1" />

結合されたサブクエリとテーブル関数に対して、正しい名前の資格のためにエイリアスを持つ必要があります。

## kafka_disable_num_consumers_limit {#kafka_disable_num_consumers_limit} 

<SettingsInfoBlock type="Bool" default_value="0" />

利用可能なCPUコアの数に依存するkafka_num_consumersの制限を無効にします。

## kafka_max_wait_ms {#kafka_max_wait_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="5000" />

再試行前に[Kafka](/engines/table-engines/integrations/kafka)からメッセージを読み取るための待機時間をミリ秒単位で指定します。

可能な値：

- 正の整数。
- 0 — 無限タイムアウト。

参照：

- [Apache Kafka](https://kafka.apache.org/)

## keeper_map_strict_mode {#keeper_map_strict_mode} 

<SettingsInfoBlock type="Bool" default_value="0" />

KeeperMapに対する操作中の追加チェックを強制します。例：既存のキーに対する挿入時に例外を投げる。

## keeper_max_retries {#keeper_max_retries} 

<SettingsInfoBlock type="UInt64" default_value="10" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "10"},{"label": "一般的なKeeper操作の最大再試行回数"}]}]}/>

一般的なKeeper操作の最大再試行回数。

## keeper_retry_initial_backoff_ms {#keeper_retry_initial_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="100" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "100"},{"label": "一般的なKeeper操作の初期バッファタイムアウト"}]}]}/>

一般的なKeeper操作の初期バッファタイムアウト。

## keeper_retry_max_backoff_ms {#keeper_retry_max_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="5000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "5000"},{"label": "一般的なKeeper操作の最大バッファタイムアウト"}]}]}/>

一般的なKeeper操作の最大バッファタイムアウト。

## least_greatest_legacy_null_behavior {#least_greatest_legacy_null_behavior} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "0"},{"label": "新しい設定"}]}]}/>

有効になっている場合、関数'least'および'greatest'はその引数のいずれかがNULLの場合にNULLを返します。

## legacy_column_name_of_tuple_literal {#legacy_column_name_of_tuple_literal} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.7"},{"label": "0"},{"label": "互換性の理由でのみこの設定を追加してください。これは、21.7未満のバージョンからより高いバージョンへのクラスターのローリングアップデートを行う際に'true'に設定することが意味を持ちます。"}]}]}/>

大きなタプルリテラルの要素名をハッシュではなくカラム名としてすべて列挙します。この設定は互換性の理由でのみ存在します。これは、21.7未満のバージョンからより高いバージョンへのクラスターのローリングアップデートを行う場合に'true'に設定することが意味があります。

## lightweight_delete_mode {#lightweight_delete_mode} 

<SettingsInfoBlock type="LightweightDeleteMode" default_value="alter_update" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "alter_update"},{"label": "新しい設定です。"}]}]}/>

軽量削除の一部として実行される内部更新クエリのモードです。

可能な値：
- `alter_update` - ヘビーウェイトの変化を生成する`ALTER UPDATE`クエリを実行します。
- `lightweight_update` - 可能な場合は軽量更新を実行し、そうでなければ`ALTER UPDATE`を実行します。
- `lightweight_update_force` - 可能な場合は軽量更新を実行し、そうでなければ例外を投げます。

## lightweight_deletes_sync {#lightweight_deletes_sync} 

<SettingsInfoBlock type="UInt64" default_value="2" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "2"},{"label": "「mutation_sync」と同じだが、軽量削除の実行のみを制御します。"}]}]}/>

[`mutations_sync`](#mutations_sync)と同じですが、軽量削除の実行のみを制御します。

可能な値：

- 0 - 変異は非同期で実行されます。
- 1 - クエリは現在のサーバーで軽量削除の完了を待機します。
- 2 - クエリはすべてのレプリカで軽量削除の完了を待機します（存在する場合）。

**関連情報**

- [ALTERクエリの同期性](../../sql-reference/statements/alter/index.md/#synchronicity-of-alter-queries)
- [変異](../../sql-reference/statements/alter/index.md/#mutations)

## limit {#limit} 

<SettingsInfoBlock type="UInt64" default_value="0" />

クエリ結果から取得する最大行数を設定します。[LIMIT](/sql-reference/statements/select/limit)句によって設定された値を調整し、この設定によって設定された制限を超えることはできません。

可能な値：

- 0 — 行数に制限はありません。
- 正の整数。

## live_view_heartbeat_interval {#live_view_heartbeat_interval} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Seconds" default_value="15" />

ライブクエリが生きていることを示すためのハートビート間隔（秒単位）。

## load_balancing {#load_balancing} 

<SettingsInfoBlock type="LoadBalancing" default_value="random" />

分散クエリ処理に使用されるレプリカ選択のアルゴリズムを指定します。

ClickHouseは次のレプリカ選択アルゴリズムをサポートしています：

- [ランダム](#load_balancing-random)（デフォルト）
- [最も近いホスト名](#load_balancing-nearest_hostname)
- [ホスト名レーベンシュタイン距離](#load_balancing-hostname_levenshtein_distance)
- [順番](#load_balancing-in_order)
- [最初またはランダム](#load_balancing-first_or_random)
- [ラウンドロビン](#load_balancing-round_robin)

参照：

- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)

### ランダム（デフォルト） {#load_balancing-random}

```sql
load_balancing = random

各レプリカのエラー数がカウントされます。クエリはエラーが最も少ないレプリカに送信され、複数ある場合はそのうちのいずれかに送信されます。
欠点：サーバーの近接性は考慮されていない。レプリカに異なるデータがある場合も、異なるデータが返されます。

### 最も近いホスト名 {#load_balancing-nearest_hostname}

```sql
load_balancing = nearest_hostname

各レプリカのエラー数がカウントされます。5分ごとに、エラー数が2で割られます。したがって、最近の時間のエラー数が指数平滑化方式で計算されます。最小のエラー数を持つレプリカが1つある場合（つまり、他のレプリカで最近エラーが発生した）、クエリはそのレプリカに送信されます。同じ最小エラー数を持つ複数のレプリカがある場合は、設定ファイルのサーバーのホスト名に最も似たホスト名を持つレプリカにクエリが送信されます。

例えば、example01-01-1とexample01-01-2は1つの位置で異なり、example01-01-1とexample01-02-2は2か所で異なります。
この方法は原始的に思えるかもしれませんが、ネットワークトポロジーに関する外部データを必要とせず、IPアドレスの比較も行いません。

したがって、同等のレプリカがある場合は、名前で最も近いものが優先されます。
同じサーバーにクエリを送信する場合、障害がない限り分散クエリも同じサーバーに送信されると考えられます。そのため、異なるデータがレプリカに配置されていても、クエリはほぼ同じ結果を返します。

### ホスト名レーベンシュタイン距離 {#load_balancing-hostname_levenshtein_distance}

```sql
load_balancing = hostname_levenshtein_distance

`nearest_hostname`と同様ですが、ホスト名を[レーベンシュタイン距離](https://en.wikipedia.org/wiki/Levenshtein_distance)の観点から比較します。例えば：

```text
example-clickhouse-0-0 ample-clickhouse-0-0
1

example-clickhouse-0-0 example-clickhouse-1-10
2

example-clickhouse-0-0 example-clickhouse-12-0
3

### 順番 {#load_balancing-in_order}

```sql
load_balancing = in_order

同じエラー数を持つレプリカにアクセスする際、構成ファイルに指定された順序に従います。
この方法は、どのレプリカが好ましいかを正確に知っている場合に適しています。

### 最初またはランダム {#load_balancing-first_or_random}

```sql
load_balancing = first_or_random

このアルゴリズムはセット内の最初のレプリカを選択するか、最初のレプリカが利用できない場合はランダムなレプリカを選択します。これは、クロスレプリケーショントポロジー設定で効果的ですが、他の設定では無駄です。

`first_or_random`アルゴリズムは、`in_order`アルゴリズムの問題を解決します。`in_order`を使用する場合、1つのレプリカがダウンすると、次のレプリカに二重の負荷がかかり、残りのレプリカは通常のトラフィックに対処します。`first_or_random`アルゴリズムを使用すると、まだ利用可能なレプリカ間で負荷が均等に分配されます。

最初のレプリカを明示的に定義することもできます。設定`load_balancing_first_offset`を使用して、クエリのワークロードをレプリカに再バランスフォーカスするためにより多くの制御ができます。

### ラウンドロビン {#load_balancing-round_robin}

```sql
load_balancing = round_robin

このアルゴリズムは、同じエラー数を持つレプリカ間でラウンドロビンポリシーを使用します（`round_robin`ポリシーのクエリのみがカウントされます）。

## load_balancing_first_offset {#load_balancing_first_offset} 

<SettingsInfoBlock type="UInt64" default_value="0" />

FIRST_OR_RANDOM負荷分散戦略を使用する際に、クエリを優先的に送信するレプリカを指定します。

## load_marks_asynchronously {#load_marks_asynchronously} 

<SettingsInfoBlock type="Bool" default_value="0" />

MergeTreeマークを非同期で読み込む。

## local_filesystem_read_method {#local_filesystem_read_method} 

<SettingsInfoBlock type="String" default_value="pread_threadpool" />

ローカルファイルシステムからデータを読み取るための方法のいずれか： read, pread, mmap, io_uring, pread_threadpool。

'io_uring'メソッドは実験的であり、Log, TinyLog, StripeLog, File, Set、そして同時に読み書きが行われる場合に適用可能な他のテーブルでは機能しません。
インターネット上で'io_uring'についての様々な記事を読んでも、それに目を奪われないでください。これはファイルを読み取るために優れた方法ではなく、小さなIOリクエストが大量にある場合の例外的なケースです。この場合はClickHouseでは問題ありません。'io_uring'を有効にする理由はありません。

## local_filesystem_read_prefetch {#local_filesystem_read_prefetch} 

<SettingsInfoBlock type="Bool" default_value="0" />

ローカルファイルシステムからのデータの読み取り時にプレフェッチを使用すべきです。

## lock_acquire_timeout {#lock_acquire_timeout} 

<SettingsInfoBlock type="Seconds" default_value="120" />

ロック要求が失敗するまでの待機時間（秒単位）を定義します。

ロックスタイムアウトは、テーブルでの読み書き操作の実行中にデッドロックを防ぐために使用されます。タイムアウトが経過し、ロック要求が失敗した場合、ClickHouseサーバーは「ロック試行がタイムアウトしました！デッドロックを回避しました。クライアントは再試行すべきです。」という例外をエラーコード`DEADLOCK_AVOIDED`で投げます。

可能な値：

- 正の整数（秒単位）。
- 0 — ロックタイムアウトなし。

## log_comment {#log_comment} 

指定された`log_comment`フィールドの値とサーバーログのコメントテキストを指定します。

サーバーログの可読性を向上させるために使用できます。さらに、`system.query_log`から[clickhouse-test](../../development/tests.md)を実行した後にテストに関連するクエリを選択するのに役立ちます。

可能な値：

- [max_query_size](#max_query_size)より長くない任意の文字列。max_query_sizeを超えると、サーバーは例外を投げます。

**例**

クエリ：

```sql
SET log_comment = 'log_commentテスト', log_queries = 1;
SELECT 1;
SYSTEM FLUSH LOGS;
SELECT type, query FROM system.query_log WHERE log_comment = 'log_commentテスト' AND event_date >= yesterday() ORDER BY event_time DESC LIMIT 2;

結果：

```text
┌─type────────┬─query─────┐
│ QueryStart  │ SELECT 1; │
│ QueryFinish │ SELECT 1; │
└─────────────┴───────────┘

## log_formatted_queries {#log_formatted_queries} 

<SettingsInfoBlock type="Bool" default_value="0" />

[system.query_log](../../operations/system-tables/query_log.md)システムテーブルにフォーマットされたクエリをログできるようにします（`formatted_query`カラムが[system.query_log](../../operations/system-tables/query_log.md)に埋め込まれます）。

可能な値：

- 0 — フォーマットされたクエリはシステムテーブルにログされません。
- 1 — フォーマットされたクエリはシステムテーブルにログされます。

## log_processors_profiles {#log_processors_profiles} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "デフォルトで有効"}]}]}/>

プロセッサがデータの実行/待機中に費やした時間を`system.processors_profile_log`テーブルに書き込みます。

参照：

- [`system.processors_profile_log`](../../operations/system-tables/processors_profile_log.md)
- [`EXPLAIN PIPELINE`](../../sql-reference/statements/explain.md/#explain-pipeline)

## log_profile_events {#log_profile_events} 

<SettingsInfoBlock type="Bool" default_value="1" />

クエリパフォーマンス統計をquery_log, query_thread_logおよびquery_views_logに記録します。

## log_queries {#log_queries} 

<SettingsInfoBlock type="Bool" default_value="1" />

クエリログの設定。

この設定によりClickHouseに送信されたクエリは、[query_log](../../operations/server-configuration-parameters/settings.md/#query_log)サーバー設定パラメーターのルールに従ってログに記録されます。

例：

```text
log_queries=1

## log_queries_cut_to_length {#log_queries_cut_to_length} 

<SettingsInfoBlock type="UInt64" default_value="100000" />

クエリの長さが指定された閾値（バイト単位）を超える場合、クエリを書く際にログにカットされます。また、通常のテキストログに出力されるクエリの長さも制限されます。

## log_queries_min_query_duration_ms {#log_queries_min_query_duration_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

有効になっている場合（ゼロ以外）、この設定の値よりも速いクエリはログに記録されません（これは[MySQLスロークエリログ](https://dev.mysql.com/doc/refman/5.7/slow-query-log.html)の`long_query_time`と考えることができ、基本的にこれにより以下のテーブルには見つかりません）。

- `system.query_log`
- `system.query_thread_log`

次のタイプのクエリのみがログに記録されます：

- `QUERY_FINISH`
- `EXCEPTION_WHILE_PROCESSING`

- タイプ：ミリ秒
- デフォルト値：0（いかなるクエリも）

## log_queries_min_type {#log_queries_min_type} 

<SettingsInfoBlock type="LogQueriesType" default_value="QUERY_START" />

ログする`query_log`の最小タイプです。

可能な値：
- `QUERY_START` (`=1`)
- `QUERY_FINISH` (`=2`)
- `EXCEPTION_BEFORE_START` (`=3`)
- `EXCEPTION_WHILE_PROCESSING` (`=4`)

どのエンティティが`query_log`に入るか制限するためにも使用できます。たとえば、エラーのみを興味深く思う場合、`EXCEPTION_WHILE_PROCESSING`を使用できます：

```text
log_queries_min_type='EXCEPTION_WHILE_PROCESSING'

## log_queries_probability {#log_queries_probability} 

<SettingsInfoBlock type="Float" default_value="1" />

[query_log](../../operations/system-tables/query_log.md)、[query_thread_log](../../operations/system-tables/query_thread_log.md)、および[query_views_log](../../operations/system-tables/query_views_log.md)システムテーブルに対して、指定された確率でランダムに選択されたクエリのみを書き込むことを許可します。これは、1秒あたりの多くのクエリで負荷を軽減するのに役立ちます。

可能な値：

- 0 — クエリはシステムテーブルにログされません。
- 0から1までの正の浮動小数点数。例えば、設定値が`0.5`の場合、約半分のクエリがシステムテーブルにログされます。
- 1 — すべてのクエリがシステムテーブルにログされます。

## log_query_settings {#log_query_settings} 

<SettingsInfoBlock type="Bool" default_value="1" />

クエリ設定をquery_logおよびOpenTelemetryスパンログに記録します。

## log_query_threads {#log_query_threads} 

<SettingsInfoBlock type="Bool" default_value="0" />

クエリスレッドロギングの設定。

この設定が`log_queries`がtrueの場合、ClickHouseによって実行されたクエリスレッドは、[query_thread_log](/operations/server-configuration-parameters/settings#query_thread_log)サーバー設定パラメータのルールに従ってログに記録されます。

可能な値：

- 0 — 無効。
- 1 — 有効。

**例**

```text
log_query_threads=1

## log_query_views {#log_query_views} 

<SettingsInfoBlock type="Bool" default_value="1" />

クエリビューのロギングを設定します。

この設定が有効な状態でClickHouseによって実行されたクエリには、関連するビュー（マテリアライズドビューまたはライブビュー）があり、それらは[query_views_log](/operations/server-configuration-parameters/settings#query_views_log)サーバー設定パラメータに記録されます。

例：

```text
log_query_views=1

## low_cardinality_allow_in_native_format {#low_cardinality_allow_in_native_format} 

<SettingsInfoBlock type="Bool" default_value="1" />

[Native](../../interfaces/formats.md/#native)形式で[LowCardinality](../../sql-reference/data-types/lowcardinality.md)データタイプの使用を許可または制限します。

`LowCardinality`の使用が制限されている場合、ClickHouseサーバーは`SELECT`クエリの場合、`LowCardinality`列を通常の列に変換し、`INSERT`クエリの場合、通常の列を`LowCardinality`列に変換します。

この設定は、主に`LowCardinality`データタイプをサポートしていないサードパーティのクライアント向けに必要です。

可能な値：

- 1 — `LowCardinality`の使用は制限されません。
- 0 — `LowCardinality`の使用が制限されています。
## low_cardinality_max_dictionary_size {#low_cardinality_max_dictionary_size} 



<SettingsInfoBlock type="UInt64" default_value="8192" />

共有グローバル辞書の最大行数を、[LowCardinality](../../sql-reference/data-types/lowcardinality.md)データ型に対してストレージファイルシステムに書き込むことができるように設定します。この設定は、辞書の成長が無制限の場合のRAMの問題を防ぎます。最大辞書サイズの制限によりエンコードできないすべてのデータは、ClickHouseによって通常の方法で書き込まれます。

可能な値:

- 任意の正の整数。
## low_cardinality_use_single_dictionary_for_part {#low_cardinality_use_single_dictionary_for_part} 



<SettingsInfoBlock type="Bool" default_value="0" />

データ部分に対して単一の辞書を使用するかどうかをオンまたはオフにします。

デフォルトでは、ClickHouseサーバーは辞書のサイズを監視し、辞書がオーバーフローすると次の辞書の書き込みを開始します。複数の辞書の作成を禁止するには、`low_cardinality_use_single_dictionary_for_part = 1`を設定します。

可能な値:

- 1 — データ部分の複数の辞書の作成が禁止されています。
- 0 — データ部分の複数の辞書の作成は禁止されていません。
## low_priority_query_wait_time_ms {#low_priority_query_wait_time_ms} 

<BetaBadge/>



<SettingsInfoBlock type="Milliseconds" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1000"},{"label": "新しい設定です。"}]}]}/>

クエリの優先順位付けメカニズムが使用されている場合（設定`priority`を参照）、低優先度のクエリは高優先度のクエリが終了するのを待ちます。この設定は、待機時間の長さを指定します。
## make_distributed_plan {#make_distributed_plan} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "新しい実験的設定です。"}]}]}/>

分散クエリプランを作成します。
## materialize_skip_indexes_on_insert {#materialize_skip_indexes_on_insert} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "挿入時にスキップインデックスのマテリアライゼーションを無効にする新しい設定を追加しました"}]}]}/>

INSERTでスキップインデックスを構築および保存します。無効にすると、スキップインデックスはマージ時または明示的なMATERIALIZE INDEXによって構築および保存されます。
## materialize_statistics_on_insert {#materialize_statistics_on_insert} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "挿入時に統計のマテリアライゼーションを無効にする新しい設定を追加しました"}]}]}/>

INSERTで統計を構築および挿入します。無効にすると、統計はマージ時または明示的なMATERIALIZE STATISTICSによって構築および保存されます。
## materialize_ttl_after_modify {#materialize_ttl_after_modify} 



<SettingsInfoBlock type="Bool" default_value="1" />

ALTER MODIFY TTLクエリの後に古いデータにTTLを適用します。
## materialized_views_ignore_errors {#materialized_views_ignore_errors} 



<SettingsInfoBlock type="Bool" default_value="0" />

MATERIALIZED VIEWのエラーを無視し、MVsに関係なく元のブロックをテーブルに渡すことを許可します。
## max_analyze_depth {#max_analyze_depth} 



<SettingsInfoBlock type="UInt64" default_value="5000" />

インタプリタによって実行される最大分析数。
## max_ast_depth {#max_ast_depth} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

クエリ構文木の最大ネスト深度。超過すると例外がスローされます。

:::note
この時点では、解析中にチェックされず、解析後にのみチェックされます。
これは、解析中に構文木が深すぎると作成される可能性があることを意味しますが、
クエリは失敗します。
:::
## max_ast_elements {#max_ast_elements} 



<SettingsInfoBlock type="UInt64" default_value="50000" />

クエリ構文木における要素の最大数。超過すると例外がスローされます。

:::note
この時点では、解析中にチェックされず、解析後にのみチェックされます。
これは、解析中に構文木が深すぎると作成される可能性があることを意味しますが、
クエリは失敗します。
:::
## max_autoincrement_series {#max_autoincrement_series} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1000"},{"label": "新しい設定です"}]}]}/>

`generateSeriesID`関数によって作成される系列の最大数の制限です。

各系列はKeeperのノードを表すため、数百万を超えないことが推奨されます。
## max_backup_bandwidth {#max_backup_bandwidth} 



<SettingsInfoBlock type="UInt64" default_value="0" />

特定のバックアップにおけるサーバーの最大読み取り速度（バイト毎秒）。ゼロは制限なしを意味します。
## max_block_size {#max_block_size} 



<SettingsInfoBlock type="NonZeroUInt64" default_value="65409" />

ClickHouseでは、データはブロックによって処理されます。ブロックはカラム部分のセットであり、単一のブロックに対する内部処理サイクルは効率的ですが、各ブロックを処理する際には目立ったコストがかかります。

`max_block_size`設定は、テーブルからデータを読み込む際に単一のブロックに含めることが推奨される最大行数を示します。`max_block_size`のサイズのブロックは必ずしもテーブルからロードされるわけではありません。ClickHouseが必要なデータが少ないと判断した場合、より小さいブロックが処理されます。

ブロックサイズは小さすぎないようにし、各ブロックを処理する際の目立ったコストを避ける必要があります。また、最初のブロックを処理した後にLIMIT句を持つクエリが迅速に実行されることを保証するため、あまり大きくない必要があります。`max_block_size`を設定する際の目標は、大量のカラムを複数のスレッドで抽出する際に過剰なメモリを消費せず、ある程度のキャッシュローカリティを保持することです。
## max_bytes_before_external_group_by {#max_bytes_before_external_group_by} 



<SettingsInfoBlock type="UInt64" default_value="0" />

クラウドのデフォルト値：レプリカあたりのメモリ量の半分。

外部メモリでの`GROUP BY`句の実行を有効または無効にします。
（[外部メモリでのGROUP BY](/sql-reference/statements/select/group-by#group-by-in-external-memory)参照）

可能な値:

- 単一の[GROUP BY](/sql-reference/statements/select/group-by)操作で使用できるRAMの最大量（バイト単位）。
- `0` — 外部メモリでの`GROUP BY`が無効にされます。

:::note
`GROUP BY`操作中のメモリ使用量がこのしきい値をバイトで超えた場合、
外部集計モードをアクティブにします（データをディスクにスピルします）。

推奨値は、利用可能なシステムメモリの半分です。
:::
## max_bytes_before_external_sort {#max_bytes_before_external_sort} 



<SettingsInfoBlock type="UInt64" default_value="0" />

クラウドのデフォルト値：レプリカあたりのメモリ量の半分。

外部メモリでの`ORDER BY`句の実行を有効または無効にします。[ORDER BYの実装の詳細](../../sql-reference/statements/select/order-by.md#implementation-details)を参照してください。
`ORDER BY`操作でのメモリ使用量がこのしきい値をバイトで超えた場合、外部ソートモード（データをディスクにスピルします）が有効になります。

可能な値:

- 単一の[ORDER BY](../../sql-reference/statements/select/order-by)操作で使用できるRAMの最大量（バイト単位）。
  推奨値は利用可能なシステムメモリの半分です。
- `0` — 外部メモリでの`ORDER BY`が無効にされます。
## max_bytes_before_remerge_sort {#max_bytes_before_remerge_sort} 



<SettingsInfoBlock type="UInt64" default_value="1000000000" />

ORDER BYとLIMITのケースで、メモリ使用量が指定されたしきい値を超えた場合、最終的なマージの前にブロックをマージする追加の手順を行い、トップLIMIT行のみを保持します。
## max_bytes_in_distinct {#max_bytes_in_distinct} 



<SettingsInfoBlock type="UInt64" default_value="0" />

DISTINCTを使用する際にハッシュテーブルによってメモリ内で使用される状態の最大バイト数（非圧縮バイト単位）。
## max_bytes_in_join {#max_bytes_in_join} 



<SettingsInfoBlock type="UInt64" default_value="0" />

テーブル結合に使用されるハッシュテーブルの最大バイト数。

この設定は[SELECT ... JOIN](/sql-reference/statements/select/join)操作および[Joinテーブルエンジン](/engines/table-engines/special/join)に適用されます。

クエリに結合が含まれる場合、ClickHouseは各中間結果についてこの設定をチェックします。

指定したリミットに達した場合、ClickHouseは異なるアクションを実行します。[join_overflow_mode](/operations/settings/settings#join_overflow_mode)設定を使用してアクションを選択します。

可能な値:

- 正の整数。
- 0 — メモリ制御が無効です。
## max_bytes_in_set {#max_bytes_in_set} 



<SettingsInfoBlock type="UInt64" default_value="0" />

サブクエリから作成されたIN句内のセットによって使用される最大バイト数（非圧縮データの）。
## max_bytes_ratio_before_external_group_by {#max_bytes_ratio_before_external_group_by} 



<SettingsInfoBlock type="Double" default_value="0.5" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0.5"},{"label": "デフォルトで自動ディスクスピルを有効にします。"}]}},{"id": "row-2","items":[{"label": "24.12"},{"label": "0"},{"label": "新しい設定です。"}]}]}/>

`GROUP BY`に許可される利用可能なメモリの比率。一度このしきい値に達すると、外部メモリが集計に使用されます。

例えば、`0.6`に設定されている場合、`GROUP BY`は実行開始時に利用可能なメモリの60%を使用することが許可され、その後外部集計を使用し始めます。
## max_bytes_ratio_before_external_sort {#max_bytes_ratio_before_external_sort} 



<SettingsInfoBlock type="Double" default_value="0.5" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0.5"},{"label": "デフォルトで自動ディスクスピルを有効にします。"}]}},{"id": "row-2","items":[{"label": "24.12"},{"label": "0"},{"label": "新しい設定です。"}]}]}/>

`ORDER BY`に許可される利用可能なメモリの比率。一度このしきい値に達すると、外部ソートが使用されます。

例えば、`0.6`に設定されている場合、`ORDER BY`は実行開始時に利用可能なメモリの60%を使用することが許可され、その後外部ソートを使用し始めます。
## max_bytes_to_read {#max_bytes_to_read} 



<SettingsInfoBlock type="UInt64" default_value="0" />

クエリ実行時にテーブルから読み取ることができる最大バイト数（非圧縮データの）。
この制限は処理された各データチャンクについてチェックされ、最も深いテーブル式にのみ適用され、リモートサーバーから読み取る際にはリモートサーバーでのみチェックされます。
## max_bytes_to_read_leaf {#max_bytes_to_read_leaf} 



<SettingsInfoBlock type="UInt64" default_value="0" />

分散クエリ実行時にリーフノードのローカルテーブルから読み取ることができる最大バイト数（非圧縮データの）。分散クエリは各シャード（リーフ）に複数のサブクエリを発行することができますが、この制限はリーフノードでの読み取り段階のみでチェックされ、ルートノードでの結果マージ段階では無視されます。

例えば、クラスターに2つのシャードがあり、それぞれのシャードに100バイトのデータが含まれている場合、`max_bytes_to_read=150`の設定を使用して両方のテーブルからすべてのデータを読み取る予定の分散クエリは、合計200バイトになるため失敗します。`max_bytes_to_read_leaf=150`のクエリは、リーフノードが最大100バイトを読み取るため成功します。

この制限は処理された各データチャンクについてチェックされます。

:::note
この設定は、`prefer_localhost_replica=1`と不安定です。
:::
## max_bytes_to_sort {#max_bytes_to_sort} 



<SettingsInfoBlock type="UInt64" default_value="0" />

ソート前の最大バイト数。ORDER BY操作に対して指定された量の非圧縮バイトを処理する必要がある場合、動作はデフォルトで設定された`sort_overflow_mode`によって決定されます。
## max_bytes_to_transfer {#max_bytes_to_transfer} 



<SettingsInfoBlock type="UInt64" default_value="0" />

GLOBAL IN/JOINセクションを実行する際にリモートサーバーに渡される、または一時テーブルに保存される最大バイト数（非圧縮データの）。
## max_columns_to_read {#max_columns_to_read} 



<SettingsInfoBlock type="UInt64" default_value="0" />

単一のクエリでテーブルから読み取ることができる最大カラム数。
クエリが指定されたカラム数を超えて読み取る必要がある場合、例外がスローされます。

:::tip
この設定は、あまりにも複雑なクエリを防ぐのに役立ちます。
:::

`0`の値は無制限を意味します。
## max_compress_block_size {#max_compress_block_size} 



<SettingsInfoBlock type="UInt64" default_value="1048576" />

テーブルに書き込むために圧縮される前の非圧縮データの最大ブロックサイズ。デフォルトは1,048,576（1 MiB）です。一般的に、ブロックサイズを小さくすると圧縮比がわずかに減少し、キャッシュローカリティのために圧縮および解凍の速度がわずかに向上し、メモリ消費が減少します。

:::note
これはエキスパートレベルの設定であり、ClickHouseに入門したばかりの場合は変更しない方が良いでしょう。
:::

圧縮用のブロック（バイトからなるメモリのチャンク）をクエリ処理用のブロック（テーブルからの行のセット）と混同しないでください。
## max_concurrent_queries_for_all_users {#max_concurrent_queries_for_all_users} 



<SettingsInfoBlock type="UInt64" default_value="0" />

この設定の値が現在処理されているクエリの数と等しいか小さい場合、例外をスローします。

例：全ユーザーに対して`max_concurrent_queries_for_all_users`を99に設定し、データベース管理者が自身のために100に設定して調査のためにクエリを実行できるようにすることができます。 

一つのクエリまたはユーザーの設定を変更しても、他のクエリには影響しません。

可能な値:

- 正の整数。
- 0 — 制限なし。

**例**

```xml
<max_concurrent_queries_for_all_users>99</max_concurrent_queries_for_all_users>

**関連情報**

- [max_concurrent_queries](/operations/server-configuration-parameters/settings#max_concurrent_queries)
## max_concurrent_queries_for_user {#max_concurrent_queries_for_user} 



<SettingsInfoBlock type="UInt64" default_value="0" />

単一ユーザーごとの同時処理クエリの最大数。

可能な値:

- 正の整数。
- 0 — 制限なし。

**例**

```xml
<max_concurrent_queries_for_user>5</max_concurrent_queries_for_user>

## max_distributed_connections {#max_distributed_connections} 



<SettingsInfoBlock type="UInt64" default_value="1024" />

単一の分散テーブルに対する単一のクエリのために、リモートサーバーとの同時接続の最大数。この値はクラスター内のサーバーの数以上に設定することが推奨されます。

次のパラメータは、分散テーブルを作成する際（およびサーバーを起動する際）にのみ使用されるため、実行時に変更する必要はありません。
## max_distributed_depth {#max_distributed_depth} 



<SettingsInfoBlock type="UInt64" default_value="5" />

[Distributed](../../engines/table-engines/special/distributed.md)テーブルの再帰的クエリの最大深さを制限します。

値を超えると、サーバーは例外をスローします。

可能な値:

- 正の整数。
- 0 — 無制限の深さ。
## max_download_buffer_size {#max_download_buffer_size} 



<SettingsInfoBlock type="UInt64" default_value="10485760" />

各スレッドの並列ダウンロード用バッファの最大サイズ（例：URLエンジン用）。
## max_download_threads {#max_download_threads} 



<SettingsInfoBlock type="MaxThreads" default_value="4" />

データをダウンロードするための最大スレッド数（例：URLエンジン用）。
## max_estimated_execution_time {#max_estimated_execution_time} 



<SettingsInfoBlock type="Seconds" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "max_execution_timeとmax_estimated_execution_timeを分離しました。"}]}]}/>

クエリの推定実行時間の最大値（秒）。[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)が期限切れになると、各データブロックで確認されます。
## max_execution_speed {#max_execution_speed} 



<SettingsInfoBlock type="UInt64" default_value="0" />

1秒あたりの実行行数の最大値。[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)が期限切れになると、各データブロックで確認されます。実行速度が高い場合、実行速度が低下します。
## max_execution_speed_bytes {#max_execution_speed_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

1秒あたりの実行バイト数の最大値。[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)が期限切れになると、各データブロックで確認されます。実行速度が高い場合、実行速度が低下します。
## max_execution_time {#max_execution_time} 



<SettingsInfoBlock type="Seconds" default_value="0" />

クエリの最大実行時間（秒）。

`max_execution_time`パラメータは、理解するのが少し難しいかもしれません。
これは、現在のクエリ実行速度に対する補間に基づいて動作します
（この動作は[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)によって制御されます）。

ClickHouseは、推定実行時間が指定された`max_execution_time`を超えた場合、クエリを中断します。デフォルトでは、`timeout_before_checking_execution_speed`は10秒に設定されています。これは、クエリ実行が10秒経過した後、ClickHouseが総実行時間を推定し始めることを意味します。例えば、`max_execution_time`が3600秒（1時間）に設定されている場合、ClickHouseは推定総時間がこの3600秒の制限を超えるとクエリを終了します。もし`timeout_before_checking_execution_speed`を0に設定すると、ClickHouseは`max_execution_time`の基準としてクロック時間を使用します。

クエリの実行時間が指定された秒数を超えると、動作は`timeout_overflow_mode`によって決定されます。デフォルトでは、これは`throw`に設定されています。

:::note
タイムアウトはチェックされ、クエリはデータ処理中の指定された場所でのみ停止できます。
現在、集約状態のマージやクエリ分析中には停止できず、実際の実行時間はこの設定の値よりも高くなります。
:::
## max_execution_time_leaf {#max_execution_time_leaf} 



<SettingsInfoBlock type="Seconds" default_value="0" />

`max_execution_time`とセマン的に似ていますが、分散またはリモートクエリのリーフノードにのみ適用されます。

例えば、リーフノードでの実行時間を`10s`に制限したいが、初期ノードには制限を設けない場合、ネストされたサブクエリ設定内の`max_execution_time`の代わりに、次のように`max_execution_time_leaf`を使用できます：

```sql
SELECT count()
FROM cluster(cluster, view(SELECT * FROM t SETTINGS max_execution_time = 10));

クエリ設定として次のように記述します：

```sql
SELECT count()
FROM cluster(cluster, view(SELECT * FROM t)) SETTINGS max_execution_time_leaf = 10;

## max_expanded_ast_elements {#max_expanded_ast_elements} 



<SettingsInfoBlock type="UInt64" default_value="500000" />

エイリアスとアスタリスクの展開後のクエリ構文木の最大ノード数。
## max_fetch_partition_retries_count {#max_fetch_partition_retries_count} 



<SettingsInfoBlock type="UInt64" default_value="5" />

他のホストからパーティションを取得するための再試行回数。
## max_final_threads {#max_final_threads} 



<SettingsInfoBlock type="MaxThreads" default_value="'auto(N)'" />

[FINAL](/sql-reference/statements/select/from#final-modifier)修飾子を持つ`SELECT`クエリデータ読み取りフェーズに対する最大並列スレッド数を設定します。

可能な値:

- 正の整数。
- 0または1 — 無効。`SELECT`クエリは単一スレッドで実行されます。
## max_http_get_redirects {#max_http_get_redirects} 



<SettingsInfoBlock type="UInt64" default_value="0" />

許可される最大のHTTP GETリダイレクトホップ数。悪意のあるサーバーがリクエストを予期しないサービスにリダイレクトしないようにするための追加のセキュリティ対策を確保します。\n\n 外部サーバーが別のアドレスにリダイレクトして、それが企業のインフラに内部のものであるかのように見える場合、その内部サーバーにHTTPリクエストを送信することで、認証をバイパスした内部ネットワークから内部APIをリクエストしたり、RedisやMemcachedなどの他のサービスを呼び出したりする可能性があります。内部インフラストラクチャ（ローカルホスト上で実行されているものを含む）がない場合や、サーバーを信頼する場合には、リダイレクトを許可するのは安全です。ただし、URLがHTTPを使用している場合、リモートサーバーだけでなくISPや中間ネットワークすべてを信頼する必要があることに注意してください。 
## max_hyperscan_regexp_length {#max_hyperscan_regexp_length} 



<SettingsInfoBlock type="UInt64" default_value="0" />

[hyperscanマルチマッチ関数](/sql-reference/functions/string-search-functions#multimatchany)における各正規表現の最大長を定義します。

可能な値:

- 正の整数。
- 0 - 長さに制限はありません。

**例**

クエリ：

```sql
SELECT multiMatchAny('abcd', ['ab','bcd','c','d']) SETTINGS max_hyperscan_regexp_length = 3;

結果：

```text
┌─multiMatchAny('abcd', ['ab', 'bcd', 'c', 'd'])─┐
│                                              1 │
└────────────────────────────────────────────────┘

クエリ：

```sql
SELECT multiMatchAny('abcd', ['ab','bcd','c','d']) SETTINGS max_hyperscan_regexp_length = 2;

結果：

```text
Exception: 正規表現の長さが大きすぎます。

**関連情報**

- [max_hyperscan_regexp_total_length](#max_hyperscan_regexp_total_length)
## max_hyperscan_regexp_total_length {#max_hyperscan_regexp_total_length} 



<SettingsInfoBlock type="UInt64" default_value="0" />

各[hyperscanマルチマッチ関数](/sql-reference/functions/string-search-functions#multimatchany)におけるすべての正規表現の合計最大長を設定します。

可能な値:

- 正の整数。
- 0 - 長さに制限はありません。

**例**

クエリ：

```sql
SELECT multiMatchAny('abcd', ['a','b','c','d']) SETTINGS max_hyperscan_regexp_total_length = 5;

結果：

```text
┌─multiMatchAny('abcd', ['a', 'b', 'c', 'd'])─┐
│                                           1 │
└─────────────────────────────────────────────┘

クエリ：

```sql
SELECT multiMatchAny('abcd', ['ab','bc','c','d']) SETTINGS max_hyperscan_regexp_total_length = 5;

結果：

```text
Exception: 正規表現の合計長さが大きすぎます。

**関連情報**

- [max_hyperscan_regexp_length](#max_hyperscan_regexp_length)
## max_insert_block_size {#max_insert_block_size} 



<SettingsInfoBlock type="UInt64" default_value="1048449" />

テーブルに挿入するために構成されるブロックのサイズ（行数単位）。
この設定は、サーバーがブロックを構成する場合にのみ適用されます。
例えば、HTTPインターフェース経由でのINSERTの場合、サーバーはデータ形式を解析し、指定されたサイズのブロックを構成します。
ただし、clickhouse-clientを使用する場合、クライアントがデータを自分で解析するため、サーバー上の`max_insert_block_size`設定は挿入されたブロックのサイズには影響しません。
`INSERT SELECT`を使用する場合、この設定には目的がありません。なぜなら、データはSELECT後に構成された同じブロックを使用して挿入されるからです。

デフォルトは`max_block_size`よりも若干大きいです。この理由は、特定のテーブルエンジン（`*MergeTree`）が挿入された各ブロックに対してディスク上にデータ部分を構成するため、かなり大きなエンティティとなるためです。同様に、`*MergeTree`テーブルは挿入時にデータをソートします。十分なブロックサイズは、RAM内でより多くのデータをソートすることを可能にします。
## max_insert_delayed_streams_for_parallel_write {#max_insert_delayed_streams_for_parallel_write} 



<SettingsInfoBlock type="UInt64" default_value="0" />

最終部分フラッシュを遅延させるための最大ストリーム数（カラム）。デフォルト - 自動（基盤ストレージが並列書き込みをサポートしている場合は100、それ以外の場合は無効）。
## max_insert_threads {#max_insert_threads} 



<SettingsInfoBlock type="UInt64" default_value="0" />

`INSERT SELECT`クエリを実行するための最大スレッド数。

可能な値:

- 0（または1） — `INSERT SELECT`は並列実行されません。
- 正の整数。1より大きい値。

クラウドのデフォルト値：サービスのサイズに応じて2から4まで。

並列`INSERT SELECT`は、`SELECT`部分が並列で実行される場合のみ有効です。[max_threads](#max_threads)設定を参照してください。
より高い値は、より高いメモリ使用量をもたらします。
## max_joined_block_size_rows {#max_joined_block_size_rows} 



<SettingsInfoBlock type="UInt64" default_value="65409" />

JOIN結果の最大ブロックサイズ（結合アルゴリズムがこれをサポートする場合）。0は無制限を意味します。
## max_limit_for_vector_search_queries {#max_limit_for_vector_search_queries} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1000"},{"label": "新しい設定です。"}]}]}/>

この設定より大きなLIMITを持つSELECTクエリは、ベクトル類似インデックスを使用できません。ベクトル類似インデックスにおけるメモリのオーバーフローを防ぐために役立ちます。
## max_live_view_insert_blocks_before_refresh {#max_live_view_insert_blocks_before_refresh} 

<ExperimentalBadge/>



<SettingsInfoBlock type="UInt64" default_value="64" />

マージ可能なブロックが破棄され、クエリが再実行される最大挿入ブロック数を制限します。
## max_local_read_bandwidth {#max_local_read_bandwidth} 



<SettingsInfoBlock type="UInt64" default_value="0" />

ローカル読み取りの最大速度（バイト毎秒）。
## max_local_write_bandwidth {#max_local_write_bandwidth} 



<SettingsInfoBlock type="UInt64" default_value="0" />

ローカル書き込みの最大速度（バイト毎秒）。
## max_memory_usage {#max_memory_usage} 



<SettingsInfoBlock type="UInt64" default_value="0" />

クラウドのデフォルト値：レプリカのRAM量に依存します。

単一サーバー上でクエリを実行するために使用する最大RAM量。
`0`の値は無制限を意味します。

この設定は、利用可能なメモリ量やマシン全体のメモリ量を考慮しません。この制限は、単一のサーバー内の単一のクエリに適用されます。

`SHOW PROCESSLIST`を使用して、各クエリの現在のメモリ消費量を確認できます。
ピ－クメモリ消費量は各クエリについて追跡され、ログに書き込まれます。

メモリ使用量は、次の集計関数の状態のためには完全に追跡されません：
- `min`
- `max`
- `any`
- `anyLast`
- `argMin`
- `argMax`

メモリ消費は、[`max_memory_usage_for_user`](/operations/settings/settings#max_memory_usage_for_user)および[`max_server_memory_usage`](/operations/server-configuration-parameters/settings#max_server_memory_usage)のパラメータによっても制限されます。
## max_memory_usage_for_user {#max_memory_usage_for_user} 



<SettingsInfoBlock type="UInt64" default_value="0" />

単一サーバー上でクエリを実行するために使用する最大RAM量。0は無制限を意味します。

デフォルトでは、制限がありません（`max_memory_usage_for_user = 0`）。

[`max_memory_usage`](/operations/settings/settings#max_memory_usage)の説明も参照してください。

例えば、ユーザー名`clickhouse_read`のために`max_memory_usage_for_user`を1000バイトに設定したい場合、次の文を使用します。

```sql
ALTER USER clickhouse_read SETTINGS max_memory_usage_for_user = 1000;

正しく設定されたかどうかは、クライアントからログアウトし、再度ログインして、次の`getSetting`関数を使用して確認できます。

```sql
SELECT getSetting('max_memory_usage_for_user');

## max_network_bandwidth {#max_network_bandwidth} 



<SettingsInfoBlock type="UInt64" default_value="0" />

データ交換の速度を何バイト毎秒に制限します。この設定は、すべてのクエリに適用されます。

可能な値:

- 正の整数。
- 0 — 帯域幅制御が無効です。
## max_network_bandwidth_for_all_users {#max_network_bandwidth_for_all_users} 



<SettingsInfoBlock type="UInt64" default_value="0" />

データ交換の速度を何バイト毎秒に制限します。この設定は、サーバー上で同時に実行されているすべてのクエリに適用されます。

可能な値:

- 正の整数。
- 0 — データ速度制御が無効です。
## max_network_bandwidth_for_user {#max_network_bandwidth_for_user} 



<SettingsInfoBlock type="UInt64" default_value="0" />

特定のユーザーが実行しているすべての同時実行クエリに対し、データ交換の速度を何バイト毎秒に制限します。

可能な値:

- 正の整数。
- 0 — データ速度制御が無効です。
## max_network_bytes {#max_network_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

クエリを実行する際にネットワーク越しに受信または送信されるデータ量（バイト単位）を制限します。この設定は、各個別のクエリに適用されます。

可能な値:

- 正の整数。
- 0 — データ量制御が無効です。
## max_number_of_partitions_for_independent_aggregation {#max_number_of_partitions_for_independent_aggregation} 



<SettingsInfoBlock type="UInt64" default_value="128" />

最適化を適用する際のテーブル内のパーティションの最大数。
## max_os_cpu_wait_time_ratio_to_throw {#max_os_cpu_wait_time_ratio_to_throw} 



<SettingsInfoBlock type="Float" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "設定値が変更され、25.4にバックポートされました。"}]},{"id": "row-2","items":[{"label": "25.4"},{"label": "0"},{"label": "新しい設定です。"}]}]}/>

OSのCPU待ち時間（OSCPUWaitMicrosecondsメトリック）と稼働時間（OSCPUVirtualTimeMicrosecondsメトリック）の比率を最大限にして、クエリを拒否するかどうかを考慮します。線形補間が最小値と最大値の比率間で使用され、確率を計算します。確率はこの時点で1です。
## max_parallel_replicas {#max_parallel_replicas} 

<SettingsInfoBlock type="NonZeroUInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1000"},{"label": "Use up to 1000 parallel replicas by default."}]}]}/>

クエリを実行する際の各シャードの最大レプリカ数。

可能な値：

- 正の整数。

**追加情報**

このオプションは、使用される設定によって異なる結果を生成します。

:::note
この設定は、ジョインやサブクエリが関与している場合に、すべてのテーブルが特定の要件を満たさないときに不正確な結果を生成します。詳細については、[Distributed Subqueries and max_parallel_replicas](/operations/settings/settings#max_parallel_replicas)を参照してください。
:::
### `SAMPLE`キーを使用した並列処理

クエリは、複数のサーバーで並行して実行されるときに、処理を迅速に行える場合があります。しかし、次のような場合に、クエリのパフォーマンスが低下する可能性があります：

- サンプリングキーの位置がパーティショニングキー内で効率的な範囲スキャンを許可しない。
- テーブルにサンプリングキーを追加すると、他のカラムによるフィルタリングの効率が低下する。
- サンプリングキーが計算コストの高い式である。
- クラスターのレイテンシ分布に長い尾があるため、より多くのサーバーをクエリすることで全体的なクエリレイテンシが増加する。
### [parallel_replicas_custom_key](#parallel_replicas_custom_key)を使用した並列処理

この設定は、すべてのレプリケートテーブルに役立ちます。
## max_parser_backtracks {#max_parser_backtracks} 

<SettingsInfoBlock type="UInt64" default_value="1000000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1000000"},{"label": "Limiting the complexity of parsing"}]}]}/>

パーサーのバックトラックの最大回数（再帰降下パースプロセス中に異なる選択肢を試す回数）。
## max_parser_depth {#max_parser_depth} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

再帰降下パーサーにおける最大再帰深度を制限します。スタックサイズを制御できます。

可能な値：

- 正の整数。
- 0 — 再帰深度は無制限です。
## max_parsing_threads {#max_parsing_threads} 

<SettingsInfoBlock type="MaxThreads" default_value="'auto(N)'" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "0"},{"label": "Add a separate setting to control number of threads in parallel parsing from files"}]}]}/>

並列パースをサポートする入力形式でデータをパースするための最大スレッド数。デフォルトでは自動的に決定されます。
## max_partition_size_to_drop {#max_partition_size_to_drop} 

<SettingsInfoBlock type="UInt64" default_value="50000000000" />

クエリ実行時のパーティション削除の制限。値0は、制限なしでパーティションを削除できることを意味します。

クラウドのデフォルト値：1 TB。

:::note
このクエリ設定は、サーバー設定相当の値を上書きします。詳細は、[max_partition_size_to_drop](/operations/server-configuration-parameters/settings#max_partition_size_to_drop)を参照してください。
:::
## max_partitions_per_insert_block {#max_partitions_per_insert_block} 

<SettingsInfoBlock type="UInt64" default_value="100" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "19.5"},{"label": "100"},{"label": "Add a limit for the number of partitions in one block"}]}]}/>

1つの挿入ブロック内における最大パーティション数を制限し、ブロックにパーティションが多すぎる場合は例外がスローされます。

- 正の整数。
- `0` — 無制限のパーティション数。

**詳細**

データを挿入する際、ClickHouseは挿入されたブロック内のパーティション数を計算します。パーティション数が`max_partitions_per_insert_block`を超えると、ClickHouseは`throw_on_max_partitions_per_insert_block`に基づいて警告を記録するか、例外をスローします。例外には以下のテキストが含まれます：

> "1つのINSERTブロックに対するパーティションが多すぎます（`partitions_count` パーティション、制限は " + toString(max_partitions) + "）。この制限は、'max_partitions_per_insert_block' 設定によって制御されます。多くのパーティションが存在するのは一般的な誤解です。これにより、サーバーの起動が遅くなったり、INSERTクエリやSELECTクエリが遅くなるなど、重大なパフォーマンスへの悪影響をもたらします。テーブルの推奨総パーティション数は1000..10000未満です。パーティショニングはSELECTクエリの高速化を目的としたものではありません（ORDER BYキーで範囲クエリが高速になります）。パーティションはデータ操作（DROP PARTITIONなど）を目的としています。"

:::note
この設定は安全閾値であり、大量のパーティションを使用することは一般的な誤解です。
:::
## max_partitions_to_read {#max_partitions_to_read} 

<SettingsInfoBlock type="Int64" default_value="-1" />

単一のクエリでアクセス可能な最大パーティション数を制限します。

テーブル作成時に指定された設定値は、クエリレベルの設定を介して上書きできます。

可能な値：

- 正の整数
- `-1` - 無制限（デフォルト）

:::note
テーブルの設定で[`max_partitions_to_read`](/operations/settings/settings#max_partitions_to_read)を指定することもできます。
:::
## max_parts_to_move {#max_parts_to_move} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1000"},{"label": "New setting"}]}]}/>

1つのクエリで移動できるパーツの数を制限します。ゼロは無制限を意味します。
## max_query_size {#max_query_size} 

<SettingsInfoBlock type="UInt64" default_value="262144" />

SQLパーサによって解析されるクエリ文字列の最大バイト数。
INSERTクエリのVALUES句内のデータは、別のストリームパーサによって処理され（O(1) RAMを消費）、この制限の影響を受けません。

:::note
`max_query_size`はSQLクエリ内で設定できません（例: `SELECT now() SETTINGS max_query_size=10000`）。ClickHouseはクエリを解析するためのバッファを割り当てる必要があり、このバッファサイズは`max_query_size`設定によって決定され、クエリの実行前に設定する必要があります。
:::
## max_read_buffer_size {#max_read_buffer_size} 

<SettingsInfoBlock type="NonZeroUInt64" default_value="1048576" />

ファイルシステムから読み取るためのバッファの最大サイズ。
## max_read_buffer_size_local_fs {#max_read_buffer_size_local_fs} 

<SettingsInfoBlock type="UInt64" default_value="131072" />

ローカルファイルシステムから読み取るためのバッファの最大サイズ。0に設定された場合、max_read_buffer_sizeが使用されます。
## max_read_buffer_size_remote_fs {#max_read_buffer_size_remote_fs} 

<SettingsInfoBlock type="UInt64" default_value="0" />

リモートファイルシステムから読み取るためのバッファの最大サイズ。0に設定された場合、max_read_buffer_sizeが使用されます。
## max_recursive_cte_evaluation_depth {#max_recursive_cte_evaluation_depth} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "1000"},{"label": "Maximum limit on recursive CTE evaluation depth"}]}]}/>

再帰的CTE評価深度の最大限度
## max_remote_read_network_bandwidth {#max_remote_read_network_bandwidth} 

<SettingsInfoBlock type="UInt64" default_value="0" />

読み取り時のネットワーク上でのデータ交換の最大速度（バイト/秒）。
## max_remote_write_network_bandwidth {#max_remote_write_network_bandwidth} 

<SettingsInfoBlock type="UInt64" default_value="0" />

書き込み時のネットワーク上でのデータ交換の最大速度（バイト/秒）。
## max_replica_delay_for_distributed_queries {#max_replica_delay_for_distributed_queries} 

<SettingsInfoBlock type="UInt64" default_value="300" />

分散クエリのために遅延するレプリカを無効にします。[Replication](../../engines/table-engines/mergetree-family/replication.md)を参照してください。

秒単位で時間を設定します。レプリカの遅延が設定値以上である場合、そのレプリカは使用されません。

可能な値：

- 正の整数。
- 0 — レプリカの遅延はチェックされません。

ゼロ以外の遅延を持つレプリカの使用を防ぐには、このパラメータを1に設定してください。

これは、レプリケートテーブルを指す分散テーブルから`SELECT`を実行する際に使用されます。
## max_result_bytes {#max_result_bytes} 

<SettingsInfoBlock type="UInt64" default_value="0" />

結果サイズ（圧縮前）の制限。しきい値を超えると、データのブロック処理が停止しますが、結果の最後のブロックをカットすることはないため、結果のサイズはしきい値より大きくなる可能性があります。

**注意点**

このしきい値にはメモリ上の結果サイズも考慮されます。
結果サイズが小さくても、LowCardinalityカラムの辞書やAggregateFunctionカラムのArenaといったメモリ内の大きなデータ構造を参照することがあり、結果サイズが小さくてもしきい値を超える可能性があります。

:::warning
この設定はかなり低レベルであり、注意して使用する必要があります。
:::
## max_result_rows {#max_result_rows} 

<SettingsInfoBlock type="UInt64" default_value="0" />

クラウドのデフォルト値: `0`。

結果の行数を制限します。サブクエリ、および分散クエリの一部を実行する際、リモートサーバーでもチェックされます。
値が`0`の場合、制限は適用されません。

データのブロック処理がしきい値に達するとクエリは停止しますが、結果の最後のブロックをカットすることはなく、したがって結果のサイズはしきい値より大きくなる可能性があります。
## max_rows_in_distinct {#max_rows_in_distinct} 

<SettingsInfoBlock type="UInt64" default_value="0" />

DISTINCTを使用する際の異なる行の最大数。
## max_rows_in_join {#max_rows_in_join} 

<SettingsInfoBlock type="UInt64" default_value="0" />

テーブルを結合する際に使用されるハッシュテーブル内の行数を制限します。

この設定は[SELECT ... JOIN](/sql-reference/statements/select/join)の操作および[Join](/engines/table-engines/special/join)テーブルエンジンに適用されます。

クエリに複数のジョインが含まれている場合、ClickHouseはすべての中間結果に対してこの設定をチェックします。

制限に達した場合、ClickHouseは異なるアクションを実行できます。アクションを選択するには[`join_overflow_mode`](/operations/settings/settings#join_overflow_mode)設定を使用します。

可能な値：

- 正の整数。
- `0` — 無制限の行数。
## max_rows_in_set {#max_rows_in_set} 

<SettingsInfoBlock type="UInt64" default_value="0" />

サブクエリから作成されたIN句内のデータセットの最大行数。
## max_rows_in_set_to_optimize_join {#max_rows_in_set_to_optimize_join} 

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "Disable join optimization as it prevents from read in order optimization"}]}]}/>

結合前に、結合されたテーブルを互いの行セットでフィルタリングするためのセットの最大サイズ。

可能な値：

- 0 — 無効にする。
- 任意の正の整数。
## max_rows_to_group_by {#max_rows_to_group_by} 

<SettingsInfoBlock type="UInt64" default_value="0" />

集計から取得される一意のキーの最大数。この設定は、集約時のメモリ消費を制限することができます。

GROUP BY中に集約によって指定された行数（ユニークGROUP BYキー）が超えると、その動作は`group_by_overflow_mode`によって決定されます。デフォルトでは`throw`ですが、近似GROUP BYモードに切り替えることもできます。
## max_rows_to_read {#max_rows_to_read} 

<SettingsInfoBlock type="UInt64" default_value="0" />

クエリを実行する際にテーブルから読み取れる最大行数。
この制限は処理されるデータの各チャンクに対してチェックされ、最も深いテーブル式に適用され、リモートサーバーから読み取る場合にのみチェックされます。
## max_rows_to_read_leaf {#max_rows_to_read_leaf} 

<SettingsInfoBlock type="UInt64" default_value="0" />

分散クエリを実行する際に、リーフノード上のローカルテーブルから読み取れる最大行数。分散クエリは各シャード（リーフ）に複数のサブクエリを発行できますが、この制限はリーフノードの読み取り段階でのみチェックされ、ルートノードの結果マージ段階では無視されます。

たとえば、クラスターが2つのシャードで構成され、それぞれのシャードが100行のテーブルを含んでいるとします。設定`max_rows_to_read=150`の分散クエリは、合計200行を読み取ることになるため失敗します。`max_rows_to_read_leaf=150`のクエリは成功します。リーフノードは最大100行を読み取るためです。

この制限は処理されるデータの各チャンクに対してチェックされます。

:::note
この設定は`prefer_localhost_replica=1`と不安定です。
:::
## max_rows_to_sort {#max_rows_to_sort} 

<SettingsInfoBlock type="UInt64" default_value="0" />

ソート前の最大行数。これにより、ソート時のメモリ消費を制限できます。
ORDER BY操作のために処理されるレコードの指定された量を超えると、その動作は`sort_overflow_mode`によって決定され、デフォルトでは`throw`に設定されています。
## max_rows_to_transfer {#max_rows_to_transfer} 

<SettingsInfoBlock type="UInt64" default_value="0" />

GLOBAL IN/JOINセクションが実行されるときに、リモートサーバーに渡したり、一時テーブルに保存できる最大サイズ（行数）。
## max_sessions_for_user {#max_sessions_for_user} 

<SettingsInfoBlock type="UInt64" default_value="0" />

ClickHouseサーバーへの認証済みユーザーごとの同時セッションの最大数。

例：

```xml
<profiles>
    <single_session_profile>
        <max_sessions_for_user>1</max_sessions_for_user>
    </single_session_profile>
    <two_sessions_profile>
        <max_sessions_for_user>2</max_sessions_for_user>
    </two_sessions_profile>
    <unlimited_sessions_profile>
        <max_sessions_for_user>0</max_sessions_for_user>
    </unlimited_sessions_profile>
</profiles>
<users>
    <!-- ユーザーAliceは、ClickHouseサーバーに1回しか接続できません。 -->
    <Alice>
        <profile>single_session_user</profile>
    </Alice>
    <!-- ユーザーBobは、2つの同時セッションを使用できます。 -->
    <Bob>
        <profile>two_sessions_profile</profile>
    </Bob>
    <!-- ユーザーCharlesは、任意の数の同時セッションを使用できます。 -->
    <Charles>
        <profile>unlimited_sessions_profile</profile>
    </Charles>
</users>

可能な値：
- 正の整数
- `0` - 同時セッション数は無限（デフォルト）
## max_size_to_preallocate_for_aggregation {#max_size_to_preallocate_for_aggregation} 

<SettingsInfoBlock type="UInt64" default_value="1000000000000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "1000000000000"},{"label": "Enable optimisation for bigger tables."}]}, {"id": "row-2","items": [{"label": "22.12"},{"label": "100000000"},{"label": "This optimizes performance"}]}]}/>

集約前に、すべてのハッシュテーブルで合計何要素のためにスペースを事前に割り当てることが許可されるか。
## max_size_to_preallocate_for_joins {#max_size_to_preallocate_for_joins} 

<SettingsInfoBlock type="UInt64" default_value="1000000000000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "100000000"},{"label": "New setting."}]}, {"id": "row-2","items": [{"label": "24.12"},{"label": "1000000000000"},{"label": "Enable optimisation for bigger tables."}]}]}/>

結合前に、すべてのハッシュテーブルで合計何要素のためにスペースを事前に割り当てることが許可されるか。
## max_streams_for_merge_tree_reading {#max_streams_for_merge_tree_reading} 

<SettingsInfoBlock type="UInt64" default_value="0" />

ゼロでない場合、MergeTreeテーブルの読み取りストリームの数を制限します。
## max_streams_multiplier_for_merge_tables {#max_streams_multiplier_for_merge_tables} 

<SettingsInfoBlock type="Float" default_value="5" />

Mergeテーブルから読み取る際に、より多くのストリームを要求します。ストリームは、Mergeテーブルが使用するテーブルにまたがって広がります。これにより、作業のスレッド間でのより均等な分配が可能になり、マージされたテーブルのサイズが異なる場合に特に役立ちます。
## max_streams_to_max_threads_ratio {#max_streams_to_max_threads_ratio} 

<SettingsInfoBlock type="Float" default_value="1" />

スレッド数より多くのソースを使用して、スレッド間での作業をより均等に分配することができます。これは一時的な解決策として想定されており、将来的にはソースの数をスレッドの数に等しくし、各ソースが利用可能な作業を動的に選択できるようになる予定です。
## max_subquery_depth {#max_subquery_depth} 

<SettingsInfoBlock type="UInt64" default_value="100" />

クエリに指定された数のネストされたサブクエリが含まれる場合、例外がスローされます。

:::tip
これは、クラスターのユーザが過度に複雑なクエリを書かないようにするための健全性チェックを提供します。
:::
## max_table_size_to_drop {#max_table_size_to_drop} 

<SettingsInfoBlock type="UInt64" default_value="50000000000" />

クエリ実行時にテーブルを削除する際の制限。値0は、制限なしでテーブルをすべて削除できることを意味します。

クラウドのデフォルト値：1 TB。

:::note
このクエリ設定は、サーバー設定相当の値を上書きします。詳細は、[max_table_size_to_drop](/operations/server-configuration-parameters/settings#max_table_size_to_drop)を参照してください。
:::
## max_temporary_columns {#max_temporary_columns} 

<SettingsInfoBlock type="UInt64" default_value="0" />

クエリ実行時に同時にRAMに保持される必要がある一時的なカラムの最大数。中間計算の結果としてクエリが指定された数の一時カラムをメモリ内に生成する場合、例外がスローされます。

:::tip
この設定は、過度に複雑なクエリを防ぐために役立ちます。
:::

`0`の値は無制限を意味します。
## max_temporary_data_on_disk_size_for_query {#max_temporary_data_on_disk_size_for_query} 

<SettingsInfoBlock type="UInt64" default_value="0" />

同時に実行されているすべてのクエリに対して、一時ファイルがディスク上で消費する最大データ量（バイト）。

可能な値：

- 正の整数。
- `0` — 無制限（デフォルト）
## max_temporary_data_on_disk_size_for_user {#max_temporary_data_on_disk_size_for_user} 

<SettingsInfoBlock type="UInt64" default_value="0" />

同時に実行されているすべてのユーザークエリによってディスク上で消費される一時ファイルの最大データ量（バイト）。

可能な値：

- 正の整数。
- `0` — 無制限（デフォルト）
## max_temporary_non_const_columns {#max_temporary_non_const_columns} 

<SettingsInfoBlock type="UInt64" default_value="0" />

`max_temporary_columns`のように、クエリ実行時に同時にRAMに保持される必要がある一時的なカラムの最大数ですが、定数カラムはカウントされません。

:::note
定数カラムは、クエリ実行時に比較的頻繁に生成されますが、ほぼゼロの計算リソースを必要とします。
:::
## max_threads {#max_threads} 

<SettingsInfoBlock type="MaxThreads" default_value="'auto(N)'" />

クエリ処理スレッドの最大数。リモートサーバーからデータを取得するためのスレッドは除外されます（`max_distributed_connections`パラメータを参照）。

このパラメータは、同じクエリ処理パイプラインの段階を並行して実行するスレッドに適用されます。
たとえば、テーブルから読み取るとき、式を評価できる場合、WHEREでフィルタリングし、GROUP BYのために事前集計を少なくとも`max_threads`数のスレッドを使用して並行して実行できる場合、`max_threads`が使用されます。

LIMITのために早く完了するクエリについては、より低い`max_threads`を設定できます。たとえば、必要な数のエントリが各ブロックに位置する場合、max_threads = 8の場合、8ブロックが取得されますが、1つだけ読み取ることが十分です。

`max_threads`の値が小さいほど、消費されるメモリが少なくなります。
## max_threads_for_indexes {#max_threads_for_indexes} 

<SettingsInfoBlock type="UInt64" default_value="0" />

インデックスを処理するためのスレッドの最大数。
## max_untracked_memory {#max_untracked_memory} 

<SettingsInfoBlock type="UInt64" default_value="4194304" />

小さな割り当てと解放はスレッドローカル変数にグループ化され、指定された値を超える絶対値が大きくなるまで追跡またはプロファイリングされません。値が`memory_profiler_step`より大きい場合は、効果的に`memory_profiler_step`に低下されます。
## memory_overcommit_ratio_denominator {#memory_overcommit_ratio_denominator} 

<SettingsInfoBlock type="UInt64" default_value="1073741824" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.5"},{"label": "1073741824"},{"label": "Enable memory overcommit feature by default"}]}]}/>

グローバルレベルでハードリミットに達した場合のソフトメモリ制限を表します。
クエリのオーバーコミット比を計算するためにこの値が使用されます。
ゼロはクエリをスキップします。
[memory overcommit](memory-overcommit.md)の詳細を読む。
## memory_overcommit_ratio_denominator_for_user {#memory_overcommit_ratio_denominator_for_user} 

<SettingsInfoBlock type="UInt64" default_value="1073741824" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.5"},{"label": "1073741824"},{"label": "Enable memory overcommit feature by default"}]}]}/>

ユーザーレベルでハードリミットに達した場合のソフトメモリ制限を表します。
クエリのオーバーコミット比を計算するためにこの値が使用されます。
ゼロはクエリをスキップします。
[memory overcommit](memory-overcommit.md)の詳細を読む。
## memory_profiler_sample_max_allocation_size {#memory_profiler_sample_max_allocation_size} 

<SettingsInfoBlock type="UInt64" default_value="0" />

指定されたサイズ以下のランダム割り当てを確率`memory_profiler_sample_probability`で収集します。0は無効を意味します。期待通りにこのしきい値が機能するように、`max_untracked_memory`を0に設定することができます。
## memory_profiler_sample_min_allocation_size {#memory_profiler_sample_min_allocation_size} 

<SettingsInfoBlock type="UInt64" default_value="0" />

指定されたサイズ以上のランダム割り当てを確率`memory_profiler_sample_probability`で収集します。0は無効を意味します。期待通りにこのしきい値が機能するように、`max_untracked_memory`を0に設定することができます。
## memory_profiler_sample_probability {#memory_profiler_sample_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

ランダム割り当てと解放を収集し、`MemorySample`トレースタイプでsystem.trace_logに書き込みます。確率は、割り当てのサイズに関係なく、すべての alloc/free に対して適用されます（これは、`memory_profiler_sample_min_allocation_size`と`memory_profiler_sample_max_allocation_size`で変更できます）。トラッキングされていないメモリの量が`max_untracked_memory`を超えるときのみサンプリングが行われることに注意してください。詳細なサンプリングを行うには、`max_untracked_memory`を0に設定することができます。
## memory_profiler_step {#memory_profiler_step} 

<SettingsInfoBlock type="UInt64" default_value="4194304" />

メモリプロファイラのステップを設定します。クエリメモリ使用量がバイト単位で各次のステップより大きくなるたびに、メモリプロファイラは割り当てられたスタックトレースを収集し、それを[trace_log](/operations/system-tables/trace_log)に書き込みます。

可能な値：

- 正の整数のバイト数。

- メモリプロファイラをオフにするために0。
## memory_tracker_fault_probability {#memory_tracker_fault_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

`exception safety`のテストのために、指定された確率でメモリを割り当てるたびに例外をスローします。
## memory_usage_overcommit_max_wait_microseconds {#memory_usage_overcommit_max_wait_microseconds} 

<SettingsInfoBlock type="UInt64" default_value="5000000" />

ユーザーレベルでのメモリオーバーコミット時に、スレッドがメモリが解放されるのを待つ最大時間（マイクロ秒）。
タイムアウトに達してもメモリが解放されない場合は、例外がスローされます。
[memory overcommit](memory-overcommit.md)の詳細を読む。
## merge_table_max_tables_to_look_for_schema_inference {#merge_table_max_tables_to_look_for_schema_inference} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1000"},{"label": "A new setting"}]}]}/>

明示的なスキーマなしで`Merge`テーブルを作成する場合や、`merge`テーブル関数を使用する場合に、指定された数の一致するテーブルのユニオンとしてスキーマを推測します。
より多くのテーブルがある場合、最初に指定された数のテーブルからスキーマが推測されます。
## merge_tree_coarse_index_granularity {#merge_tree_coarse_index_granularity} 

<SettingsInfoBlock type="UInt64" default_value="8" />

データを検索する際、ClickHouseはインデックスファイル内のデータマークを確認します。必要なキーがある範囲が見つかると、その範囲を`merge_tree_coarse_index_granularity`のサブレンジに分割し、再帰的に必要なキーを検索します。

可能な値：

- いずれの正の偶数の整数。
## merge_tree_compact_parts_min_granules_to_multibuffer_read {#merge_tree_compact_parts_min_granules_to_multibuffer_read} 

<CloudOnlyBadge/>

<SettingsInfoBlock type="UInt64" default_value="16" />

ClickHouse Cloudでのみ効果があります。MergeTreeテーブルのコンパクト部分のストライプ内でマルチバッファリーダーを使用するためのグラニュール数。これにより、並列読み込みと予測がサポートされます。リモートファイルシステムから読み取る場合、マルチバッファリーダーの使用により、読み取りリクエストの数が増加します。
## merge_tree_determine_task_size_by_prewhere_columns {#merge_tree_determine_task_size_by_prewhere_columns} 

<SettingsInfoBlock type="Bool" default_value="1" />

読み取りタスクサイズを決定する際に、プレイスクリアのカラムサイズのみを使用するかどうか。
## merge_tree_max_bytes_to_use_cache {#merge_tree_max_bytes_to_use_cache} 

<SettingsInfoBlock type="UInt64" default_value="2013265920" />

ClickHouseが1つのクエリで`merge_tree_max_bytes_to_use_cache`バイト以上を読み取る必要がある場合、未圧縮ブロックのキャッシュを使用しません。

未圧縮ブロックのキャッシュは、クエリ用に抽出されたデータを保存します。ClickHouseは、このキャッシュを使用して、再度小さなクエリに対する応答を高速化します。この設定は、大量のデータを読み取るクエリによってキャッシュがゴミ化されるのを防ぎます。[uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size)サーバー設定が、未圧縮ブロックのキャッシュのサイズを定義します。

可能な値：

- いずれの正の整数。
## merge_tree_max_rows_to_use_cache {#merge_tree_max_rows_to_use_cache} 

<SettingsInfoBlock type="UInt64" default_value="1048576" />

ClickHouseが1つのクエリで`merge_tree_max_rows_to_use_cache`行以上を読み取る必要がある場合、未圧縮ブロックのキャッシュを使用しません。

未圧縮ブロックのキャッシュは、クエリ用に抽出されたデータを保存します。ClickHouseは、このキャッシュを使用して、再度小さなクエリに対する応答を高速化します。この設定は、大量のデータを読み取るクエリによってキャッシュがゴミ化されるのを防ぎます。[uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size)サーバー設定が、未圧縮ブロックのキャッシュのサイズを定義します。

可能な値：

- いずれの正の整数。
## merge_tree_min_bytes_for_concurrent_read {#merge_tree_min_bytes_for_concurrent_read} 

<SettingsInfoBlock type="UInt64" default_value="251658240" />

[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)エンジンの1つのファイルから読み取るバイト数が`merge_tree_min_bytes_for_concurrent_read`を超える場合、ClickHouseは、このファイルを数スレッドで並行して読み取ろうとします。

可能な値：

- 正の整数。
## merge_tree_min_rows_for_concurrent_read_for_remote_filesystem {#merge_tree_min_rows_for_concurrent_read_for_remote_filesystem} 

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "Setting is deprecated"}]}]}/>

リモートファイルシステムから読み取るときに、[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)エンジンが並列読み取りを実行できるようになるまで、一つのファイルから読み取る必要がある最小行数です。この設定の使用はお勧めしません。

可能な値：

- 正の整数。

## merge_tree_min_rows_for_seek {#merge_tree_min_rows_for_seek} 

<SettingsInfoBlock type="UInt64" default_value="0" />

一つのファイル内の二つのデータブロック間の距離が `merge_tree_min_rows_for_seek` 行よりも少ない場合、ClickHouseはファイルをシークせず、データを順次読み取ります。

可能な値：

- いかなる正の整数。

## merge_tree_read_split_ranges_into_intersecting_and_non_intersecting_injection_probability {#merge_tree_read_split_ranges_into_intersecting_and_non_intersecting_injection_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "`PartsSplitter` のテスト用 - 指定された確率で、MergeTreeから読み取るたびに、読み取り範囲を交差するものと交差しないものに分割します。"}]}]}/>

`PartsSplitter` のテスト用 - 指定された確率で、MergeTreeから読み取るたびに、読み取り範囲を交差するものと交差しないものに分割します。

## merge_tree_use_const_size_tasks_for_remote_reading {#merge_tree_use_const_size_tasks_for_remote_reading} 

<SettingsInfoBlock type="Bool" default_value="1" />

リモートテーブルからの読み取りに一定のサイズのタスクを使用するかどうか。

## merge_tree_use_deserialization_prefixes_cache {#merge_tree_use_deserialization_prefixes_cache} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "MergeTreeにおけるデシリアライズプレフィックスキャッシュの使用を制御する新しい設定"}]}]}/>

Wideパーツから読み取る際に、ファイルプレフィックスからのカラムメタデータのキャッシングを有効にします。

## merge_tree_use_prefixes_deserialization_thread_pool {#merge_tree_use_prefixes_deserialization_thread_pool} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "MergeTreeにおける並列プレフィックスデシリアライズのためのスレッドプールの使用を制御する新しい設定"}]}]}/>

Wideパーツにおける並列プレフィックス読み取りのためにスレッドプールの使用を有効にします。このスレッドプールのサイズは、サーバ設定 `max_prefixes_deserialization_thread_pool_size` によって制御されます。

## merge_tree_use_v1_object_and_dynamic_serialization {#merge_tree_use_v1_object_and_dynamic_serialization} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "JSONおよびDynamicタイプのための新しいシリアリゼーションV2バージョンを追加します"}]}]}/>

有効にすると、MergeTree内でJSONおよびDynamicタイプのV1シリアリゼーションバージョンが使用され、V2の代わりになります。この設定を変更するには、サーバの再起動が必要です。

## metrics_perf_events_enabled {#metrics_perf_events_enabled} 

<SettingsInfoBlock type="Bool" default_value="0" />

有効にすると、いくつかのperfイベントがクエリの実行中に測定されます。

## metrics_perf_events_list {#metrics_perf_events_list} 

カンマ区切りのperfメトリクスのリストがクエリ実行中に測定されます。空であればすべてのイベントを意味します。使用可能なイベントに関してはソースのPerfEventInfoを参照してください。

## min_bytes_to_use_direct_io {#min_bytes_to_use_direct_io} 

<SettingsInfoBlock type="UInt64" default_value="0" />

ディスクストレージへの直接I/Oアクセスを使用するために必要な最小データボリュームです。

ClickHouseはこの設定を、テーブルからデータを読み取る際に使用します。読み取るすべてのデータの合計ストレージボリュームが `min_bytes_to_use_direct_io` バイトを超える場合、ClickHouseは `O_DIRECT` オプションを使用してストレージディスクからデータを読み取ります。

可能な値：

- 0 — 直接I/Oが無効です。
- 正の整数。

## min_bytes_to_use_mmap_io {#min_bytes_to_use_mmap_io} 

<SettingsInfoBlock type="UInt64" default_value="0" />

これは実験的な設定です。カーネルからユーザースペースにデータをコピーせずに大きなファイルを読み込むための最小メモリ量を設定します。推奨の閾値は約64 MBです。なぜなら、[mmap/munmap](https://en.wikipedia.org/wiki/Mmap) は遅いからです。それは大きなファイルにのみ適用され、データがページキャッシュに存在するときにのみ役立ちます。

可能な値：

- 正の整数。
- 0 — 大きなファイルはカーネルからユーザースペースへのデータのコピーのみで読み取られます。

## min_chunk_bytes_for_parallel_parsing {#min_chunk_bytes_for_parallel_parsing} 

<SettingsInfoBlock type="NonZeroUInt64" default_value="10485760" />

- タイプ: unsigned int
- デフォルト値: 1 MiB

各スレッドが並行して解析する最小チャンクサイズ（バイト単位）です。

## min_compress_block_size {#min_compress_block_size} 

<SettingsInfoBlock type="UInt64" default_value="65536" />

[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)テーブルに対して。クエリ処理時のレイテンシを減少させるために、次のマークを書くとき、そのサイズが `min_compress_block_size` 以上であればブロックは圧縮されます。デフォルトは65,536です。

非圧縮データが `max_compress_block_size` より小さい場合、ブロックの実際のサイズはこの値以上であり、一つのマークのデータボリューム以上になります。

例を見てみましょう。`index_granularity` がテーブル作成時に8192に設定されていたと仮定します。

UInt32型のカラム（値ごとに4バイト）を書き込む際、8192行を記録すると、データの総量は32 KBになります。 `min_compress_block_size` = 65,536 があるため、圧縮ブロックは2つのマークごとに形成されます。

文字列型のURLカラム（値ごとに平均60バイト）の場合、8192行を記録すると、平均的に500 KBを少し下回るデータになります。このため、65,536を超えているため、各マークごとに圧縮ブロックが形成されます。この場合、一つのマークの範囲でディスクからデータを読み込む際に余分なデータは解凍されないでしょう。

:::note
これは専門家向けの設定であり、ClickHouseを始めたばかりの場合には変更しないでください。
:::

## min_count_to_compile_aggregate_expression {#min_count_to_compile_aggregate_expression} 

<SettingsInfoBlock type="UInt64" default_value="3" />

JITコンパイルを開始するための最小同一集約式の数。これは、[compile_aggregate_expressions](#compile_aggregate_expressions)設定が有効な場合のみ機能します。

可能な値：

- 正の整数。
- 0 — 同一の集約式は常にJITコンパイルされます。

## min_count_to_compile_expression {#min_count_to_compile_expression} 

<SettingsInfoBlock type="UInt64" default_value="3" />

コンパイルされる前に、同じ式が実行される最小数です。

## min_count_to_compile_sort_description {#min_count_to_compile_sort_description} 

<SettingsInfoBlock type="UInt64" default_value="3" />

JITコンパイルされる前の同一のソート記述の数です。

## min_execution_speed {#min_execution_speed} 

<SettingsInfoBlock type="UInt64" default_value="0" />

最小実行速度（行/秒単位）。`[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)` の期限が切れると、各データブロックで確認されます。実行速度が低い場合は例外がスローされます。

## min_execution_speed_bytes {#min_execution_speed_bytes} 

<SettingsInfoBlock type="UInt64" default_value="0" />

毎秒の最小実行バイト数。`[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)` の期限が切れると、各データブロックで確認されます。実行速度が低い場合は例外がスローされます。

## min_external_sort_block_bytes {#min_external_sort_block_bytes} 

<SettingsInfoBlock type="UInt64" default_value="104857600" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "104857600"},{"label": "新しい設定。"}]}]}/>

ディスクにダンプされる外部ソートのための最小ブロックサイズ（バイト単位）、ファイルが多すぎるのを避けるため。

## min_external_table_block_size_bytes {#min_external_table_block_size_bytes} 

<SettingsInfoBlock type="UInt64" default_value="268402944" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "268402944"},{"label": "ブロックが十分に大きくない場合は、指定したサイズ（バイト単位）に外部テーブルに渡されるブロックを縮小します。"}]}]}/>

ブロックが十分に大きくない場合は、指定したサイズ（バイト単位）に外部テーブルに渡されるブロックを縮小します。

## min_external_table_block_size_rows {#min_external_table_block_size_rows} 

<SettingsInfoBlock type="UInt64" default_value="1048449" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1048449"},{"label": "ブロックが十分に大きくない場合は、指定したサイズ（行数）に外部テーブルに渡されるブロックを縮小します。"}]}]}/>

ブロックが十分に大きくない場合は、指定したサイズ（行数）に外部テーブルに渡されるブロックを縮小します。

## min_free_disk_bytes_to_perform_insert {#min_free_disk_bytes_to_perform_insert} 

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "一時的な書き込みを許可しながら、挿入のための空きディスクスペースバイトを維持します。"}]}]}/>

挿入を行うための最小自由ディスクスペースバイト数です。

## min_free_disk_ratio_to_perform_insert {#min_free_disk_ratio_to_perform_insert} 

<SettingsInfoBlock type="Float" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "一時的な書き込みを許可しながら、挿入のために総ディスクスペースに対する比率として空きディスクスペースバイトを維持します。"}]}]}/>

挿入を行うための最小自由ディスクスペース比率です。

## min_free_disk_space_for_temporary_data {#min_free_disk_space_for_temporary_data} 

<SettingsInfoBlock type="UInt64" default_value="0" />

外部ソートや集約で使用される一時データを書き込む際に保持する最小ディスクスペースです。

## min_hit_rate_to_use_consecutive_keys_optimization {#min_hit_rate_to_use_consecutive_keys_optimization} 

<SettingsInfoBlock type="Float" default_value="0.5" />

集約における連続キー最適化を維持するために使用されるキャッシュの最小ヒット率です。

## min_insert_block_size_bytes {#min_insert_block_size_bytes} 

<SettingsInfoBlock type="UInt64" default_value="268402944" />

`INSERT` クエリによってテーブルに挿入できるブロック内の最小バイト数を設定します。サイズが小さいブロックは大きなブロックに圧縮されます。

可能な値：

- 正の整数。
- 0 — 圧縮無効。

## min_insert_block_size_bytes_for_materialized_views {#min_insert_block_size_bytes_for_materialized_views} 

<SettingsInfoBlock type="UInt64" default_value="0" />

`INSERT` クエリによってテーブルに挿入できるブロック内の最小バイト数を設定します。サイズが小さいブロックは大きなブロックに圧縮されます。この設定は[materialized view](../../sql-reference/statements/create/view.md)に挿入されるブロックにのみ適用されます。この設定を調整することで、物化ビューへのプッシュ時にブロックの圧縮を制御し、過剰なメモリ使用を避けます。

可能な値：

- いかなる正の整数。
- 0 — 圧縮無効。

**参照**

- [min_insert_block_size_bytes](#min_insert_block_size_bytes)

## min_insert_block_size_rows {#min_insert_block_size_rows} 

<SettingsInfoBlock type="UInt64" default_value="1048449" />

`INSERT` クエリによってテーブルに挿入できるブロック内の最小行数を設定します。サイズが小さいブロックは大きなブロックに圧縮されます。

可能な値：

- 正の整数。
- 0 — 圧縮無効。

## min_insert_block_size_rows_for_materialized_views {#min_insert_block_size_rows_for_materialized_views} 

<SettingsInfoBlock type="UInt64" default_value="0" />

`INSERT` クエリによってテーブルに挿入できるブロック内の最小行数を設定します。サイズが小さいブロックは大きなブロックに圧縮されます。この設定は[materialized view](../../sql-reference/statements/create/view.md)に挿入されるブロックにのみ適用されます。この設定を調整することで、物化ビューへのプッシュ時にブロックの圧縮を制御し、過剰なメモリ使用を避けます。

可能な値：

- いかなる正の整数。
- 0 — 圧縮無効。

**参照**

- [min_insert_block_size_rows](#min_insert_block_size_rows)

## min_joined_block_size_bytes {#min_joined_block_size_bytes} 

<SettingsInfoBlock type="UInt64" default_value="524288" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "524288"},{"label": "新しい設定。"}]}]}/>

JOIN結果の最小ブロックサイズ（結合アルゴリズムがそれをサポートしている場合）。0は無制限を意味します。

## min_os_cpu_wait_time_ratio_to_throw {#min_os_cpu_wait_time_ratio_to_throw} 

<SettingsInfoBlock type="Float" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "設定値が変更され、25.4にバックポートされました"}]}, {"id": "row-2","items": [{"label": "25.4"},{"label": "0"},{"label": "新しい設定"}]}]}/>

CPU待機（OSCPUWaitMicrosecondsメトリクス）とビジー（OSCPUVirtualTimeMicrosecondsメトリクス）時間を考慮してクエリを拒否するための最小比率。最小と最大の比率の間で線形補間が使用され、確率が計算され、この時点で確率は0です。

## mongodb_throw_on_unsupported_query {#mongodb_throw_on_unsupported_query} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "1"},{"label": "新しい設定。"}]}]}/>

有効にすると、MongoDBクエリが構築できない場合、MongoDBテーブルはエラーを返します。それ以外の場合、ClickHouseはテーブル全体を読み取ってローカルで処理します。このオプションは 'allow_experimental_analyzer=0' の場合には適用されません。

## move_all_conditions_to_prewhere {#move_all_conditions_to_prewhere} 

<SettingsInfoBlock type="Bool" default_value="1" />

すべての有効な条件をWHEREからPREWHEREに移動します。

## move_primary_key_columns_to_end_of_prewhere {#move_primary_key_columns_to_end_of_prewhere} 

<SettingsInfoBlock type="Bool" default_value="1" />

主キー列を含むPREWHERE条件をANDチェーンの末尾に移動します。これらの条件は主キーの分析中に考慮される可能性が高いため、PREWHEREフィルタリングにあまり寄与しないでしょう。

## multiple_joins_try_to_keep_original_names {#multiple_joins_try_to_keep_original_names} 

<SettingsInfoBlock type="Bool" default_value="0" />

複数の結合書き換え時に最上位の式リストにエイリアスを追加しません。

## mutations_execute_nondeterministic_on_initiator {#mutations_execute_nondeterministic_on_initiator} 

<SettingsInfoBlock type="Bool" default_value="0" />

もしtrueであれば、定数非決定論的関数（例：関数 `now()`）はイニシエータで実行され、`UPDATE`および`DELETE`クエリ内のリテラルに置き換えられます。これは、定数非決定論的関数でミューテーションを実行中にレプリカ間でデータを同期させるのに役立ちます。デフォルト値：`false`。

## mutations_execute_subqueries_on_initiator {#mutations_execute_subqueries_on_initiator} 

<SettingsInfoBlock type="Bool" default_value="0" />

もしtrueであれば、スカラーサブクエリはイニシエータで実行され、`UPDATE`および`DELETE`クエリ内のリテラルに置き換えられます。デフォルト値：`false`。

## mutations_max_literal_size_to_replace {#mutations_max_literal_size_to_replace} 

<SettingsInfoBlock type="UInt64" default_value="16384" />

`UPDATE`および`DELETE`クエリ内で置き換えるためのシリアル化リテラルの最大サイズ（バイト単位）。上記の2つの設定のいずれかが有効な場合にのみ有効になります。デフォルト値：16384（16 KiB）。

## mutations_sync {#mutations_sync} 

<SettingsInfoBlock type="UInt64" default_value="0" />

`ALTER TABLE ... UPDATE|DELETE|MATERIALIZE INDEX|MATERIALIZE PROJECTION|MATERIALIZE COLUMN|MATERIALIZE STATISTICS`クエリ([mutations](../../sql-reference/statements/alter/index.md/#mutations))を同期的に実行できるようにします。

可能な値：

- 0 - ミューテーションは非同期に実行されます。
- 1 - クエリは現在のサーバーでのすべてのミューテーションの完了を待機します。
- 2 - クエリはすべてのレプリカのミューテーション完了を待機します（存在する場合）。

## mysql_datatypes_support_level {#mysql_datatypes_support_level} 

MySQLタイプが対応するClickHouseタイプに変換される方法を定義します。`decimal`、`datetime64`、`date2Date32` 、または `date2String` の任意の組み合わせのカンマ区切りのリスト。

- `decimal`: 精度が許可される場合、`NUMERIC` および `DECIMAL` タイプを `Decimal` に変換します。
- `datetime64`: 精度が `0` でない場合、`DATETIME` および `TIMESTAMP` タイプを `DateTime64` に変換します。
- `date2Date32`: `DATE` を `Date32` に変換します。
- `date2String`: `DATE` を `String` に変換します。

## mysql_map_fixed_string_to_text_in_show_columns {#mysql_map_fixed_string_to_text_in_show_columns} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "ClickHouseとBIツールを接続するための設定作業を減らします。"}]}]}/>

有効にすると、[FixedString](../../sql-reference/data-types/fixedstring.md) ClickHouseデータ型は[SHOW COLUMNS](../../sql-reference/statements/show.md/#show_columns)内で `TEXT` として表示されます。

MySQLワイヤプロトコルを介して接続を行うときのみ影響します。

- 0 - `BLOB`を使用。
- 1 - `TEXT`を使用。

## mysql_map_string_to_text_in_show_columns {#mysql_map_string_to_text_in_show_columns} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "ClickHouseとBIツールを接続するための設定作業を減らします。"}]}]}/>

有効にすると、[String](../../sql-reference/data-types/string.md) ClickHouseデータ型は[SHOW COLUMNS](../../sql-reference/statements/show.md/#show_columns)内で `TEXT` として表示されます。

MySQLワイヤプロトコルを介して接続を行うときのみ影響します。

- 0 - `BLOB`を使用。
- 1 - `TEXT`を使用。

## mysql_max_rows_to_insert {#mysql_max_rows_to_insert} 

<SettingsInfoBlock type="UInt64" default_value="65536" />

MySQLストレージエンジンのMySQLバッチ挿入での最大行数です。

## network_compression_method {#network_compression_method} 

<SettingsInfoBlock type="String" default_value="LZ4" />

サーバー間およびサーバーと[clickhouse-client](../../interfaces/cli.md)間の通信に使用されるデータ圧縮の方法を設定します。

可能な値：

- `LZ4` — LZ4圧縮方式を設定します。
- `ZSTD` — ZSTD圧縮方式を設定します。

**参照**

- [network_zstd_compression_level](#network_zstd_compression_level)

## network_zstd_compression_level {#network_zstd_compression_level} 

<SettingsInfoBlock type="Int64" default_value="1" />

ZSTD圧縮のレベルを調整します。これは、[network_compression_method](#network_compression_method) が `ZSTD` に設定されているときのみ使用されます。

可能な値：

- 1から15の正の整数。

## normalize_function_names {#normalize_function_names} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.3"},{"label": "1"},{"label": "関数名をその標準名に正規化します。これは投影クエリのルーティングに必要でした。"}]}]}/>

関数名をその標準名に正規化します。

## number_of_mutations_to_delay {#number_of_mutations_to_delay} 

<SettingsInfoBlock type="UInt64" default_value="0" />

変異テーブルに未終了のミューテーションが少なくともこの数含まれている場合、そのテーブルのミューテーションを人工的に遅延させます。0 - 無効。

## number_of_mutations_to_throw {#number_of_mutations_to_throw} 

<SettingsInfoBlock type="UInt64" default_value="0" />

変異テーブルに未終了のミューテーションが少なくともこの数含まれている場合、「ミューテーションが多すぎる...」という例外をスローします。0 - 無効。

## odbc_bridge_connection_pool_size {#odbc_bridge_connection_pool_size} 

<SettingsInfoBlock type="UInt64" default_value="16" />

ODBCブリッジ内の接続設定文字列ごとの接続プールサイズです。

## odbc_bridge_use_connection_pooling {#odbc_bridge_use_connection_pooling} 

<SettingsInfoBlock type="Bool" default_value="1" />

ODBCブリッジにおける接続プールを使用します。falseに設定した場合、毎回新しい接続が作成されます。

## offset {#offset} 

<SettingsInfoBlock type="UInt64" default_value="0" />

クエリから戻す行を開始する前にスキップする行数を設定します。[OFFSET](/sql-reference/statements/select/offset)句によって設定されたオフセットを調整し、これら二つの値が合算されるようにします。

可能な値：

- 0 — 行はスキップされません。
- 正の整数。

**例**

入力テーブル：

```sql
CREATE TABLE test (i UInt64) ENGINE = MergeTree() ORDER BY i;
INSERT INTO test SELECT number FROM numbers(500);

クエリ：

```sql
SET limit = 5;
SET offset = 7;
SELECT * FROM test LIMIT 10 OFFSET 100;

結果：

```text
┌───i─┐
│ 107 │
│ 108 │
│ 109 │
└─────┘

## opentelemetry_start_trace_probability {#opentelemetry_start_trace_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

実行されたクエリに対してClickHouseがトレースを開始できる確率を設定します（親の[トレーサーコンテキスト](https://www.w3.org/TR/trace-context/)が供給されていない場合）。

可能な値：

- 0 — すべての実行されたクエリのトレースを無効にします（親のトレーサーコンテキストが供給されていない場合）。
- [0..1] の範囲内の正の浮動小数点数。例えば、設定値が `0.5` の場合、ClickHouseは平均して半分のクエリでトレースを開始することができます。
- 1 — すべての実行されたクエリのトレースを有効にします。

## opentelemetry_trace_processors {#opentelemetry_trace_processors} 

<SettingsInfoBlock type="Bool" default_value="0" />

プロセッサのためにOpenTelemetryスパンを収集します。

## optimize_aggregation_in_order {#optimize_aggregation_in_order} 

<SettingsInfoBlock type="Bool" default_value="0" />

[GROUP BY](/sql-reference/statements/select/group-by)の最適化を[SELECT](../../sql-reference/statements/select/index.md)クエリにおいて有効にし、MergeTree（../../engines/table-engines/mergetree-family/mergetree.md）テーブルでのデータを対応する順序で集約します。

可能な値：

- 0 — `GROUP BY`の最適化が無効です。
- 1 — `GROUP BY`の最適化が有効です。

**参照**

- [GROUP BYの最適化](/sql-reference/statements/select/group-by#group-by-optimization-depending-on-table-sorting-key)

## optimize_aggregators_of_group_by_keys {#optimize_aggregators_of_group_by_keys} 

<SettingsInfoBlock type="Bool" default_value="1" />

SELECTセクションでGROUP BYキーのmin/max/any/anyLast集計関数を排除します。

## optimize_and_compare_chain {#optimize_and_compare_chain} 

<SettingsInfoBlock type="Bool" default_value="1" />

一定の比較をANDチェーンに入れることでフィルタリング能力を強化します。サポートする演算子は、`<`、`<=`、`>`、`>=`、`=`とその混合です。例えば、`(a < b) AND (b < c) AND (c < 5)` は、`(a < b) AND (b < c) AND (c < 5) AND (b < 5) AND (a < 5)` となります。

## optimize_append_index {#optimize_append_index} 

<SettingsInfoBlock type="Bool" default_value="0" />

[constraints](../../sql-reference/statements/create/table.md/#constraints)を使用してインデックス条件を追加します。デフォルトは `false` です。

可能な値：

- true, false

## optimize_arithmetic_operations_in_aggregate_functions {#optimize_arithmetic_operations_in_aggregate_functions} 

<SettingsInfoBlock type="Bool" default_value="1" />

集計関数外に算術演算を移動します。

## optimize_count_from_files {#optimize_count_from_files} 

<SettingsInfoBlock type="Bool" default_value="1" />

異なる入力形式のファイルからの行数を数える最適化を有効または無効にします。これには、テーブル関数/エンジン `file`/`s3`/`url`/`hdfs`/`azureBlobStorage` が適用されます。

可能な値：

- 0 — 最適化無効。
- 1 — 最適化有効。

## optimize_distinct_in_order {#optimize_distinct_in_order} 

DISTINCTの最適化を有効にします。DISTINCTの一部のカラムがソートの接頭辞を形成します。メルゲツリーまたはORDER BYステートメント内のソートキー。

## optimize_distributed_group_by_sharding_key {#optimize_distributed_group_by_sharding_key} 

`GROUP BY sharding_key` クエリを最適化し、イニシエータサーバーでのコストのかかる集約を回避します（これにより、イニシエータサーバーにおけるメモリ使用量を削減します）。

次のタイプのクエリがサポートされています（そのすべての組み合わせ）：

- `SELECT DISTINCT [..., ]sharding_key[, ...] FROM dist`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...]`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] ORDER BY x`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] LIMIT 1`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] LIMIT 1 BY x`

次のタイプのクエリはサポートされていません（その一部のサポートは後に追加される可能性があります）：

- `SELECT ... GROUP BY sharding_key[, ...] WITH TOTALS`
- `SELECT ... GROUP BY sharding_key[, ...] WITH ROLLUP`
- `SELECT ... GROUP BY sharding_key[, ...] WITH CUBE`
- `SELECT ... GROUP BY sharding_key[, ...] SETTINGS extremes=1`

可能な値：

- 0 — 無効。
- 1 — 有効。

参照：

- [distributed_group_by_no_merge](#distributed_group_by_no_merge)
- [distributed_push_down_limit](#distributed_push_down_limit)
- [optimize_skip_unused_shards](#optimize_skip_unused_shards)

:::note
現在は、`optimize_skip_unused_shards` が必要です（その理由は、ある日デフォルトで有効にされ、データがDistributedテーブルを介して挿入された場合にのみ、正しく機能するためです。つまり、データはシャーディングキーに従って分散されます）。
:::

## optimize_extract_common_expressions {#optimize_extract_common_expressions} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "共通の式を結合の論理式から抽出してWHERE、PREWHERE、ON、HAVING、QUALIFYの式を最適化します。"}]}]}/>

論理式を分解し、WHERE、PREWHERE、ON、HAVING、およびQUALIFY式から共通の式を抽出することを可能にします。`(A AND B) OR (A AND C)`のような論理式は、`A AND (B OR C)`に書き換え可能であり、以下の利用を助ける可能性があります。
- 単純なフィルタリング式におけるインデックス
- 内部結合の最適化に対する交差

## optimize_functions_to_subcolumns {#optimize_functions_to_subcolumns} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "1"},{"label": "デフォルトで有効化された設定です。"}]}]}/>

一部の関数をサブカラム読み取りに変換することによる最適化を有効または無効にします。これにより、読み取るデータ量が減少します。

変換可能な関数：

- [length](/sql-reference/functions/array-functions#length) を [size0](../../sql-reference/data-types/array.md/#array-size) サブカラムを読み取るために。
- [empty](/sql-reference/functions/array-functions#empty) を [size0](../../sql-reference/data-types/array.md/#array-size) サブカラムを読み取るために。
- [notEmpty](/sql-reference/functions/array-functions#notempty) を [size0](../../sql-reference/data-types/array.md/#array-size) サブカラムを読み取るために。
- [isNull](/sql-reference/functions/functions-for-nulls#isnull) を [null](../../sql-reference/data-types/nullable.md/#finding-null) サブカラムを読み取るために。
- [isNotNull](/sql-reference/functions/functions-for-nulls#isnotnull) を [null](../../sql-reference/data-types/nullable.md/#finding-null) サブカラムを読み取るために。
- [count](/sql-reference/aggregate-functions/reference/count) を [null](../../sql-reference/data-types/nullable.md/#finding-null) サブカラムを読み取るために。
- [mapKeys](/sql-reference/functions/tuple-map-functions#mapkeys) を [keys](../../sql-reference/data-types/map#reading-subcolumns-of-map) サブカラムを読み取るために。
- [mapValues](/sql-reference/functions/tuple-map-functions#mapvalues) を [values](../../sql-reference/data-types/map#reading-subcolumns-of-map) サブカラムを読み取るために。

可能な値：

- 0 — 最適化無効。
- 1 — 最適化有効。

## optimize_group_by_constant_keys {#optimize_group_by_constant_keys} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.9"},{"label": "1"},{"label": "デフォルトで定数キーによるGROUP BYを最適化します。"}]}]}/>

すべてのキーが定数である場合のGROUP BYを最適化します。

## optimize_group_by_function_keys {#optimize_group_by_function_keys} 

<SettingsInfoBlock type="Bool" default_value="1" />

GROUP BYセクションにおいて他のキーの関数を排除します。

## optimize_if_chain_to_multiif {#optimize_if_chain_to_multiif} 

<SettingsInfoBlock type="Bool" default_value="0" />

if(cond1, then1, if(cond2, ...)) チェーンを multiIf に置き換えます。現在のところ、数値型に対しては利点がありません。

## optimize_if_transform_strings_to_enum {#optimize_if_transform_strings_to_enum} 



<SettingsInfoBlock type="Bool" default_value="0" />

IfおよびTransform内の文字列型引数をenumに置き換えます。分散クエリにおいて不整合な変更を引き起こす可能性があるため、デフォルトでは無効になっています。
## optimize_injective_functions_in_group_by {#optimize_injective_functions_in_group_by} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "1"},{"label": "GROUP BYセクションでの逆写像関数を引数に置き換える"}]}]}/>

GROUP BYセクションでの逆写像関数をその引数に置き換えます。
## optimize_injective_functions_inside_uniq {#optimize_injective_functions_inside_uniq} 



<SettingsInfoBlock type="Bool" default_value="1" />

uniq*()関数内の1つの引数の逆写像関数を削除します。
## optimize_min_equality_disjunction_chain_length {#optimize_min_equality_disjunction_chain_length} 



<SettingsInfoBlock type="UInt64" default_value="3" />

最適化のための式`expr = x1 OR ... expr = xN`の最小長。
## optimize_min_inequality_conjunction_chain_length {#optimize_min_inequality_conjunction_chain_length} 



<SettingsInfoBlock type="UInt64" default_value="3" />

最適化のための式`expr <> x1 AND ... expr <> xN`の最小長。
## optimize_move_to_prewhere {#optimize_move_to_prewhere} 



<SettingsInfoBlock type="Bool" default_value="1" />

[SELECT](../../sql-reference/statements/select/index.md)クエリにおける自動[PREWHERE](../../sql-reference/statements/select/prewhere.md)最適化を有効または無効にします。

この設定は、[*MergeTree](../../engines/table-engines/mergetree-family/index.md)テーブルでのみ機能します。

可能な値:

- 0 — 自動`PREWHERE`最適化は無効です。
- 1 — 自動`PREWHERE`最適化は有効です。
## optimize_move_to_prewhere_if_final {#optimize_move_to_prewhere_if_final} 



<SettingsInfoBlock type="Bool" default_value="0" />

[FINAL](/sql-reference/statements/select/from#final-modifier)修飾子を持つ[SELECT](../../sql-reference/statements/select/index.md)クエリにおける自動[PREWHERE](../../sql-reference/statements/select/prewhere.md)最適化を有効または無効にします。

この設定は、[*MergeTree](../../engines/table-engines/mergetree-family/index.md)テーブルでのみ機能します。

可能な値:

- 0 — `FINAL`修飾子付きの`SELECT`クエリにおける自動`PREWHERE`最適化は無効です。
- 1 — `FINAL`修飾子付きの`SELECT`クエリにおける自動`PREWHERE`最適化は有効です。

**関連情報**

- [optimize_move_to_prewhere](#optimize_move_to_prewhere) 設定
## optimize_multiif_to_if {#optimize_multiif_to_if} 



<SettingsInfoBlock type="Bool" default_value="1" />

'multiIf'を条件が1つだけの'if'に置き換えます。
## optimize_normalize_count_variants {#optimize_normalize_count_variants} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.3"},{"label": "1"},{"label": "count()と同義の集約関数をデフォルトでcount()として書き換える"}]}]}/>

count()と同義の集約関数をcount()として書き換えます。
## optimize_on_insert {#optimize_on_insert} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.1"},{"label": "1"},{"label": "ユーザーエクスペリエンス向上のため、INSERT時のデータ最適化をデフォルトで有効化する"}]}]}/>

挿入前にデータ変換を有効または無効にします。これは、テーブルエンジンに基づいてこのブロックでマージが行われたかのようになります。

可能な値:

- 0 — 無効。
- 1 — 有効。

**例**

有効と無効の違い:

クエリ:

```sql
SET optimize_on_insert = 1;

CREATE TABLE test1 (`FirstTable` UInt32) ENGINE = ReplacingMergeTree ORDER BY FirstTable;

INSERT INTO test1 SELECT number % 2 FROM numbers(5);

SELECT * FROM test1;

SET optimize_on_insert = 0;

CREATE TABLE test2 (`SecondTable` UInt32) ENGINE = ReplacingMergeTree ORDER BY SecondTable;

INSERT INTO test2 SELECT number % 2 FROM numbers(5);

SELECT * FROM test2;

結果:

```text
┌─FirstTable─┐
│          0 │
│          1 │
└────────────┘

┌─SecondTable─┐
│           0 │
│           0 │
│           0 │
│           1 │
│           1 │
└─────────────┘

この設定は、[Materialized view](/sql-reference/statements/create/view#materialized-view)の動作に影響を与えることに注意してください。
## optimize_or_like_chain {#optimize_or_like_chain} 



<SettingsInfoBlock type="Bool" default_value="0" />

複数のOR LIKEをmultiMatchAnyに最適化します。この最適化は、インデックス解析に反する場合があるため、デフォルトでは有効にすべきではありません。
## optimize_read_in_order {#optimize_read_in_order} 



<SettingsInfoBlock type="Bool" default_value="1" />

[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)テーブルからデータを読むための[SELECT](../../sql-reference/statements/select/index.md)クエリにおける[ORDER BY](/sql-reference/statements/select/order-by#optimization-of-data-reading)最適化を有効にします。

可能な値:

- 0 — `ORDER BY`最適化は無効です。
- 1 — `ORDER BY`最適化は有効です。

**関連情報**

- [ORDER BY句](/sql-reference/statements/select/order-by#optimization-of-data-reading)
## optimize_read_in_window_order {#optimize_read_in_window_order} 



<SettingsInfoBlock type="Bool" default_value="1" />

MergeTreeテーブルのウィンドウ句におけるデータの読み取り順序に対するORDER BY最適化を有効にします。
## optimize_redundant_functions_in_order_by {#optimize_redundant_functions_in_order_by} 



<SettingsInfoBlock type="Bool" default_value="1" />

ORDER BYの引数がORDER BYにも含まれている場合、ORDER BYから関数を削除します。
## optimize_respect_aliases {#optimize_respect_aliases} 



<SettingsInfoBlock type="Bool" default_value="1" />

trueに設定されている場合、WHERE/GROUP BY/ORDER BYのエイリアスを尊重し、パーティションプルーニング/セカンダリインデックス/optimize_aggregation_in_order/optimize_read_in_order/optimize_trivial_countを助けます。
## optimize_rewrite_aggregate_function_with_if {#optimize_rewrite_aggregate_function_with_if} 



<SettingsInfoBlock type="Bool" default_value="1" />

論理的に同等である場合、if式を引数に持つ集約関数を書き換えます。
例えば、`avg(if(cond, col, null))`は`avgOrNullIf(cond, col)`に書き換えられます。これによりパフォーマンスが向上する可能性があります。

:::note
この設定は分析ツールと共にしかサポートされません (`enable_analyzer = 1`)。
:::
## optimize_rewrite_array_exists_to_has {#optimize_rewrite_array_exists_to_has} 



<SettingsInfoBlock type="Bool" default_value="0" />

論理的に同等である場合、arrayExists()関数をhas()に書き換えます。例えば、arrayExists(x -> x = 1, arr)はhas(arr, 1)に書き換えられます。
## optimize_rewrite_sum_if_to_count_if {#optimize_rewrite_sum_if_to_count_if} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "1"},{"label": "分析ツール専用。正しく動作します"}]}]}/>

論理的に同等である場合、sumIf()およびsum(if())関数をcountIf()関数に書き換えます。
## optimize_skip_merged_partitions {#optimize_skip_merged_partitions} 



<SettingsInfoBlock type="Bool" default_value="0" />

有効にすると、TTLが切れていないレベルが0を超えるパーツが1つしかない場合に、[OPTIMIZE TABLE ... FINAL](../../sql-reference/statements/optimize.md)クエリの最適化を有効または無効にします。

- `OPTIMIZE TABLE ... FINAL SETTINGS optimize_skip_merged_partitions=1`

デフォルトでは、`OPTIMIZE TABLE ... FINAL`クエリは、たとえ1つのパーツであってもそれを書き換えます。

可能な値:

- 1 — 最適化を有効にします。
- 0 — 最適化を無効にします。
## optimize_skip_unused_shards {#optimize_skip_unused_shards} 



<SettingsInfoBlock type="Bool" default_value="0" />

`WHERE/PREWHERE`にシャーディングキー条件がある[SELECT](../../sql-reference/statements/select/index.md)クエリの未使用シャードのスキップを有効または無効にします（データがシャーディングキーによって分散されていると仮定します。そうでない場合、クエリは正しい結果を返しません）。

可能な値:

- 0 — 無効。
- 1 — 有効。
## optimize_skip_unused_shards_limit {#optimize_skip_unused_shards_limit} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

シャーディングキーの値の数に対する制限で、制限に達した場合は`optimize_skip_unused_shards`を無効にします。

値が多すぎると処理に多くのリソースが必要になる可能性がありますが、利益は疑わしいです。なぜなら、`IN (...)`内に大量の値がある場合、クエリはおそらくすべてのシャードに送信されるためです。
## optimize_skip_unused_shards_nesting {#optimize_skip_unused_shards_nesting} 



<SettingsInfoBlock type="UInt64" default_value="0" />

分散クエリのネスティングレベルに依存する[`optimize_skip_unused_shards`](#optimize_skip_unused_shards)を制御します（別の`Distributed`テーブルを見ている場合）。

可能な値:

- 0 — 無効、`optimize_skip_unused_shards`は常に機能します。
- 1 — 最初のレベルのみで`optimize_skip_unused_shards`を有効にします。
- 2 — 第二レベルまで`optimize_skip_unused_shards`を有効にします。
## optimize_skip_unused_shards_rewrite_in {#optimize_skip_unused_shards_rewrite_in} 



<SettingsInfoBlock type="Bool" default_value="1" />

シャードに属さない値を除外するためにリモートシャードのクエリ内のINを書き換えます（`optimize_skip_unused_shards`が必要です）。

可能な値:

- 0 — 無効。
- 1 — 有効。
## optimize_sorting_by_input_stream_properties {#optimize_sorting_by_input_stream_properties} 



<SettingsInfoBlock type="Bool" default_value="1" />

入力ストリームの特性によるソートを最適化します。
## optimize_substitute_columns {#optimize_substitute_columns} 



<SettingsInfoBlock type="Bool" default_value="0" />

[制約](../../sql-reference/statements/create/table.md/#constraints)をカラムの置換に使用します。デフォルトは`false`です。

可能な値:

- true、false
## optimize_syntax_fuse_functions {#optimize_syntax_fuse_functions} 



<SettingsInfoBlock type="Bool" default_value="0" />

同一の引数を持つ集約関数を融合することを有効にします。これは、同一の引数を持つ少なくとも2つの集約関数（[sum](/sql-reference/aggregate-functions/reference/sum)、[count](/sql-reference/aggregate-functions/reference/count)、または[avg](/sql-reference/aggregate-functions/reference/avg)）を[sumCount](/sql-reference/aggregate-functions/reference/sumcount)に書き換えます。

可能な値:

- 0 — 同一の引数を持つ関数は融合されません。
- 1 — 同一の引数を持つ関数は融合されます。

**例**

クエリ:

```sql
CREATE TABLE fuse_tbl(a Int8, b Int8) Engine = Log;
SET optimize_syntax_fuse_functions = 1;
EXPLAIN SYNTAX SELECT sum(a), sum(b), count(b), avg(b) from fuse_tbl FORMAT TSV;

結果:

```text
SELECT
    sum(a),
    sumCount(b).1,
    sumCount(b).2,
    (sumCount(b).1) / (sumCount(b).2)
FROM fuse_tbl

## optimize_throw_if_noop {#optimize_throw_if_noop} 



<SettingsInfoBlock type="Bool" default_value="0" />

OPTIMIZE(../../sql-reference/statements/optimize.md)クエリがマージを実行しなかった場合に例外をスローすることを有効または無効にします。

デフォルトでは、何もしなくても`OPTIMIZE`は正常に返ります。この設定により、これらの状況を区別し、例外メッセージで理由を取得できます。

可能な値:

- 1 — 例外をスローすることが有効です。
- 0 — 例外をスローすることが無効です。
## optimize_time_filter_with_preimage {#optimize_time_filter_with_preimage} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "関数を変換なしに同等の比較に変換することで、DateおよびDateTimeの述語を最適化する（例: `toYear(col) = 2023 -> col >= '2023-01-01' AND col <= '2023-12-31'`）"}]}]}/>

DateおよびDateTimeの述語を関数を変換なしに同等の比較に変換することで最適化します（例: `toYear(col) = 2023 -> col >= '2023-01-01' AND col <= '2023-12-31'`）。
## optimize_trivial_approximate_count_query {#optimize_trivial_approximate_count_query} 



<SettingsInfoBlock type="Bool" default_value="0" />

そのような推定をサポートするストレージのトリビアルカウント最適化のために近似値を使用します。例: EmbeddedRocksDB。

可能な値：

   - 0 — 最適化無効。
   - 1 — 最適化有効。
## optimize_trivial_count_query {#optimize_trivial_count_query} 



<SettingsInfoBlock type="Bool" default_value="1" />

テーブルからのトリビアルクエリ`SELECT count()`の最適化を有効または無効にします。行レベルのセキュリティを使用する必要がある場合は、この設定を無効にします。

可能な値：

   - 0 — 最適化無効。
   - 1 — 最適化有効。

関連情報:

- [optimize_functions_to_subcolumns](#optimize_functions_to_subcolumns)
## optimize_trivial_insert_select {#optimize_trivial_insert_select} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "この最適化は多くの場合意味がない"}]}]}/>

トリビアルな'INSERT INTO table SELECT ... FROM TABLES'クエリを最適化します。
## optimize_uniq_to_count {#optimize_uniq_to_count} 



<SettingsInfoBlock type="Bool" default_value="1" />

uniqおよびその変種（uniqUpToを除く）を、サブクエリがdistinctまたはgroup by句を持つ場合はcount ifに書き換えます。
## optimize_use_implicit_projections {#optimize_use_implicit_projections} 



<SettingsInfoBlock type="Bool" default_value="1" />

SELECTクエリを実行するために暗黙の投影を自動的に選択します。
## optimize_use_projections {#optimize_use_projections} 



<SettingsInfoBlock type="Bool" default_value="1" />

`SELECT`クエリを処理する際の[プロジェクション](../../engines/table-engines/mergetree-family/mergetree.md/#projections)最適化を有効または無効にします。

可能な値:

- 0 — プロジェクション最適化無効。
- 1 — プロジェクション最適化有効。
## optimize_using_constraints {#optimize_using_constraints} 



<SettingsInfoBlock type="Bool" default_value="0" />

クエリ最適化のために[制約](../../sql-reference/statements/create/table.md/#constraints)を使用します。デフォルトは`false`です。

可能な値:

- true、false
## os_thread_priority {#os_thread_priority} 



<SettingsInfoBlock type="Int64" default_value="0" />

クエリを実行するスレッドの優先度（[nice](https://en.wikipedia.org/wiki/Nice_(Unix)))を設定します。OSスケジューラは、各利用可能なCPUコア上で実行される次のスレッドを選択する際にこの優先度を考慮します。

:::note
この設定を使用するには、`CAP_SYS_NICE`権限を設定する必要があります。`clickhouse-server`パッケージは、インストール中にそれを設定します。一部の仮想環境では、`CAP_SYS_NICE`権限を設定することができません。この場合、`clickhouse-server`は開始時にそれについてのメッセージを表示します。
:::

可能な値:

- `[-20, 19]`の範囲の値を設定できます。

値が低いほど優先度が高くなります。`nice`優先度値が低いスレッドは、高い値のスレッドよりも頻繁に実行されます。高い値は、実行時間が長い非対話型クエリにとって好ましいです。なぜなら、それにより短い対話型クエリが到着した際にすぐにリソースを譲渡できるからです。
## output_format_compression_level {#output_format_compression_level} 



<SettingsInfoBlock type="UInt64" default_value="3" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "3"},{"label": "クエリ出力で圧縮レベルを変更できるようにする"}]}]}/>

クエリ出力が圧縮されている場合のデフォルト圧縮レベル。この設定は、`SELECT`クエリが`INTO OUTFILE`を持っている場合、またはテーブル関数`file`、`url`、`hdfs`、`s3`、または`azureBlobStorage`に書き込むときに適用されます。

可能な値: `1`から`22`まで
## output_format_compression_zstd_window_log {#output_format_compression_zstd_window_log} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "zstd圧縮を使用する場合にクエリ出力のzstdウィンドウログを変更できるようにする"}]}]}/>

出力圧縮方式が`zstd`の場合に使用されます。0より大きい場合、この設定は圧縮ウィンドウサイズ（2の累乗）を明示的に設定し、zstd圧縮に長距離モードを有効にします。これにより、より良い圧縮率を得ることができる場合があります。

可能な値: 非負の数。値が小さすぎたり大きすぎたりすると、`zstdlib`は例外をスローします。典型的な値は、`20`（ウィンドウサイズ = `1MB`）から`30`（ウィンドウサイズ = `1GB`）です。
## output_format_parallel_formatting {#output_format_parallel_formatting} 



<SettingsInfoBlock type="Bool" default_value="1" />

データフォーマットの並列フォーマットを有効または無効にします。[TSV](../../interfaces/formats.md/#tabseparated)、[TSKV](../../interfaces/formats.md/#tskv)、[CSV](../../interfaces/formats.md/#csv)および[JSONEachRow](../../interfaces/formats.md/#jsoneachrow)形式でのみサポートされています。

可能な値:

- 1 — 有効。
- 0 — 無効。
## page_cache_block_size {#page_cache_block_size} 



<SettingsInfoBlock type="UInt64" default_value="1048576" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1048576"},{"label": "この設定をクエリレベルで調整できるようにした。"}]}]}/>

ユーザースペースのページキャッシュに保存するファイルチャンクのサイズ（バイト単位）。キャッシュを介って行われるすべての読み取りは、このサイズの倍数に切り上げられます。

この設定はクエリレベルで調整できますが、異なるブロックサイズのキャッシュエントリは再利用できません。この設定を変更すると、既存のエントリがキャッシュから無効になります。

1 MiBのような高い値は高スループットクエリに適しており、64 KiBのような低い値は低遅延ポイントクエリに適しています。
## page_cache_inject_eviction {#page_cache_inject_eviction} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "ユーザースペースページキャッシュを追加した"}]}]}/>

ユーザースペースのページキャッシュは、ランダムにページのいくつかを無効にすることがあります。テスト目的で使用されます。
## page_cache_lookahead_blocks {#page_cache_lookahead_blocks} 



<SettingsInfoBlock type="UInt64" default_value="16" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "16"},{"label": "この設定をクエリレベルで調整できるようにした。"}]}]}/>

ユーザースペースページキャッシュミス時に、キャッシュにない通常のストレージからこの数だけの連続したブロックを一度に読み取ります。それぞれのブロックはpage_cache_block_sizeバイトです。

高い値は高スループットクエリに適しており、低遅延ポイントクエリはリードアヘッドなしでより良く機能します。
## parallel_distributed_insert_select {#parallel_distributed_insert_select} 



<SettingsInfoBlock type="UInt64" default_value="0" />

並列分散`INSERT ... SELECT`クエリを有効にします。

`INSERT INTO distributed_table_a SELECT ... FROM distributed_table_b`クエリを実行し、両方のテーブルが同じクラスターを使用し、両方のテーブルが[レプリケート](../../engines/table-engines/mergetree-family/replication.md)または非レプリケートの場合、このクエリは各シャードでローカルに処理されます。

可能な値:

- 0 — 無効。
- 1 — `SELECT`は分散エンジンの基底テーブルの各シャードで実行されます。
- 2 — `SELECT`と`INSERT`は分散エンジンの基底テーブルの各シャードで実行されます。
## parallel_hash_join_threshold {#parallel_hash_join_threshold} 



<SettingsInfoBlock type="UInt64" default_value="100000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "100000"},{"label": "新しい設定"}]}, {"id": "row-2","items": [{"label": "25.4"},{"label": "0"},{"label": "新しい設定"}]}, {"id": "row-3","items": [{"label": "25.3"},{"label": "0"},{"label": "新しい設定"}]}]}/>

ハッシュベースの結合アルゴリズムが適用される場合、この閾値は`hash`と`parallel_hash`を使用するかどうかを決定するのに役立ちます（右テーブルのサイズの推定が利用可能な場合のみ）。前者は、右テーブルのサイズが閾値を下回っていることがわかっているときに使用されます。
## parallel_replica_offset {#parallel_replica_offset} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />

この設定は内部的なもので、直接使用するべきではなく、'並列レプリカ'モードの実装の詳細を表します。この設定は、分散クエリの処理に参加するレプリカのインデックスに対して、イニシエーターサーバーによって自動的に設定されます。
## parallel_replicas_allow_in_with_subquery {#parallel_replicas_allow_in_with_subquery} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "trueの場合、INサブクエリはすべてのフォロワーレプリカで実行されます"}]}]}/>

trueの場合、INのサブクエリはすべてのフォローレプリカで実行されます。
## parallel_replicas_connect_timeout_ms {#parallel_replicas_connect_timeout_ms} 

<BetaBadge/>



<SettingsInfoBlock type="Milliseconds" default_value="300" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.6"},{"label": "300"},{"label": "並列レプリカクエリ用の接続タイムアウト"}]}]}/>

並列レプリカを使用したクエリ実行中に、リモートレプリカに接続する際のタイムアウト（ミリ秒）。タイムアウトが切れた場合、クエリ実行に使用されるそのレプリカはなくなります。
## parallel_replicas_count {#parallel_replicas_count} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />

この設定は内部的なもので、直接使用するべきではなく、'並列レプリカ'モードの実装の詳細を表します。この設定は、分散クエリの処理に参加する並列レプリカの数について、イニシエーターサーバーによって自動的に設定されます。
## parallel_replicas_custom_key {#parallel_replicas_custom_key} 

<BetaBadge/>

特定のテーブルのレプリカ間で作業を分割するために使用できる任意の整数式。
値は任意の整数式で構いません。

主キーを使用した単純な式が好まれます。

この設定が、複数のレプリカを持つ単一のシャードからなるクラスターで使用される場合、これらのレプリカは仮想シャードに変換されます。
そうでなければ、`SAMPLE`キーのように振る舞います。各シャードの複数のレプリカを使用します。
## parallel_replicas_custom_key_range_lower {#parallel_replicas_custom_key_range_lower} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "動的シャードを用いた並列レプリカ使用時に、範囲フィルタの制御に関する設定を追加"}]}]}/>

フィルタ種別`range`を使用して、カスタム範囲`[parallel_replicas_custom_key_range_lower, INT_MAX]`に基づいてレプリカ間で均等に作業を分割できます。

[parallel_replicas_custom_key_range_upper](#parallel_replicas_custom_key_range_upper)と組み合わせて使用すると、範囲`[parallel_replicas_custom_key_range_lower, parallel_replicas_custom_key_range_upper]`でレプリカ間で均等に作業を分割できます。

注: この設定は、クエリ処理中に追加データがフィルタリングされる原因にはならず、並列処理のために範囲フィルタが`[0, INT_MAX]`の範囲を分割する点を変更します。
## parallel_replicas_custom_key_range_upper {#parallel_replicas_custom_key_range_upper} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "動的シャードを用いた並列レプリカ使用時に、範囲フィルタの制御に関する設定を追加。0の値は上限を無効にします"}]}]}/>

フィルタ種別`range`を使用して、カスタム範囲`[0, parallel_replicas_custom_key_range_upper]`に基づいてレプリカ間で均等に作業を分割できます。値が0の場合、上限は無効になり、カスタムキー式の最大値が設定されます。

[parallel_replicas_custom_key_range_lower](#parallel_replicas_custom_key_range_lower)と組み合わせて使用すると、範囲`[parallel_replicas_custom_key_range_lower, parallel_replicas_custom_key_range_upper]`でレプリカ間で均等に作業を分割できます。

注: この設定は、クエリ処理中に追加データがフィルタリングされる原因にはならず、並列処理のために範囲フィルタが`[0, INT_MAX]`の範囲を分割する点を変更します。
## parallel_replicas_for_cluster_engines {#parallel_replicas_for_cluster_engines} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "1"},{"label": "新しい設定。"}]}]}/>

テーブル関数エンジンをその-Cluster代替に置換します。
## parallel_replicas_for_non_replicated_merge_tree {#parallel_replicas_for_non_replicated_merge_tree} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

trueの場合、ClickHouseは非レプリケートMergeTreeテーブルに対しても並列レプリカアルゴリズムを使用します。
## parallel_replicas_index_analysis_only_on_coordinator {#parallel_replicas_index_analysis_only_on_coordinator} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "1"},{"label": "インデックス分析はレプリカコーディネーターのみに実行され、他のレプリカではスキップされる。並列レプリカローカルプランが有効な場合に効果的"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "1"},{"label": "インデックス分析はレプリカコーディネーターのみに実行され、他のレプリカではスキップされる。並列レプリカローカルプランが有効な場合に効果的"}]}]}/>

インデックス分析はレプリカコーディネーターのみに実行され、他のレプリカではスキップされます。並列レプリカローカルプランが有効な場合に効果的です。
## parallel_replicas_insert_select_local_pipeline {#parallel_replicas_insert_select_local_pipeline} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "並列レプリカを持つ分散INSERT SELECTの間、ローカルパイプラインを使用します。現在はパフォーマンスの問題により無効です"}]}, {"id": "row-2","items": [{"label": "25.4"},{"label": "0"},{"label": "並列レプリカを持つ分散INSERT SELECTの間、ローカルパイプラインを使用します。現在はパフォーマンスの問題により無効です"}]}]}/>

並列レプリカを持つ分散INSERT SELECTの間、ローカルパイプラインを使用します。
## parallel_replicas_local_plan {#parallel_replicas_local_plan} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "並列レプリカを持つクエリにおけるローカルレプリカのためのローカルプランを使用する"}]}, {"id": "row-2","items": [{"label": "24.11"},{"label": "1"},{"label": "並列レプリカを持つクエリにおけるローカルレプリカのためのローカルプランを使用する"}]}, {"id": "row-3","items": [{"label": "24.10"},{"label": "1"},{"label": "並列レプリカを持つクエリにおけるローカルレプリカのためのローカルプランを使用する"}]}]}/>

ローカルレプリカのためのローカルプランを構築します。
## parallel_replicas_mark_segment_size {#parallel_replicas_mark_segment_size} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "この設定の値は自動的に決定されるようになった"}]}, {"id": "row-2","items": [{"label": "24.1","label": "128"},{"label": "新しい並列レプリカコーディネーター実装でのセグメントサイズを制御する新しい設定を追加"}]}]}/>

パーツが並列読み取りのためにレプリカ間で分配されるように仮想的に分割されたセグメント。これにより、これらのセグメントのサイズを制御します。何をしているのか完全に確信していない限り、この設定は変更しないことをお勧めします。値は[128; 16384]の範囲であるべきです。
## parallel_replicas_min_number_of_rows_per_replica {#parallel_replicas_min_number_of_rows_per_replica} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />

クエリに使用されるレプリカの数を(推定する行数 / min_number_of_rows_per_replica)に制限します。最大は依然として'max_parallel_replicas'によって制限されます。
## parallel_replicas_mode {#parallel_replicas_mode} 

<BetaBadge/>



<SettingsInfoBlock type="ParallelReplicasMode" default_value="read_tasks" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "read_tasks"},{"label": "この設定は、並列レプリカ機能をベータ版として提供する一環として導入されました"}]}]}/>

カスタムキーで並列レプリカ用に使用するフィルタの種類。デフォルト - カスタムキーに対して剰余演算を使用する、範囲 - カスタムキーを使用して値タイプのすべての可能な値を使用して範囲フィルタを使用します。
## parallel_replicas_only_with_analyzer {#parallel_replicas_only_with_analyzer} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "並列レプリカは分析器が有効でないとサポートされません"}]}]}/>

並列レプリカを使用するには分析器を有効にする必要があります。分析器が無効の場合、クエリ実行はローカル実行にフォールバックし、並列読み取りが有効であっても機能しません。分析器が有効でない場合に並列レプリカを使用することはサポートされていません。

## parallel_replicas_prefer_local_join {#parallel_replicas_prefer_local_join} 

<BetaBadge/>

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "真の場合、JOINが並列レプリカアルゴリズムで実行でき、右側のJOIN部分のすべてのストレージが *MergeTree の場合、GLOBAL JOIN の代わりにローカル JOIN が使用されます。"}]}]}/>

真の場合、JOINが並列レプリカアルゴリズムで実行でき、右側のJOIN部分のすべてのストレージが *MergeTree の場合、ローカル JOIN が使用されます。

## parallel_view_processing {#parallel_view_processing} 

<SettingsInfoBlock type="Bool" default_value="0" />

添付されたビューへのプッシュを逐次的ではなく同時に行うことを有効にします。

## parallelize_output_from_storages {#parallelize_output_from_storages} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.5"},{"label": "1"},{"label": "ファイル/url/s3などから読み取るクエリを実行するときに並列処理を許可します。これにより行が再配列される場合があります。"}]}]}/>

ストレージからの読み込みステップの出力を並列化します。可能であれば、ストレージから読み込んだ直後にクエリ処理の並列化を許可します。

## parsedatetime_e_requires_space_padding {#parsedatetime_e_requires_space_padding} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "MySQL DATE_FORMAT/STR_TO_DATE との互換性が向上しました。"}]}]}/>

関数 'parseDateTime' のフォーマッタ '%e' は、1 桁の日付がスペースパディングされていることを期待します。たとえば、' 2' は受け入れられますが、'2' はエラーを引き起こします。

## parsedatetime_parse_without_leading_zeros {#parsedatetime_parse_without_leading_zeros} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.11"},{"label": "1"},{"label": "MySQL DATE_FORMAT/STR_TO_DATE との互換性が向上しました。"}]}]}/>

関数 'parseDateTime' のフォーマッタ '%c', '%l' および '%k' は、先頭のゼロなしで月と時間を解析します。

## partial_merge_join_left_table_buffer_bytes {#partial_merge_join_left_table_buffer_bytes} 

<SettingsInfoBlock type="UInt64" default_value="0" />

0 でない場合は、部分マージ JOIN の左側のテーブルの左側のブロックを大きなものにグループ化します。結合スレッドごとに指定されたメモリの最大 2 倍を使用します。

## partial_merge_join_rows_in_right_blocks {#partial_merge_join_rows_in_right_blocks} 

<SettingsInfoBlock type="UInt64" default_value="65536" />

[JOIN](../../sql-reference/statements/select/join.md) クエリの部分マージ JOIN アルゴリズムにおける右側の結合データブロックのサイズを制限します。

ClickHouse サーバー:

1. 右側の結合データを指定された行数までのブロックに分割します。
2. 各ブロックを最小値と最大値でインデックスします。
3. 可能であれば、準備されたブロックをディスクにアンロードします。

可能な値:

- 正の整数。推奨される値の範囲: \[1000, 100000\]。

## partial_result_on_first_cancel {#partial_result_on_first_cancel} 

<SettingsInfoBlock type="Bool" default_value="0" />

クエリがキャンセルされた後に部分結果を返すことを許可します。

## parts_to_delay_insert {#parts_to_delay_insert} 

<SettingsInfoBlock type="UInt64" default_value="0" />

宛先テーブルに単一のパーティションにおいてこの数以上のアクティブなパーツが含まれている場合、テーブルへの挿入を人工的に遅延させます。

## parts_to_throw_insert {#parts_to_throw_insert} 

<SettingsInfoBlock type="UInt64" default_value="0" />

宛先テーブルの単一パーティションにおいてこの数以上のアクティブなパーツがある場合、'Too many parts ...' 例外をスローします。

## periodic_live_view_refresh {#periodic_live_view_refresh} 

<SettingsInfoBlock type="Seconds" default_value="60" />

定期的に更新されるライブビューを強制的に更新する間隔。

## poll_interval {#poll_interval} 

<SettingsInfoBlock type="UInt64" default_value="10" />

サーバーでのクエリ待機ループのブロックを指定された秒数増加させます。

## postgresql_connection_attempt_timeout {#postgresql_connection_attempt_timeout} 

<SettingsInfoBlock type="UInt64" default_value="2" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "2"},{"label": "PostgreSQL 接続の 'connect_timeout' パラメータを制御することを許可します。"}]}]}/>

PostgreSQL エンドポイントへの接続試行の接続タイムアウト（秒）。

接続 URL の `connect_timeout` パラメータとして値が渡されます。

## postgresql_connection_pool_auto_close_connection {#postgresql_connection_pool_auto_close_connection} 

<SettingsInfoBlock type="Bool" default_value="0" />

接続をプールに戻す前に接続を閉じます。

## postgresql_connection_pool_retries {#postgresql_connection_pool_retries} 

<SettingsInfoBlock type="UInt64" default_value="2" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "2"},{"label": "PostgreSQL 接続プールのリトライ回数を制御することを許可します。"}]}]}/>

PostgreSQL テーブルエンジンおよびデータベースエンジンの接続プールのプッシュ/ポップリトライ回数。

## postgresql_connection_pool_size {#postgresql_connection_pool_size} 

<SettingsInfoBlock type="UInt64" default_value="16" />

PostgreSQL テーブルエンジンおよびデータベースエンジン用の接続プールのサイズ。

## postgresql_connection_pool_wait_timeout {#postgresql_connection_pool_wait_timeout} 

<SettingsInfoBlock type="UInt64" default_value="5000" />

PostgreSQL テーブルエンジンおよびデータベースエンジンの空のプールでの接続プールのプッシュ/ポップタイムアウト。デフォルトでは空のプールでブロックします。

## postgresql_fault_injection_probability {#postgresql_fault_injection_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "0"},{"label": "新しい設定"}]}]}/>

内部（レプリケーション用）PostgreSQL クエリが失敗するおおよその確率。有効な値の範囲は [0.0f, 1.0f] です。

## prefer_column_name_to_alias {#prefer_column_name_to_alias} 

<SettingsInfoBlock type="Bool" default_value="0" />

クエリ式や句において別名の代わりに元のカラム名を使用するかどうかを有効または無効にします。別名がカラム名と同じ場合、特に重要です。[式の別名](/sql-reference/syntax#notes-on-usage)を参照してください。この設定を有効にすると、ClickHouse のエイリアス構文ルールがほとんどの他のデータベースエンジンとより互換性が高くなります。

可能な値:

- 0 — 列名をエイリアスで置き換えます。
- 1 — 列名はエイリアスで置き換えられません。

**例**

有効と無効の違い:

クエリ:

```sql
SET prefer_column_name_to_alias = 0;
SELECT avg(number) AS number, max(number) FROM numbers(10);

結果:

```text
サーバーから受信した例外 (バージョン 21.5.1):
コード: 184. DB::Exception: localhost:9000 から受信。DB::Exception: 集約関数 avg(number) は、クエリ内の別の集約関数内で見つかりました: avg(number) AS number を処理中です。

クエリ:

```sql
SET prefer_column_name_to_alias = 1;
SELECT avg(number) AS number, max(number) FROM numbers(10);

結果:

```text
┌─number─┬─max(number)─┐
│    4.5 │           9 │
└────────┴─────────────┘

## prefer_external_sort_block_bytes {#prefer_external_sort_block_bytes} 

<SettingsInfoBlock type="UInt64" default_value="16744704" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "16744704"},{"label": "外部ソート用の最大ブロックバイト数を優先し、マージ中のメモリ使用量を減少させます。"}]}]}/>

外部ソート用の最大ブロックバイト数を優先し、マージ中のメモリ使用量を減少させます。

## prefer_global_in_and_join {#prefer_global_in_and_join} 

<SettingsInfoBlock type="Bool" default_value="0" />

`IN`/`JOIN` 演算子を `GLOBAL IN`/`GLOBAL JOIN` に置き換えることを有効にします。

可能な値:

- 0 — 無効。`IN`/`JOIN` 演算子は `GLOBAL IN`/`GLOBAL JOIN` に置き換えられません。
- 1 — 有効。`IN`/`JOIN` 演算子は `GLOBAL IN`/`GLOBAL JOIN` に置き換えられます。

**使用法**

`SET distributed_product_mode=global` は、分散テーブルのクエリの動作を変更しますが、ローカルテーブルや外部リソースからのテーブルには適していません。ここで `prefer_global_in_and_join` 設定の出番です。

たとえば、ローカルテーブルを持つクエリサービングノードがあるとします。これらは分散に適していません。分散処理中にデータを流動的に分散させるには、`GLOBAL` キーワード、`GLOBAL IN`/`GLOBAL JOIN` が必要です。

`prefer_global_in_and_join` の別の使用ケースは、外部エンジンによって作成されたテーブルにアクセスすることです。この設定は、そのようなテーブルを結合する際の外部ソースへの呼び出し回数を減らすのに役立ちます: クエリごとに1回のみの呼び出し。

**詳細情報:**

- `GLOBAL IN`/`GLOBAL JOIN` の使い方については、[分散サブクエリ](/sql-reference/operators/in#distributed-subqueries)を参照してください。

## prefer_localhost_replica {#prefer_localhost_replica} 

<SettingsInfoBlock type="Bool" default_value="1" />

分散クエリの処理時にローカルホストレプリカを優先的に使用するかどうかを有効または無効にします。

可能な値:

- 1 — ClickHouse は、存在する場合、必ずローカルホストレプリカにクエリを送信します。
- 0 — ClickHouse は、[load_balancing](#load_balancing) 設定で指定されたバランス戦略を使用します。

:::note
[max_parallel_replicas](#max_parallel_replicas) を [parallel_replicas_custom_key](#parallel_replicas_custom_key) なしで使用する場合は、この設定を無効にしてください。
[parallel_replicas_custom_key](#parallel_replicas_custom_key) が設定されている場合は、複数のレプリカを含む複数のシャードがあるクラスターで使用されている場合にのみ、この設定を無効にします。
単一のシャードと複数のレプリカがあるクラスターで使用されている場合、この設定を無効にすると悪影響があります。
:::

## prefer_warmed_unmerged_parts_seconds {#prefer_warmed_unmerged_parts_seconds} 

<CloudOnlyBadge/>

<SettingsInfoBlock type="Int64" default_value="0" />

ClickHouse Cloud でのみ効果があります。マージされていないパーツがこの秒数未満で古く、事前に暖められていない（[cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch)を参照）が、すべてのソースパーツが利用可能で事前に暖められている場合、SELECT クエリはそれらのパーツから読み取ります。Replicated-/SharedMergeTree のみが対象です。この設定は、CacheWarmer がパーツを処理したかどうかのみを確認します。他の何かによってキャッシュに取得された場合、CacheWarmer がその部分に到達するまで冷たいと見なされます。また、キャッシュから追い出された場合、温かいままとみなされます。

## preferred_block_size_bytes {#preferred_block_size_bytes} 

<SettingsInfoBlock type="UInt64" default_value="1000000" />

この設定は、クエリ処理のデータブロックサイズを調整し、より粗い 'max_block_size' 設定に追加の微調整を表します。カラムが大きく、'max_block_size' 行がある場合、ブロックサイズは指定されたバイト数よりも大きくなる可能性があります。そのサイズは、より良い CPU キャッシュの局所性のために小さくなります。

## preferred_max_column_in_block_size_bytes {#preferred_max_column_in_block_size_bytes} 

<SettingsInfoBlock type="UInt64" default_value="0" />

読み取り中のブロック内での最大カラムサイズの制限。キャッシュミスの回数を減少させます。L2 キャッシュサイズに近い必要があります。

## preferred_optimize_projection_name {#preferred_optimize_projection_name} 

空でない文字列に設定されている場合、ClickHouse はクエリ内で指定されたプロジェクションを適用しようとします。

可能な値:

- 文字列: 指定されたプロジェクションの名前。

## prefetch_buffer_size {#prefetch_buffer_size} 

<SettingsInfoBlock type="UInt64" default_value="1048576" />

ファイルシステムから読み込むためのプフェッチバッファの最大サイズ。

## print_pretty_type_names {#print_pretty_type_names} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "1"},{"label": "より良いユーザー体験。"}]}]}/>

`DESCRIBE` クエリおよび `toTypeName()` 関数で深くネストされた型名をインデント付きできれいに印刷できるようにします。

例:

```sql
CREATE TABLE test (a Tuple(b String, c Tuple(d Nullable(UInt64), e Array(UInt32), f Array(Tuple(g String, h Map(String, Array(Tuple(i String, j UInt64))))), k Date), l Nullable(String))) ENGINE=Memory;
DESCRIBE TABLE test FORMAT TSVRaw SETTINGS print_pretty_type_names=1;

a   Tuple(
    b String,
    c Tuple(
        d Nullable(UInt64),
        e Array(UInt32),
        f Array(Tuple(
            g String,
            h Map(
                String,
                Array(Tuple(
                    i String,
                    j UInt64
                ))
            )
        )),
        k Date
    ),
    l Nullable(String)
)

## priority {#priority} 

<SettingsInfoBlock type="UInt64" default_value="0" />

クエリの優先度。1 - 最も高い、値が高いほど優先度が低くなります; 0 - 優先度を使用しません。

## push_external_roles_in_interserver_queries {#push_external_roles_in_interserver_queries} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "新しい設定。"}]}]}/>

クエリを実行する際に、オリジネーターから他のノードへのユーザーロールのプッシュを有効にします。

## query_cache_compress_entries {#query_cache_compress_entries} 

<SettingsInfoBlock type="Bool" default_value="1" />

[クエリキャッシュ](../query-cache.md)内のエントリを圧縮します。クエリキャッシュのメモリ消費を減らしますが、挿入や読み取りが遅くなります。

可能な値:

- 0 - 無効
- 1 - 有効

## query_cache_max_entries {#query_cache_max_entries} 

<SettingsInfoBlock type="UInt64" default_value="0" />

現在のユーザーが[クエリキャッシュ](../query-cache.md)に保存できるクエリ結果の最大数。0は無制限を意味します。

可能な値:

- 正の整数 >= 0。

## query_cache_max_size_in_bytes {#query_cache_max_size_in_bytes} 

<SettingsInfoBlock type="UInt64" default_value="0" />

現在のユーザーが[クエリキャッシュ](../query-cache.md)に割り当てられる最大メモリ量（バイト単位）。0は無制限を意味します。

可能な値:

- 正の整数 >= 0。

## query_cache_min_query_duration {#query_cache_min_query_duration} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

クエリが[クエリキャッシュ](../query-cache.md)に保存されるために必要な最低実行時間（ミリ秒単位）。

可能な値:

- 正の整数 >= 0。

## query_cache_min_query_runs {#query_cache_min_query_runs} 

<SettingsInfoBlock type="UInt64" default_value="0" />

結果が[クエリキャッシュ](../query-cache.md)に保存される前に`SELECT`クエリが実行される必要がある最小回数。

可能な値:

- 正の整数 >= 0。

## query_cache_nondeterministic_function_handling {#query_cache_nondeterministic_function_handling} 

<SettingsInfoBlock type="QueryResultCacheNondeterministicFunctionHandling" default_value="throw" />

非決定的関数（`rand()`や`now()` など）を含む `SELECT` クエリに対して、[クエリキャッシュ](../query-cache.md)がどのように対処するかを制御します。

可能な値:

- `'throw'` - 例外をスローし、クエリ結果をキャッシュしません。
- `'save'` - クエリ結果をキャッシュします。
- `'ignore'` - クエリ結果をキャッシュせず、例外もスローしません。

## query_cache_share_between_users {#query_cache_share_between_users} 

<SettingsInfoBlock type="Bool" default_value="0" />

この設定をオンにすると、[クエリキャッシュ](../query-cache.md)にキャッシュされた`SELECT`クエリの結果を他のユーザーが読み取ることができます。
セキュリティ上の理由から、この設定を有効にすることは推奨されません。

可能な値:

- 0 - 無効
- 1 - 有効

## query_cache_squash_partial_results {#query_cache_squash_partial_results} 

<SettingsInfoBlock type="Bool" default_value="1" />

部分結果ブロックを[max_block_size](#max_block_size)のサイズのブロックに押しつぶします。[クエリキャッシュ](../query-cache.md)への挿入のパフォーマンスは低下しますが、キャッシュエントリの圧縮可能性は向上します（[query_cache_compress-entries](#query_cache_compress_entries)を参照）。

可能な値:

- 0 - 無効
- 1 - 有効

## query_cache_system_table_handling {#query_cache_system_table_handling} 

<SettingsInfoBlock type="QueryResultCacheSystemTableHandling" default_value="throw" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "throw"},{"label": "クエリキャッシュはもはやシステムテーブルに対するクエリの結果をキャッシュしません。"}]}]}/>

[クエリキャッシュ](../query-cache.md)が、すなわち`system.*`および`information_schema.*`データベース内のテーブルに対する `SELECT` クエリをどのように処理するかを制御します。

可能な値:

- `'throw'` - 例外をスローし、クエリ結果をキャッシュしません。
- `'save'` - クエリ結果をキャッシュします。
- `'ignore'` - クエリ結果をキャッシュせず、例外もスローしません。

## query_cache_tag {#query_cache_tag} 

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": ""},{"label": "クエリキャッシュ設定にラベルを付けるための新しい設定。"}]}]}/>

[クエリキャッシュ](../query-cache.md)エントリにラベルとして機能する文字列。
異なるタグを持つ同じクエリは、クエリキャッシュによって異なるものと見なされます。

可能な値:

- 任意の文字列。

## query_cache_ttl {#query_cache_ttl} 

<SettingsInfoBlock type="Seconds" default_value="60" />

この時間（秒）後に[クエリキャッシュ](../query-cache.md)内のエントリは古くなります。

可能な値:

- 正の整数 >= 0。

## query_condition_cache_store_conditions_as_plaintext {#query_condition_cache_store_conditions_as_plaintext} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "新しい設定"}]}]}/>

[クエリ条件キャッシュ](/operations/query-condition-cache)のフィルター条件を平文で保存します。
有効にすると、`system.query_condition_cache`は、キャッシュの問題をデバッグするのに役立つ正確なフィルター条件を表示します。
平文のフィルター条件は、機密情報を暴露する可能性があるため、デフォルトでは無効です。

可能な値:

- 0 - 無効
- 1 - 有効

## query_metric_log_interval {#query_metric_log_interval} 

<SettingsInfoBlock type="Int64" default_value="-1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "-1"},{"label": "新しい設定。"}]}]}/>

個々のクエリに対して、[query_metric_log](../../operations/system-tables/query_metric_log.md)が収集される間隔（ミリ秒単位）。

負の値に設定されている場合は、[query_metric_log 設定](/operations/server-configuration-parameters/settings#query_metric_log)からの値 `collect_interval_milliseconds` を使用するか、存在しない場合はデフォルトで 1000 になります。

単一のクエリの収集を無効にするには、`query_metric_log_interval` を 0 に設定します。

デフォルト値: -1

## query_plan_aggregation_in_order {#query_plan_aggregation_in_order} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.12"},{"label": "1"},{"label": "クエリプランに関する一部のリファクタリングを有効にします。"}]}]}/>

クエリプランレベルの最適化として、集約を順序通りに切り替えます。
設定 [query_plan_enable_optimizations](#query_plan_enable_optimizations) が 1 の場合にのみ効果があります。

:::note
これは専門家レベルの設定であり、開発者によるデバッグ目的でのみ使用する必要があります。この設定は、将来的に互換性のない方法で変更されるか、削除される可能性があります。
:::

可能な値:

- 0 - 無効
- 1 - 有効

## query_plan_convert_join_to_in {#query_plan_convert_join_to_in} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "新しい設定"}]}]}/>

左側のテーブルにのみ結びついている出力列に対して、JOIN を IN のサブクエリに変換することを許可します。

## query_plan_convert_outer_join_to_inner_join {#query_plan_convert_outer_join_to_inner_join} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "1"},{"label": "JOIN 後のフィルターが常にデフォルト値をフィルタリングする場合、OUTER JOINをINNER JOINに変換できるようにします。"}]}]}/>

JOIN 後のフィルターが常にデフォルト値をフィルタリングする場合、OUTER JOIN を INNER JOIN に変換することを許可します。

## query_plan_enable_multithreading_after_window_functions {#query_plan_enable_multithreading_after_window_functions} 

<SettingsInfoBlock type="Bool" default_value="1" />

ウィンドウ関数の評価後にマルチスレッド処理を有効にして、並列ストリーム処理を可能にします。

## query_plan_enable_optimizations {#query_plan_enable_optimizations} 

<SettingsInfoBlock type="Bool" default_value="1" />

クエリプランレベルの最適化を切り替えます。

:::note
これは専門家レベルの設定であり、開発者によるデバッグ目的でのみ使用する必要があります。この設定は、将来的に互換性のない方法で変更されるか、削除される可能性があります。
:::

可能な値:

- 0 - クエリプランレベルのすべての最適化を無効にする。
- 1 - クエリプランレベルの最適化を有効にする（ただし、個々の最適化は個別の設定を介して依然として無効にすることができます）。

## query_plan_execute_functions_after_sorting {#query_plan_execute_functions_after_sorting} 

<SettingsInfoBlock type="Bool" default_value="1" />

ソートステップの後に式を移動するクエリプランレベルの最適化を切り替えます。
設定 [query_plan_enable_optimizations](#query_plan_enable_optimizations) が 1 の場合にのみ効果があります。

:::note
これは専門家レベルの設定であり、開発者によるデバッグ目的でのみ使用する必要があります。この設定は、将来的に互換性のない方法で変更されるか、削除される可能性があります。
:::

可能な値:

- 0 - 無効
- 1 - 有効

## query_plan_filter_push_down {#query_plan_filter_push_down} 

<SettingsInfoBlock type="Bool" default_value="1" />

クエリプランレベルの最適化を切り替えて、実行プラン内でフィルターを下に移動します。
設定 [query_plan_enable_optimizations](#query_plan_enable_optimizations) が 1 の場合にのみ効果があります。

:::note
これは専門家レベルの設定であり、開発者によるデバッグ目的でのみ使用する必要があります。この設定は、将来的に互換性のない方法で変更されるか、削除される可能性があります。
:::

可能な値:

- 0 - 無効
- 1 - 有効

## query_plan_join_shard_by_pk_ranges {#query_plan_join_shard_by_pk_ranges} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "新しい設定"}]}]}/>

両方のテーブルの結合キーが主キーのプレフィックスを含む場合、JOIN にシャーディングを適用します。hash、parallel_hash、full_sorting_merge アルゴリズムがサポートされます。

## query_plan_join_swap_table {#query_plan_join_swap_table} 

<SettingsInfoBlock type="BoolAuto" default_value="auto" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "auto"},{"label": "新しい設定。以前は右テーブルが常に選択されていました。"}]}]}/>

クエリプラン内でどちらの側をビルドテーブル（別名、ハッシュ結合用のハッシュテーブルに挿入される側）とすべきかを決定します。この設定は、`JOIN ON` 句を使用した `ALL` 結合の厳密さにのみ対応しています。可能な値は以下の通りです。

- 'auto': プランナーがビルドテーブルに使用するテーブルを決定します。
- 'false': テーブルを交換しない（右テーブルがビルドテーブル）。
- 'true': テーブルを常に交換する（左テーブルがビルドテーブル）。

## query_plan_lift_up_array_join {#query_plan_lift_up_array_join} 

<SettingsInfoBlock type="Bool" default_value="1" />

ARRAY JOIN を実行プランで上に移動するクエリプランレベルの最適化を切り替えます。
設定 [query_plan_enable_optimizations](#query_plan_enable_optimizations) が 1 の場合にのみ効果があります。

:::note
これは専門家レベルの設定であり、開発者によるデバッグ目的でのみ使用する必要があります。この設定は、将来的に互換性のない方法で変更されるか、削除される可能性があります。
:::

可能な値:

- 0 - 無効
- 1 - 有効

## query_plan_lift_up_union {#query_plan_lift_up_union} 

<SettingsInfoBlock type="Bool" default_value="1" />

クエリプランの大きなサブツリーをマージに移動する最適化を切り替え、さらなる最適化を有効にします。
設定 [query_plan_enable_optimizations](#query_plan_enable_optimizations) が 1 の場合にのみ効果があります。

:::note
これは専門家レベルの設定であり、開発者によるデバッグ目的でのみ使用する必要があります。この設定は、将来的に互換性のない方法で変更されるか、削除される可能性があります。
:::

可能な値:

- 0 - 無効
- 1 - 有効

## query_plan_max_limit_for_lazy_materialization {#query_plan_max_limit_for_lazy_materialization} 

<SettingsInfoBlock type="UInt64" default_value="10" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "10"},{"label": "クエリプランを使用して遅延マテリアリゼーションの最適化を行う最大リミット値を制御するための新しい設定を追加しました。ゼロの場合、制限はありません。"}]}]}/>

クエリプランを使用して遅延マテリアリゼーション最適化を行う最大リミット値を制御します。ゼロの場合、制限はありません。

## query_plan_max_optimizations_to_apply {#query_plan_max_optimizations_to_apply} 

<SettingsInfoBlock type="UInt64" default_value="10000" />

クエリプランに適用される最大最適化の合計数を制限します。[query_plan_enable_optimizations](#query_plan_enable_optimizations) の設定を参照してください。
複雑なクエリの長い最適化時間を避けるのに便利です。
EXPLAIN PLAN クエリでは、この制限に達した後に最適化を停止し、そのままのプランを返します。
通常のクエリ実行では、実際の最適化数がこの設定を超えた場合、例外がスローされます。

:::note
これは専門家レベルの設定であり、開発者によるデバッグ目的でのみ使用する必要があります。この設定は、将来的に互換性のない方法で変更されるか、削除される可能性があります。
:::

## query_plan_merge_expressions {#query_plan_merge_expressions} 

<SettingsInfoBlock type="Bool" default_value="1" />

連続するフィルターをマージするクエリプランレベルの最適化を切り替えます。
設定 [query_plan_enable_optimizations](#query_plan_enable_optimizations) が 1 の場合にのみ効果があります。

:::note
これは専門家レベルの設定であり、開発者によるデバッグ目的でのみ使用する必要があります。この設定は、将来的に互換性のない方法で変更されるか、削除される可能性があります。
:::

可能な値:

- 0 - 無効
- 1 - 有効

## query_plan_merge_filter_into_join_condition {#query_plan_merge_filter_into_join_condition} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "フィルターをJOIN条件にマージし、CROSS JOINをINNER JOINに変換できるようにします。"}]}]}/>

フィルターをJOIN条件にマージし、CROSS JOINをINNER JOINに変換できるようにします。

## query_plan_merge_filters {#query_plan_merge_filters} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "クエリプラン内のフィルターをマージできるようにします。"}]}, {"id": "row-2","items": [{"label": "24.11"},{"label": "1"},{"label": "クエリプラン内のフィルターをマージできるようになりました。この新しいアナライザーでフィルタープッシュダウンを適切にサポートするために必要です。"}]}]}/>

クエリプラン内のフィルターをマージできるようにします。

## query_plan_optimize_lazy_materialization {#query_plan_optimize_lazy_materialization} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "遅延マテリアリゼーション最適化にクエリプランを使用できるようになります。"}]}]}/>

遅延マテリアリゼーション最適化にクエリプランを使用できるようになります。

## query_plan_optimize_prewhere {#query_plan_optimize_prewhere} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "対応するストレージのFILTERをPREWHERE式にプッシュダウンできるようにします。"}]}]}/>

対応するストレージのフィルターをPREWHERE式にプッシュダウンできるようにします。

## query_plan_push_down_limit {#query_plan_push_down_limit} 

<SettingsInfoBlock type="Bool" default_value="1" />

実行プラン内でLIMITを下に移動するクエリプランレベルの最適化を切り替えます。
設定 [query_plan_enable_optimizations](#query_plan_enable_optimizations) が 1 の場合にのみ効果があります。

:::note
これは専門家レベルの設定であり、開発者によるデバッグ目的でのみ使用する必要があります。この設定は、将来的に互換性のない方法で変更されるか、削除される可能性があります。
:::

可能な値:

- 0 - 無効
- 1 - 有効

## query_plan_read_in_order {#query_plan_read_in_order} 

<SettingsInfoBlock type="Bool" default_value="1" />

読み取り順序の最適化をクエリプランレベル正に切り替えます。
設定 [query_plan_enable_optimizations](#query_plan_enable_optimizations) が 1 の場合にのみ効果があります。

:::note
これは専門家レベルの設定であり、開発者によるデバッグ目的でのみ使用する必要があります。この設定は、将来的に互換性のない方法で変更されるか、削除される可能性があります。
:::

可能な値:

- 0 - 無効
- 1 - 有効

## query_plan_remove_redundant_distinct {#query_plan_remove_redundant_distinct} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.2"},{"label": "1"},{"label": "クエリプラン内の冗長なDistinct手順を削除します。"}]}]}/>

冗長なDISTINCT手順をクエリプラン内から削除するための最適化を切り替えます。
設定 [query_plan_enable_optimizations](#query_plan_enable_optimizations) が 1 の場合にのみ効果があります。

:::note
これは専門家レベルの設定であり、開発者によるデバッグ目的でのみ使用する必要があります。この設定は、将来的に互換性のない方法で変更されるか、削除される可能性があります。
:::

可能な値:

- 0 - 無効
- 1 - 有効
## query_plan_remove_redundant_sorting {#query_plan_remove_redundant_sorting} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.1"},{"label": "1"},{"label": "クエリプランで冗長なソートを削除します。たとえば、サブクエリ内のORDER BY句に関連するソートステップ"}]}]}/>

クエリプランレベルの最適化を切り替え、冗長なソートステップを削除します。たとえば、サブクエリ内のソートステップなどです。設定[query_plan_enable_optimizations](#query_plan_enable_optimizations)が1である場合のみ有効になります。

:::note
これは開発者によるデバッグのためにのみ使用されるべきエキスパートレベルの設定です。設定は将来的に後方互換性のない変更を受ける可能性があるか、削除されることがあります。
:::

可能な値:

- 0 - 無効化
- 1 - 有効化

## query_plan_reuse_storage_ordering_for_window_functions {#query_plan_reuse_storage_ordering_for_window_functions} 

<SettingsInfoBlock type="Bool" default_value="1" />

クエリプランレベルの最適化を切り替え、ウィンドウ関数のソート時にストレージのソートを使用します。設定[query_plan_enable_optimizations](#query_plan_enable_optimizations)が1である場合のみ有効になります。

:::note
これは開発者によるデバッグのためにのみ使用されるべきエキスパートレベルの設定です。設定は将来的に後方互換性のない変更を受ける可能性があるか、削除されることがあります。
:::

可能な値:

- 0 - 無効化
- 1 - 有効化

## query_plan_split_filter {#query_plan_split_filter} 

<SettingsInfoBlock type="Bool" default_value="1" />

:::note
これは開発者によるデバッグのためにのみ使用されるべきエキスパートレベルの設定です。設定は将来的に後方互換性のない変更を受ける可能性があるか、削除されることがあります。
:::

クエリプランレベルの最適化を切り替え、フィルタを式に分割します。設定[query_plan_enable_optimizations](#query_plan_enable_optimizations)が1である場合のみ有効になります。

可能な値:

- 0 - 無効化
- 1 - 有効化

## query_plan_try_use_vector_search {#query_plan_try_use_vector_search} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "新しい設定。"}]}]}/>

ベクター類似性インデックスを使用しようとするクエリプランレベルの最適化を切り替えます。設定[query_plan_enable_optimizations](#query_plan_enable_optimizations)が1である場合のみ有効になります。

:::note
これは開発者によるデバッグのためにのみ使用されるべきエキスパートレベルの設定です。設定は将来的に後方互換性のない変更を受ける可能性があるか、削除されることがあります。
:::

可能な値:

- 0 - 無効化
- 1 - 有効化

## query_plan_use_new_logical_join_step {#query_plan_use_new_logical_join_step} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "新しいステップを有効化"}]}, {"id": "row-2","items": [{"label": "25.1"},{"label": "0"},{"label": "新しい結合ステップ、内部の変更"}]}]}/>

クエリプランで新しい論理結合ステップを使用します。

## query_profiler_cpu_time_period_ns {#query_profiler_cpu_time_period_ns} 

<SettingsInfoBlock type="UInt64" default_value="1000000000" />

[クエリプロファイラー](../../operations/optimizing-performance/sampling-query-profiler.md)のCPUクロックタイマーの期間を設定します。このタイマーはCPU時間のみにカウントされます。

可能な値:

- 正の整数ナノ秒数。

    推奨される値:

            - 単一クエリで10000000（毎秒100回）ナノ秒以上。
            - クラスター全体のプロファイリングで1000000000（毎秒1回）。

- タイマーをオフにするには0を使用します。

**ClickHouse Cloudでは一時的に無効です。**

参考情報:

- システムテーブル[trace_log](/operations/system-tables/trace_log)

## query_profiler_real_time_period_ns {#query_profiler_real_time_period_ns} 

<SettingsInfoBlock type="UInt64" default_value="1000000000" />

[クエリプロファイラー](../../operations/optimizing-performance/sampling-query-profiler.md)の実際のクロックタイマーの期間を設定します。実際のクロックタイマーは壁時計時間をカウントします。

可能な値:

- 正の整数ナノ秒数。

    推奨される値:

            - 単一クエリで10000000（毎秒100回）ナノ秒以下。
            - クラスター全体のプロファイリングで1000000000（毎秒1回）。

- タイマーをオフにするには0を使用します。

**ClickHouse Cloudでは一時的に無効です。**

参考情報:

- システムテーブル[trace_log](/operations/system-tables/trace_log)

## queue_max_wait_ms {#queue_max_wait_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

要求キュー内での待機時間です。並行要求の数が最大を超える場合。

## rabbitmq_max_wait_ms {#rabbitmq_max_wait_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="5000" />

RabbitMQから読む際の待機時間です。リトライの前に待ちます。

## read_backoff_max_throughput {#read_backoff_max_throughput} 

<SettingsInfoBlock type="UInt64" default_value="1048576" />

遅い読み取りの場合にスレッド数を減少させる設定です。読み取り帯域幅がそれ以下のバイト数/秒であるときにイベントをカウントします。

## read_backoff_min_concurrency {#read_backoff_min_concurrency} 

<SettingsInfoBlock type="UInt64" default_value="1" />

遅い読み取りの場合に最小スレッド数を保とうとする設定です。

## read_backoff_min_events {#read_backoff_min_events} 

<SettingsInfoBlock type="UInt64" default_value="2" />

遅い読み取りの場合にスレッド数を減少させる設定です。スレッド数が減少するイベントの数です。

## read_backoff_min_interval_between_events_ms {#read_backoff_min_interval_between_events_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="1000" />

遅い読み取りの場合にスレッド数を減少させる設定です。特定の間のイベントに対して無視し、前のイベントが一定時間未満経過している場合は無視します。

## read_backoff_min_latency_ms {#read_backoff_min_latency_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="1000" />

遅い読み取りの場合にスレッド数を減少させる設定です。少なくともその時間がかかった読み取りのみを考慮します。

## read_from_filesystem_cache_if_exists_otherwise_bypass_cache {#read_from_filesystem_cache_if_exists_otherwise_bypass_cache} 

<SettingsInfoBlock type="Bool" default_value="0" />

パッシブモードでファイルシステムキャッシュを使用できるようにします - 既存のキャッシュエントリから利益を得ますが、キャッシュに新しいエントリを追加しません。この設定を重いad-hocクエリ向けに設定し、短いリアルタイムクエリには無効のままにすると、重いクエリによるキャッシュのスラッシングを回避し、全体のシステム効率を向上させることができます。

## read_from_page_cache_if_exists_otherwise_bypass_cache {#read_from_page_cache_if_exists_otherwise_bypass_cache} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "ユーザースペースのページキャッシュを追加"}]}]}/>

パッシブモードでユーザースペースのページキャッシュを使用します。read_from_filesystem_cache_if_exists_otherwise_bypass_cacheのような動作をします。

## read_in_order_two_level_merge_threshold {#read_in_order_two_level_merge_threshold} 

<SettingsInfoBlock type="UInt64" default_value="100" />

主キーの順序でのマルチスレッド読み取り中に予備マージステップを実行するために読み取る最小パーツ数です。

## read_in_order_use_buffering {#read_in_order_use_buffering} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "1"},{"label": "主キーの順序で読み取る際にマージ前にバッファリングを使用"}]}]}/>

主キーの順序で読み取る際にマージ前にバッファリングを使用します。これにより、クエリの実行の並行性が増加します。

## read_in_order_use_virtual_row {#read_in_order_use_virtual_row} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "主キーまたはその単調関数の順序で読み取り中に仮想行を使用します。これは、関連する部分のみを触れるため、複数の部分を検索する際に便利です。"}]}]}/>

主キーまたはその単調関数の順序で読み取る際に仮想行を使用します。これは、複数の部分を検索する際に関連する部分のみを触れるため便利です。

## read_overflow_mode {#read_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

制限を超えた場合の動作を設定します。

## read_overflow_mode_leaf {#read_overflow_mode_leaf} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

データ読み取りのボリュームがリーフ限界の一つを超える場合に発生する動作を設定します。

可能なオプション:
- `throw`: 例外をスローします（デフォルト）。
- `break`: クエリの実行を停止し、部分結果を返します。

## read_priority {#read_priority} 

<SettingsInfoBlock type="Int64" default_value="0" />

ローカルファイルシステムまたはリモートファイルシステムからデータを読み取る優先度です。ローカルファイルシステムに対する'pread_threadpool'メソッドとリモートファイルシステムに対する`threadpool`メソッドでのみサポートされています。

## read_through_distributed_cache {#read_through_distributed_cache} 

<CloudOnlyBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "ClickHouse Cloud用の設定"}]}]}/>

ClickHouse Cloudでのみ有効です。分散キャッシュからの読み取りを許可します。 

## readonly {#readonly} 

<SettingsInfoBlock type="UInt64" default_value="0" />

0 - 読み取り専用の制限なし。 1 - 読み取り要求のみ、明示的に許可された設定の変更も。 2 - 読み取り要求のみ、設定の変更も可能ですが、'readonly'設定を除く。 

## receive_data_timeout_ms {#receive_data_timeout_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="2000" />

最初のデータパケットまたはレプリカからの進行を示すパケットを受信するための接続タイムアウトです。

## receive_timeout {#receive_timeout} 

<SettingsInfoBlock type="Seconds" default_value="300" />

ネットワークからデータを受信する際のタイムアウトで、秒単位です。この間にバイトが受信されなかった場合、例外がスローされます。クライアントでこの設定を行った場合、サーバーの対応する接続端でも'send_timeout'が設定されます。

## regexp_max_matches_per_row {#regexp_max_matches_per_row} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

1行あたりの正規表現の最大一致数を設定します。[extractAllGroupsHorizontal](/sql-reference/functions/string-search-functions#extractallgroupshorizontal)関数を使用する際にメモリの過負荷から保護するために使用します。

可能な値:

- 正の整数。

## reject_expensive_hyperscan_regexps {#reject_expensive_hyperscan_regexps} 

<SettingsInfoBlock type="Bool" default_value="1" />

高いコストがかかると考えられるハイパースキャンで評価されるパターンを拒否します（NFA状態の爆発のため）。

## remerge_sort_lowered_memory_bytes_ratio {#remerge_sort_lowered_memory_bytes_ratio} 

<SettingsInfoBlock type="Float" default_value="2" />

再マージ後のメモリ使用量がこの比率で削減されない場合、再マージは無効になります。

## remote_filesystem_read_method {#remote_filesystem_read_method} 

<SettingsInfoBlock type="String" default_value="threadpool" />

リモートファイルシステムからデータを読み取る方法です。readまたはthreadpoolのいずれかです。

## remote_filesystem_read_prefetch {#remote_filesystem_read_prefetch} 

<SettingsInfoBlock type="Bool" default_value="1" />

リモートファイルシステムからデータを読み取る際にプレフェッチを使用するべきです。

## remote_fs_read_backoff_max_tries {#remote_fs_read_backoff_max_tries} 

<SettingsInfoBlock type="UInt64" default_value="5" />

バックオフ時の最大読み取り試行回数です。

## remote_fs_read_max_backoff_ms {#remote_fs_read_max_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="10000" />

リモートディスクからデータを読み取る際の最大待機時間です。

## remote_read_min_bytes_for_seek {#remote_read_min_bytes_for_seek} 

<SettingsInfoBlock type="UInt64" default_value="4194304" />

リモート読み取り（url、s3）のためにシークを行うために必要な最小バイト数です。読み取りを無視します。

## rename_files_after_processing {#rename_files_after_processing} 

- **タイプ:** String

- **デフォルト値:** 空文字列

この設定では、`file`テーブル関数によって処理されたファイルの名前変更パターンを指定できます。オプションが設定されている場合、`file`テーブル関数によって読み取られたすべてのファイルは、処理が成功した場合のみ指定されたパターンに従って名前が変更されます。

### プレースホルダー

- `%a` — 完全な元のファイル名（例："sample.csv"）。
- `%f` — 拡張子なしの元のファイル名（例："sample"）。
- `%e` — 元のファイル拡張子（ドット付き）（例：".csv"）。
- `%t` — タイムスタンプ（マイクロ秒）。
- `%%` — パーセント記号 ("%")。

### サンプル
- オプション: `--rename_files_after_processing="processed_%f_%t%e"`

- クエリ: `SELECT * FROM file('sample.csv')`

`sample.csv`の読み取りが成功すると、ファイルは`processed_sample_1683473210851438.csv`に名前が変更されます。

## replace_running_query {#replace_running_query} 

<SettingsInfoBlock type="Bool" default_value="0" />

HTTPインターフェースを使用する場合、'query_id'パラメータを渡すことができます。これはクエリ識別子となる任意の文字列です。
この時点で同じユーザーから同じ'query_id'のクエリが既に存在する場合の動作は、'replace_running_query'パラメータによって異なります。

`0`（デフォルト） – 例外をスローする（同じ'query_id'のクエリが既に実行中である場合、クエリを実行できません）。

`1` – 古いクエリをキャンセルし、新しいクエリを実行し始めます。

このパラメータを1に設定すると、セグメンテーション条件の提案を実装できます。次の文字を入力した後に古いクエリが終了していない場合は、それをキャンセルする必要があります。

## replace_running_query_max_wait_ms {#replace_running_query_max_wait_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="5000" />

[replace_running_query](#replace_running_query)設定がアクティブな場合、同じ`query_id`のクエリが終了するまでの最大待機時間です。

可能な値:

- 正の整数。
- 0 — 同じ`query_id`のクエリが既に実行されている場合に新しいクエリを実行できない例外をスローします。

## replication_wait_for_inactive_replica_timeout {#replication_wait_for_inactive_replica_timeout} 

<SettingsInfoBlock type="Int64" default_value="120" />

[ALTER](../../sql-reference/statements/alter/index.md)、[OPTIMIZE](../../sql-reference/statements/optimize.md)、または[TRUNCATE](../../sql-reference/statements/truncate.md)クエリを実行するために、非アクティブなレプリカを待機する秒数を指定します。

可能な値:

- 0 — 待機しない。
- 負の整数 — 制限なしに待機します。
- 正の整数 — 待機する秒数です。

## restore_replace_external_dictionary_source_to_null {#restore_replace_external_dictionary_source_to_null} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "新しい設定。"}]}]}/>

復元時に外部辞書のソースをNullに置き換えます。テスト目的に便利です。

## restore_replace_external_engines_to_null {#restore_replace_external_engines_to_null} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "新しい設定。"}]}]}/>

テスト目的のために。すべての外部エンジンをNullに置き換え、外部接続を開始しないようにします。

## restore_replace_external_table_functions_to_null {#restore_replace_external_table_functions_to_null} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "新しい設定。"}]}]}/>

テスト目的のために。すべての外部テーブル関数をNullに置き換え、外部接続を開始しないようにします。

## restore_replicated_merge_tree_to_shared_merge_tree {#restore_replicated_merge_tree_to_shared_merge_tree} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "0"},{"label": "新しい設定。"}]}]}/>

RESTORE中にテーブルエンジンをReplicated*MergeTreeからShared*MergeTreeに置き換えます。

## result_overflow_mode {#result_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

Cloudのデフォルト値： `throw`

結果のボリュームが制限の一つを超えた場合の動作を設定します。

可能な値:
- `throw`: 例外をスローします（デフォルト）。
- `break`: クエリの実行を停止し、部分結果を返します。ソースデータが切れたかのように。

'break'を使用することは、LIMITを使用することに似ています。`break`はブロックレベルでのみ実行を中断します。これにより、返される行の数は[`max_result_rows`](/operations/settings/settings#max_result_rows)を超え、[`max_block_size`](/operations/settings/settings#max_block_size)の倍数となり、[`max_threads`](/operations/settings/settings#max_threads)に依存します。

**サンプル**

```sql title="クエリ"
SET max_threads = 3, max_block_size = 3333;
SET max_result_rows = 3334, result_overflow_mode = 'break';

SELECT *
FROM numbers_mt(100000)
FORMAT Null;

```text title="結果"
6666 行のセット。...

## rewrite_count_distinct_if_with_count_distinct_implementation {#rewrite_count_distinct_if_with_count_distinct_implementation} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.8"},{"label": "1"},{"label": "countDistinctIfをcount_distinct_implementation設定に書き換える"}]}]}/>

`countDistcintIf`を[count_distinct_implementation](#count_distinct_implementation)設定で書き換えることを許可します。

可能な値:

- true — 許可。
- false — 許可しない。

## s3_allow_multipart_copy {#s3_allow_multipart_copy} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "新しい設定。"}]}]}/>

S3でマルチパートコピーを許可します。

## s3_allow_parallel_part_upload {#s3_allow_parallel_part_upload} 

<SettingsInfoBlock type="Bool" default_value="1" />

S3マルチパートアップロードのために複数スレッドを使用します。これにより、わずかにメモリ使用量が増加する可能性があります。

## s3_check_objects_after_upload {#s3_check_objects_after_upload} 

<SettingsInfoBlock type="Bool" default_value="0" />

S3にアップロードされた各オブジェクトを確認するためにHEADリクエストを送信し、アップロードが成功したことを確認します。

## s3_connect_timeout_ms {#s3_connect_timeout_ms} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1000"},{"label": "s3接続タイムアウト用の新しい専用設定を導入する"}]}]}/>

s3ディスクのホストへの接続タイムアウトです。

## s3_create_new_file_on_insert {#s3_create_new_file_on_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

S3エンジンテーブルに挿入するたびに新しいファイルを作成することを有効または無効にします。有効にすると、各挿入で、次のようなパターンでキーを持つ新しいS3オブジェクトが作成されます:

初期: `data.Parquet.gz` -> `data.1.Parquet.gz` -> `data.2.Parquet.gz` など。

可能な値:
- 0 — `INSERT`クエリは新しいファイルを作成するか、ファイルが既に存在する場合は失敗します（s3_truncate_on_insertが設定されていない場合）。
- 1 — `INSERT`クエリは、s3_truncate_on_insertが設定されていない場合に、各挿入で新しいファイルをサフィックスを使用して作成します（2回目以降から）。

詳細を[こちら](/integrations/s3#inserting-data)で確認してください。

## s3_disable_checksum {#s3_disable_checksum} 

<SettingsInfoBlock type="Bool" default_value="0" />

ファイルをS3に送信する際にチェックサムを計算しないようにします。これにより、ファイルの過剰な処理パスを避けることで、書き込みが高速化されます。MergeTreeテーブルのデータは、ClickHouseによってチェックサムされるため、ほぼ安全であり、S3にHTTPSでアクセスする場合、TLS層はすでにネットワークを通じて転送する間の整合性を提供します。S3に追加のチェックサムを持つことは、深い防御を提供します。

## s3_ignore_file_doesnt_exist {#s3_ignore_file_doesnt_exist} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "S3テーブルエンジンで要求されたファイルが存在しない場合に0行を返すことを許可します。例外をスローする代わりに。"}]}]}/>

特定のキーを読み取る際にファイルが存在しない場合でも、その不足を無視します。

可能な値:
- 1 — `SELECT`が空の結果を返します。
- 0 — `SELECT`が例外をスローします。

## s3_list_object_keys_size {#s3_list_object_keys_size} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

ListObjectリクエストでバッチとして返される可能性のある最大ファイル数です。

## s3_max_connections {#s3_max_connections} 

<SettingsInfoBlock type="UInt64" default_value="1024" />

サーバーあたりの最大接続数です。

## s3_max_get_burst {#s3_max_get_burst} 

<SettingsInfoBlock type="UInt64" default_value="0" />

リクエスト毎秒制限に達する前に同時に発行できる最大リクエスト数です。デフォルト（0）は`s3_max_get_rps`に等しいです。

## s3_max_get_rps {#s3_max_get_rps} 

<SettingsInfoBlock type="UInt64" default_value="0" />

スロットリング前のS3 GETリクエスト毎秒率の制限です。ゼロは無制限を意味します。

## s3_max_inflight_parts_for_one_file {#s3_max_inflight_parts_for_one_file} 

<SettingsInfoBlock type="UInt64" default_value="20" />

マルチパートアップロードリクエストで同時に読み込むことができる最大パーツ数です。0は無制限を意味します。

## s3_max_part_number {#s3_max_part_number} 

<SettingsInfoBlock type="UInt64" default_value="10000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "10000"},{"label": "S3アップロードパートの最大パート番号"}]}]}/>

S3アップロードパートの最大パート番号です。

## s3_max_put_burst {#s3_max_put_burst} 

<SettingsInfoBlock type="UInt64" default_value="0" />

リクエスト毎秒制限に達する前に同時に発行できる最大リクエスト数です。デフォルト（0）は`s3_max_put_rps`に等しいです。

## s3_max_put_rps {#s3_max_put_rps} 

<SettingsInfoBlock type="UInt64" default_value="0" />

スロットリング前のS3 PUTリクエスト毎秒率の制限です。ゼロは無制限を意味します。

## s3_max_redirects {#s3_max_redirects} 

<SettingsInfoBlock type="UInt64" default_value="10" />

許可される最大のS3リダイレクトホップ数です。

## s3_max_single_operation_copy_size {#s3_max_single_operation_copy_size} 

<SettingsInfoBlock type="UInt64" default_value="33554432" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "33554432"},{"label": "S3での単一コピー操作の最大サイズ"}]}]}/>

S3での単一操作のコピーの最大サイズです。この設定は、s3_allow_multipart_copyがtrueの場合にのみ使用されます。

## s3_max_single_part_upload_size {#s3_max_single_part_upload_size} 

<SettingsInfoBlock type="UInt64" default_value="33554432" />

単一パートアップロードをS3に対して行う際の最大オブジェクトサイズです。

## s3_max_single_read_retries {#s3_max_single_read_retries} 

<SettingsInfoBlock type="UInt64" default_value="4" />

単一S3読み取り中の最大リトライ回数です。

## s3_max_unexpected_write_error_retries {#s3_max_unexpected_write_error_retries} 

<SettingsInfoBlock type="UInt64" default_value="4" />

S3書き込み中の予期しないエラー時に最大リトライ回数です。

## s3_max_upload_part_size {#s3_max_upload_part_size} 

<SettingsInfoBlock type="UInt64" default_value="5368709120" />

マルチパートアップロード中にS3にアップロードするマートの最大サイズです。

## s3_min_upload_part_size {#s3_min_upload_part_size} 

<SettingsInfoBlock type="UInt64" default_value="16777216" />

マルチパートアップロード中にS3にアップロードする部分の最小サイズです。

## s3_request_timeout_ms {#s3_request_timeout_ms} 

<SettingsInfoBlock type="UInt64" default_value="30000" />

S3へのデータの送受信時のアイドルタイムアウトです。単一のTCP読み取りまたは書き込み呼び出しがこの時間ブロックされた場合に失敗します。

## s3_retry_attempts {#s3_retry_attempts} 

<SettingsInfoBlock type="UInt64" default_value="100" />

Aws::Client::RetryStrategyの設定で、Aws::Clientは自動的にリトライします。0はリトライなしを意味します。

## s3_skip_empty_files {#s3_skip_empty_files} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "より良いUXを提供できることを期待しています"}]}]}/>

S3エンジンテーブルで空のファイルをスキップできるようにします。

可能な値:
- 0 — 空のファイルが要求された形式と互換性がない場合、`SELECT`は例外をスローします。
- 1 — 空のファイルの場合、`SELECT`は空の結果を返します。

## s3_slow_all_threads_after_network_error {#s3_slow_all_threads_after_network_error} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "新しい設定"}]}]}/>

`true`に設定すると、同じエンドポイントに対してs3リクエストを実行するすべてのスレッドが、リトライ可能なネットワークエラーで1つのs3リクエストが失敗した後、しばらくスローダウンします。
`false`に設定すると、s3リクエストを実行する各スレッドがネットワークエラーに対して独立したバックオフセットを使用します。

## s3_strict_upload_part_size {#s3_strict_upload_part_size} 

<SettingsInfoBlock type="UInt64" default_value="0" />

マルチパートアップロード中にS3にアップロードする部分の正確なサイズ（いくつかの実装では可変サイズのパーツをサポートしていません）。

## s3_throw_on_zero_files_match {#s3_throw_on_zero_files_match} 

<SettingsInfoBlock type="Bool" default_value="0" />

ListObjectsリクエストがファイルと一致しない場合にエラーをスローします。

## s3_truncate_on_insert {#s3_truncate_on_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

S3エンジンテーブルに挿入の前にトランケートを有効または無効にします。無効にした場合、既にS3オブジェクトが存在する場合の挿入試行では例外がスローされます。

可能な値:
- 0 — `INSERT`クエリは新しいファイルを作成するか、ファイルが既に存在する場合は失敗します（s3_create_new_file_on_insertが設定されていない場合）。
- 1 — `INSERT`クエリは既存のファイルの内容を新しいデータで置き換えます。

詳細を[こちら](/integrations/s3#inserting-data)で確認してください。

## s3_upload_part_size_multiply_factor {#s3_upload_part_size_multiply_factor} 

<SettingsInfoBlock type="UInt64" default_value="2" />

s3_multiply_parts_count_thresholdからの単一書き込みでアップロードされた各パーツごとにs3_min_upload_part_sizeにこの係数を掛けます。

## s3_upload_part_size_multiply_parts_count_threshold {#s3_upload_part_size_multiply_parts_count_threshold} 

<SettingsInfoBlock type="UInt64" default_value="500" />

この数のパーツがS3にアップロードされた際に、s3_min_upload_part_sizeがs3_upload_part_size_multiply_factorで掛け合わされます。

## s3_use_adaptive_timeouts {#s3_use_adaptive_timeouts} 

<SettingsInfoBlock type="Bool" default_value="1" />

`true`に設定すると、すべてのs3リクエストで最初の2回の試行が低い送信および受信タイムアウトで行われます。
`false`に設定すると、すべての試行が同一のタイムアウトで行われます。

## s3_validate_request_settings {#s3_validate_request_settings} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "S3リクエスト設定のバリデーションを無効にすることを許可します。"}]}]}/>

s3リクエスト設定のバリデーションを有効にします。

可能な値:
- 1 — 設定をバリデートします。
- 0 — 設定をバリデートしません。

## s3queue_default_zookeeper_path {#s3queue_default_zookeeper_path} 

<SettingsInfoBlock type="String" default_value="/clickhouse/s3queue/" />

S3QueueエンジンのデフォルトのZookeeperパスプレフィックスです。

## s3queue_enable_logging_to_s3queue_log {#s3queue_enable_logging_to_s3queue_log} 

<SettingsInfoBlock type="Bool" default_value="0" />

system.s3queue_logへの書き込みを有効にします。値はテーブル設定でテーブルごとに上書きできます。

## s3queue_migrate_old_metadata_to_buckets {#s3queue_migrate_old_metadata_to_buckets} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "新しい設定。"}]}]}/>

S3Queueテーブルの古いメタデータ構造を新しいものに移行します。

## schema_inference_cache_require_modification_time_for_url {#schema_inference_cache_require_modification_time_for_url} 

<SettingsInfoBlock type="Bool" default_value="1" />

最終変更時刻の検証を伴うURLのキャッシュを使用します（Last-Modifiedヘッダー付きのURL）。

## schema_inference_use_cache_for_azure {#schema_inference_use_cache_for_azure} 

<SettingsInfoBlock type="Bool" default_value="1" />

Azureテーブル関数を使用するときにスキーマ推論時にキャッシュを使用します。

## schema_inference_use_cache_for_file {#schema_inference_use_cache_for_file} 

<SettingsInfoBlock type="Bool" default_value="1" />

ファイルテーブル関数を使用するときにスキーマ推論時にキャッシュを使用します。

## schema_inference_use_cache_for_hdfs {#schema_inference_use_cache_for_hdfs} 

<SettingsInfoBlock type="Bool" default_value="1" />

HDFSテーブル関数を使用するときにスキーマ推論時にキャッシュを使用します。

## schema_inference_use_cache_for_s3 {#schema_inference_use_cache_for_s3} 

<SettingsInfoBlock type="Bool" default_value="1" />

S3テーブル関数を使用するときにスキーマ推論時にキャッシュを使用します。

## schema_inference_use_cache_for_url {#schema_inference_use_cache_for_url} 

<SettingsInfoBlock type="Bool" default_value="1" />

URLテーブル関数を使用するときにスキーマ推論時にキャッシュを使用します。

## secondary_indices_enable_bulk_filtering {#secondary_indices_enable_bulk_filtering} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "データスキッピングインデックスによるフィルタリングの新しいアルゴリズム"}]}]}/>

インデックスのバルクフィルタリングアルゴリズムを有効にします。常に改善されることが期待されていますが、互換性と制御のためにこの設定があります。
## select_sequential_consistency {#select_sequential_consistency} 

<SettingsInfoBlock type="UInt64" default_value="0" />

:::note
この設定は SharedMergeTree と ReplicatedMergeTree の間で動作が異なります。SharedMergeTree における `select_sequential_consistency` の動作についての詳細は、[SharedMergeTree 一貫性](/cloud/reference/shared-merge-tree#consistency) を参照してください。
:::

`SELECT` クエリのための逐次的一貫性を有効または無効にします。`insert_quorum_parallel` を無効にする必要があります（デフォルトでは有効）。

可能な値:

- 0 — 無効。
- 1 — 有効。

使用法

逐次的一貫性が有効な場合、ClickHouse はクライアントが `INSERT` クエリで実行されたすべてのデータを含むレプリカに対してのみ、`SELECT` クエリを実行することを許可します。クライアントが部分的なレプリカを参照した場合、ClickHouse は例外を生成します。SELECT クエリは、クオラムのレプリカにまだ書き込まれていないデータを含みません。

`insert_quorum_parallel` が有効な場合（デフォルト）、`select_sequential_consistency` は機能しません。これは、並行した `INSERT` クエリが異なるセットのクオラムレプリカに書き込まれる可能性があるため、単一のレプリカがすべての書き込みを受け取った保証がないからです。

関連情報:

- [insert_quorum](#insert_quorum)
- [insert_quorum_timeout](#insert_quorum_timeout)
- [insert_quorum_parallel](#insert_quorum_parallel)

## send_logs_level {#send_logs_level} 

<SettingsInfoBlock type="LogsLevel" default_value="fatal" />

クライアントに送信するサーバーテキストログの最小レベルを指定します。有効な値: 'trace', 'debug', 'information', 'warning', 'error', 'fatal', 'none'

## send_logs_source_regexp {#send_logs_source_regexp} 

ログソース名に一致する指定された正規表現でサーバーテキストログを送信します。空はすべてのソースを意味します。

## send_progress_in_http_headers {#send_progress_in_http_headers} 

<SettingsInfoBlock type="Bool" default_value="0" />

`clickhouse-server` のレスポンスにおいて、`X-ClickHouse-Progress` HTTP レスポンスヘッダーを有効または無効にします。

詳細については、[HTTP インターフェースの説明](../../interfaces/http.md)を参照してください。

可能な値:

- 0 — 無効。
- 1 — 有効。

## send_timeout {#send_timeout} 

<SettingsInfoBlock type="Seconds" default_value="300" />

ネットワークにデータを送信するためのタイムアウト（秒単位）。クライアントがデータを送信する必要があるが、この間にバイトを送信できない場合、例外がスローされます。この設定をクライアントで設定すると、サーバーの対応する接続のソケットに対して 'receive_timeout' も設定されます。

## serialize_query_plan {#serialize_query_plan} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "新しい設定"}]}]}/>

分散処理のためのクエリプランをシリアライズします。

## session_timezone {#session_timezone} 

<BetaBadge/>

現在のセッションまたはクエリの暗黙的なタイムゾーンを設定します。
暗黙的なタイムゾーンは、明示的に指定されたタイムゾーンがない DateTime/DateTime64 型の値に適用されます。
この設定は、グローバルに設定された（サーバーレベルの）暗黙的なタイムゾーンに優先します。
''（空文字列）の値は、現在のセッションまたはクエリの暗黙的なタイムゾーンが [サーバーのタイムゾーン](../server-configuration-parameters/settings.md/#timezone) と等しいことを意味します。

`timeZone()` と `serverTimeZone()` 関数を使って、セッションタイムゾーンとサーバータイムゾーンを取得できます。

可能な値:

- `system.time_zones` からの任意のタイムゾーン名、例: `Europe/Berlin`, `UTC` または `Zulu`

例:

```sql
SELECT timeZone(), serverTimeZone() FORMAT CSV

"Europe/Berlin","Europe/Berlin"

```sql
SELECT timeZone(), serverTimeZone() SETTINGS session_timezone = 'Asia/Novosibirsk' FORMAT CSV

"Asia/Novosibirsk","Europe/Berlin"

内部 DateTime に対して明示的にタイムゾーンが指定されていない場合に 'America/Denver' セッションタイムゾーンを割り当てる:

```sql
SELECT toDateTime64(toDateTime64('1999-12-12 23:23:23.123', 3), 3, 'Europe/Zurich') SETTINGS session_timezone = 'America/Denver' FORMAT TSV

1999-12-13 07:23:23.123

:::warning
DateTime/DateTime64 を解析するすべての関数が `session_timezone` を尊重するわけではありません。これにより微妙なエラーが発生する可能性があります。
次の例と説明を参照してください。
:::

```sql
CREATE TABLE test_tz (`d` DateTime('UTC')) ENGINE = Memory AS SELECT toDateTime('2000-01-01 00:00:00', 'UTC');

SELECT *, timeZone() FROM test_tz WHERE d = toDateTime('2000-01-01 00:00:00') SETTINGS session_timezone = 'Asia/Novosibirsk'
0 rows in set.

SELECT *, timeZone() FROM test_tz WHERE d = '2000-01-01 00:00:00' SETTINGS session_timezone = 'Asia/Novosibirsk'
┌───────────────────d─┬─timeZone()───────┐
│ 2000-01-01 00:00:00 │ Asia/Novosibirsk │
└─────────────────────┴──────────────────┘

これは異なる解析パイプラインによって発生します:

- 最初の `SELECT` クエリで使用される `toDateTime()` は、設定 `session_timezone` とグローバルなタイムゾーンを尊重します。
- 二番目のクエリでは、文字列から DateTime を解析し、既存のカラム `d` の型とタイムゾーンを継承します。したがって、設定 `session_timezone` とグローバルなタイムゾーンは尊重されません。

**関連情報**

- [timezone](../server-configuration-parameters/settings.md/#timezone)

## set_overflow_mode {#set_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

データの量が制限の一つを超えた場合に何が起こるかを設定します。

可能な値:
- `throw`: 例外をスローします（デフォルト）。
- `break`: クエリの実行を停止し、ソースデータが尽きたかのように部分結果を返します。

## shared_merge_tree_sync_parts_on_partition_operations {#shared_merge_tree_sync_parts_on_partition_operations} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "1"},{"label": "新しい設定。デフォルトでパーツは常に同期されます"}]}]}/>

SMT テーブルにおける MOVE|REPLACE|ATTACH パーティション操作の後にデータパーツのセットを自動的に同期します。クラウド専用。

## short_circuit_function_evaluation {#short_circuit_function_evaluation} 

<SettingsInfoBlock type="ShortCircuitFunctionEvaluation" default_value="enable" />

[if](../../sql-reference/functions/conditional-functions.md/#if), [multiIf](../../sql-reference/functions/conditional-functions.md/#multiif), [and](/sql-reference/functions/logical-functions#and), および [or](/sql-reference/functions/logical-functions#or) 関数を [短絡方式](https://en.wikipedia.org/wiki/Short-circuit_evaluation) に従って計算することを可能にします。これにより、これらの関数内の複雑な式の実行を最適化し、予期しない場合のゼロ除算などの可能な例外を防止します。

可能な値:

- `enable` — 適用可能な関数のために短絡関数評価を有効にします（例外をスローする可能性があるか計算が重い）。
- `force_enable` — すべての関数のために短絡関数評価を有効にします。
- `disable` — 短絡関数評価を無効にします。

## short_circuit_function_evaluation_for_nulls {#short_circuit_function_evaluation_for_nulls} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "Nullable 引数のある関数を、すべての引数が非 NULL の行でのみ実行できるようにします"}]}]}/>

任意の引数が NULL の場合、NULL を返す関数の評価を最適化します。関数の引数内の NULL 値の割合が short_circuit_function_evaluation_for_nulls_threshold を超えると、システムは行ごとの関数評価をスキップします。その代わりに、すべての行に対して NULL を即座に返し、不要な計算を回避します。

## short_circuit_function_evaluation_for_nulls_threshold {#short_circuit_function_evaluation_for_nulls_threshold} 

<SettingsInfoBlock type="Double" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "Nullable 引数のある関数を、すべての引数が非 NULL の行でのみ実行するための NULL 値の比率しきい値。この設定が有効な場合に適用されます。"}]}]}/>

Nullable 引数のある関数を、すべての引数が非 NULL の行でのみ実行するための NULL 値の比率しきい値。この設定が有効な場合に適用されます。
NULL 値を含む行の比率がこのしきい値を超えると、NULL 値を含む行は評価されません。

## show_table_uuid_in_table_create_query_if_not_nil {#show_table_uuid_in_table_create_query_if_not_nil} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "20.7"},{"label": "0"},{"label": "Engine=Atomic 用の CREATE クエリで、テーブルの UID を表示しないようにします"}]}]}/>

`SHOW TABLE` クエリの表示を設定します。

可能な値:

- 0 — テーブル UUID なしでクエリが表示されます。
- 1 — テーブル UUID 付きでクエリが表示されます。

## single_join_prefer_left_table {#single_join_prefer_left_table} 

<SettingsInfoBlock type="Bool" default_value="1" />

単一の JOIN において、識別子の曖昧さがある場合は左側のテーブルを優先します。

## skip_redundant_aliases_in_udf {#skip_redundant_aliases_in_udf} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "0"},{"label": "有効な場合、同じユーザー定義関数を同一のテーブル内で複数のマテリアライズドカラムに使用できるようになります。"}]}]}/>

ユーザー定義関数内で冗長なエイリアスを使用しないことで、使いやすさを簡素化します。

可能な値:

- 1 — UDF 内でエイリアスがスキップされます。
- 0 — UDF 内でエイリアスがスキップされません。

**例**

有効と無効の違い:

クエリ:

```sql
SET skip_redundant_aliases_in_udf = 0;
CREATE FUNCTION IF NOT EXISTS test_03274 AS ( x ) -> ((x + 1 as y, y + 2));

EXPLAIN SYNTAX SELECT test_03274(4 + 2);

結果:

```text
SELECT ((4 + 2) + 1 AS y, y + 2)

クエリ:

```sql
SET skip_redundant_aliases_in_udf = 1;
CREATE FUNCTION IF NOT EXISTS test_03274 AS ( x ) -> ((x + 1 as y, y + 2));

EXPLAIN SYNTAX SELECT test_03274(4 + 2);

結果:

```text
SELECT ((4 + 2) + 1, ((4 + 2) + 1) + 2)

## skip_unavailable_shards {#skip_unavailable_shards} 

<SettingsInfoBlock type="Bool" default_value="0" />

利用できないシャードを黙ってスキップすることを有効または無効にします。

シャードは、すべてのレプリカが利用できない場合に利用できないと見なされます。レプリカは以下の場合に利用できません：

- 何らかの理由で ClickHouse がレプリカに接続できない。

    レプリカへの接続時に、ClickHouse は複数回接続を試みます。これらすべての試みが失敗した場合、そのレプリカは利用できないと見なされます。

- レプリカが DNS を介して解決できない。

    レプリカのホスト名が DNS を介して解決できない場合、次の状況が考えられます：

    - レプリカのホストに DNS レコードがない場合。これは、Kubernetesなどの動的DNSシステムで発生する可能性があります。ダウンタイム中にノードが解決不可能になることがありますが、これはエラーではありません。

    - 構成エラー。ClickHouse 構成ファイルに間違ったホスト名が含まれている。

可能な値:

- 1 — スキップが有効。

    シャードが利用できない場合、ClickHouse は部分データに基づいた結果を返し、ノードの可用性問題を報告しません。

- 0 — スキップが無効。

    シャードが利用できない場合、ClickHouse は例外をスローします。

## sleep_after_receiving_query_ms {#sleep_after_receiving_query_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

TCPHandler でクエリを受信後にスリープする時間。

## sleep_in_send_data_ms {#sleep_in_send_data_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

TCPHandler でデータ送信中にスリープする時間。

## sleep_in_send_tables_status_ms {#sleep_in_send_tables_status_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

TCPHandler でテーブル状態応答を送信中にスリープする時間。

## sort_overflow_mode {#sort_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

ソート前に受け取った行の数が制限の一つを超えた場合に何が起こるかを設定します。

可能な値:
- `throw`: 例外をスローします。
- `break`: クエリの実行を停止し、部分結果を返します。

## split_intersecting_parts_ranges_into_layers_final {#split_intersecting_parts_ranges_into_layers_final} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "FINAL 最適化中に交差するパーツの範囲をレイヤーに分割することを許可します"}]}, {"id": "row-2","items": [{"label": "24.1"},{"label": "1"},{"label": "FINAL 最適化中に交差するパーツの範囲をレイヤーに分割することを許可します"}]}]}/>

FINAL 最適化中に交差するパーツの範囲をレイヤーに分割します。

## split_parts_ranges_into_intersecting_and_non_intersecting_final {#split_parts_ranges_into_intersecting_and_non_intersecting_final} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "FINAL 最適化中にパーツの範囲を交差するものとしないものに分割することを許可します"}]}, {"id": "row-2","items": [{"label": "24.1"},{"label": "1"},{"label": "FINAL 最適化中にパーツの範囲を交差するものとしないものに分割することを許可します"}]}]}/>

FINAL 最適化中にパーツの範囲を交差するものとしないものに分割します。

## splitby_max_substrings_includes_remaining_string {#splitby_max_substrings_includes_remaining_string} 

<SettingsInfoBlock type="Bool" default_value="0" />

期待値 `max_substrings` > 0 のときに、[splitBy*()](../../sql-reference/functions/splitting-merging-functions.md) 関数が結果配列の最後の要素に残りの文字列を含むかどうかを制御します。

可能な値:

- `0` - 残りの文字列は結果配列の最後の要素には含まれません。
- `1` - 残りの文字列は結果配列の最後の要素に含まれます。これは、Spark の [`split()`](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.split.html) 関数および Python の ['string.split()'](https://docs.python.org/3/library/stdtypes.html#str.split) メソッドの動作です。

## stop_refreshable_materialized_views_on_startup {#stop_refreshable_materialized_views_on_startup} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

サーバー起動時に、SYSTEM STOP VIEWS のようにリフレッシュ可能なマテリアライズドビューのスケジュールを防ぎます。その後、`SYSTEM START VIEWS` または `SYSTEM START VIEW <name>` で手動で開始できます。新しく作成したビューにも適用されます。リフレッシュ不可のマテリアライズドビューには影響しません。

## storage_file_read_method {#storage_file_read_method} 

<SettingsInfoBlock type="LocalFSReadMethod" default_value="pread" />

ストレージファイルからデータを読み取る方法の設定。`read`, `pread`, `mmap` のいずれかです。mmap メソッドは clickhouse-server には適用されず（clickhouse-local 用です）。

## storage_system_stack_trace_pipe_read_timeout_ms {#storage_system_stack_trace_pipe_read_timeout_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="100" />

`system.stack_trace` テーブルをクエリ中にスレッドから情報を受信するためにパイプから読み込む最大時間。この設定はテスト目的で使用され、ユーザーによって変更されることを意図していません。

## stream_flush_interval_ms {#stream_flush_interval_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="7500" />

タイムアウトの場合、またはスレッドが [max_insert_block_size](#max_insert_block_size) 行を生成する場合に、ストリーミング対応のテーブルで機能します。

デフォルト値は 7500 です。

値が小さいほど、データがテーブルにフラッシュされる頻度が高くなります。値を小さくしすぎると、パフォーマンスが低下します。

## stream_like_engine_allow_direct_select {#stream_like_engine_allow_direct_select} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.12"},{"label": "0"},{"label": "デフォルトでは Kafka/RabbitMQ/FileLog に対する直接SELECTを許可しない"}]}]}/>

Kafka、RabbitMQ、FileLog、Redis Streams、および NATS エンジンに直接 SELECT クエリを許可します。マテリアライズドビュウが接続されている場合、この設定が有効でも SELECT クエリは許可されません。

## stream_like_engine_insert_queue {#stream_like_engine_insert_queue} 

ストリームライクエンジンが複数のキューから読み込む場合、書き込み時に挿入するキューを選択する必要があります。Redis Streams および NATS に使用されます。

## stream_poll_timeout_ms {#stream_poll_timeout_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="500" />

ストリーミングストレージからデータをポーリングしている際のタイムアウト。

## system_events_show_zero_values {#system_events_show_zero_values} 

<SettingsInfoBlock type="Bool" default_value="0" />

[`system.events`](../../operations/system-tables/events.md) からゼロ値のイベントを選択することを許可します。

一部の監視システムでは、メトリックの値がゼロであっても、それらを各チェックポイントに渡す必要があります。

可能な値:

- 0 — 無効。
- 1 — 有効。

**例**

クエリ

```sql
SELECT * FROM system.events WHERE event='QueryMemoryLimitExceeded';

結果

```text
Ok.

クエリ
```sql
SET system_events_show_zero_values = 1;
SELECT * FROM system.events WHERE event='QueryMemoryLimitExceeded';

結果

```text
┌─event────────────────────┬─value─┬─description───────────────────────────────────────────┐
│ QueryMemoryLimitExceeded │     0 │ クエリ用のメモリ制限が超えた回数。                        │
└──────────────────────────┴───────┴───────────────────────────────────────────────────────┘

## table_function_remote_max_addresses {#table_function_remote_max_addresses} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

[remote](../../sql-reference/table-functions/remote.md) 関数のパターンから生成される最大アドレス数を設定します。

可能な値:

- 正の整数。

## tcp_keep_alive_timeout {#tcp_keep_alive_timeout} 

<SettingsInfoBlock type="Seconds" default_value="290" />

TCP が keepalive プローブを送信し始める前に接続がアイドルでなければならない時間（秒単位）。

## temporary_data_in_cache_reserve_space_wait_lock_timeout_milliseconds {#temporary_data_in_cache_reserve_space_wait_lock_timeout_milliseconds} 

<SettingsInfoBlock type="UInt64" default_value="600000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "600000"},{"label": "ファイルシステムキャッシュ内の一時データのスペース予約のためにキャッシュをロックするための待機時間"}]}]}/>

ファイルシステムキャッシュ内の一時データのスペース予約のためにキャッシュをロックするための待機時間。

## temporary_files_codec {#temporary_files_codec} 

<SettingsInfoBlock type="String" default_value="LZ4" />

ディスク上でのソートと結合操作に使用される一時ファイルの圧縮コーデックを設定します。

可能な値:

- LZ4 — [LZ4](https://en.wikipedia.org/wiki/LZ4_(compression_algorithm)) 圧縮が適用されます。
- NONE — 圧縮は適用されません。

## throw_if_deduplication_in_dependent_materialized_views_enabled_with_async_insert {#throw_if_deduplication_in_dependent_materialized_views_enabled_with_async_insert} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "依存するマテリアライズドビューでの重複排除が非同期挿入と共に機能しません。"}]}]}/>

設定 `deduplicate_blocks_in_dependent_materialized_views` が `async_insert` と共に有効な場合、INSERT クエリで例外をスローします。これにより正確性が保証されます。これらの機能は一緒に機能できません。

## throw_if_no_data_to_insert {#throw_if_no_data_to_insert} 

<SettingsInfoBlock type="Bool" default_value="1" />

空の INSERT を許可または禁止します。デフォルトでは有効（空の挿入時にエラーをスローします）。これは、[`clickhouse-client`](/interfaces/cli) または [gRPC インターフェース](/interfaces/grpc) を使用している INSERT のみに適用されます。

## throw_on_error_from_cache_on_write_operations {#throw_on_error_from_cache_on_write_operations} 

<SettingsInfoBlock type="Bool" default_value="0" />

書き込み操作（INSERT、マージ）のキャッシュ時のエラーを無視します。

## throw_on_max_partitions_per_insert_block {#throw_on_max_partitions_per_insert_block} 

<SettingsInfoBlock type="Bool" default_value="1" />

`max_partitions_per_insert_block` に達したときの動作を制御します。

可能な値:
- `true`  — 挿入ブロックが `max_partitions_per_insert_block` に達したときに例外をスローします。
- `false` — `max_partitions_per_insert_block` に達したときに警告をログに記録します。

:::tip
これは、[`max_partitions_per_insert_block`](/operations/settings/settings#max_partitions_per_insert_block) を変更する際にユーザーに対する影響を理解しようとする場合に便利です。
:::

## throw_on_unsupported_query_inside_transaction {#throw_on_unsupported_query_inside_transaction} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="1" />

トランザクション内でサポートされていないクエリが使用された場合に例外をスローします。

## timeout_before_checking_execution_speed {#timeout_before_checking_execution_speed} 

<SettingsInfoBlock type="Seconds" default_value="10" />

指定された秒数が経過した後に、実行速度が遅すぎないこと（`min_execution_speed` より遅くないこと）を確認します。

## timeout_overflow_mode {#timeout_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

クエリが `max_execution_time` より長く実行されるか、推定実行時間が `max_estimated_execution_time` より長くなる場合に何をするかを設定します。

可能な値:
- `throw`: 例外をスローします（デフォルト）。
- `break`: クエリの実行を停止し、ソースデータが尽きたかのように部分結果を返します。

## timeout_overflow_mode_leaf {#timeout_overflow_mode_leaf} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

葉ノードでクエリが `max_execution_time_leaf` より長く実行された場合に何が起こるかを設定します。

可能な値:
- `throw`: 例外をスローします（デフォルト）。
- `break`: クエリの実行を停止し、ソースデータが尽きたかのように部分結果を返します。

## totals_auto_threshold {#totals_auto_threshold} 

<SettingsInfoBlock type="Float" default_value="0.5" />

`totals_mode = 'auto'` のしきい値。
「WITH TOTALS 修飾子」を参照してください。

## totals_mode {#totals_mode} 

<SettingsInfoBlock type="TotalsMode" default_value="after_having_exclusive" />

HAVING が存在する場合および max_rows_to_group_by および group_by_overflow_mode = 'any' が存在する場合に TOTALS を計算する方法。
「WITH TOTALS 修飾子」を参照してください。

## trace_profile_events {#trace_profile_events} 

<SettingsInfoBlock type="Bool" default_value="0" />

プロファイルイベントの各更新の際に、プロファイルイベントの名前、インクリメントの値と共にスタックトレースを収集し、[trace_log](/operations/system-tables/trace_log) に送信することを有効または無効にします。

可能な値:

- 1 — プロファイルイベントのトレースを有効にします。
- 0 — プロファイルイベントのトレースを無効にします。

## transfer_overflow_mode {#transfer_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

データの量が制限の一つを超えた場合に何が起こるかを設定します。

可能な値:
- `throw`: 例外をスローします（デフォルト）。
- `break`: クエリの実行を停止し、ソースデータが尽きたかのように部分結果を返します。

## transform_null_in {#transform_null_in} 

<SettingsInfoBlock type="Bool" default_value="0" />

[IN](../../sql-reference/operators/in.md) 演算子のために [NULL](/sql-reference/syntax#null) 値の同等性を有効にします。

デフォルトでは、`NULL` 値は比較できません。なぜなら `NULL` は未定義値を意味するからです。したがって、比較 `expr = NULL` は常に `false` を返さなければなりません。この設定を使用することで、`NULL = NULL` が `IN` 演算子に対して `true` を返します。

可能な値:

- 0 — `IN` 演算子での `NULL` 値の比較が `false` を返します。
- 1 — `IN` 演算子での `NULL` 値の比較が `true` を返します。

**例**

`null_in` テーブルを考えます：

```text
┌──idx─┬─────i─┐
│    1 │     1 │
│    2 │  NULL │
│    3 │     3 │
└──────┴───────┘

クエリ:

```sql
SELECT idx, i FROM null_in WHERE i IN (1, NULL) SETTINGS transform_null_in = 0;

結果:

```text
┌──idx─┬────i─┐
│    1 │    1 │
└──────┴──────┘

クエリ:

```sql
SELECT idx, i FROM null_in WHERE i IN (1, NULL) SETTINGS transform_null_in = 1;

結果:

```text
┌──idx─┬─────i─┐
│    1 │     1 │
│    2 │  NULL │
└──────┴───────┘

**関連情報**

- [IN 演算子における NULL 処理](/sql-reference/operators/in#null-processing)

## traverse_shadow_remote_data_paths {#traverse_shadow_remote_data_paths} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "system.remote_data_paths をクエリする際にシャドウディレクトリを横断します。"}]}]}/>

`system.remote_data_paths` をクエリする際に、実際のテーブルデータに加えて凍結データ（シャドウディレクトリ）を横断します。

## union_default_mode {#union_default_mode} 

`SELECT` クエリの結果を結合するモードを設定します。この設定は、`UNION` と共有する際に、`UNION ALL` または `UNION DISTINCT` を明示的に指定しない場合のみ使用されます。

可能な値:

- `'DISTINCT'` — ClickHouse は、重複行を削除した結果を結合クエリの行として出力します。
- `'ALL'` — ClickHouse は、重複行を含むすべての行を結合クエリの結果として出力します。
- `''` — ClickHouse は、`UNION` で使用されるときに例外を生成します。

例については [UNION](../../sql-reference/statements/select/union.md) を参照してください。

## unknown_packet_in_send_data {#unknown_packet_in_send_data} 

<SettingsInfoBlock type="UInt64" default_value="0" />

データ N 番目のデータパケットの代わりに未知のパケットを送信します。

## update_parallel_mode {#update_parallel_mode} 

<SettingsInfoBlock type="UpdateParallelMode" default_value="auto" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "auto"},{"label": "新しい設定"}]}]}/>

並行更新クエリの動作を決定します。

可能な値:
- `sync` — すべての `UPDATE` クエリを逐次的に実行します。
- `auto` — 依存している列の間の依存関係を持つ `UPDATE` クエリのみを逐次的に実行します。
- `async` — 更新クエリを同期しません。

## update_sequential_consistency {#update_sequential_consistency} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "新しい設定"}]}]}/>

true の場合、更新の実行前にパーツのセットが最新バージョンに更新されます。

## use_async_executor_for_materialized_views {#use_async_executor_for_materialized_views} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "0"},{"label": "新しい設定。"}]}]}/>

マテリアライズドビュークエリの非同期および潜在的にマルチスレッド実行を使用します。INSERT 中にビュー処理を加速する可能性がありますが、メモリを多く消費することもあります。

## use_cache_for_count_from_files {#use_cache_for_count_from_files} 

<SettingsInfoBlock type="Bool" default_value="1" />

マテリアライズドファイルテーブル関数 `file`/`s3`/`url`/`hdfs`/`azureBlobStorage` からカウントする際に行数のキャッシュを有効にします。

デフォルトで有効です。

## use_client_time_zone {#use_client_time_zone} 

<SettingsInfoBlock type="Bool" default_value="0" />

DateTime 文字列値の解釈にクライアントのタイムゾーンを使用します。サーバータイムゾーンを採用するのではなく。

## use_compact_format_in_distributed_parts_names {#use_compact_format_in_distributed_parts_names} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.1"},{"label": "1"},{"label": "デフォルトで Distributed テーブルへの非同期 INSERT にコンパクトフォーマットを使用します。"}]}]}/>

`Distributed` エンジンのテーブルへのバックグラウンド挿入 (`distributed_foreground_insert`) に対してブロックを保存するためのコンパクトフォーマットを使用します。

可能な値:

- 0 — `user[:password]@host:port#default_database` ディレクトリフォーマットを使用します。
- 1 — `[shard{shard_index}[_replica{replica_index}]]` ディレクトリフォーマットを使用します。

:::note
- `use_compact_format_in_distributed_parts_names=0` でシャード定義の変更がバックグラウンド INSERT に適用されなくなります。
- `use_compact_format_in_distributed_parts_names=1` でクラスタ定義内のノードの順序を変更すると、`shard_index` / `replica_index` が変更されるため、注意が必要です。
:::

## use_concurrency_control {#use_concurrency_control} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "1"},{"label": "デフォルトで競合制御を有効にします。"}]}]}/>

サーバーの競合制御を尊重します（グローバルサーバ設定 `concurrent_threads_soft_limit_num` および `concurrent_threads_soft_limit_ratio_to_cores` を参照）。無効にすると、サーバーが過負荷の場合でもより多くのスレッドを使用できるようになります（通常の使用には推奨されず、主にテストに必要です）。
## use_hedged_requests {#use_hedged_requests} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.9"},{"label": "1"},{"label": "デフォルトでヘッジリクエスト機能を有効にする"}]}]}/>

リモートクエリ用のヘッジリクエストロジックを有効にします。これにより、クエリのために異なるレプリカへの多くの接続を確立できます。
既存の接続（レプリカとの接続）が `hedged_connection_timeout` 内に確立されていない場合、または `receive_data_timeout` 内にデータが受信されなかった場合、新しい接続が有効になります。クエリは、非空の進行状況パケット（または、`allow_changing_replica_until_first_data_packet`が設定されている場合はデータパケット）を送信する最初の接続を使用します。他の接続はキャンセルされます。`max_parallel_replicas > 1` のクエリがサポートされています。

デフォルトで有効。

クラウドではデフォルトで無効。

## use_hive_partitioning {#use_hive_partitioning} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "デフォルトで設定を有効にしました。"}]}], [{"id": "row-2","items": [{"label": "24.8"},{"label": "0"},{"label": "File、URL、S3、AzureBlobStorage、および HDFS エンジンでのハイブ パーティショニングの使用を許可します。"}]}]}/>

有効にすると、ClickHouse はファイルのようなテーブルエンジン [File](/sql-reference/table-functions/file#hive-style-partitioning)/[S3](/sql-reference/table-functions/s3#hive-style-partitioning)/[URL](/sql-reference/table-functions/url#hive-style-partitioning)/[HDFS](/sql-reference/table-functions/hdfs#hive-style-partitioning)/[AzureBlobStorage](/sql-reference/table-functions/azureBlobStorage#hive-style-partitioning) で、パス内にハイブスタイルのパーティショニング（`/name=value/`）を検出し、クエリ内でパーティションカラムを仮想カラムとして使用できるようにします。これらの仮想カラムは、パーティション化されたパスの同じ名前を持ちますが、`_` で始まります。

## use_iceberg_metadata_files_cache {#use_iceberg_metadata_files_cache} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "新しい設定"}]}]}/>

有効にすると、アイスバーグ テーブル関数とアイスバーグ ストレージがアイスバーグ メタデータファイルキャッシュを利用できる場合があります。

可能な値:

- 0 - 無効
- 1 - 有効

## use_iceberg_partition_pruning {#use_iceberg_partition_pruning} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.6"},{"label": "1"},{"label": "デフォルトでアイスバーグ パーティション プルーニングを有効にします。"}]}], [{"id": "row-2","items": [{"label": "25.1"},{"label": "0"},{"label": "アイスバーグ パーティション プルーニングの新しい設定。"}]}]}/>

アイスバーグテーブル用にアイスバーグパーティションプルーニングを使用します。

## use_index_for_in_with_subqueries {#use_index_for_in_with_subqueries} 

<SettingsInfoBlock type="Bool" default_value="1" />

IN 演算子の右側にサブクエリまたはテーブル式がある場合、インデックスを使用してみてください。

## use_index_for_in_with_subqueries_max_values {#use_index_for_in_with_subqueries_max_values} 

<SettingsInfoBlock type="UInt64" default_value="0" />

IN 演算子の右側の集合の最大サイズで、フィルタリングのためにテーブルインデックスを使用します。これにより、大きなクエリのために追加データ構造の準備に伴うパフォーマンスの低下とメモリ使用量を回避できます。ゼロは制限を意味します。

## use_json_alias_for_old_object_type {#use_json_alias_for_old_object_type} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "新しい JSON タイプを作成するために JSON タイプエイリアスを使用する"}]}]}/>

有効にすると、`JSON` データ型エイリアスを使用して新しい [JSON](../../sql-reference/data-types/newjson.md) 型ではなく、古い [Object('json')](../../sql-reference/data-types/json.md) 型を作成します。

## use_legacy_to_time {#use_legacy_to_time} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "新しい設定。ユーザーが toTime の古い関数ロジックを使用できるようにします。これは toTimeWithFixedDate として機能します。"}]}]}/>

有効にすると、日付と時間をある固定の日付に変換するレガシー toTime 関数を使用できますが、時間は保たれます。
そうでなければ、異なるタイプのデータを Time 型に変換する新しい toTime 関数を使用します。
古いレガシー関数は toTimeWithFixedDate として無条件に利用可能です。

## use_page_cache_for_disks_without_file_cache {#use_page_cache_for_disks_without_file_cache} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "ユーザースペースページキャッシュを追加"}]}]}/>

ファイルシステムキャッシュが有効になっていないリモートディスクに対してユーザースペースページキャッシュを使用します。

## use_page_cache_with_distributed_cache {#use_page_cache_with_distributed_cache} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "0"},{"label": "新しい設定"}]}]}/>

分散キャッシュが使用されている場合にユーザースペースページキャッシュを使用します。

## use_query_cache {#use_query_cache} 

<SettingsInfoBlock type="Bool" default_value="0" />

有効にすると、`SELECT` クエリが [クエリキャッシュ](../query-cache.md) を利用できる場合があります。パラメータ [enable_reads_from_query_cache](#enable_reads_from_query_cache) および [enable_writes_to_query_cache](#enable_writes_to_query_cache) が、キャッシュの使用方法を詳細に制御します。

可能な値:

- 0 - 無効
- 1 - 有効

## use_query_condition_cache {#use_query_condition_cache} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "新しい最適化"}]}, {"id": "row-2","items": [{"label": "25.3"},{"label": "0"},{"label": "新しい設定。"}]}]}/>

[クエリ条件キャッシュ](/operations/query-condition-cache) を有効にします。キャッシュは、`WHERE` 句で条件を満たさないデータパーツのグラニュールの範囲を保存し、後続のクエリのためにこの情報をエフェメラルインデックスとして再利用します。

可能な値:

- 0 - 無効
- 1 - 有効

## use_skip_indexes {#use_skip_indexes} 

<SettingsInfoBlock type="Bool" default_value="1" />

クエリ実行中にデータスキッピングインデックスを使用します。

可能な値:

- 0 — 無効。
- 1 — 有効。

## use_skip_indexes_if_final {#use_skip_indexes_if_final} 

<SettingsInfoBlock type="Bool" default_value="0" />

FINAL 修飾子でクエリを実行する際にスキップインデックスが使用されるかどうかを制御します。

デフォルトではこの設定は無効です。スキップインデックスは、最新データを含む行（グラニュール）を除外する可能性があり、これにより不正確な結果が得られることがあります。有効にすると、FINAL 修飾子を使用する場合でもスキップインデックスが適用され、パフォーマンスが向上しますが、最新の更新が失われるリスクがあります。

可能な値:

- 0 — 無効。
- 1 — 有効。

## use_skip_indexes_if_final_exact_mode {#use_skip_indexes_if_final_exact_mode} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "この設定は、スキップインデックスを使用して FINAL クエリが正しい結果を返すのを助けるために導入されました"}]}]}/>

FINAL 修飾子でクエリを実行する際に、スキップインデックスによって返されるグラニュールが新しい部分に拡張され、正しい結果を返すかどうかを制御します。

スキップインデックスを使用すると、最新データを含む行（グラニュール）が除外される可能性があり、これにより不正確な結果が得られることがあります。この設定は、スキップインデックスによって返された範囲と重複する新しい部分をスキャンすることによって正しい結果が得られることを保証できます。

可能な値:

- 0 — 無効。
- 1 — 有効。

## use_structure_from_insertion_table_in_table_functions {#use_structure_from_insertion_table_in_table_functions} 

<SettingsInfoBlock type="UInt64" default_value="2" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.11"},{"label": "2"},{"label": "テーブル関数での挿入テーブルからの構造の使用を改善"}]}]}/>

データからのスキーマ推論の代わりに、挿入テーブルからの構造を使用します。可能な値: 0 - 無効、1 - 有効、2 - 自動

## use_uncompressed_cache {#use_uncompressed_cache} 

<SettingsInfoBlock type="Bool" default_value="0" />

非圧縮ブロックのキャッシュを使用するかどうか。0 または 1 を受け入れます。デフォルトは 0 (無効) です。
非圧縮キャッシュ (MergeTree ファミリーのテーブルのみに対応) を使用すると、数多くの短いクエリを実行する際の待ち時間が大幅に短縮され、スループットが向上する可能性があります。頻繁に短いリクエストを送信するユーザーに対してこの設定を有効にしてください。また、[uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size) 構成パラメータ（構成ファイルのみに設定）にも注目してください – 非圧縮キャッシュブロックのサイズです。デフォルトでは、8 GiB です。非圧縮キャッシュは必要に応じて充填され、最も使用されていないデータが自動的に削除されます。

少なくともある程度の大容量データ（100 万行以上）を読み取るクエリに対しては、真に小さなクエリのためのスペースを確保するために非圧縮キャッシュが自動的に無効にされます。これは、'use_uncompressed_cache'設定を常に1に設定できることを意味します。

## use_variant_as_common_type {#use_variant_as_common_type} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "共通型がない場合に if/multiIf で Variant を使用できるようにします"}]}]}/>

共通型がない場合に、[if](../../sql-reference/functions/conditional-functions.md/#if)/[multiIf](../../sql-reference/functions/conditional-functions.md/#multiif)/[array](../../sql-reference/functions/array-functions.md)/[map](../../sql-reference/functions/tuple-map-functions.md) 関数の結果型として `Variant` 型を使用できるようにします。

例:

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(if(number % 2, number, range(number))) as variant_type FROM numbers(1);
SELECT if(number % 2, number, range(number)) as variant FROM numbers(5);

```text
┌─variant_type───────────────────┐
│ Variant(Array(UInt64), UInt64) │
└────────────────────────────────┘
┌─variant───┐
│ []        │
│ 1         │
│ [0,1]     │
│ 3         │
│ [0,1,2,3] │
└───────────┘

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(multiIf((number % 4) = 0, 42, (number % 4) = 1, [1, 2, 3], (number % 4) = 2, 'Hello, World!', NULL)) AS variant_type FROM numbers(1);
SELECT multiIf((number % 4) = 0, 42, (number % 4) = 1, [1, 2, 3], (number % 4) = 2, 'Hello, World!', NULL) AS variant FROM numbers(4);

```text
─variant_type─────────────────────────┐
│ Variant(Array(UInt8), String, UInt8) │
└──────────────────────────────────────┘

┌─variant───────┐
│ 42            │
│ [1,2,3]       │
│ Hello, World! │
│ ᴺᵁᴸᴸ          │
└───────────────┘

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(array(range(number), number, 'str_' || toString(number))) as array_of_variants_type from numbers(1);
SELECT array(range(number), number, 'str_' || toString(number)) as array_of_variants FROM numbers(3);

```text
┌─array_of_variants_type────────────────────────┐
│ Array(Variant(Array(UInt64), String, UInt64)) │
└───────────────────────────────────────────────┘

┌─array_of_variants─┐
│ [[],0,'str_0']    │
│ [[0],1,'str_1']   │
│ [[0,1],2,'str_2'] │
└───────────────────┘

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(map('a', range(number), 'b', number, 'c', 'str_' || toString(number))) as map_of_variants_type from numbers(1);
SELECT map('a', range(number), 'b', number, 'c', 'str_' || toString(number)) as map_of_variants FROM numbers(3);

```text
┌─map_of_variants_type────────────────────────────────┐
│ Map(String, Variant(Array(UInt64), String, UInt64)) │
└─────────────────────────────────────────────────────┘

┌─map_of_variants───────────────┐
│ {'a':[],'b':0,'c':'str_0'}    │
│ {'a':[0],'b':1,'c':'str_1'}   │
│ {'a':[0,1],'b':2,'c':'str_2'} │
└───────────────────────────────┘

## use_with_fill_by_sorting_prefix {#use_with_fill_by_sorting_prefix} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.5"},{"label": "1"},{"label": "ORDER BY 句のWITH FILL 列の前のカラムがソートプレフィックスを形成します。ソートプレフィックス内の異なる値を持つ行は独立して充填されます"}]}]}/>

ORDER BY 句の WITH FILL 列の前のカラムがソートプレフィックスを形成します。ソートプレフィックス内の異なる値を持つ行は独立して充填されます。

## validate_enum_literals_in_operators {#validate_enum_literals_in_operators} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "新しい設定"}]}]}/>

有効になっている場合、`IN`、`NOT IN`、`==`、`!=` などの演算子では、列挙型に対して列挙リテラルを検証し、リテラルが有効な列挙値でない場合は例外をスローします。

## validate_mutation_query {#validate_mutation_query} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "デフォルトで変更クエリを検証するための新しい設定。"}]}]}/>

変更クエリを受け入れる前に検証します。変更はバックグラウンドで実行され、無効なクエリを実行すると、変更がスタックして手動での介入が必要になります。

後方互換性のないバグが発生した場合のみ、この設定を変更してください。

## validate_polygons {#validate_polygons} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "20.4"},{"label": "1"},{"label": "不正なポリゴンがある場合は、関数 pointInPolygon で例外をスローします。デフォルトでは、可能性のある間違った結果が返されます。"}]}]}/>

ポリゴンが自己交差または自己接触している場合、[pointInPolygon](/sql-reference/functions/geo/coordinates#pointinpolygon) 関数内で例外をスローするかどうかを有効または無効にします。

可能な値:

- 0 — 例外をスローすることは無効です。`pointInPolygon` は無効なポリゴンを受け入れ、それに対して可能性のある不正確な結果を返します。
- 1 — 例外をスローすることは有効です。

## vector_search_filter_strategy {#vector_search_filter_strategy} 

<BetaBadge/>

<SettingsInfoBlock type="VectorSearchFilterStrategy" default_value="auto" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "auto"},{"label": "新しい設定"}]}]}/>

ベクター検索クエリに WHERE 句がある場合、この設定は、最初に評価されるか（事前フィルタリング）またはベクトル類似性インデックスが最初にチェックされるか（事後フィルタリング）を決定します。可能な値：
- 'auto' - 事後フィルタリング (正確な意味は将来的に変更される可能性があります)。
- 'postfilter' - ベクトル類似性インデックスを使って最近傍を特定し、その後他のフィルターを適用します。
- 'prefilter' - まず他のフィルターを評価し、その後ブルートフォース検索を行って最近傍を特定します。

## vector_search_postfilter_multiplier {#vector_search_postfilter_multiplier} 

<BetaBadge/>

<SettingsInfoBlock type="Float" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "新しい設定"}]}]}/>

他の述語に対して事後フィルタリングを行う前に、ベクトル類似性インデックスからフェッチした最近傍をこの数で乗算します。

## wait_changes_become_visible_after_commit_mode {#wait_changes_become_visible_after_commit_mode} 

<ExperimentalBadge/>

<SettingsInfoBlock type="TransactionsWaitCSNMode" default_value="wait_unknown" />

コミットされた変更が最新のスナップショットで実際に表示されるまで待ちます。

## wait_for_async_insert {#wait_for_async_insert} 

<SettingsInfoBlock type="Bool" default_value="1" />

正しい場合、非同期挿入の処理を待ちます。

## wait_for_async_insert_timeout {#wait_for_async_insert_timeout} 

<SettingsInfoBlock type="Seconds" default_value="120" />

非同期挿入を処理するための待機タイムアウト。

## wait_for_window_view_fire_signal_timeout {#wait_for_window_view_fire_signal_timeout} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Seconds" default_value="10" />

イベントタイム処理におけるウィンドウビューの発火信号を待つためのタイムアウト。

## window_view_clean_interval {#window_view_clean_interval} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Seconds" default_value="60" />

古いデータを解放するためのウィンドウビューのクリン間隔（秒）。

## window_view_heartbeat_interval {#window_view_heartbeat_interval} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Seconds" default_value="15" />

ウォッチクエリが生きていることを示すためのハートビート間隔（秒）。

## workload {#workload} 

<SettingsInfoBlock type="String" default_value="default" />

リソースにアクセスするために使用するワークロードの名前。

## write_through_distributed_cache {#write_through_distributed_cache} 

<CloudOnlyBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "ClickHouse Cloud 用の設定"}]}]}/>

ClickHouse Cloud のみで効果があります。分散キャッシュへの書き込みを許可します（S3 への書き込みも分散キャッシュによって行われます）。

## zstd_window_log_max {#zstd_window_log_max} 

<SettingsInfoBlock type="Int64" default_value="0" />

ZSTD の最大ウィンドウログを選択できます（MergeTree ファミリーでは使用されません）。
