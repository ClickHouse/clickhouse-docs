---
title: "セッション設定"
sidebar_label: "セッション設定"
slug: /operations/settings/settings
toc_max_heading_level: 2
description: "``system.settings``テーブルに含まれる設定。"
doc_type: "reference"
---

import ExperimentalBadge from "@theme/badges/ExperimentalBadge"
import BetaBadge from "@theme/badges/BetaBadge"
import CloudOnlyBadge from "@theme/badges/CloudOnlyBadge"
import SettingsInfoBlock from "@theme/SettingsInfoBlock/SettingsInfoBlock"
import VersionHistory from "@theme/VersionHistory/VersionHistory"

<!-- Autogenerated -->

以下のすべての設定は、[system.settings](/docs/operations/system-tables/settings)テーブルでも利用できます。これらの設定は[ソース](https://github.com/ClickHouse/ClickHouse/blob/master/src/Core/Settings.cpp)から自動生成されています。


## add_http_cors_header {#add_http_cors_header}

<SettingsInfoBlock type='Bool' default_value='0' />

HTTP CORSヘッダーを追加します。


## additional_result_filter {#additional_result_filter}

`SELECT`クエリの結果に適用する追加のフィルタ式。
この設定はサブクエリには適用されない。

**例**

```sql
INSERT INTO table_1 VALUES (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');
SElECT * FROM table_1;
```

```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 2 │ bb   │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```

```sql
SELECT *
FROM table_1
SETTINGS additional_result_filter = 'x != 2'
```

```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```


## additional_table_filters {#additional_table_filters}

<SettingsInfoBlock type='Map' default_value='{}' />

指定されたテーブルからの読み取り後に適用される追加のフィルタ式。

**例**

```sql
INSERT INTO table_1 VALUES (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');
SELECT * FROM table_1;
```

```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 2 │ bb   │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```

```sql
SELECT *
FROM table_1
SETTINGS additional_table_filters = {'table_1': 'x != 2'}
```

```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```


## aggregate_functions_null_for_empty {#aggregate_functions_null_for_empty}

<SettingsInfoBlock type='Bool' default_value='0' />

クエリ内のすべての集約関数を書き換えて [-OrNull](/sql-reference/aggregate-functions/combinators#-ornull) サフィックスを追加するかどうかを制御します。SQL標準との互換性のために有効にしてください。
この機能は、分散クエリで一貫した結果を得るために、クエリの書き換え（[count_distinct_implementation](#count_distinct_implementation) 設定と同様）によって実装されています。

設定可能な値:

- 0 — 無効。
- 1 — 有効。

**例**

次の集約関数を含むクエリを考えます:

```sql
SELECT SUM(-1), MAX(0) FROM system.one WHERE 0;
```

`aggregate_functions_null_for_empty = 0` の場合、次の結果が生成されます:

```text
┌─SUM(-1)─┬─MAX(0)─┐
│       0 │      0 │
└─────────┴────────┘
```

`aggregate_functions_null_for_empty = 1` の場合、結果は次のようになります:

```text
┌─SUMOrNull(-1)─┬─MAXOrNull(0)─┐
│          NULL │         NULL │
└───────────────┴──────────────┘
```


## aggregation_in_order_max_block_bytes {#aggregation_in_order_max_block_bytes}

<SettingsInfoBlock type='UInt64' default_value='50000000' />

プライマリキーの順序で集約を行う際に蓄積されるブロックの最大サイズ（バイト単位）。ブロックサイズを小さくすることで、集約の最終マージステージの並列化を促進できます。


## aggregation_memory_efficient_merge_threads {#aggregation_memory_efficient_merge_threads}

<SettingsInfoBlock type='UInt64' default_value='0' />

メモリ効率モードで中間集計結果をマージする際に使用するスレッド数。値が大きいほど、メモリ消費量が増加します。0 は 'max_threads' と同じ値を意味します。


## allow_aggregate_partitions_independently {#allow_aggregate_partitions_independently}

<SettingsInfoBlock type='Bool' default_value='0' />

パーティションキーがGROUP BYキーに適合する場合、別々のスレッドでパーティションを独立して集計できるようにします。パーティション数がコア数に近く、各パーティションのサイズがほぼ均等である場合に効果的です


## allow_archive_path_syntax {#allow_archive_path_syntax}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.8" },
        { label: "1" },
        { label: "アーカイブパス構文を無効化するための新しい設定を追加しました。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.5" },
        { label: "1" },
        { label: "アーカイブパス構文を無効化するための新しい設定を追加しました。" }
      ]
    }
  ]}
/>

File/S3エンジン/テーブル関数は、アーカイブが正しい拡張子を持つ場合、'::'を含むパスを`<archive> :: <file>`として解析します。


## allow_asynchronous_read_from_io_pool_for_merge_tree {#allow_asynchronous_read_from_io_pool_for_merge_tree}

<SettingsInfoBlock type='Bool' default_value='0' />

MergeTreeテーブルからの読み取りにバックグラウンドI/Oプールを使用します。この設定により、I/Oバウンドなクエリのパフォーマンスが向上する可能性があります


## allow_changing_replica_until_first_data_packet {#allow_changing_replica_until_first_data_packet}

<SettingsInfoBlock type='Bool' default_value='0' />

この設定を有効にすると、ヘッジドリクエストにおいて、既に何らかの進捗がある場合でも（ただし、`receive_data_timeout` タイムアウトの間に進捗が更新されていない場合）、最初のデータパケットを受信するまで新しい接続を開始できます。無効の場合、最初に進捗が発生した後はレプリカの変更が無効になります。


## allow_create_index_without_type {#allow_create_index_without_type}

<SettingsInfoBlock type='Bool' default_value='0' />

TYPE を指定しない CREATE INDEX クエリを許可します。クエリは無視されます。SQL 互換性テストのために作成されました。


## allow_custom_error_code_in_throwif {#allow_custom_error_code_in_throwif}

<SettingsInfoBlock type='Bool' default_value='0' />

throwIf()関数でカスタムエラーコードを有効にします。trueに設定すると、スローされる例外が予期しないエラーコードを持つ場合があります。


## allow_ddl {#allow_ddl}

<SettingsInfoBlock type='Bool' default_value='1' />

trueに設定すると、ユーザーはDDLクエリを実行できます。


## allow_deprecated_database_ordinary {#allow_deprecated_database_ordinary}

<SettingsInfoBlock type='Bool' default_value='0' />

非推奨のOrdinaryエンジンを使用したデータベースの作成を許可する


## allow_deprecated_error_prone_window_functions {#allow_deprecated_error_prone_window_functions}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.5" },
        { label: "0" },
        {
          label:
            "非推奨のエラーが発生しやすいウィンドウ関数(neighbor、runningAccumulate、runningDifferenceStartingWithFirstValue、runningDifference)の使用を許可します"
        }
      ]
    }
  ]}
/>

非推奨のエラーが発生しやすいウィンドウ関数(neighbor、runningAccumulate、runningDifferenceStartingWithFirstValue、runningDifference)の使用を許可します


## allow_deprecated_snowflake_conversion_functions {#allow_deprecated_snowflake_conversion_functions}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "非推奨の関数 snowflakeToDateTime[64] および dateTime[64]ToSnowflake を無効化しました。"
        }
      ]
    }
  ]}
/>

関数 `snowflakeToDateTime`、`snowflakeToDateTime64`、`dateTimeToSnowflake`、および `dateTime64ToSnowflake` は非推奨となり、デフォルトで無効化されています。
代わりに関数 `snowflakeIDToDateTime`、`snowflakeIDToDateTime64`、`dateTimeToSnowflakeID`、および `dateTime64ToSnowflakeID` を使用してください。

非推奨の関数を再度有効化する場合(例:移行期間中)は、この設定を `true` に設定してください。


## allow_deprecated_syntax_for_merge_tree {#allow_deprecated_syntax_for_merge_tree}

<SettingsInfoBlock type='Bool' default_value='0' />

非推奨のエンジン定義構文を使用した\*MergeTreeテーブルの作成を許可する


## allow_distributed_ddl {#allow_distributed_ddl}

<SettingsInfoBlock type='Bool' default_value='1' />

trueに設定すると、ユーザーは分散DDLクエリを実行できるようになります。


## allow_drop_detached {#allow_drop_detached}

<SettingsInfoBlock type='Bool' default_value='0' />

ALTER TABLE ... DROP DETACHED PART[ITION] ... クエリを許可する


## allow_dynamic_type_in_join_keys {#allow_dynamic_type_in_join_keys}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.10" },
        { label: "0" },
        { label: "デフォルトで JOIN キーでの Dynamic 型の使用を禁止" }
      ]
    }
  ]}
/>

JOIN キーで Dynamic 型の使用を許可します。互換性のために追加されました。他の型との比較で予期しない結果が生じる可能性があるため、JOIN キーで Dynamic 型を使用することは推奨されません。


## allow_execute_multiif_columnar {#allow_execute_multiif_columnar}

<SettingsInfoBlock type='Bool' default_value='1' />

multiIf関数のカラム単位実行を許可します


## allow_experimental_alias_table_engine {#allow_experimental_alias_table_engine}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

Aliasエンジンを使用したテーブルの作成を許可します。


## allow_experimental_analyzer {#allow_experimental_analyzer}

**エイリアス**: `enable_analyzer`

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1" },
        { label: "アナライザーとプランナーをデフォルトで有効化する" }
      ]
    }
  ]}
/>

新しいクエリアナライザーを有効にします。


## allow_experimental_codecs {#allow_experimental_codecs}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

trueに設定すると、実験的な圧縮コーデックの指定が許可されます(ただし、現時点ではそのようなコーデックは存在しないため、このオプションは機能しません)。


## allow_experimental_correlated_subqueries {#allow_experimental_correlated_subqueries}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "1" },
        { label: "相関サブクエリのサポートをベータ版としてマークしました。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.4" },
        { label: "0" },
        { label: "相関サブクエリの実行を許可する新しい設定が追加されました。" }
      ]
    }
  ]}
/>

相関サブクエリの実行を許可します。


## allow_experimental_database_glue_catalog {#allow_experimental_database_glue_catalog}

<BetaBadge />

**エイリアス**: `allow_database_glue_catalog`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.3" },
        { label: "0" },
        {
          label:
            "catalog_type = 'glue' の実験的データベースエンジン DataLakeCatalog を許可"
        }
      ]
    }
  ]}
/>

catalog_type = 'glue' の実験的データベースエンジン DataLakeCatalog を許可


## allow_experimental_database_hms_catalog {#allow_experimental_database_hms_catalog}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        {
          label:
            "catalog_type = 'hive' の実験的データベースエンジン DataLakeCatalog を許可"
        }
      ]
    }
  ]}
/>

catalog_type = 'hms' の実験的データベースエンジン DataLakeCatalog を許可


## allow_experimental_database_iceberg {#allow_experimental_database_iceberg}

<BetaBadge />

**エイリアス**: `allow_database_iceberg`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.12" }, { label: "0" }, { label: "新規設定。" }]
    }
  ]}
/>

catalog_type = 'iceberg' を指定した実験的データベースエンジン DataLakeCatalog を許可します


## allow_experimental_database_materialized_postgresql {#allow_experimental_database_materialized_postgresql}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

Engine=MaterializedPostgreSQL(...)を使用したデータベースの作成を許可します。


## allow_experimental_database_unity_catalog {#allow_experimental_database_unity_catalog}

<BetaBadge />

**エイリアス**: `allow_database_unity_catalog`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.3" },
        { label: "0" },
        {
          label:
            "catalog_type = 'unity' の実験的データベースエンジン DataLakeCatalog を許可"
        }
      ]
    }
  ]}
/>

catalog_type = 'unity' の実験的データベースエンジン DataLakeCatalog を許可


## allow_experimental_delta_kernel_rs {#allow_experimental_delta_kernel_rs}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "1" }, { label: "New setting" }]
    }
  ]}
/>

実験的な delta-kernel-rs 実装を許可します。


## allow_experimental_delta_lake_writes {#allow_experimental_delta_lake_writes}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新しい設定です。" }]
    }
  ]}
/>

delta-kernelの書き込み機能を有効にします。


## allow_experimental_full_text_index {#allow_experimental_full_text_index}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        { label: "実験的なテキストインデックスを有効化" }
      ]
    }
  ]}
/>

trueに設定すると、実験的なテキストインデックスの使用を許可します。


## allow_experimental_funnel_functions {#allow_experimental_funnel_functions}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

ファネル分析用の実験的な関数を有効にします。


## allow_experimental_hash_functions {#allow_experimental_hash_functions}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

実験的なハッシュ関数を有効化します


## allow_experimental_iceberg_compaction {#allow_experimental_iceberg_compaction}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "New setting " }]
    }
  ]}
/>

Icebergテーブルに対して'OPTIMIZE'を明示的に使用できるようにします。


## allow_experimental_insert_into_iceberg {#allow_experimental_insert_into_iceberg}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.7" }, { label: "0" }, { label: "New setting." }]
    }
  ]}
/>

Icebergへの`INSERT`クエリの実行を許可します。


## allow_experimental_join_right_table_sorting {#allow_experimental_join_right_table_sorting}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        {
          label:
            "trueに設定され、`join_to_sort_minimum_perkey_rows`と`join_to_sort_maximum_table_rows`の条件が満たされている場合、左結合または内部ハッシュ結合のパフォーマンスを向上させるために右テーブルをキーで並べ替えます"
        }
      ]
    }
  ]}
/>

trueに設定され、`join_to_sort_minimum_perkey_rows`と`join_to_sort_maximum_table_rows`の条件が満たされている場合、左結合または内部ハッシュ結合のパフォーマンスを向上させるために右テーブルをキーで並べ替えます。


## allow_experimental_kafka_offsets_storage_in_keeper {#allow_experimental_kafka_offsets_storage_in_keeper}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.8" },
        { label: "0" },
        {
          label:
            "コミット済みオフセットをClickHouse Keeperに保存する実験的なKafkaストレージエンジンの使用を許可"
        }
      ]
    }
  ]}
/>

Kafka関連のオフセットをClickHouse Keeperに保存する実験的機能を許可します。有効にすると、KafkaテーブルエンジンにClickHouse Keeperのパスとレプリカ名を指定できるようになります。その結果、通常のKafkaエンジンの代わりに、コミット済みオフセットを主にClickHouse Keeperに保存する新しいタイプのストレージエンジンが使用されます


## allow_experimental_kusto_dialect {#allow_experimental_kusto_dialect}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "0" }, { label: "A new setting" }]
    }
  ]}
/>

Kusto Query Language (KQL) を有効にします。SQL の代替クエリ言語です。


## allow_experimental_materialized_postgresql_table {#allow_experimental_materialized_postgresql_table}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

MaterializedPostgreSQLテーブルエンジンの使用を許可します。この機能は実験的機能であるため、デフォルトでは無効化されています


## allow_experimental_nlp_functions {#allow_experimental_nlp_functions}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

自然言語処理用の実験的関数を有効にします。


## allow_experimental_parallel_reading_from_replicas {#allow_experimental_parallel_reading_from_replicas}

<BetaBadge />

**エイリアス**: `enable_parallel_replicas`

<SettingsInfoBlock type='UInt64' default_value='0' />

SELECT クエリの実行時に、各シャードから最大 `max_parallel_replicas` 個のレプリカを使用します。読み取りは並列化され、動的に調整されます。0 - 無効、1 - 有効(失敗時は自動的に無効化)、2 - 有効(失敗時は例外をスロー)


## allow_experimental_prql_dialect {#allow_experimental_prql_dialect}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "0" }, { label: "A new setting" }]
    }
  ]}
/>

PRQL（SQLの代替）を有効にします。


## allow_experimental_qbit_type {#allow_experimental_qbit_type}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.10" },
        { label: "0" },
        { label: "新しい実験的な設定" }
      ]
    }
  ]}
/>

[QBit](../../sql-reference/data-types/qbit.md)データ型の作成を許可します。


## allow_experimental_query_deduplication {#allow_experimental_query_deduplication}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

パートUUIDに基づくSELECTクエリの実験的データ重複排除


## allow_experimental_statistics {#allow_experimental_statistics}

<ExperimentalBadge />

**エイリアス**: `allow_experimental_statistic`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "設定名が変更されました。以前の名前は `allow_experimental_statistic` です。"
        }
      ]
    }
  ]}
/>

[統計情報](../../engines/table-engines/mergetree-family/mergetree.md/#table_engine-mergetree-creating-a-table)を持つカラムの定義と[統計情報の操作](../../engines/table-engines/mergetree-family/mergetree.md/#column-statistics)を許可します。


## allow_experimental_time_series_aggregate_functions {#allow_experimental_time_series_aggregate_functions}

<ExperimentalBadge />

**エイリアス**: `allow_experimental_ts_to_grid_aggregate_function`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "0" },
        {
          label:
            "実験的なtimeSeries*集約関数を有効化する新しい設定。"
        }
      ]
    }
  ]}
/>

Prometheus形式の時系列リサンプリング、レート計算、デルタ計算のための実験的なtimeSeries\*集約関数。


## allow_experimental_time_series_table {#allow_experimental_time_series_table}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.8" },
        { label: "0" },
        { label: "TimeSeriesテーブルエンジンを許可する新しい設定を追加しました" }
      ]
    }
  ]}
/>

[TimeSeries](../../engines/table-engines/integrations/time-series.md)テーブルエンジンを使用したテーブルの作成を許可します。指定可能な値:

- 0 — [TimeSeries](../../engines/table-engines/integrations/time-series.md)テーブルエンジンが無効になります。
- 1 — [TimeSeries](../../engines/table-engines/integrations/time-series.md)テーブルエンジンが有効になります。


## allow_experimental_time_time64_type {#allow_experimental_time_time64_type}

<ExperimentalBadge />

**エイリアス**: `enable_time_time64_type`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "0" },
        {
          label:
            "新しい設定。実験的なTimeおよびTime64データ型の使用を許可します。"
        }
      ]
    }
  ]}
/>

[Time](../../sql-reference/data-types/time.md)および[Time64](../../sql-reference/data-types/time64.md)データ型の作成を許可します。


## allow_experimental_window_view {#allow_experimental_window_view}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

WINDOW VIEWを有効にします。まだ十分に成熟していません。


## allow_experimental_ytsaurus_dictionary_source {#allow_experimental_ytsaurus_dictionary_source}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "New setting." }]
    }
  ]}
/>

    YTsaurus統合用の実験的なディクショナリソース。


## allow_experimental_ytsaurus_table_engine {#allow_experimental_ytsaurus_table_engine}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "New setting." }]
    }
  ]}
/>

YTsaurusとの統合のための実験的なテーブルエンジン。


## allow_experimental_ytsaurus_table_function {#allow_experimental_ytsaurus_table_function}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "New setting." }]
    }
  ]}
/>

YTsaurusとの統合のための実験的なテーブルエンジンです。


## allow_general_join_planning {#allow_general_join_planning}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "1" },
        {
          label:
            "ハッシュ結合アルゴリズムが有効な場合に、より汎用的な結合計画アルゴリズムを許可します。"
        }
      ]
    }
  ]}
/>

より複雑な条件を処理できる汎用的な結合計画アルゴリズムを許可します。ただし、ハッシュ結合でのみ動作します。ハッシュ結合が有効でない場合、この設定の値に関係なく、通常の結合計画アルゴリズムが使用されます。


## allow_get_client_http_header {#allow_get_client_http_header}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        { label: "新しい関数が導入されました。" }
      ]
    }
  ]}
/>

`getClientHTTPHeader`関数の使用を許可します。この関数は、現在のHTTPリクエストのヘッダー値を取得できます。`Cookie`などの一部のヘッダーには機密情報が含まれている可能性があるため、セキュリティ上の理由からデフォルトでは無効になっています。なお、`X-ClickHouse-*`および`Authentication`ヘッダーは常に制限されており、この関数では取得できません。


## allow_hyperscan {#allow_hyperscan}

<SettingsInfoBlock type='Bool' default_value='1' />

Hyperscanライブラリを使用する関数を許可します。コンパイル時間の長期化や過剰なリソース使用を回避するには無効化してください。


## allow_introspection_functions {#allow_introspection_functions}

<SettingsInfoBlock type='Bool' default_value='0' />

クエリプロファイリング用の[イントロスペクション関数](../../sql-reference/functions/introspection.md)を有効または無効にします。

設定可能な値:

- 1 — イントロスペクション関数を有効にします。
- 0 — イントロスペクション関数を無効にします。

**関連項目**

- [サンプリングクエリプロファイラ](../../operations/optimizing-performance/sampling-query-profiler.md)
- システムテーブル [trace_log](/operations/system-tables/trace_log)


## allow_materialized_view_with_bad_select {#allow_materialized_view_with_bad_select}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.4" },
        { label: "0" },
        {
          label:
            "存在しないカラムまたはテーブルを参照するマテリアライズドビューの作成を許可しない"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.9" },
        { label: "1" },
        {
          label:
            "CREATE MATERIALIZED VIEWにおけるより厳格な検証をサポート(ただし、まだ有効化されていない)"
        }
      ]
    }
  ]}
/>

存在しないテーブルまたはカラムを参照するSELECTクエリを含むCREATE MATERIALIZED VIEWを許可します。構文的には有効である必要があります。リフレッシュ可能なマテリアライズドビューには適用されません。マテリアライズドビューのスキーマがSELECTクエリから推論される必要がある場合(つまり、CREATEにカラムリストもTOテーブルも指定されていない場合)には適用されません。ソーステーブルの作成前にマテリアライズドビューを作成する際に使用できます。


## allow_named_collection_override_by_default {#allow_named_collection_override_by_default}

<SettingsInfoBlock type='Bool' default_value='1' />

デフォルトで名前付きコレクションのフィールドの上書きを許可します。


## allow_non_metadata_alters {#allow_non_metadata_alters}

<SettingsInfoBlock type='Bool' default_value='1' />

テーブルのメタデータだけでなく、ディスク上のデータにも影響を与えるALTER操作の実行を許可します


## allow_nonconst_timezone_arguments {#allow_nonconst_timezone_arguments}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "0" },
        {
          label:
            "toTimeZone()、fromUnixTimestamp*()、snowflakeToDateTime*()などの特定の時間関連関数において、非定数のタイムゾーン引数を許可します。"
        }
      ]
    }
  ]}
/>

toTimeZone()、fromUnixTimestamp*()、snowflakeToDateTime*()などの特定の時間関連関数において、非定数のタイムゾーン引数を許可します。
この設定は互換性のためにのみ存在します。ClickHouseでは、タイムゾーンはデータ型、つまりカラムのプロパティです。
この設定を有効にすると、カラム内の異なる値が異なるタイムゾーンを持つことができるという誤った印象を与えます。
したがって、この設定は有効にしないでください。


## allow_nondeterministic_mutations {#allow_nondeterministic_mutations}

<SettingsInfoBlock type='Bool' default_value='0' />

レプリケートテーブルのミューテーションで`dictGet`などの非決定的関数の使用を許可するユーザーレベル設定です。

例えば、ディクショナリはノード間で同期されていない可能性があるため、デフォルトではレプリケートテーブルにおいてディクショナリから値を取得するミューテーションは許可されていません。この設定を有効にすると、この動作が許可されますが、使用するデータがすべてのノード間で同期されていることを保証する責任はユーザーが負うことになります。

**例**

```xml
<profiles>
    <default>
        <allow_nondeterministic_mutations>1</allow_nondeterministic_mutations>

        <!-- ... -->
    </default>

    <!-- ... -->

</profiles>
```


## allow_nondeterministic_optimize_skip_unused_shards {#allow_nondeterministic_optimize_skip_unused_shards}

<SettingsInfoBlock type='Bool' default_value='0' />

シャーディングキーで非決定的な関数（`rand`や`dictGet`など。`dictGet`は更新時にいくつかの注意点があります）を許可します。

設定可能な値:

- 0 — 許可しない。
- 1 — 許可する。


## allow_not_comparable_types_in_comparison_functions {#allow_not_comparable_types_in_comparison_functions}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "0" },
        {
          label:
            "デフォルトでは比較関数で比較不可能な型を許可しない"
        }
      ]
    }
  ]}
/>

比較関数 `equal/less/greater/etc` において、比較不可能な型（JSON/AggregateFunctionなど）の使用を許可または制限します。


## allow_not_comparable_types_in_order_by {#allow_not_comparable_types_in_order_by}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "0" },
        { label: "デフォルトでORDER BYにおける比較不可能な型を許可しない" }
      ]
    }
  ]}
/>

比較不可能な型(JSONやAggregateFunctionなど)をORDER BYキーで使用することを許可または制限します。


## allow_prefetched_read_pool_for_local_filesystem {#allow_prefetched_read_pool_for_local_filesystem}

<SettingsInfoBlock type='Bool' default_value='0' />

すべてのパーツがローカルファイルシステム上にある場合、プリフェッチスレッドプールを優先する


## allow_prefetched_read_pool_for_remote_filesystem {#allow_prefetched_read_pool_for_remote_filesystem}

<SettingsInfoBlock type='Bool' default_value='1' />

すべてのパーツがリモートファイルシステム上にある場合、プリフェッチスレッドプールを優先する


## allow_push_predicate_ast_for_distributed_subqueries {#allow_push_predicate_ast_for_distributed_subqueries}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

アナライザーが有効な分散サブクエリに対して、ASTレベルでの述語のプッシュダウンを許可します


## allow_push_predicate_when_subquery_contains_with {#allow_push_predicate_when_subquery_contains_with}

<SettingsInfoBlock type='Bool' default_value='1' />

サブクエリにWITH句が含まれている場合に述語のプッシュダウンを許可します


## allow_reorder_prewhere_conditions {#allow_reorder_prewhere_conditions}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

WHERE句からPREWHERE句へ条件を移動する際に、フィルタリングを最適化するための条件の並び替えを許可します


## allow_settings_after_format_in_insert {#allow_settings_after_format_in_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.4" },
        { label: "0" },
        {
          label:
            "INSERTクエリにおいてFORMATの後のSETTINGSを許可しない。ClickHouseがSETTINGSを値として解釈するため、誤解を招く"
        }
      ]
    }
  ]}
/>

`INSERT`クエリにおいて`FORMAT`の後に`SETTINGS`を記述することを許可するかどうかを制御します。`SETTINGS`の一部が値として解釈される可能性があるため、この設定の使用は推奨されません。

例:

```sql
INSERT INTO FUNCTION null('foo String') SETTINGS max_threads=1 VALUES ('bar');
```

ただし、次のクエリは`allow_settings_after_format_in_insert`が有効な場合のみ動作します:

```sql
SET allow_settings_after_format_in_insert=1;
INSERT INTO FUNCTION null('foo String') VALUES ('bar') SETTINGS max_threads=1;
```

設定可能な値:

- 0 — 許可しない。
- 1 — 許可する。

:::note
古い構文に依存するユースケースがある場合にのみ、後方互換性のためにこの設定を使用してください。
:::


## allow_simdjson {#allow_simdjson}

<SettingsInfoBlock type='Bool' default_value='1' />

AVX2命令が利用可能な場合、'JSON\*'関数でsimdjsonライブラリの使用を許可します。無効化した場合はrapidjsonが使用されます。


## allow_special_serialization_kinds_in_output_formats {#allow_special_serialization_kinds_in_output_formats}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1" },
        {
          label:
            "一部の出力フォーマットにおいて、SparseやReplicatedなどの特殊なカラム表現の直接出力を有効化"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.10" },
        { label: "0" },
        {
          label:
            "SparseやReplicatedなどの特殊なカラム表現を完全なカラムに変換せずに出力できる設定を追加"
        }
      ]
    }
  ]}
/>

SparseやReplicatedなどの特殊なシリアライゼーション種別を持つカラムを、完全なカラム表現に変換せずに出力できるようにします。
これにより、フォーマット処理中の不要なデータコピーを回避できます。


## allow_statistics_optimize {#allow_statistics_optimize}

<ExperimentalBadge />

**エイリアス**: `allow_statistic_optimize`

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "設定名が変更されました。以前の名前は `allow_statistic_optimize` です。"
        }
      ]
    }
  ]}
/>

統計情報を使用したクエリの最適化を許可します


## allow_suspicious_codecs {#allow_suspicious_codecs}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "20.5" },
        { label: "0" },
        { label: "無意味な圧縮コーデックの指定を許可しない" }
      ]
    }
  ]}
/>

trueに設定すると、無意味な圧縮コーデックの指定が許可されます。


## allow_suspicious_fixed_string_types {#allow_suspicious_fixed_string_types}

<SettingsInfoBlock type='Bool' default_value='0' />

CREATE TABLE文で、n > 256のFixedString(n)型カラムの作成を許可します。長さ256以上のFixedStringは不適切である可能性が高く、誤用を示していると考えられます


## allow_suspicious_indices {#allow_suspicious_indices}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "0" },
        { label: "trueの場合、同一の式でインデックスを定義可能" }
      ]
    }
  ]}
/>

同一の式を持つプライマリ/セカンダリインデックスおよびソートキーを拒否する


## allow_suspicious_low_cardinality_types {#allow_suspicious_low_cardinality_types}

<SettingsInfoBlock type='Bool' default_value='0' />

8バイト以下の固定サイズを持つデータ型（数値データ型および`FixedString(8_bytes_or_less)`）で[LowCardinality](../../sql-reference/data-types/lowcardinality.md)の使用を許可または制限します。

小さな固定値に対して`LowCardinality`を使用することは通常非効率的です。これはClickHouseが各行に対して数値インデックスを格納するためです。その結果：

- ディスク使用量が増加する可能性があります。
- 辞書のサイズに応じて、RAM消費量が高くなる可能性があります。
- 追加のコーディング/エンコーディング操作により、一部の関数の動作が遅くなる可能性があります。

上記のすべての理由により、[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)エンジンテーブルでのマージ時間が長くなる可能性があります。

設定可能な値：

- 1 — `LowCardinality`の使用は制限されません。
- 0 — `LowCardinality`の使用は制限されます。


## allow_suspicious_primary_key {#allow_suspicious_primary_key}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        {
          label:
            "MergeTreeで疑わしいPRIMARY KEY/ORDER BYを禁止（例：SimpleAggregateFunction）"
        }
      ]
    }
  ]}
/>

MergeTreeで疑わしい`PRIMARY KEY`/`ORDER BY`を許可します（例：SimpleAggregateFunction）。


## allow_suspicious_ttl_expressions {#allow_suspicious_ttl_expressions}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.12" },
        { label: "0" },
        {
          label:
            "これは新しい設定です。以前のバージョンでは、許可する動作と同等でした。"
        }
      ]
    }
  ]}
/>

テーブルのいずれのカラムにも依存しないTTL式を拒否します。これは多くの場合、ユーザーエラーを示しています。


## allow_suspicious_types_in_group_by {#allow_suspicious_types_in_group_by}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "0" },
        { label: "デフォルトでは GROUP BY での Variant/Dynamic 型を許可しない" }
      ]
    }
  ]}
/>

GROUP BY キーでの [Variant](../../sql-reference/data-types/variant.md) 型および [Dynamic](../../sql-reference/data-types/dynamic.md) 型の使用を許可または制限します。


## allow_suspicious_types_in_order_by {#allow_suspicious_types_in_order_by}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "0" },
        { label: "デフォルトでは ORDER BY での Variant/Dynamic 型を許可しない" }
      ]
    }
  ]}
/>

ORDER BY キーで [Variant](../../sql-reference/data-types/variant.md) 型および [Dynamic](../../sql-reference/data-types/dynamic.md) 型の使用を許可または制限します。


## allow_suspicious_variant_types {#allow_suspicious_variant_types}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "0" },
        {
          label:
            "デフォルトでは疑わしいバリアントを持つVariant型の作成を許可しない"
        }
      ]
    }
  ]}
/>

CREATE TABLE文で、類似したバリアント型(例:異なる数値型や日付型)を持つVariant型の指定を許可します。この設定を有効にすると、類似した型の値を扱う際に曖昧性が生じる可能性があります。


## allow_unrestricted_reads_from_keeper {#allow_unrestricted_reads_from_keeper}

<SettingsInfoBlock type='Bool' default_value='0' />

system.zookeeperテーブルからの無制限の読み取り（パス条件なし）を許可します。便利ですが、ZooKeeperにとって安全ではありません


## alter_move_to_space_execute_async {#alter_move_to_space_execute_async}

<SettingsInfoBlock type='Bool' default_value='0' />

ALTER TABLE MOVE ... TO [DISK|VOLUME] を非同期で実行する


## alter_partition_verbose_result {#alter_partition_verbose_result}

<SettingsInfoBlock type='Bool' default_value='0' />

パーティションおよびパートに対する操作が正常に適用されたパートに関する情報の表示を有効または無効にします。
[ATTACH PARTITION|PART](/sql-reference/statements/alter/partition#attach-partitionpart)および[FREEZE PARTITION](/sql-reference/statements/alter/partition#freeze-partition)に適用可能です。

設定可能な値:

- 0 — 詳細表示を無効にします。
- 1 — 詳細表示を有効にします。

**例**

```sql
CREATE TABLE test(a Int64, d Date, s String) ENGINE = MergeTree PARTITION BY toYYYYMDECLARE(d) ORDER BY a;
INSERT INTO test VALUES(1, '2021-01-01', '');
INSERT INTO test VALUES(1, '2021-01-01', '');
ALTER TABLE test DETACH PARTITION ID '202101';

ALTER TABLE test ATTACH PARTITION ID '202101' SETTINGS alter_partition_verbose_result = 1;

┌─command_type─────┬─partition_id─┬─part_name────┬─old_part_name─┐
│ ATTACH PARTITION │ 202101       │ 202101_7_7_0 │ 202101_5_5_0  │
│ ATTACH PARTITION │ 202101       │ 202101_8_8_0 │ 202101_6_6_0  │
└──────────────────┴──────────────┴──────────────┴───────────────┘

ALTER TABLE test FREEZE SETTINGS alter_partition_verbose_result = 1;

┌─command_type─┬─partition_id─┬─part_name────┬─backup_name─┬─backup_path───────────────────┬─part_backup_path────────────────────────────────────────────┐
│ FREEZE ALL   │ 202101       │ 202101_7_7_0 │ 8           │ /var/lib/clickhouse/shadow/8/ │ /var/lib/clickhouse/shadow/8/data/default/test/202101_7_7_0 │
│ FREEZE ALL   │ 202101       │ 202101_8_8_0 │ 8           │ /var/lib/clickhouse/shadow/8/ │ /var/lib/clickhouse/shadow/8/data/default/test/202101_8_8_0 │
└──────────────┴──────────────┴──────────────┴─────────────┴───────────────────────────────┴─────────────────────────────────────────────────────────────┘
```


## alter_sync {#alter_sync}

**エイリアス**: `replication_alter_partitions_sync`

<SettingsInfoBlock type='UInt64' default_value='1' />

[ALTER](../../sql-reference/statements/alter/index.md)、[OPTIMIZE](../../sql-reference/statements/optimize.md)、または[TRUNCATE](../../sql-reference/statements/truncate.md)クエリによるレプリカ上でのアクション実行の待機を設定します。

設定可能な値:

- `0` — 待機しない。
- `1` — 自身の実行完了を待機する。
- `2` — すべてのレプリカの実行完了を待機する。

Cloudのデフォルト値: `1`。

:::note
`alter_sync`は`Replicated`テーブルにのみ適用されます。`Replicated`でないテーブルの変更には影響しません。
:::


## alter_update_mode {#alter_update_mode}

<SettingsInfoBlock type='AlterUpdateMode' default_value='heavy' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "heavy" }, { label: "新しい設定" }]
    }
  ]}
/>

`UPDATE`コマンドを含む`ALTER`クエリのモード。

設定可能な値:

- `heavy` - 通常のミューテーションを実行します。
- `lightweight` - 可能な場合は軽量更新を実行し、それ以外の場合は通常のミューテーションを実行します。
- `lightweight_force` - 可能な場合は軽量更新を実行し、それ以外の場合は例外をスローします。


## analyze_index_with_space_filling_curves {#analyze_index_with_space_filling_curves}

<SettingsInfoBlock type='Bool' default_value='1' />

テーブルのインデックスに空間充填曲線が含まれている場合（例：`ORDER BY mortonEncode(x, y)` または `ORDER BY hilbertEncode(x, y)`）で、かつクエリがその引数に対する条件を持つ場合（例：`x >= 10 AND x <= 20 AND y >= 20 AND y <= 30`）、インデックス解析に空間充填曲線を使用します。


## analyzer_compatibility_allow_compound_identifiers_in_unflatten_nested {#analyzer_compatibility_allow_compound_identifiers_in_unflatten_nested}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1" }, { label: "新しい設定。" }]
    }
  ]}
/>

ネスト構造に複合識別子の追加を許可します。この設定はクエリ結果を変更するため、互換性設定となっています。無効にした場合、`SELECT a.b.c FROM table ARRAY JOIN a` は動作せず、`SELECT a FROM table` は `Nested a` の結果に `a.b.c` カラムを含めません。


## analyzer_compatibility_join_using_top_level_identifier {#analyzer_compatibility_join_using_top_level_identifier}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        { label: "射影からJOIN USING内の識別子を強制解決" }
      ]
    }
  ]}
/>

射影からJOIN USING内の識別子を強制的に解決します(例:`SELECT a + 1 AS b FROM t1 JOIN t2 USING (b)`では、結合は`t1.b = t2.b`ではなく`t1.a + 1 = t2.b`で実行されます)。


## any_join_distinct_right_table_keys {#any_join_distinct_right_table_keys}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "19.14" },
        { label: "0" },
        {
          label:
            "不整合を避けるため、デフォルトでANY RIGHTおよびANY FULL JOINを無効化"
        }
      ]
    }
  ]}
/>

`ANY INNER|LEFT JOIN`操作における従来のClickHouseサーバーの動作を有効にします。

:::note
従来の`JOIN`動作に依存するユースケースがある場合にのみ、後方互換性のためにこの設定を使用してください。
:::

従来の動作が有効な場合:

- `t1 ANY LEFT JOIN t2`と`t2 ANY RIGHT JOIN t1`操作の結果は等しくありません。これは、ClickHouseが多対一の左から右へのテーブルキーマッピングのロジックを使用するためです。
- `ANY INNER JOIN`操作の結果には、`SEMI LEFT JOIN`操作と同様に、左テーブルのすべての行が含まれます。

従来の動作が無効な場合:

- `t1 ANY LEFT JOIN t2`と`t2 ANY RIGHT JOIN t1`操作の結果は等しくなります。これは、ClickHouseが`ANY RIGHT JOIN`操作において一対多のキーマッピングを提供するロジックを使用するためです。
- `ANY INNER JOIN`操作の結果には、左テーブルと右テーブルの両方からキーごとに1行が含まれます。

設定可能な値:

- 0 — 従来の動作は無効です。
- 1 — 従来の動作は有効です。

関連項目:

- [JOIN厳密性](/sql-reference/statements/select/join#settings)


## apply_deleted_mask {#apply_deleted_mask}

<SettingsInfoBlock type='Bool' default_value='1' />

軽量DELETEで削除された行をフィルタリングして除外します。無効にすると、クエリでそれらの行を読み取ることができるようになります。これはデバッグや「削除の取り消し」シナリオで有用です


## apply_mutations_on_fly {#apply_mutations_on_fly}

<SettingsInfoBlock type='Bool' default_value='0' />

trueの場合、データパーツにマテリアライズされていないミューテーション（UPDATEおよびDELETE）がSELECT実行時に適用されます。


## apply_patch_parts {#apply_patch_parts}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "1" }, { label: "A new setting" }]
    }
  ]}
/>

trueの場合、パッチパート（軽量更新を表す）がSELECT実行時に適用されます。


## apply_patch_parts_join_cache_buckets {#apply_patch_parts_join_cache_buckets}

<SettingsInfoBlock type='NonZeroUInt64' default_value='8' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "8" }, { label: "新しい設定" }]
    }
  ]}
/>

Joinモードでパッチパーツを適用する際の一時キャッシュのバケット数。


## apply_settings_from_server {#apply_settings_from_server}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.2" },
        { label: "1" },
        {
          label:
            "クライアント側のコード(INSERT入力の解析やクエリ出力のフォーマットなど)は、サーバー設定ファイルからの設定を含め、サーバーと同じ設定を使用します。"
        }
      ]
    }
  ]}
/>

クライアントがサーバーからの設定を受け入れるかどうかを指定します。

この設定はクライアント側で実行される操作にのみ影響し、特にINSERT入力データの解析とクエリ結果のフォーマットに影響します。クエリ実行の大部分はサーバー側で行われるため、この設定による影響を受けません。

通常、この設定はユーザープロファイル(users.xmlまたは`ALTER USER`などのクエリ)で設定すべきであり、クライアント経由(クライアントのコマンドライン引数、`SET`クエリ、または`SELECT`クエリの`SETTINGS`セクション)では設定すべきではありません。クライアント経由でfalseに変更することは可能ですが、trueに変更することはできません(ユーザープロファイルで`apply_settings_from_server = false`が設定されている場合、サーバーは設定を送信しないため)。

なお、当初(24.12)はサーバー設定(`send_settings_to_client`)が存在していましたが、その後、使いやすさの向上のため、このクライアント設定に置き換えられました。


## arrow_flight_request_descriptor_type {#arrow_flight_request_descriptor_type}

<SettingsInfoBlock type='ArrowFlightDescriptorType' default_value='path' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "path" },
        {
          label:
            "新しい設定。Arrow Flightリクエストで使用するディスクリプタのタイプ：'path'または'command'。Dremioでは'command'が必要です。"
        }
      ]
    }
  ]}
/>

Arrow Flightリクエストで使用するディスクリプタのタイプ。'path'はデータセット名をパスディスクリプタとして送信します。'command'はSQLクエリをコマンドディスクリプタとして送信します（Dremioで必要）。

使用可能な値：

- 'path' — FlightDescriptor::Pathを使用（デフォルト、ほとんどのArrow Flightサーバーで動作します）
- 'command' — SELECTクエリでFlightDescriptor::Commandを使用（Dremioで必要）


## asterisk_include_alias_columns {#asterisk_include_alias_columns}

<SettingsInfoBlock type='Bool' default_value='0' />

ワイルドカードクエリ（`SELECT *`）に[ALIAS](../../sql-reference/statements/create/table.md/#alias)カラムを含めます。

設定可能な値：

- 0 - 無効
- 1 - 有効


## asterisk_include_materialized_columns {#asterisk_include_materialized_columns}

<SettingsInfoBlock type='Bool' default_value='0' />

ワイルドカードクエリ（`SELECT *`）に[MATERIALIZED](/sql-reference/statements/create/view#materialized-view)列を含めます。

設定可能な値：

- 0 - 無効
- 1 - 有効


## async_insert {#async_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

trueの場合、INSERTクエリのデータはキューに格納され、後でバックグラウンドでテーブルにフラッシュされます。wait_for_async_insertがfalseの場合、INSERTクエリはほぼ即座に処理されます。それ以外の場合、クライアントはデータがテーブルにフラッシュされるまで待機します。


## async_insert_busy_timeout_decrease_rate {#async_insert_busy_timeout_decrease_rate}

<SettingsInfoBlock type='Double' default_value='0.2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "0.2" },
        {
          label:
            "適応的非同期挿入タイムアウトが減少する際の指数的減衰率"
        }
      ]
    }
  ]}
/>

適応的非同期挿入タイムアウトが減少する際の指数的減衰率


## async_insert_busy_timeout_increase_rate {#async_insert_busy_timeout_increase_rate}

<SettingsInfoBlock type='Double' default_value='0.2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "0.2" },
        {
          label:
            "適応的非同期挿入タイムアウトが増加する際の指数関数的成長率"
        }
      ]
    }
  ]}
/>

適応的非同期挿入タイムアウトが増加する際の指数関数的成長率


## async_insert_busy_timeout_max_ms {#async_insert_busy_timeout_max_ms}

**エイリアス**: `async_insert_busy_timeout_ms`

<SettingsInfoBlock type='Milliseconds' default_value='200' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "200" },
        {
          label:
            "非同期挿入タイムアウトの最小値(ミリ秒単位); async_insert_busy_timeout_msはasync_insert_busy_timeout_max_msのエイリアスとなりました"
        }
      ]
    }
  ]}
/>

最初のデータが到着してから、クエリごとに収集されたデータをダンプするまでの最大待機時間。


## async_insert_busy_timeout_min_ms {#async_insert_busy_timeout_min_ms}

<SettingsInfoBlock type='Milliseconds' default_value='50' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "50" },
        {
          label:
            "非同期挿入タイムアウトの最小値(ミリ秒単位)。適応アルゴリズムによって後で増加される可能性のある初期値としても機能します"
        }
      ]
    }
  ]}
/>

async_insert_use_adaptive_busy_timeoutによって自動調整が有効になっている場合、最初のデータが出現してからクエリごとに収集されたデータをダンプするまでの最小待機時間を指定します。また、適応アルゴリズムの初期値としても機能します


## async_insert_deduplicate {#async_insert_deduplicate}

<SettingsInfoBlock type='Bool' default_value='0' />

レプリケートされたテーブルでの非同期INSERTクエリに対して、挿入ブロックの重複排除を実行するように指定します


## async_insert_max_data_size {#async_insert_max_data_size}

<SettingsInfoBlock type='UInt64' default_value='10485760' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "10485760" },
        { label: "以前の値は小さすぎました。" }
      ]
    }
  ]}
/>

挿入前にクエリごとに収集される未解析データの最大サイズ（バイト単位）


## async_insert_max_query_number {#async_insert_max_query_number}

<SettingsInfoBlock type='UInt64' default_value='450' />

挿入が実行されるまでの最大挿入クエリ数。
設定 [`async_insert_deduplicate`](#async_insert_deduplicate) が 1 の場合にのみ有効になります。


## async_insert_poll_timeout_ms {#async_insert_poll_timeout_ms}

<SettingsInfoBlock type='Milliseconds' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "10" },
        {
          label:
            "非同期挿入キューからのデータポーリングのタイムアウト(ミリ秒)"
        }
      ]
    }
  ]}
/>

非同期挿入キューからのデータポーリングのタイムアウト


## async_insert_use_adaptive_busy_timeout {#async_insert_use_adaptive_busy_timeout}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        { label: "適応型非同期挿入タイムアウトを使用" }
      ]
    }
  ]}
/>

trueに設定すると、非同期挿入に適応型ビジータイムアウトが使用されます


## async_query_sending_for_remote {#async_query_sending_for_remote}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.3" },
        { label: "1" },
        { label: "シャード間で接続を作成し、非同期でクエリを送信" }
      ]
    }
  ]}
/>

リモートクエリの実行時に、非同期での接続作成とクエリ送信を有効にします。

デフォルトで有効です。


## async_socket_for_remote {#async_socket_for_remote}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.5" },
        { label: "1" },
        {
          label:
            "すべての問題を修正し、リモートクエリのソケットからの非同期読み取りをデフォルトで再度有効化"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "21.3" },
        { label: "0" },
        {
          label:
            "いくつかの問題により、リモートクエリのソケットからの非同期読み取りを無効化"
        }
      ]
    }
  ]}
/>

リモートクエリの実行中にソケットからの非同期読み取りを有効にします。

デフォルトで有効になっています。


## azure_allow_parallel_part_upload {#azure_allow_parallel_part_upload}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "true" },
        { label: "Azureマルチパートアップロードで複数のスレッドを使用します。" }
      ]
    }
  ]}
/>

Azureマルチパートアップロードで複数のスレッドを使用します。


## azure_check_objects_after_upload {#azure_check_objects_after_upload}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "0" },
        {
          label:
            "Azure Blob Storageにアップロードされた各オブジェクトをチェックし、アップロードが正常に完了したことを確認します"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.10" },
        { label: "0" },
        {
          label:
            "Azure Blob Storageにアップロードされた各オブジェクトをチェックし、アップロードが正常に完了したことを確認します"
        }
      ]
    }
  ]}
/>

Azure Blob Storageにアップロードされた各オブジェクトをチェックし、アップロードが正常に完了したことを確認します


## azure_connect_timeout_ms {#azure_connect_timeout_ms}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1000" }, { label: "新しい設定" }]
    }
  ]}
/>

Azureディスクのホストに対する接続タイムアウト。


## azure_create_new_file_on_insert {#azure_create_new_file_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

Azureエンジンテーブルへの各INSERT時に新しいファイルを作成するかどうかを有効化または無効化します


## azure_ignore_file_doesnt_exist {#azure_ignore_file_doesnt_exist}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "AzureBlobStorageテーブルエンジンで、要求されたファイルが存在しない場合に例外をスローせず0行を返すことを許可"
        }
      ]
    }
  ]}
/>

特定のキーを読み取る際、ファイルが存在しない場合はその不在を無視します。

設定可能な値:

- 1 — `SELECT`は空の結果を返します。
- 0 — `SELECT`は例外をスローします。


## azure_list_object_keys_size {#azure_list_object_keys_size}

<SettingsInfoBlock type='UInt64' default_value='1000' />

ListObjectリクエストでバッチで返却できるファイルの最大数


## azure_max_blocks_in_multipart_upload {#azure_max_blocks_in_multipart_upload}

<SettingsInfoBlock type='UInt64' default_value='50000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.5" },
        { label: "50000" },
        { label: "Azure のマルチパートアップロードにおけるブロックの最大数。" }
      ]
    }
  ]}
/>

Azure のマルチパートアップロードにおけるブロックの最大数。


## azure_max_get_burst {#azure_max_get_burst}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

1秒あたりのリクエスト制限に達する前に同時発行可能なリクエストの最大数。デフォルト(0)では`azure_max_get_rps`と同じ値になります


## azure_max_get_rps {#azure_max_get_rps}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

スロットリング前の Azure GET リクエストの秒間レート制限。0 は無制限を意味します。


## azure_max_inflight_parts_for_one_file {#azure_max_inflight_parts_for_one_file}

<SettingsInfoBlock type='UInt64' default_value='20' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "20" },
        {
          label:
            "マルチパートアップロードリクエストにおける同時にロードされるパーツの最大数。0は無制限を意味します。"
        }
      ]
    }
  ]}
/>

マルチパートアップロードリクエストにおける同時にロードされるパーツの最大数。0は無制限を意味します。


## azure_max_put_burst {#azure_max_put_burst}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

1秒あたりのリクエスト制限に達する前に同時発行可能なリクエストの最大数。デフォルト(0)の場合、`azure_max_put_rps`と等しくなります


## azure_max_put_rps {#azure_max_put_rps}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

スロットリング前のAzure PUTリクエストの秒間レート制限。0は無制限を意味します。


## azure_max_redirects {#azure_max_redirects}

<SettingsInfoBlock type='UInt64' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "10" }, { label: "New setting" }]
    }
  ]}
/>

許可されるAzureリダイレクトホップの最大数。


## azure_max_single_part_copy_size {#azure_max_single_part_copy_size}

<SettingsInfoBlock type='UInt64' default_value='268435456' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "268435456" },
        {
          label:
            "Azureブロブストレージに単一パートコピーでコピーできるオブジェクトの最大サイズ。"
        }
      ]
    }
  ]}
/>

Azureブロブストレージに単一パートコピーでコピーできるオブジェクトの最大サイズ。


## azure_max_single_part_upload_size {#azure_max_single_part_upload_size}

<SettingsInfoBlock type='UInt64' default_value='33554432' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "33554432" },
        { label: "S3に合わせる" }
      ]
    }
  ]}
/>

Azureブロブストレージにシングルパートアップロードでアップロードできるオブジェクトの最大サイズ。


## azure_max_single_read_retries {#azure_max_single_read_retries}

<SettingsInfoBlock type='UInt64' default_value='4' />

単一のAzure Blob Storage読み取り時の最大リトライ回数。


## azure_max_unexpected_write_error_retries {#azure_max_unexpected_write_error_retries}

<SettingsInfoBlock type='UInt64' default_value='4' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "4" },
        {
          label:
            "Azure Blob Storage への書き込み中に予期しないエラーが発生した場合の最大再試行回数"
        }
      ]
    }
  ]}
/>

Azure Blob Storage への書き込み中に予期しないエラーが発生した場合の最大再試行回数


## azure_max_upload_part_size {#azure_max_upload_part_size}

<SettingsInfoBlock type='UInt64' default_value='5368709120' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "5368709120" },
        {
          label:
            "Azure Blob Storageへのマルチパートアップロード中にアップロードするパートの最大サイズ。"
        }
      ]
    }
  ]}
/>

Azure Blob Storageへのマルチパートアップロード中にアップロードするパートの最大サイズ。


## azure_min_upload_part_size {#azure_min_upload_part_size}

<SettingsInfoBlock type='UInt64' default_value='16777216' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "16777216" },
        {
          label:
            "Azure Blob Storageへのマルチパートアップロード中にアップロードするパートの最小サイズ。"
        }
      ]
    }
  ]}
/>

Azure Blob Storageへのマルチパートアップロード中にアップロードするパートの最小サイズ。


## azure_request_timeout_ms {#azure_request_timeout_ms}

<SettingsInfoBlock type='UInt64' default_value='30000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "30000" }, { label: "新しい設定" }]
    }
  ]}
/>

Azureとの間でデータを送受信する際のアイドルタイムアウト。単一のTCP読み取りまたは書き込み呼び出しがこの時間ブロックされた場合は失敗します。


## azure_sdk_max_retries {#azure_sdk_max_retries}

<SettingsInfoBlock type='UInt64' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "10" },
        { label: "Azure SDK における最大リトライ回数" }
      ]
    }
  ]}
/>

Azure SDK における最大リトライ回数


## azure_sdk_retry_initial_backoff_ms {#azure_sdk_retry_initial_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "10" },
        { label: "Azure SDK での再試行間の最小バックオフ時間" }
      ]
    }
  ]}
/>

Azure SDK での再試行間の最小バックオフ時間


## azure_sdk_retry_max_backoff_ms {#azure_sdk_retry_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "1000" },
        { label: "Azure SDK における再試行間の最大バックオフ時間" }
      ]
    }
  ]}
/>

Azure SDK における再試行間の最大バックオフ時間


## azure_skip_empty_files {#azure_skip_empty_files}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        { label: "Azureテーブルエンジンで空ファイルのスキップを許可" }
      ]
    }
  ]}
/>

Azureエンジンにおける空ファイルのスキップを有効または無効にします。

設定可能な値:

- 0 — 空ファイルが要求された形式と互換性がない場合、`SELECT`は例外をスローします。
- 1 — 空ファイルに対して`SELECT`は空の結果を返します。


## azure_strict_upload_part_size {#azure_strict_upload_part_size}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        {
          label:
            "Azure Blob ストレージへのマルチパートアップロード時にアップロードする各パートの正確なサイズ。"
        }
      ]
    }
  ]}
/>

Azure Blob ストレージへのマルチパートアップロード時にアップロードする各パートの正確なサイズ。


## azure_throw_on_zero_files_match {#azure_throw_on_zero_files_match}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "AzureBlobStorageエンジンでListObjectsリクエストがファイルに一致しない場合、空のクエリ結果の代わりにエラーをスローできるようにします"
        }
      ]
    }
  ]}
/>

glob展開ルールに従って一致するファイルが0件の場合、エラーをスローします。

設定可能な値:

- 1 — `SELECT`は例外をスローします。
- 0 — `SELECT`は空の結果を返します。


## azure_truncate_on_insert {#azure_truncate_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

Azureエンジンテーブルへの挿入前のトランケート（切り詰め）を有効または無効にします。


## azure_upload_part_size_multiply_factor {#azure_upload_part_size_multiply_factor}

<SettingsInfoBlock type='UInt64' default_value='2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "2" },
        {
          label:
            "Azure Blob Storageへの単一書き込みでazure_multiply_parts_count_threshold個のパートがアップロードされるたびに、azure_min_upload_part_sizeにこの係数を乗算します。"
        }
      ]
    }
  ]}
/>

Azure Blob Storageへの単一書き込みでazure_multiply_parts_count_threshold個のパートがアップロードされるたびに、azure_min_upload_part_sizeにこの係数を乗算します。


## azure_upload_part_size_multiply_parts_count_threshold {#azure_upload_part_size_multiply_parts_count_threshold}

<SettingsInfoBlock type='UInt64' default_value='500' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "500" },
        {
          label:
            "この数のパートがAzure Blob Storageにアップロードされるたびに、azure_min_upload_part_sizeがazure_upload_part_size_multiply_factorで乗算されます。"
        }
      ]
    }
  ]}
/>

この数のパートがAzure Blob Storageにアップロードされるたびに、azure_min_upload_part_sizeがazure_upload_part_size_multiply_factorで乗算されます。


## azure_use_adaptive_timeouts {#azure_use_adaptive_timeouts}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

`true`に設定すると、すべてのAzureリクエストに対して最初の2回の試行が低い送信および受信タイムアウトで実行されます。
`false`に設定すると、すべての試行が同一のタイムアウトで実行されます。


## backup_restore_batch_size_for_keeper_multi {#backup_restore_batch_size_for_keeper_multi}

<SettingsInfoBlock type='UInt64' default_value='1000' />

バックアップまたはリストア中に[Zoo]Keeperへのマルチリクエストに使用するバッチの最大サイズ


## backup_restore_batch_size_for_keeper_multiread {#backup_restore_batch_size_for_keeper_multiread}

<SettingsInfoBlock type='UInt64' default_value='10000' />

バックアップまたはリストア中に[Zoo]Keeperへのマルチリードリクエストに使用するバッチの最大サイズ


## backup_restore_failure_after_host_disconnected_for_seconds {#backup_restore_failure_after_host_disconnected_for_seconds}

<SettingsInfoBlock type='UInt64' default_value='3600' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "3600" }, { label: "新しい設定。" }]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "3600" }, { label: "新しい設定。" }]
    }
  ]}
/>

BACKUP ON CLUSTERまたはRESTORE ON CLUSTER操作中に、ホストがこの時間内にZooKeeper内の一時的な'alive'ノードを再作成しない場合、バックアップまたはリストア全体が失敗したと見なされます。
この値は、障害発生後にホストがZooKeeperに再接続するために必要な妥当な時間よりも大きく設定する必要があります。
ゼロは無制限を意味します。


## backup_restore_finish_timeout_after_error_sec {#backup_restore_finish_timeout_after_error_sec}

<SettingsInfoBlock type='UInt64' default_value='180' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "180" }, { label: "新しい設定。" }]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "180" }, { label: "新しい設定。" }]
    }
  ]}
/>

現在の BACKUP ON CLUSTER または RESTORE ON CLUSTER 操作において、イニシエーターが他のホストの 'error' ノードへの反応と作業停止を待機する時間を指定します。


## backup_restore_keeper_fault_injection_probability {#backup_restore_keeper_fault_injection_probability}

<SettingsInfoBlock type='Float' default_value='0' />

バックアップまたはリストア中のKeeperリクエストが失敗する概算確率。有効な値は区間[0.0f, 1.0f]です


## backup_restore_keeper_fault_injection_seed {#backup_restore_keeper_fault_injection_seed}

<SettingsInfoBlock type='UInt64' default_value='0' />

0 - ランダムシード、それ以外は設定値


## backup_restore_keeper_max_retries {#backup_restore_keeper_max_retries}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "1000" },
        {
          label:
            "BACKUPまたはRESTORE操作の途中で一時的な[Zoo]Keeperの障害が発生しても、操作全体が失敗しないように十分大きな値に設定する必要があります。"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.10" },
        { label: "1000" },
        {
          label:
            "BACKUPまたはRESTORE操作の途中で一時的な[Zoo]Keeperの障害が発生しても、操作全体が失敗しないように十分大きな値に設定する必要があります。"
        }
      ]
    }
  ]}
/>

BACKUPまたはRESTORE操作の途中で実行される[Zoo]Keeper操作の最大リトライ回数。
一時的な[Zoo]Keeper障害によって操作全体が失敗しないように、十分大きな値に設定する必要があります。


## backup_restore_keeper_max_retries_while_handling_error {#backup_restore_keeper_max_retries_while_handling_error}

<SettingsInfoBlock type='UInt64' default_value='20' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "20" }, { label: "新しい設定。" }]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "20" }, { label: "新しい設定。" }]
    }
  ]}
/>

BACKUP ON CLUSTERまたはRESTORE ON CLUSTER操作のエラー処理時における[Zoo]Keeper操作の最大再試行回数。


## backup_restore_keeper_max_retries_while_initializing {#backup_restore_keeper_max_retries_while_initializing}

<SettingsInfoBlock type='UInt64' default_value='20' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "20" }, { label: "新しい設定。" }]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "20" }, { label: "新しい設定。" }]
    }
  ]}
/>

BACKUP ON CLUSTERまたはRESTORE ON CLUSTER操作の初期化時における[Zoo]Keeper操作の最大再試行回数。


## backup_restore_keeper_retry_initial_backoff_ms {#backup_restore_keeper_retry_initial_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='100' />

バックアップまたはリストア時の[Zoo]Keeper操作に対する初期バックオフタイムアウト


## backup_restore_keeper_retry_max_backoff_ms {#backup_restore_keeper_retry_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='5000' />

バックアップまたはリストア中の[Zoo]Keeper操作における最大バックオフタイムアウト


## backup_restore_keeper_value_max_size {#backup_restore_keeper_value_max_size}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

バックアップ中の[Zoo]Keeperノードのデータの最大サイズ


## backup_restore_s3_retry_attempts {#backup_restore_s3_retry_attempts}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "1000" },
        {
          label:
            "Aws::Client::RetryStrategyの設定。Aws::Client自体がリトライを実行します。0はリトライなしを意味します。バックアップ/リストア時のみ有効です。"
        }
      ]
    }
  ]}
/>

Aws::Client::RetryStrategyの設定。Aws::Client自体がリトライを実行します。0はリトライなしを意味します。バックアップ/リストア時のみ有効です。


## backup_restore_s3_retry_initial_backoff_ms {#backup_restore_s3_retry_initial_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='25' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "25" }, { label: "新しい設定" }]
    }
  ]}
/>

    バックアップおよびリストア中の最初の再試行前の初期バックオフ遅延(ミリ秒単位)。以降の再試行では、`backup_restore_s3_retry_max_backoff_ms`で指定された最大値まで遅延が指数関数的に増加します


## backup_restore_s3_retry_jitter_factor {#backup_restore_s3_retry_jitter_factor}

<SettingsInfoBlock type='Float' default_value='0.1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0.1" }, { label: "新しい設定" }]
    }
  ]}
/>

    バックアップおよびリストア操作中にAws::Client::RetryStrategyの再試行バックオフ遅延に適用されるジッター係数。計算されたバックオフ遅延は、[1.0, 1.0 + jitter]の範囲内のランダム係数で乗算され、最大値`backup_restore_s3_retry_max_backoff_ms`まで適用されます。値は[0.0, 1.0]の範囲内である必要があります


## backup_restore_s3_retry_max_backoff_ms {#backup_restore_s3_retry_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='5000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "5000" }, { label: "New setting" }]
    }
  ]}
/>

    バックアップおよびリストア操作中のリトライ間の最大遅延（ミリ秒）。


## backup_slow_all_threads_after_retryable_s3_error {#backup_slow_all_threads_after_retryable_s3_error}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新しい設定" }]
    },
    {
      id: "row-2",
      items: [{ label: "25.6" }, { label: "0" }, { label: "新しい設定" }]
    },
    {
      id: "row-3",
      items: [
        { label: "25.10" },
        { label: "0" },
        { label: "デフォルトで設定を無効化" }
      ]
    }
  ]}
/>

`true`に設定すると、いずれかのS3リクエストが'Slow Down'などの再試行可能なS3エラーに遭遇した場合、同じバックアップエンドポイントに対してS3リクエストを実行しているすべてのスレッドが減速されます。
`false`に設定すると、各スレッドは他のスレッドとは独立してS3リクエストのバックオフを処理します。


## cache_warmer_threads {#cache_warmer_threads}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='4' />

ClickHouse Cloudでのみ有効です。[cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch)が有効な場合、新しいデータパートを投機的にファイルキャッシュへダウンロードするバックグラウンドスレッドの数を指定します。無効化する場合は0を設定します。


## calculate_text_stack_trace {#calculate_text_stack_trace}

<SettingsInfoBlock type='Bool' default_value='1' />

クエリ実行中に例外が発生した場合、テキスト形式のスタックトレースを計算します。これがデフォルト設定です。シンボル検索が必要となるため、大量の不正なクエリが実行されるファジングテストでは処理速度が低下する可能性があります。通常の使用では、このオプションを無効にしないでください。


## cancel_http_readonly_queries_on_client_close {#cancel_http_readonly_queries_on_client_close}

<SettingsInfoBlock type='Bool' default_value='0' />

クライアントが応答を待たずに接続を閉じた場合、HTTP読み取り専用クエリ(例: SELECT)をキャンセルします。

Cloudのデフォルト値: `0`


## cast_ipv4_ipv6_default_on_conversion_error {#cast_ipv4_ipv6_default_on_conversion_error}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.3" },
        { label: "0" },
        {
          label:
            "cast(value, 'IPv4')関数とcast(value, 'IPv6')関数の動作をtoIPv4関数およびtoIPv6関数と同じにする"
        }
      ]
    }
  ]}
/>

IPv4へのCASTオペレータ、IPv6型へのCASTオペレータ、toIPv4関数、toIPv6関数は、変換エラー時に例外をスローせず、デフォルト値を返します。


## cast_keep_nullable {#cast_keep_nullable}

<SettingsInfoBlock type='Bool' default_value='0' />

[CAST](/sql-reference/functions/type-conversion-functions#cast)操作において`Nullable`データ型を保持するかどうかを有効化または無効化します。

この設定が有効で、`CAST`関数の引数が`Nullable`の場合、結果も`Nullable`型に変換されます。設定が無効の場合、結果は常に指定された変換先の型になります。

設定可能な値:

- 0 — `CAST`の結果は指定された変換先の型になります。
- 1 — 引数の型が`Nullable`の場合、`CAST`の結果は`Nullable(DestinationDataType)`に変換されます。

**例**

以下のクエリは変換先のデータ型そのものを返します:

```sql
SET cast_keep_nullable = 0;
SELECT CAST(toNullable(toInt32(0)) AS Int32) as x, toTypeName(x);
```

結果:

```text
┌─x─┬─toTypeName(CAST(toNullable(toInt32(0)), 'Int32'))─┐
│ 0 │ Int32                                             │
└───┴───────────────────────────────────────────────────┘
```

以下のクエリは変換先のデータ型に`Nullable`修飾子が付加された結果を返します:

```sql
SET cast_keep_nullable = 1;
SELECT CAST(toNullable(toInt32(0)) AS Int32) as x, toTypeName(x);
```

結果:

```text
┌─x─┬─toTypeName(CAST(toNullable(toInt32(0)), 'Int32'))─┐
│ 0 │ Nullable(Int32)                                   │
└───┴───────────────────────────────────────────────────┘
```

**関連項目**

- [CAST](/sql-reference/functions/type-conversion-functions#cast)関数


## cast_string_to_date_time_mode {#cast_string_to_date_time_mode}

<SettingsInfoBlock type='DateTimeInputFormat' default_value='basic' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "basic" },
        {
          label:
            "文字列からDateTimeへのキャストで異なるDateTime解析モードの使用を許可"
        }
      ]
    }
  ]}
/>

文字列からのキャスト時に、日付と時刻のテキスト表現のパーサーを選択できます。

使用可能な値:

- `'best_effort'` — 拡張解析を有効にします。

  ClickHouseは基本的な`YYYY-MM-DD HH:MM:SS`形式と、すべての[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601)日付時刻形式を解析できます。例: `'2018-06-08T01:02:03.000Z'`

- `'best_effort_us'` — `best_effort`と同様です（相違点については[parseDateTimeBestEffortUS](../../sql-reference/functions/type-conversion-functions#parsedatetimebesteffortus)を参照してください）

- `'basic'` — 基本パーサーを使用します。

  ClickHouseは基本的な`YYYY-MM-DD HH:MM:SS`または`YYYY-MM-DD`形式のみを解析できます。例: `2019-08-20 10:18:56`または`2019-08-20`

関連項目:

- [DateTime データ型](../../sql-reference/data-types/datetime.md)
- [日付と時刻を扱う関数](../../sql-reference/functions/date-time-functions.md)


## cast_string_to_dynamic_use_inference {#cast_string_to_dynamic_use_inference}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.5" },
        { label: "0" },
        {
          label:
            "パース処理によるStringからDynamicへの変換を許可する設定を追加"
        }
      ]
    }
  ]}
/>

StringからDynamicへの変換時に型推論を使用


## cast_string_to_variant_use_inference {#cast_string_to_variant_use_inference}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.4" },
        { label: "1" },
        {
          label:
            "StringからVariantへのCAST時に型推論を有効化/無効化する新しい設定"
        }
      ]
    }
  ]}
/>

StringからVariantへの変換時に型推論を使用します。


## check_query_single_value_result {#check_query_single_value_result}

<SettingsInfoBlock type='Bool' default_value='1' />

`MergeTree`ファミリーエンジンに対する[CHECK TABLE](/sql-reference/statements/check-table)クエリ結果の詳細レベルを定義します。

設定可能な値:

- 0 — クエリはテーブルの個々のデータパートごとにチェックステータスを表示します。
- 1 — クエリはテーブル全体のチェックステータスを表示します。


## check_referential_table_dependencies {#check_referential_table_dependencies}

<SettingsInfoBlock type='Bool' default_value='0' />

DDLクエリ(DROP TABLEやRENAMEなど)が参照依存関係を破壊しないかを確認します


## check_table_dependencies {#check_table_dependencies}

<SettingsInfoBlock type='Bool' default_value='1' />

DDLクエリ(DROP TABLEやRENAMEなど)が依存関係を破壊しないかを確認します


## checksum_on_read {#checksum_on_read}

<SettingsInfoBlock type='Bool' default_value='1' />

読み取り時にチェックサムを検証します。デフォルトで有効になっており、本番環境では常に有効にしておく必要があります。この設定を無効にしても利点はありません。実験やベンチマークの目的でのみ使用してください。この設定はMergeTreeファミリーのテーブルにのみ適用されます。他のテーブルエンジンやネットワーク経由でデータを受信する場合、チェックサムは常に検証されます。


## cloud_mode {#cloud_mode}

<SettingsInfoBlock type='Bool' default_value='0' />

クラウドモード


## cloud_mode_database_engine {#cloud_mode_database_engine}

<SettingsInfoBlock type='UInt64' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "1" },
        { label: "ClickHouse Cloudの設定" }
      ]
    }
  ]}
/>

Cloudで許可されるデータベースエンジン。1 - ReplicatedデータベースをDDLで使用するように書き換える、2 - SharedデータベースをDDLで使用するように書き換える


## cloud_mode_engine {#cloud_mode_engine}

<SettingsInfoBlock type='UInt64' default_value='1' />

Cloudで許可されるエンジンファミリー。

- 0 - すべて許可
- 1 - DDLを\*ReplicatedMergeTreeを使用するように書き換える
- 2 - DDLをSharedMergeTreeを使用するように書き換える
- 3 - リモートディスクが明示的に指定されている場合を除き、DDLをSharedMergeTreeを使用するように書き換える

公開部分を最小化するためのUInt64型


## cluster_for_parallel_replicas {#cluster_for_parallel_replicas}

<BetaBadge />

現在のサーバーが配置されているシャードのクラスタ


## cluster_function_process_archive_on_multiple_nodes {#cluster_function_process_archive_on_multiple_nodes}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.7" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

`true` に設定すると、クラスタ関数でのアーカイブ処理のパフォーマンスが向上します。以前のバージョンでアーカイブを使用するクラスタ関数を利用している場合は、25.7以降へのアップグレード時の互換性を保ち、エラーを回避するために `false` に設定してください。


## cluster_table_function_buckets_batch_size {#cluster_table_function_buckets_batch_size}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

`bucket`分割粒度を使用するクラスタテーブル関数のタスク分散処理において、バッチの概算サイズ(バイト単位)を定義します。システムは少なくともこの量に達するまでデータを蓄積します。実際のサイズは、データ境界に合わせるために若干大きくなる場合があります。


## cluster_table_function_split_granularity {#cluster_table_function_split_granularity}

<SettingsInfoBlock type='ObjectStorageGranularityLevel' default_value='file' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "file" }, { label: "新しい設定" }]
    }
  ]}
/>

CLUSTER TABLE FUNCTIONの実行時に、データをタスクに分割する方法を制御します。

この設定は、クラスタ全体での作業分散の粒度を定義します:

- `file` — 各タスクがファイル全体を処理します。
- `bucket` — ファイル内の内部データブロックごとにタスクが作成されます(例: Parquetの行グループ)。

より細かい粒度(`bucket`など)を選択すると、少数の大きなファイルを扱う際の並列処理性能が向上します。
例えば、Parquetファイルに複数の行グループが含まれている場合、`bucket`粒度を有効にすることで、各グループを異なるワーカーが独立して処理できるようになります。


## collect_hash_table_stats_during_aggregation {#collect_hash_table_stats_during_aggregation}

<SettingsInfoBlock type='Bool' default_value='1' />

メモリ割り当ての最適化のためにハッシュテーブル統計の収集を有効にします


## collect_hash_table_stats_during_joins {#collect_hash_table_stats_during_joins}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.7" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

メモリ割り当てを最適化するためにハッシュテーブルの統計情報収集を有効にします


## compatibility {#compatibility}

`compatibility`設定により、ClickHouseは指定された以前のバージョンのデフォルト設定を使用します。バージョンは設定値として指定します。

設定がデフォルト以外の値に設定されている場合、それらの設定が優先されます（`compatibility`設定の影響を受けるのは、変更されていない設定のみです）。

この設定は、`22.3`や`22.8`のような文字列形式のClickHouseバージョン番号を指定します。空の値は、この設定が無効であることを意味します。

デフォルトでは無効です。

:::note
ClickHouse Cloudでは、サービスレベルのデフォルト`compatibility`設定は、ClickHouse Cloudサポートによって設定される必要があります。設定を依頼するには、[サポートケースを開いて](https://clickhouse.cloud/support)ください。
ただし、`compatibility`設定は、セッション内で`SET compatibility = '22.3'`を使用したり、クエリ内で`SETTINGS compatibility = '22.3'`を使用したりするなど、標準的なClickHouseの設定メカニズムを使用して、ユーザー、ロール、プロファイル、クエリ、またはセッションレベルで上書きすることができます。
:::


## compatibility_ignore_auto_increment_in_create_table {#compatibility_ignore_auto_increment_in_create_table}

<SettingsInfoBlock type='Bool' default_value='0' />

trueの場合、カラム宣言内のAUTO_INCREMENTキーワードを無視します。それ以外の場合はエラーを返します。MySQLからの移行を簡素化します


## compatibility_ignore_collation_in_create_table {#compatibility_ignore_collation_in_create_table}

<SettingsInfoBlock type='Bool' default_value='1' />

CREATE TABLE文で照合順序を無視する互換性設定


## compile_aggregate_expressions {#compile_aggregate_expressions}

<SettingsInfoBlock type='Bool' default_value='1' />

集約関数のネイティブコードへのJITコンパイルを有効または無効にします。この設定を有効にすることで、パフォーマンスが向上する可能性があります。

設定可能な値:

- 0 — JITコンパイルを使用せずに集約が実行されます。
- 1 — JITコンパイルを使用して集約が実行されます。

**関連項目**

- [min_count_to_compile_aggregate_expression](#min_count_to_compile_aggregate_expression)


## compile_expressions {#compile_expressions}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "1" },
        {
          label:
            "JITコンパイラの基盤となるLLVMインフラストラクチャが十分に安定しているため、この設定をデフォルトで有効にしています。"
        }
      ]
    }
  ]}
/>

一部のスカラー関数と演算子をネイティブコードにコンパイルします。


## compile_sort_description {#compile_sort_description}

<SettingsInfoBlock type='Bool' default_value='1' />

ソート記述をネイティブコードにコンパイルします。


## connect_timeout {#connect_timeout}

<SettingsInfoBlock type='Seconds' default_value='10' />

レプリカが存在しない場合の接続タイムアウト。


## connect_timeout_with_failover_ms {#connect_timeout_with_failover_ms}

<SettingsInfoBlock type='Milliseconds' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "1000" },
        { label: "非同期接続に伴いデフォルト接続タイムアウトを増加" }
      ]
    }
  ]}
/>

クラスタ定義で'shard'および'replica'セクションが使用されている場合の、Distributedテーブルエンジンにおけるリモートサーバーへの接続タイムアウト(ミリ秒単位)。
接続に失敗した場合は、複数のレプリカへの接続が試行されます。


## connect_timeout_with_failover_secure_ms {#connect_timeout_with_failover_secure_ms}

<SettingsInfoBlock type='Milliseconds' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "1000" },
        {
          label:
            "非同期接続に対応するため、デフォルトのセキュア接続タイムアウトを増加"
        }
      ]
    }
  ]}
/>

最初の正常なレプリカを選択する際の接続タイムアウト（セキュア接続の場合）。


## connection_pool_max_wait_ms {#connection_pool_max_wait_ms}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

接続プールが満杯の場合に接続を待機する時間（ミリ秒単位）。

設定可能な値：

- 正の整数
- 0 — タイムアウトなし（無制限）


## connections_with_failover_max_tries {#connections_with_failover_max_tries}

<SettingsInfoBlock type='UInt64' default_value='3' />

Distributedテーブルエンジンの各レプリカに対する接続試行の最大回数。


## convert_query_to_cnf {#convert_query_to_cnf}

<SettingsInfoBlock type='Bool' default_value='0' />

`true`に設定すると、`SELECT`クエリは連言標準形(CNF)に変換されます。クエリをCNFで書き換えることで実行速度が向上する場合があります(詳細については、この[Githubイシュー](https://github.com/ClickHouse/ClickHouse/issues/11749)を参照してください)。

例えば、以下の`SELECT`クエリが変更されない様子(デフォルトの動作)を確認してください:

```sql
EXPLAIN SYNTAX
SELECT *
FROM
(
    SELECT number AS x
    FROM numbers(20)
) AS a
WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))
SETTINGS convert_query_to_cnf = false;
```

結果は次のとおりです:

```response
┌─explain────────────────────────────────────────────────────────┐
│ SELECT x                                                       │
│ FROM                                                           │
│ (                                                              │
│     SELECT number AS x                                         │
│     FROM numbers(20)                                           │
│     WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15)) │
│ ) AS a                                                         │
│ WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))     │
│ SETTINGS convert_query_to_cnf = 0                              │
└────────────────────────────────────────────────────────────────┘
```

次に、`convert_query_to_cnf`を`true`に設定して、何が変わるか見てみましょう:

```sql
EXPLAIN SYNTAX
SELECT *
FROM
(
    SELECT number AS x
    FROM numbers(20)
) AS a
WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))
SETTINGS convert_query_to_cnf = true;
```

`WHERE`句がCNFで書き換えられていますが、結果セットは同一です。ブール論理は変更されていません:

```response
┌─explain───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SELECT x                                                                                                              │
│ FROM                                                                                                                  │
│ (                                                                                                                     │
│     SELECT number AS x                                                                                                │
│     FROM numbers(20)                                                                                                  │
│     WHERE ((x <= 15) OR (x <= 5)) AND ((x <= 15) OR (x >= 1)) AND ((x >= 10) OR (x <= 5)) AND ((x >= 10) OR (x >= 1)) │
│ ) AS a                                                                                                                │
│ WHERE ((x >= 10) OR (x >= 1)) AND ((x >= 10) OR (x <= 5)) AND ((x <= 15) OR (x >= 1)) AND ((x <= 15) OR (x <= 5))     │
│ SETTINGS convert_query_to_cnf = 1                                                                                     │
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

指定可能な値: true, false


## correlated_subqueries_default_join_kind {#correlated_subqueries_default_join_kind}

<SettingsInfoBlock type='DecorrelationJoinKind' default_value='right' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "right" },
        { label: "新しい設定。非相関化クエリプランのデフォルト結合種類。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.10" },
        { label: "right" },
        { label: "新しい設定。非相関化クエリプランのデフォルト結合種類。" }
      ]
    }
  ]}
/>

非相関化クエリプランにおける結合の種類を制御します。デフォルト値は `right` で、非相関化プランではサブクエリ入力が右側に配置されたRIGHT JOINが含まれることを意味します。

設定可能な値:

- `left` - 非相関化プロセスはLEFT JOINを生成し、入力テーブルが左側に配置されます。
- `right` - 非相関化プロセスはRIGHT JOINを生成し、入力テーブルが右側に配置されます。


## correlated_subqueries_substitute_equivalent_expressions {#correlated_subqueries_substitute_equivalent_expressions}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "1" },
        { label: "相関サブクエリの計画最適化に関する新しい設定。" }
      ]
    }
  ]}
/>

CROSS JOINを作成する代わりに、フィルタ式を使用して等価な式を推論し、それらで置換します。


## count_distinct_implementation {#count_distinct_implementation}

<SettingsInfoBlock type='String' default_value='uniqExact' />

[COUNT(DISTINCT ...)](/sql-reference/aggregate-functions/reference/count) 構文の実行に使用する `uniq*` 関数を指定します。

使用可能な値:

- [uniq](/sql-reference/aggregate-functions/reference/uniq)
- [uniqCombined](/sql-reference/aggregate-functions/reference/uniqcombined)
- [uniqCombined64](/sql-reference/aggregate-functions/reference/uniqcombined64)
- [uniqHLL12](/sql-reference/aggregate-functions/reference/uniqhll12)
- [uniqExact](/sql-reference/aggregate-functions/reference/uniqexact)


## count_distinct_optimization {#count_distinct_optimization}

<SettingsInfoBlock type='Bool' default_value='0' />

COUNT DISTINCTをGROUP BYのサブクエリに書き換えます


## count_matches_stop_at_empty_match {#count_matches_stop_at_empty_match}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.6" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

`countMatches`関数において、パターンが長さゼロにマッチした時点でカウントを停止します。


## create_if_not_exists {#create_if_not_exists}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.9" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

デフォルトで`CREATE`文に対して`IF NOT EXISTS`を有効にします。この設定または`IF NOT EXISTS`のいずれかが指定されており、指定された名前のテーブルが既に存在する場合、例外はスローされません。


## create_index_ignore_unique {#create_index_ignore_unique}

<SettingsInfoBlock type='Bool' default_value='0' />

CREATE UNIQUE INDEX の UNIQUE キーワードを無視します。SQL 互換性テストのために用意されています。


## create_replicated_merge_tree_fault_injection_probability {#create_replicated_merge_tree_fault_injection_probability}

<SettingsInfoBlock type='Float' default_value='0' />

ZooKeeperでメタデータを作成した後のテーブル作成時に、フォールトインジェクションが発生する確率


## create_table_empty_primary_key_by_default {#create_table_empty_primary_key_by_default}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "1" }, { label: "ユーザビリティの向上" }]
    }
  ]}
/>

ORDER BYおよびPRIMARY KEYが指定されていない場合、空のプライマリキーを持つ\*MergeTreeテーブルの作成を許可します


## cross_join_min_bytes_to_compress {#cross_join_min_bytes_to_compress}

<SettingsInfoBlock type='UInt64' default_value='1073741824' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.5" },
        { label: "1073741824" },
        {
          label:
            "CROSS JOINで圧縮するブロックの最小サイズ。値を0にすると、この閾値が無効になります。ブロックは、2つの閾値(行数またはバイト数)のいずれかに達した時点で圧縮されます。"
        }
      ]
    }
  ]}
/>

CROSS JOINで圧縮するブロックの最小サイズ。値を0にすると、この閾値が無効になります。ブロックは、2つの閾値(行数またはバイト数)のいずれかに達した時点で圧縮されます。


## cross_join_min_rows_to_compress {#cross_join_min_rows_to_compress}

<SettingsInfoBlock type='UInt64' default_value='10000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.5" },
        { label: "10000000" },
        {
          label:
            "CROSS JOINでブロックを圧縮するための最小行数。値を0にすると、この閾値が無効になります。ブロックは、2つの閾値(行数またはバイト数)のいずれかに達した時点で圧縮されます。"
        }
      ]
    }
  ]}
/>

CROSS JOINでブロックを圧縮するための最小行数。値を0にすると、この閾値が無効になります。ブロックは、2つの閾値(行数またはバイト数)のいずれかに達した時点で圧縮されます。


## data_type_default_nullable {#data_type_default_nullable}

<SettingsInfoBlock type='Bool' default_value='0' />

カラム定義において明示的な修飾子[NULL or NOT NULL](/sql-reference/statements/create/table#null-or-not-null-modifiers)を持たないデータ型を[Nullable](/sql-reference/data-types/nullable)にします。

設定可能な値:

- 1 — カラム定義のデータ型がデフォルトで`Nullable`に設定されます。
- 0 — カラム定義のデータ型がデフォルトで`Nullable`以外に設定されます。


## database_atomic_wait_for_drop_and_detach_synchronously {#database_atomic_wait_for_drop_and_detach_synchronously}

<SettingsInfoBlock type='Bool' default_value='0' />

すべての`DROP`および`DETACH`クエリに`SYNC`修飾子を追加します。

設定可能な値:

- 0 — クエリは遅延して実行されます。
- 1 — クエリは即座に実行されます。


## database_replicated_allow_explicit_uuid {#database_replicated_allow_explicit_uuid}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        {
          label:
            "テーブルUUIDの明示的な指定を禁止する新しい設定を追加しました"
        }
      ]
    }
  ]}
/>

0 - Replicatedデータベース内のテーブルに対してUUIDを明示的に指定することを許可しない。1 - 許可する。2 - 許可するが、指定されたUUIDを無視してランダムなものを生成する。


## database_replicated_allow_heavy_create {#database_replicated_allow_heavy_create}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "0" },
        {
          label:
            "Replicatedデータベースエンジンの長時間実行されるDDLクエリ（CREATE AS SELECTおよびPOPULATE）が禁止されました"
        }
      ]
    }
  ]}
/>

Replicatedデータベースエンジンで長時間実行されるDDLクエリ（CREATE AS SELECTおよびPOPULATE）を許可します。DDLキューが長時間ブロックされる可能性があることに注意してください。


## database_replicated_allow_only_replicated_engine {#database_replicated_allow_only_replicated_engine}

<SettingsInfoBlock type='Bool' default_value='0' />

Replicatedエンジンを使用するデータベースで、Replicatedテーブルのみの作成を許可します


## database_replicated_allow_replicated_engine_arguments {#database_replicated_allow_replicated_engine_arguments}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        { label: "デフォルトでは明示的な引数を許可しない" }
      ]
    }
  ]}
/>

0 - Replicatedデータベース内の*MergeTreeテーブルに対してZooKeeperパスとレプリカ名を明示的に指定することを許可しない。1 - 許可する。2 - 許可するが、指定されたパスを無視してデフォルトを使用する。3 - 許可し、警告をログに記録しない。


## database_replicated_always_detach_permanently {#database_replicated_always_detach_permanently}

<SettingsInfoBlock type='Bool' default_value='0' />

データベースエンジンがReplicatedの場合、DETACH TABLEをDETACH TABLE PERMANENTLYとして実行します


## database_replicated_enforce_synchronous_settings {#database_replicated_enforce_synchronous_settings}

<SettingsInfoBlock type='Bool' default_value='0' />

一部のクエリに対して同期待機を強制します（database_atomic_wait_for_drop_and_detach_synchronously、mutations_sync、alter_syncも参照してください）。この設定を有効にすることは推奨されません。


## database_replicated_initial_query_timeout_sec {#database_replicated_initial_query_timeout_sec}

<SettingsInfoBlock type='UInt64' default_value='300' />

初期DDLクエリがレプリケートされたデータベースで以前のDDLキューエントリを処理するまで待機する時間を秒単位で設定します。

設定可能な値:

- 正の整数
- 0 — 無制限


## database_shared_drop_table_delay_seconds {#database_shared_drop_table_delay_seconds}

<SettingsInfoBlock type='UInt64' default_value='28800' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "28800" }, { label: "新しい設定。" }]
    }
  ]}
/>

共有データベースから削除されたテーブルが実際に削除されるまでの遅延時間(秒単位)です。この期間内であれば、`UNDROP TABLE`ステートメントを使用してテーブルを復元できます。


## decimal_check_overflow {#decimal_check_overflow}

<SettingsInfoBlock type='Bool' default_value='1' />

DECIMAL型の算術演算/比較演算のオーバーフローをチェックします


## deduplicate_blocks_in_dependent_materialized_views {#deduplicate_blocks_in_dependent_materialized_views}

<SettingsInfoBlock type='Bool' default_value='0' />

Replicated\* テーブルからデータを受け取るマテリアライズドビューに対する重複排除チェックを有効または無効にします。

設定可能な値:

      0 — 無効。
      1 — 有効。

有効にすると、ClickHouseはReplicated\* テーブルに依存するマテリアライズドビュー内のブロックに対して重複排除を実行します。
この設定は、障害により挿入操作が再試行される際に、マテリアライズドビューに重複データが含まれないようにする場合に有用です。

**関連項目**

- [IN演算子におけるNULL処理](/guides/developer/deduplicating-inserts-on-retries#insert-deduplication-with-materialized-views)


## default_materialized_view_sql_security {#default_materialized_view_sql_security}

<SettingsInfoBlock type='SQLSecurityType' default_value='DEFINER' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "DEFINER" },
        {
          label:
            "マテリアライズドビュー作成時のSQL SECURITYオプションのデフォルト値を設定可能にします"
        }
      ]
    }
  ]}
/>

マテリアライズドビュー作成時のSQL SECURITYオプションのデフォルト値を設定します。[SQL securityの詳細](../../sql-reference/statements/create/view.md/#sql_security)。

デフォルト値は`DEFINER`です。


## default_max_bytes_in_join {#default_max_bytes_in_join}

<SettingsInfoBlock type='UInt64' default_value='1000000000' />

制限が必要だが `max_bytes_in_join` が設定されていない場合の右側テーブルの最大サイズ。


## default_normal_view_sql_security {#default_normal_view_sql_security}

<SettingsInfoBlock type='SQLSecurityType' default_value='INVOKER' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "INVOKER" },
        {
          label:
            "通常のビュー作成時のデフォルト`SQL SECURITY`オプションを設定可能にします"
        }
      ]
    }
  ]}
/>

通常のビュー作成時のデフォルト`SQL SECURITY`オプションを設定します。[SQLセキュリティの詳細](../../sql-reference/statements/create/view.md/#sql_security)。

デフォルト値は`INVOKER`です。


## default_table_engine {#default_table_engine}

<SettingsInfoBlock type='DefaultTableEngine' default_value='MergeTree' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "MergeTree" },
        { label: "使いやすさ向上のためデフォルトテーブルエンジンをMergeTreeに設定" }
      ]
    }
  ]}
/>

`CREATE`文で`ENGINE`が指定されていない場合に使用するデフォルトのテーブルエンジン。

指定可能な値:

- 有効なテーブルエンジン名を表す文字列

Cloudのデフォルト値:`SharedMergeTree`

**例**

クエリ:

```sql
SET default_table_engine = 'Log';

SELECT name, value, changed FROM system.settings WHERE name = 'default_table_engine';
```

結果:

```response
┌─name─────────────────┬─value─┬─changed─┐
│ default_table_engine │ Log   │       1 │
└──────────────────────┴───────┴─────────┘
```

この例では、`Engine`を指定しない新しいテーブルはすべて`Log`テーブルエンジンを使用します:

クエリ:

```sql
CREATE TABLE my_table (
    x UInt32,
    y UInt32
);

SHOW CREATE TABLE my_table;
```

結果:

```response
┌─statement────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.my_table
(
    `x` UInt32,
    `y` UInt32
)
ENGINE = Log
└──────────────────────────────────────────────────────────────────────────┘
```


## default_temporary_table_engine {#default_temporary_table_engine}

<SettingsInfoBlock type='DefaultTableEngine' default_value='Memory' />

[default_table_engine](#default_table_engine)と同じですが、一時テーブルに適用されます。

この例では、`Engine`を指定しない新しい一時テーブルはすべて`Log`テーブルエンジンを使用します:

クエリ:

```sql
SET default_temporary_table_engine = 'Log';

CREATE TEMPORARY TABLE my_table (
    x UInt32,
    y UInt32
);

SHOW CREATE TEMPORARY TABLE my_table;
```

結果:

```response
┌─statement────────────────────────────────────────────────────────────────┐
│ CREATE TEMPORARY TABLE default.my_table
(
    `x` UInt32,
    `y` UInt32
)
ENGINE = Log
└──────────────────────────────────────────────────────────────────────────┘
```


## default_view_definer {#default_view_definer}

<SettingsInfoBlock type='String' default_value='CURRENT_USER' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "CURRENT_USER" },
        {
          label: "ビュー作成時のデフォルト`DEFINER`オプションを設定可能にします"
        }
      ]
    }
  ]}
/>

ビュー作成時のデフォルト`DEFINER`オプションを設定可能にします。[SQLセキュリティの詳細](../../sql-reference/statements/create/view.md/#sql_security)。

デフォルト値は`CURRENT_USER`です。


## delta_lake_enable_engine_predicate {#delta_lake_enable_engine_predicate}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

delta-kernelの内部データプルーニングを有効にします。


## delta_lake_enable_expression_visitor_logging {#delta_lake_enable_expression_visitor_logging}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

DeltaLake式ビジターのTestレベルログを有効にします。これらのログは、テストログとしても冗長になりすぎる可能性があります。


## delta_lake_insert_max_bytes_in_data_file {#delta_lake_insert_max_bytes_in_data_file}

<SettingsInfoBlock type='NonZeroUInt64' default_value='1073741824' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.9" },
        { label: "1073741824" },
        { label: "新しい設定。" }
      ]
    }
  ]}
/>

Delta Lakeに挿入される単一データファイルのバイト数上限を定義します。


## delta_lake_insert_max_rows_in_data_file {#delta_lake_insert_max_rows_in_data_file}

<SettingsInfoBlock type='NonZeroUInt64' default_value='1000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.9" },
        { label: "1000000" },
        { label: "新しい設定です。" }
      ]
    }
  ]}
/>

Delta Lakeに挿入される単一のデータファイルの行数上限を定義します。


## delta_lake_log_metadata {#delta_lake_log_metadata}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

Delta Lakeメタデータファイルのシステムテーブルへのログ記録を有効にします。


## delta_lake_snapshot_version {#delta_lake_snapshot_version}

<SettingsInfoBlock type='Int64' default_value='-1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "-1" }, { label: "新しい設定" }]
    }
  ]}
/>

読み取るDelta Lakeスナップショットのバージョン。値-1は最新バージョンを読み取ることを意味します（値0は有効なスナップショットバージョンです）。


## delta_lake_throw_on_engine_predicate_error {#delta_lake_throw_on_engine_predicate_error}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

delta-kernelでスキャン述語の解析時にエラーが発生した場合、例外をスローします。


## describe_compact_output {#describe_compact_output}

<SettingsInfoBlock type='Bool' default_value='0' />

trueの場合、DESCRIBEクエリの結果にカラム名と型のみを含めます


## describe_include_subcolumns {#describe_include_subcolumns}

<SettingsInfoBlock type='Bool' default_value='0' />

[DESCRIBE](../../sql-reference/statements/describe-table.md)クエリでサブカラムの記述を有効にします。例えば、[Tuple](../../sql-reference/data-types/tuple.md)のメンバーや、[Map](/sql-reference/data-types/map#reading-subcolumns-of-map)、[Nullable](../../sql-reference/data-types/nullable.md/#finding-null)、[Array](../../sql-reference/data-types/array.md/#array-size)データ型のサブカラムなどが対象となります。

設定可能な値:

- 0 — `DESCRIBE`クエリにサブカラムを含めません。
- 1 — `DESCRIBE`クエリにサブカラムを含めます。

**例**

[DESCRIBE](../../sql-reference/statements/describe-table.md)ステートメントの例を参照してください。


## describe_include_virtual_columns {#describe_include_virtual_columns}

<SettingsInfoBlock type='Bool' default_value='0' />

trueの場合、テーブルの仮想列がDESCRIBEクエリの結果に含まれます


## dialect {#dialect}

<SettingsInfoBlock type='Dialect' default_value='clickhouse' />

クエリの解析に使用するダイアレクト


## dictionary_validate_primary_key_type {#dictionary_validate_primary_key_type}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "0" },
        {
          label:
            "ディクショナリのプライマリキー型を検証します。デフォルトでは、シンプルレイアウトのID型は暗黙的にUInt64に変換されます。"
        }
      ]
    }
  ]}
/>

ディクショナリのプライマリキー型を検証します。デフォルトでは、シンプルレイアウトのID型は暗黙的にUInt64に変換されます。


## distinct_overflow_mode {#distinct_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

データ量がいずれかの制限を超えた場合の動作を設定します。

設定可能な値:

- `throw`: 例外をスローします（デフォルト）。
- `break`: クエリの実行を停止し、ソースデータが尽きた場合と同様に部分的な結果を返します。


## distributed_aggregation_memory_efficient {#distributed_aggregation_memory_efficient}

<SettingsInfoBlock type='Bool' default_value='1' />

分散集約のメモリ節約モードが有効になっているかどうか。


## distributed_background_insert_batch {#distributed_background_insert_batch}

**エイリアス**: `distributed_directory_monitor_batch_inserts`

<SettingsInfoBlock type='Bool' default_value='0' />

挿入データのバッチ送信を有効化/無効化します。

バッチ送信が有効な場合、[Distributed](../../engines/table-engines/special/distributed.md) テーブルエンジンは、挿入データの複数のファイルを個別に送信するのではなく、1回の操作でまとめて送信しようとします。バッチ送信により、サーバーとネットワークリソースをより効率的に活用することで、クラスタのパフォーマンスが向上します。

設定可能な値:

- 1 — 有効。
- 0 — 無効。


## distributed_background_insert_max_sleep_time_ms {#distributed_background_insert_max_sleep_time_ms}

**エイリアス**: `distributed_directory_monitor_max_sleep_time_ms`

<SettingsInfoBlock type='Milliseconds' default_value='30000' />

[Distributed](../../engines/table-engines/special/distributed.md)テーブルエンジンがデータを送信する際の最大間隔。[distributed_background_insert_sleep_time_ms](#distributed_background_insert_sleep_time_ms)設定で設定された間隔の指数関数的増加を制限します。

設定可能な値:

- ミリ秒単位の正の整数


## distributed_background_insert_sleep_time_ms {#distributed_background_insert_sleep_time_ms}

**エイリアス**: `distributed_directory_monitor_sleep_time_ms`

<SettingsInfoBlock type='Milliseconds' default_value='100' />

[Distributed](../../engines/table-engines/special/distributed.md)テーブルエンジンがデータを送信する基本間隔。エラーが発生した場合、実際の間隔は指数関数的に増加します。

設定可能な値:

- ミリ秒単位の正の整数


## distributed_background_insert_split_batch_on_failure {#distributed_background_insert_split_batch_on_failure}

**エイリアス**: `distributed_directory_monitor_split_batch_on_failure`

<SettingsInfoBlock type='Bool' default_value='0' />

失敗時のバッチ分割を有効化/無効化します。

特定のバッチをリモートシャードに送信する際、後続の複雑なパイプライン(例: `GROUP BY`を含む`MATERIALIZED VIEW`)により`Memory limit exceeded`などのエラーが発生して失敗することがあります。この場合、リトライしても効果がなく(テーブルの分散送信が停止します)、そのバッチからファイルを1つずつ送信することでINSERTが成功する可能性があります。

この設定を`1`にすると、このようなバッチに対してバッチ処理が無効化されます(つまり、失敗したバッチに対して`distributed_background_insert_batch`が一時的に無効化されます)。

設定可能な値:

- 1 — 有効。
- 0 — 無効。

:::note
この設定は、異常なサーバー(マシン)終了および[Distributed](../../engines/table-engines/special/distributed.md)テーブルエンジンに対する`fsync_after_insert`/`fsync_directories`の未設定により発生する可能性のある破損したバッチにも影響します。
:::

:::note
自動バッチ分割に依存すべきではありません。パフォーマンスに悪影響を及ぼす可能性があるためです。
:::


## distributed_background_insert_timeout {#distributed_background_insert_timeout}

**エイリアス**: `insert_distributed_timeout`

<SettingsInfoBlock type='UInt64' default_value='0' />

分散テーブルへの挿入クエリのタイムアウト。この設定は insert_distributed_sync が有効な場合にのみ使用されます。値が0の場合、タイムアウトは設定されません。


## distributed_cache_alignment {#distributed_cache_alignment}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "0" },
        { label: "distributed_cache_read_alignmentから名称変更" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。テスト目的の設定のため、変更しないでください


## distributed_cache_bypass_connection_pool {#distributed_cache_bypass_connection_pool}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "ClickHouse Cloudの設定" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュ接続プールのバイパスを許可します


## distributed_cache_connect_backoff_max_ms {#distributed_cache_connect_backoff_max_ms}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='50' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "50" }, { label: "新しい設定" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュ接続作成時の最大バックオフ時間(ミリ秒)。


## distributed_cache_connect_backoff_min_ms {#distributed_cache_connect_backoff_min_ms}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新規設定" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュ接続作成時の最小バックオフ時間（ミリ秒）。


## distributed_cache_connect_max_tries {#distributed_cache_connect_max_tries}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='5' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "5" },
        { label: "設定値を変更" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "25.1" }, { label: "20" }, { label: "Cloudのみ" }]
    },
    {
      id: "row-3",
      items: [
        { label: "24.10" },
        { label: "20" },
        { label: "ClickHouse Cloud用の設定" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュへの接続に失敗した場合の再試行回数


## distributed_cache_connect_timeout_ms {#distributed_cache_connect_timeout_ms}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='50' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "50" }, { label: "New setting" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュサーバーへの接続時の接続タイムアウト。


## distributed_cache_credentials_refresh_period_seconds {#distributed_cache_credentials_refresh_period_seconds}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='5' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "5" },
        { label: "新しいプライベート設定" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。認証情報の更新間隔を指定します。


## distributed_cache_data_packet_ack_window {#distributed_cache_data_packet_ack_window}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='5' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "5" },
        { label: "ClickHouse Cloudの設定" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。単一の分散キャッシュ読み取りリクエストにおけるDataPacketシーケンスのACK送信ウィンドウ


## distributed_cache_discard_connection_if_unread_data {#distributed_cache_discard_connection_if_unread_data}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "1" }, { label: "New setting" }]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "1" }, { label: "New setting" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。未読データが残っている場合、接続を破棄します。


## distributed_cache_fetch_metrics_only_from_current_az {#distributed_cache_fetch_metrics_only_from_current_az}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "1" },
        { label: "ClickHouse Cloud用の設定" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。system.distributed_cache_metrics、system.distributed_cache_eventsにおいて、現在のアベイラビリティゾーンからのみメトリクスを取得します


## distributed_cache_log_mode {#distributed_cache_log_mode}

<CloudOnlyBadge />

<SettingsInfoBlock type='DistributedCacheLogMode' default_value='on_error' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "on_error" },
        { label: "ClickHouse Cloud の設定" }
      ]
    }
  ]}
/>

ClickHouse Cloud でのみ有効です。system.distributed_cache_log への書き込みモードを指定します。


## distributed_cache_max_unacked_inflight_packets {#distributed_cache_max_unacked_inflight_packets}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "10" },
        { label: "ClickHouse Cloud の設定" }
      ]
    }
  ]}
/>

ClickHouse Cloud でのみ有効です。単一の分散キャッシュ読み取りリクエストにおける未確認インフライトパケットの最大数


## distributed_cache_min_bytes_for_seek {#distributed_cache_min_bytes_for_seek}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "0" },
        { label: "新しいプライベート設定。" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュでシーク操作を実行するための最小バイト数。


## distributed_cache_pool_behaviour_on_limit {#distributed_cache_pool_behaviour_on_limit}

<CloudOnlyBadge />

<SettingsInfoBlock
  type='DistributedCachePoolBehaviourOnLimit'
  default_value='wait'
/>

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "wait" }, { label: "Cloud only" }]
    },
    {
      id: "row-2",
      items: [
        { label: "24.10" },
        { label: "allocate_bypassing_pool" },
        { label: "A setting for ClickHouse Cloud" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。プール制限に達した場合の分散キャッシュ接続の動作を識別します


## distributed_cache_prefer_bigger_buffer_size {#distributed_cache_prefer_bigger_buffer_size}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新しい設定です。" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。filesystem_cache_prefer_bigger_buffer_sizeと同じですが、分散キャッシュに適用されます。


## distributed_cache_read_only_from_current_az {#distributed_cache_read_only_from_current_az}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。現在のアベイラビリティゾーンからのみ読み取りを許可します。無効にした場合、すべてのアベイラビリティゾーンのすべてのキャッシュサーバーから読み取ります。


## distributed_cache_read_request_max_tries {#distributed_cache_read_request_max_tries}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "10" },
        { label: "設定値を変更" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "25.4" }, { label: "20" }, { label: "新規設定" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュリクエストが失敗した場合の再試行回数


## distributed_cache_receive_response_wait_milliseconds {#distributed_cache_receive_response_wait_milliseconds}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='60000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "60000" },
        { label: "ClickHouse Cloudの設定" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュからリクエストに対するデータを受信するまでの待機時間(ミリ秒単位)


## distributed_cache_receive_timeout_milliseconds {#distributed_cache_receive_timeout_milliseconds}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='10000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "10000" },
        { label: "ClickHouse Cloudの設定" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュからの応答を受信するまでの待機時間(ミリ秒)


## distributed_cache_receive_timeout_ms {#distributed_cache_receive_timeout_ms}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='3000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "3000" }, { label: "新しい設定" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュサーバーからデータを受信する際のタイムアウト時間をミリ秒単位で指定します。この時間内にバイトが受信されなかった場合、例外がスローされます。


## distributed_cache_send_timeout_ms {#distributed_cache_send_timeout_ms}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='3000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "3000" }, { label: "新しい設定" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュサーバーへのデータ送信タイムアウトをミリ秒単位で設定します。クライアントがデータを送信する必要があるものの、この時間内に1バイトも送信できない場合、例外がスローされます。


## distributed_cache_tcp_keep_alive_timeout_ms {#distributed_cache_tcp_keep_alive_timeout_ms}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='2900' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "2900" }, { label: "新しい設定" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。TCPがキープアライブプローブの送信を開始する前に、分散キャッシュサーバーへの接続がアイドル状態を維持する必要がある時間をミリ秒単位で指定します。


## distributed_cache_throw_on_error {#distributed_cache_throw_on_error}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "ClickHouse Cloudの設定" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュとの通信中に発生した例外、または分散キャッシュから受信した例外を再スローします。それ以外の場合、エラー発生時には分散キャッシュをスキップするようフォールバックします


## distributed_cache_wait_connection_from_pool_milliseconds {#distributed_cache_wait_connection_from_pool_milliseconds}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='100' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "100" },
        { label: "ClickHouse Cloudの設定" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。distributed_cache_pool_behaviour_on_limitがwaitに設定されている場合、接続プールから接続を取得するまでの待機時間(ミリ秒単位)を指定します


## distributed_connections_pool_size {#distributed_connections_pool_size}

<SettingsInfoBlock type='UInt64' default_value='1024' />

単一のDistributedテーブルへのすべてのクエリを分散処理する際の、リモートサーバーとの同時接続数の上限です。クラスタ内のサーバー数以上の値に設定することを推奨します。


## distributed_ddl_entry_format_version {#distributed_ddl_entry_format_version}

<SettingsInfoBlock type='UInt64' default_value='5' />

分散DDL（ON CLUSTER）クエリの互換バージョン


## distributed_ddl_output_mode {#distributed_ddl_output_mode}

<SettingsInfoBlock type='DistributedDDLOutputMode' default_value='throw' />

分散DDLクエリの結果フォーマットを設定します。

設定可能な値:

- `throw` — クエリが完了したすべてのホストについて、クエリ実行ステータスを含む結果セットを返します。一部のホストでクエリが失敗した場合は、最初の例外を再スローします。一部のホストでクエリがまだ完了しておらず、[distributed_ddl_task_timeout](#distributed_ddl_task_timeout)を超過した場合は、`TIMEOUT_EXCEEDED`例外をスローします。
- `none` — `throw`と同様ですが、分散DDLクエリは結果セットを返しません。
- `null_status_on_timeout` — 対応するホストでクエリが完了していない場合、`TIMEOUT_EXCEEDED`をスローする代わりに、結果セットの一部の行の実行ステータスとして`NULL`を返します。
- `never_throw` — 一部のホストでクエリが失敗した場合でも、`TIMEOUT_EXCEEDED`をスローせず、例外を再スローしません。
- `none_only_active` - `none`と同様ですが、`Replicated`データベースの非アクティブなレプリカを待機しません。注意: このモードでは、一部のレプリカでクエリが実行されず、バックグラウンドで実行されることを判別できません。
- `null_status_on_timeout_only_active` — `null_status_on_timeout`と同様ですが、`Replicated`データベースの非アクティブなレプリカを待機しません
- `throw_only_active` — `throw`と同様ですが、`Replicated`データベースの非アクティブなレプリカを待機しません

Cloudのデフォルト値: `throw`


## distributed_ddl_task_timeout {#distributed_ddl_task_timeout}

<SettingsInfoBlock type='Int64' default_value='180' />

クラスタ内のすべてのホストからのDDLクエリ応答のタイムアウトを設定します。すべてのホストでDDLリクエストが実行されていない場合、応答にはタイムアウトエラーが含まれ、リクエストは非同期モードで実行されます。負の値は無限を意味します。

設定可能な値:

- 正の整数。
- 0 — 非同期モード。
- 負の整数 — 無限タイムアウト。


## distributed_foreground_insert {#distributed_foreground_insert}

**エイリアス**: `insert_distributed_sync`

<SettingsInfoBlock type='Bool' default_value='0' />

[Distributed](/engines/table-engines/special/distributed)テーブルへの同期データ挿入を有効または無効にします。

デフォルトでは、`Distributed`テーブルにデータを挿入する際、ClickHouseサーバーはバックグラウンドモードでクラスターノードにデータを送信します。`distributed_foreground_insert=1`の場合、データは同期的に処理され、すべてのシャードにデータが保存された後にのみ`INSERT`操作が成功します（`internal_replication`がtrueの場合は各シャードに少なくとも1つのレプリカ）。

設定可能な値:

- `0` — データはバックグラウンドモードで挿入されます。
- `1` — データは同期モードで挿入されます。

Cloudのデフォルト値: `0`

**関連項目**

- [Distributedテーブルエンジン](/engines/table-engines/special/distributed)
- [Distributedテーブルの管理](/sql-reference/statements/system#managing-distributed-tables)


## distributed_group_by_no_merge {#distributed_group_by_no_merge}

<SettingsInfoBlock type='UInt64' default_value='0' />

分散クエリ処理において、異なるサーバーからの集約状態をマージしません。異なるシャードに異なるキーが存在することが確実な場合に使用できます。

設定可能な値:

- `0` — 無効（最終的なクエリ処理はイニシエーターノードで実行されます）。
- `1` - 分散クエリ処理において、異なるサーバーからの集約状態をマージしません（クエリはシャードで完全に処理され、イニシエーターはデータのプロキシのみを行います）。異なるシャードに異なるキーが存在することが確実な場合に使用できます。
- `2` - `1`と同様ですが、イニシエーターで`ORDER BY`と`LIMIT`を適用します（`distributed_group_by_no_merge=1`のようにクエリがリモートノードで完全に処理される場合は不可能です）。`ORDER BY`や`LIMIT`を含むクエリに使用できます。

**例**

```sql
SELECT *
FROM remote('127.0.0.{2,3}', system.one)
GROUP BY dummy
LIMIT 1
SETTINGS distributed_group_by_no_merge = 1
FORMAT PrettyCompactMonoBlock

┌─dummy─┐
│     0 │
│     0 │
└───────┘
```

```sql
SELECT *
FROM remote('127.0.0.{2,3}', system.one)
GROUP BY dummy
LIMIT 1
SETTINGS distributed_group_by_no_merge = 2
FORMAT PrettyCompactMonoBlock

┌─dummy─┐
│     0 │
└───────┘
```


## distributed_insert_skip_read_only_replicas {#distributed_insert_skip_read_only_replicas}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        {
          label: "trueの場合、DistributedへのINSERTで読み取り専用レプリカをスキップします"
        }
      ]
    }
  ]}
/>

DistributedテーブルへのINSERTクエリで読み取り専用レプリカをスキップする機能を有効にします。

設定可能な値:

- 0 — 通常通りINSERTが実行されます。読み取り専用レプリカに送信される場合は失敗します
- 1 — イニシエーターはシャードにデータを送信する前に読み取り専用レプリカをスキップします。


## distributed_plan_default_reader_bucket_count {#distributed_plan_default_reader_bucket_count}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='8' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "8" },
        { label: "新しい実験的な設定です。" }
      ]
    }
  ]}
/>

分散クエリにおける並列読み取りのデフォルトタスク数です。タスクはレプリカ間に分散されます。


## distributed_plan_default_shuffle_join_bucket_count {#distributed_plan_default_shuffle_join_bucket_count}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='8' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "8" },
        { label: "新しい実験的な設定。" }
      ]
    }
  ]}
/>

分散シャッフルハッシュ結合のデフォルトのバケット数。


## distributed_plan_execute_locally {#distributed_plan_execute_locally}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "新しい実験的な設定です。" }
      ]
    }
  ]}
/>

分散クエリプランのすべてのタスクをローカルで実行します。テストおよびデバッグに役立ちます。


## distributed_plan_force_exchange_kind {#distributed_plan_force_exchange_kind}

<ExperimentalBadge />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "" },
        { label: "新しい実験的設定。" }
      ]
    }
  ]}
/>

分散クエリステージ間で使用するExchange演算子の種類を強制指定します。

指定可能な値:

- '' - Exchange演算子の種類を強制せず、オプティマイザに選択を任せます。
- 'Persisted' - オブジェクトストレージ内の一時ファイルを使用します。
- 'Streaming' - ネットワーク経由でExchangeデータをストリーミングします。


## distributed_plan_force_shuffle_aggregation {#distributed_plan_force_shuffle_aggregation}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "0" },
        { label: "新しい実験的な設定" }
      ]
    }
  ]}
/>

分散クエリプランにおいて、PartialAggregation + Merge の代わりに Shuffle 集約戦略を使用します。


## distributed_plan_max_rows_to_broadcast {#distributed_plan_max_rows_to_broadcast}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='20000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "20000" },
        { label: "新しい実験的な設定。" }
      ]
    }
  ]}
/>

分散クエリプランにおいて、シャッフル結合ではなくブロードキャスト結合を使用する最大行数。


## distributed_plan_optimize_exchanges {#distributed_plan_optimize_exchanges}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "1" },
        { label: "新しい実験的な設定。" }
      ]
    }
  ]}
/>

分散クエリプランにおける不要なデータ交換を削除します。デバッグ時には無効化してください。


## distributed_product_mode {#distributed_product_mode}

<SettingsInfoBlock type='DistributedProductMode' default_value='deny' />

[分散サブクエリ](../../sql-reference/operators/in.md)の動作を変更します。

ClickHouseは、クエリが分散テーブルの積を含む場合、つまり分散テーブルに対するクエリが分散テーブルに対する非GLOBALサブクエリを含む場合に、この設定を適用します。

制限事項:

- INおよびJOINサブクエリにのみ適用されます。
- FROM句が複数のシャードを含む分散テーブルを使用する場合のみ。
- サブクエリが複数のシャードを含む分散テーブルを対象とする場合。
- テーブル値[remote](../../sql-reference/table-functions/remote.md)関数には使用されません。

設定可能な値:

- `deny` — デフォルト値。これらのタイプのサブクエリの使用を禁止します("Double-distributed in/JOIN subqueries is denied"例外を返します)。
- `local` — サブクエリ内のデータベースとテーブルを宛先サーバー(シャード)のローカルなものに置き換え、通常の`IN`/`JOIN`を維持します。
- `global` — `IN`/`JOIN`クエリを`GLOBAL IN`/`GLOBAL JOIN`に置き換えます。
- `allow` — これらのタイプのサブクエリの使用を許可します。


## distributed_push_down_limit {#distributed_push_down_limit}

<SettingsInfoBlock type='UInt64' default_value='1' />

各シャードに対して個別に[LIMIT](#limit)を適用するかどうかを有効化または無効化します。

これにより以下を回避できます:

- ネットワーク経由での余分な行の送信
- イニシエーターでの制限を超えた行の処理

バージョン21.9以降では、`distributed_push_down_limit`は以下の条件のうち少なくとも1つが満たされる場合にのみクエリ実行を変更するため、不正確な結果が得られることはなくなりました:

- [distributed_group_by_no_merge](#distributed_group_by_no_merge) > 0の場合
- クエリが`GROUP BY`/`DISTINCT`/`LIMIT BY`を**持たず**、`ORDER BY`/`LIMIT`を持つ場合
- クエリが`GROUP BY`/`DISTINCT`/`LIMIT BY`を`ORDER BY`/`LIMIT`とともに**持ち**、かつ以下のいずれかが該当する場合:
  - [optimize_skip_unused_shards](#optimize_skip_unused_shards)が有効化されている
  - [optimize_distributed_group_by_sharding_key](#optimize_distributed_group_by_sharding_key)が有効化されている

設定可能な値:

- 0 — 無効
- 1 — 有効

関連項目:

- [distributed_group_by_no_merge](#distributed_group_by_no_merge)
- [optimize_skip_unused_shards](#optimize_skip_unused_shards)
- [optimize_distributed_group_by_sharding_key](#optimize_distributed_group_by_sharding_key)


## distributed_replica_error_cap {#distributed_replica_error_cap}

<SettingsInfoBlock type='UInt64' default_value='1000' />

- 型: 符号なし整数
- デフォルト値: 1000

各レプリカのエラー数はこの値で上限が設定され、単一のレプリカが過度にエラーを蓄積することを防ぎます。

関連項目:

- [load_balancing](#load_balancing-round_robin)
- [Distributedテーブルエンジン](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_half_life](#distributed_replica_error_half_life)
- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)


## distributed_replica_error_half_life {#distributed_replica_error_half_life}

<SettingsInfoBlock type='Seconds' default_value='60' />

- Type: seconds
- Default value: 60 seconds

分散テーブルにおけるエラーがゼロにリセットされる速度を制御します。レプリカが一定時間利用できない状態で5つのエラーが蓄積され、distributed_replica_error_half_lifeが1秒に設定されている場合、最後のエラーから3秒後にそのレプリカは正常とみなされます。

関連項目:

- [load_balancing](#load_balancing-round_robin)
- [Distributedテーブルエンジン](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_cap](#distributed_replica_error_cap)
- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)


## distributed_replica_max_ignored_errors {#distributed_replica_max_ignored_errors}

<SettingsInfoBlock type='UInt64' default_value='0' />

- 型: 符号なし整数
- デフォルト値: 0

レプリカ選択時に無視されるエラーの数（`load_balancing`アルゴリズムに基づく）。

関連項目:

- [load_balancing](#load_balancing-round_robin)
- [テーブルエンジン Distributed](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_cap](#distributed_replica_error_cap)
- [distributed_replica_error_half_life](#distributed_replica_error_half_life)


## do_not_merge_across_partitions_select_final {#do_not_merge_across_partitions_select_final}

<SettingsInfoBlock type='Bool' default_value='0' />

SELECT FINAL において、単一のパーティション内でのみパーツをマージします


## empty_result_for_aggregation_by_constant_keys_on_empty_set {#empty_result_for_aggregation_by_constant_keys_on_empty_set}

<SettingsInfoBlock type='Bool' default_value='1' />

空のセットに対して定数キーで集計する場合、空の結果を返します。


## empty_result_for_aggregation_by_empty_set {#empty_result_for_aggregation_by_empty_set}

<SettingsInfoBlock type='Bool' default_value='0' />

空のセットに対してキーなしで集計する場合に、空の結果を返します。


## enable_adaptive_memory_spill_scheduler {#enable_adaptive_memory_spill_scheduler}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.2" },
        { label: "0" },
        {
          label:
            "新しい設定。メモリデータを外部ストレージへ適応的にスピルすることを有効にします。"
        }
      ]
    }
  ]}
/>

プロセッサが外部ストレージへデータを適応的にスピルするようトリガーします。現在、grace joinがサポートされています。


## enable_add_distinct_to_in_subqueries {#enable_add_distinct_to_in_subqueries}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "0" },
        {
          label:
            "分散INサブクエリで転送される一時テーブルのサイズを削減するための新しい設定"
        }
      ]
    }
  ]}
/>

`IN`サブクエリで`DISTINCT`を有効にします。これはトレードオフの設定です。有効にすると、一意の値のみが送信されるようになるため、分散`IN`サブクエリで転送される一時テーブルのサイズを大幅に削減し、シャード間のデータ転送を大幅に高速化できます。
ただし、この設定を有効にすると、重複排除(DISTINCT)を実行する必要があるため、各ノードで追加のマージ処理が発生します。ネットワーク転送がボトルネックであり、追加のマージコストが許容できる場合にこの設定を使用してください。


## enable_blob_storage_log {#enable_blob_storage_log}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "1" },
        {
          label:
            "Blobストレージ操作に関する情報を system.blob_storage_log テーブルに書き込みます"
        }
      ]
    }
  ]}
/>

Blobストレージ操作に関する情報を system.blob_storage_log テーブルに書き込みます


## enable_deflate_qpl_codec {#enable_deflate_qpl_codec}

<SettingsInfoBlock type='Bool' default_value='0' />

有効にすると、DEFLATE_QPL コーデックを使用してカラムを圧縮できます。


## enable_early_constant_folding {#enable_early_constant_folding}

<SettingsInfoBlock type='Bool' default_value='1' />

関数とサブクエリの結果を解析し、定数が含まれている場合にクエリを書き換えるクエリ最適化を有効にします


## enable_extended_results_for_datetime_functions {#enable_extended_results_for_datetime_functions}

<SettingsInfoBlock type='Bool' default_value='0' />

`Date`型と比較して拡張範囲を持つ`Date32`型、または`DateTime`型と比較して拡張範囲を持つ`DateTime64`型の結果を返すかどうかを有効化または無効化します。

設定可能な値:

- `0` — すべての引数型に対して、関数は`Date`または`DateTime`を返します。
- `1` — `Date32`または`DateTime64`の引数に対しては`Date32`または`DateTime64`を返し、それ以外の場合は`Date`または`DateTime`を返します。

以下の表は、各種日付時刻関数におけるこの設定の動作を示しています。


| 関数                        | `enable_extended_results_for_datetime_functions = 0`          | `enable_extended_results_for_datetime_functions = 1`                                                                   |
| ------------------------- | ------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------- |
| `toStartOfYear`           | `Date` または `DateTime` を返します                                   | `Date`/`DateTime` を入力として受け取り、`Date`/`DateTime` を返す<br />`Date32`/`DateTime64` を入力として受け取り、`Date32`/`DateTime64` を返す     |
| `toStartOfISOYear`        | `Date` または `DateTime` 型を返します                                  | `Date`/`DateTime` 型の入力に対して `Date`/`DateTime` を返します<br />`Date32`/`DateTime64` 型の入力に対して `Date32`/`DateTime64` を返します     |
| `toStartOfQuarter`        | `Date` または `DateTime` を返します                                   | `Date`/`DateTime` 型の入力に対しては `Date`/`DateTime` 型を返します<br />`Date32`/`DateTime64` 型の入力に対しては `Date32`/`DateTime64` 型を返します |
| `toStartOfMonth`          | `Date` または `DateTime` を返します                                   | `Date`/`DateTime` 型の入力に対して `Date`/`DateTime` を返します<br />`Date32`/`DateTime64` 型の入力に対して `Date32`/`DateTime64` を返します     |
| `toStartOfWeek`           | `Date` または `DateTime` を返します                                   | `Date`/`DateTime` 型の入力に対しては `Date`/`DateTime` を返します<br />`Date32`/`DateTime64` 型の入力に対しては `Date32`/`DateTime64` を返します   |
| `toLastDayOfWeek`         | `Date` または `DateTime` を返します                                   | `Date`/`DateTime` 型の入力に対しては `Date`/`DateTime` を返す<br />`Date32`/`DateTime64` 型の入力に対しては `Date32`/`DateTime64` を返す       |
| `toLastDayOfMonth`        | `Date` または `DateTime` を返します                                   | `Date`/`DateTime` 型の入力の場合は `Date`/`DateTime` を返します。<br />`Date32`/`DateTime64` 型の入力の場合は `Date32`/`DateTime64` を返します。   |
| `toMonday`                | `Date` または `DateTime` を返します                                   | `Date`/`DateTime` 型の入力に対しては `Date`/`DateTime` を返します<br />`Date32`/`DateTime64` 型の入力に対しては `Date32`/`DateTime64` を返します   |
| `toStartOfDay`            | `DateTime` を返す<br />*注: 1970 年から 2149 年の範囲外の値では誤った結果になります*    | `Date`/`DateTime` 型の入力に対して `DateTime` を返します<br />`Date32`/`DateTime64` 型の入力に対して `DateTime64` を返します                     |
| `toStartOfHour`           | `DateTime` を返す<br />*注意: 1970 年から 2149 年の範囲外の値では誤った結果が返されます*  | `Date`/`DateTime` 型の入力に対しては `DateTime` を返す<br />`Date32`/`DateTime64` 型の入力に対しては `DateTime64` を返す                       |
| `toStartOfFifteenMinutes` | Returns `DateTime`<br />*注意: 1970〜2149 の範囲外の値に対しては誤った結果を返します* | `Date`/`DateTime` 型の入力には `DateTime` を返す<br />`Date32`/`DateTime64` 型の入力には `DateTime64` を返す                             |
| `toStartOfTenMinutes`     | `DateTime` を返す<br />*注意: 1970〜2149年の範囲外の値に対しては誤った結果になります*     | `Date`/`DateTime` 入力に対しては `DateTime` を返します<br />`Date32`/`DateTime64` 入力に対しては `DateTime64` を返します                       |
| `toStartOfFiveMinutes`    | `DateTime` を返します<br />*注: 1970〜2149 年の範囲外の値では誤った結果になります*      | `Date`/`DateTime` 型の入力に対しては `DateTime` を返す<br />`Date32`/`DateTime64` 型の入力に対しては `DateTime64` を返す                       |
| `toStartOfMinute`         | `DateTime` を返します<br />*注: 1970〜2149年の範囲外の値では誤った結果を返す可能性があります* | `Date`/`DateTime` 型の入力に対しては `DateTime` を返します<br />`Date32`/`DateTime64` 型の入力に対しては `DateTime64` を返します                   |
| `timeSlot`                | `DateTime` を返します<br />*注意: 1970〜2149 年の範囲外の値では誤った結果になります*     | `Date`/`DateTime` 型の入力に対しては `DateTime` を返します<br />`Date32`/`DateTime64` 型の入力に対しては `DateTime64` を返します                   |





## enable_filesystem_cache {#enable_filesystem_cache}

<SettingsInfoBlock type='Bool' default_value='1' />

リモートファイルシステムのキャッシュを使用します。この設定はディスクのキャッシュのオン/オフを切り替えるものではなく(ディスク設定で行う必要があります)、必要に応じて特定のクエリでキャッシュをバイパスできるようにします


## enable_filesystem_cache_log {#enable_filesystem_cache_log}

<SettingsInfoBlock type='Bool' default_value='0' />

各クエリのファイルシステムキャッシュログの記録を有効にします


## enable_filesystem_cache_on_write_operations {#enable_filesystem_cache_on_write_operations}

<SettingsInfoBlock type='Bool' default_value='0' />

`write-through`キャッシュを有効または無効にします。`false`に設定した場合、書き込み操作時に`write-through`キャッシュが無効になります。`true`に設定した場合、サーバー設定のキャッシュディスク構成セクションで`cache_on_write_operations`が有効になっていれば、`write-through`キャッシュが有効になります。
詳細については、[「ローカルキャッシュの使用」](/operations/storing-data#using-local-cache)を参照してください。


## enable_filesystem_read_prefetches_log {#enable_filesystem_read_prefetches_log}

<SettingsInfoBlock type='Bool' default_value='0' />

クエリ実行中に system.filesystem_prefetch_log へログを記録します。テストまたはデバッグ目的でのみ使用すべきであり、デフォルトで有効にすることは推奨されません


## enable_global_with_statement {#enable_global_with_statement}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.2" },
        { label: "1" },
        {
          label:
            "WITH文をUNIONクエリおよびすべてのサブクエリにデフォルトで伝播します"
        }
      ]
    }
  ]}
/>

WITH文をUNIONクエリおよびすべてのサブクエリに伝播します


## enable_hdfs_pread {#enable_hdfs_pread}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "1" }, { label: "新しい設定。" }]
    }
  ]}
/>

HDFSファイルに対するpreadの有効化または無効化を設定します。デフォルトでは`hdfsPread`が使用されます。無効化した場合、HDFSファイルの読み取りには`hdfsRead`と`hdfsSeek`が使用されます。


## enable_http_compression {#enable_http_compression}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.10" },
        { label: "1" },
        { label: "一般的に有益です" }
      ]
    }
  ]}
/>

HTTPリクエストに対するレスポンスでのデータ圧縮を有効または無効にします。

詳細については、[HTTPインターフェースの説明](../../interfaces/http.md)を参照してください。

設定可能な値:

- 0 — 無効。
- 1 — 有効。


## enable_job_stack_trace {#enable_job_stack_trace}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "0" },
        {
          label:
            "パフォーマンスのオーバーヘッドを避けるため、この設定はデフォルトで無効化されました。"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.11" },
        { label: "0" },
        {
          label:
            "ジョブのスケジューリングからスタックトレースの収集を有効にします。パフォーマンスのオーバーヘッドを避けるため、デフォルトでは無効になっています。"
        }
      ]
    }
  ]}
/>

ジョブが例外を発生させた際に、ジョブ作成者のスタックトレースを出力します。パフォーマンスのオーバーヘッドを避けるため、デフォルトでは無効になっています。


## enable_join_runtime_filters {#enable_join_runtime_filters}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "New setting" }]
    }
  ]}
/>

実行時に右側から収集したJOINキーのセットで左側をフィルタリングします。


## enable_lazy_columns_replication {#enable_lazy_columns_replication}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1" },
        {
          label:
            "JOINおよびARRAY JOINにおける遅延カラム複製をデフォルトで有効化"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.10" },
        { label: "0" },
        {
          label:
            "JOINおよびARRAY JOINにおける遅延カラム複製を有効化する設定を追加"
        }
      ]
    }
  ]}
/>

JOINおよびARRAY JOINにおける遅延カラム複製を有効化します。これにより、メモリ内で同一行の不要な複数回コピーを回避できます。


## enable_lightweight_delete {#enable_lightweight_delete}

**エイリアス**: `allow_experimental_lightweight_delete`

<SettingsInfoBlock type='Bool' default_value='1' />

MergeTreeテーブルの軽量DELETE変更を有効にします。


## enable_lightweight_update {#enable_lightweight_update}

<BetaBadge />

**エイリアス**: `allow_experimental_lightweight_update`

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "1" },
        {
          label:
            "軽量アップデートがベータ版に移行しました。設定 'allow_experimental_lightweight_update' のエイリアスが追加されました。"
        }
      ]
    }
  ]}
/>

    軽量アップデートの使用を許可します。


## enable_memory_bound_merging_of_aggregation_results {#enable_memory_bound_merging_of_aggregation_results}

<SettingsInfoBlock type='Bool' default_value='1' />

集約結果のメモリ制限付きマージ戦略を有効にします。


## enable_multiple_prewhere_read_steps {#enable_multiple_prewhere_read_steps}

<SettingsInfoBlock type='Bool' default_value='1' />

AND で結合された複数の条件がある場合、WHERE から PREWHERE により多くの条件を移動し、ディスクからの読み取りとフィルタリングを複数のステップで実行します


## enable_named_columns_in_function_tuple {#enable_named_columns_in_function_tuple}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "0" },
        {
          label:
            "すべての名前が一意でクォートなしの識別子として扱える場合、tuple()関数で名前付きタプルを生成します。"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "ユーザビリティ改善待ちのため無効化" }
      ]
    }
  ]}
/>

すべての名前が一意でクォートなしの識別子として扱える場合、tuple()関数で名前付きタプルを生成します。


## enable_optimize_predicate_expression {#enable_optimize_predicate_expression}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "18.12.17" },
        { label: "1" },
        { label: "デフォルトでサブクエリへの述語最適化を有効化" }
      ]
    }
  ]}
/>

`SELECT`クエリにおける述語プッシュダウンを有効にします。

述語プッシュダウンにより、分散クエリのネットワークトラフィックを大幅に削減できます。

設定可能な値:

- 0 — 無効。
- 1 — 有効。

使用方法

以下のクエリを考えてみましょう:

1.  `SELECT count() FROM test_table WHERE date = '2018-10-10'`
2.  `SELECT count() FROM (SELECT * FROM test_table) WHERE date = '2018-10-10'`

`enable_optimize_predicate_expression = 1`の場合、ClickHouseはサブクエリの処理時に`WHERE`句を適用するため、これらのクエリの実行時間は同等になります。

`enable_optimize_predicate_expression = 0`の場合、サブクエリの完了後にすべてのデータに対して`WHERE`句が適用されるため、2番目のクエリの実行時間は大幅に長くなります。


## enable_optimize_predicate_expression_to_final_subquery {#enable_optimize_predicate_expression_to_final_subquery}

<SettingsInfoBlock type='Bool' default_value='1' />

述語を最終サブクエリにプッシュすることを許可します。


## enable_order_by_all {#enable_order_by_all}

<SettingsInfoBlock type='Bool' default_value='1' />

`ORDER BY ALL` 構文によるソートを有効化または無効化します。詳細は [ORDER BY](../../sql-reference/statements/select/order-by.md) を参照してください。

設定可能な値:

- 0 — ORDER BY ALL を無効化します。
- 1 — ORDER BY ALL を有効化します。

**例**

クエリ:

```sql
CREATE TABLE TAB(C1 Int, C2 Int, ALL Int) ENGINE=Memory();

INSERT INTO TAB VALUES (10, 20, 30), (20, 20, 10), (30, 10, 20);

SELECT * FROM TAB ORDER BY ALL; -- ALL が曖昧であるというエラーを返します

SELECT * FROM TAB ORDER BY ALL SETTINGS enable_order_by_all = 0;
```

結果:

```text
┌─C1─┬─C2─┬─ALL─┐
│ 20 │ 20 │  10 │
│ 30 │ 10 │  20 │
│ 10 │ 20 │  30 │
└────┴────┴─────┘
```


## enable_parallel_blocks_marshalling {#enable_parallel_blocks_marshalling}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.6" }, { label: "true" }, { label: "新しい設定" }]
    }
  ]}
/>

分散クエリにのみ影響します。有効にすると、イニシエーターへの送信前後に、ブロックがパイプラインスレッド上で(デフォルトよりも高い並列度で)(デ)シリアライズおよび(解)圧縮されます。


## enable_parsing_to_custom_serialization {#enable_parsing_to_custom_serialization}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

trueの場合、テーブルから取得したシリアライゼーションのヒントに従って、カスタムシリアライゼーション（例：Sparse）を持つカラムにデータを直接パースできます。


## enable_positional_arguments {#enable_positional_arguments}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.7" },
        { label: "1" },
        { label: "位置引数機能をデフォルトで有効化" }
      ]
    }
  ]}
/>

[GROUP BY](/sql-reference/statements/select/group-by)、[LIMIT BY](../../sql-reference/statements/select/limit-by.md)、[ORDER BY](../../sql-reference/statements/select/order-by.md)ステートメントにおける位置引数のサポートを有効または無効にします。

設定可能な値:

- 0 — 位置引数はサポートされません。
- 1 — 位置引数がサポートされます:カラム名の代わりにカラム番号を使用できます。

**例**

クエリ:

```sql
CREATE TABLE positional_arguments(one Int, two Int, three Int) ENGINE=Memory();

INSERT INTO positional_arguments VALUES (10, 20, 30), (20, 20, 10), (30, 10, 20);

SELECT * FROM positional_arguments ORDER BY 2,3;
```

結果:

```text
┌─one─┬─two─┬─three─┐
│  30 │  10 │   20  │
│  20 │  20 │   10  │
│  10 │  20 │   30  │
└─────┴─────┴───────┘
```


## enable_producing_buckets_out_of_order_in_aggregation {#enable_producing_buckets_out_of_order_in_aggregation}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

メモリ効率の良い集約（`distributed_aggregation_memory_efficient`を参照）において、バケットを順不同で生成することを許可します。
集約バケットのサイズに偏りがある場合、レプリカが低いIDの重いバケットを処理している間に、より高いIDのバケットをイニシエーターに送信できるようにすることで、パフォーマンスが向上する可能性があります。
欠点として、メモリ使用量が増加する可能性があります。


## enable_reads_from_query_cache {#enable_reads_from_query_cache}

<SettingsInfoBlock type='Bool' default_value='1' />

有効にすると、`SELECT`クエリの結果が[クエリキャッシュ](../query-cache.md)から取得されます。

使用可能な値:

- 0 - 無効
- 1 - 有効


## enable_s3_requests_logging {#enable_s3_requests_logging}

<SettingsInfoBlock type='Bool' default_value='0' />

S3リクエストの詳細なログ記録を有効にします。デバッグ時のみ使用することを推奨します。


## enable_scalar_subquery_optimization {#enable_scalar_subquery_optimization}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "19.18" },
        { label: "1" },
        {
          label:
            "スカラーサブクエリによる大きなスカラー値のシリアライズ/デシリアライズを防止し、同じサブクエリの複数回実行を回避できる可能性があります"
        }
      ]
    }
  ]}
/>

trueに設定すると、スカラーサブクエリによる大きなスカラー値のシリアライズ/デシリアライズを防止し、同じサブクエリの複数回実行を回避できる可能性があります。


## enable_scopes_for_with_statement {#enable_scopes_for_with_statement}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "1" },
        {
          label: "旧アナライザーとの後方互換性のための新しい設定。"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.6" },
        { label: "1" },
        {
          label: "旧アナライザーとの後方互換性のための新しい設定。"
        }
      ]
    },
    {
      id: "row-3",
      items: [
        { label: "25.5" },
        { label: "1" },
        {
          label: "旧アナライザーとの後方互換性のための新しい設定。"
        }
      ]
    },
    {
      id: "row-4",
      items: [
        { label: "25.4" },
        { label: "1" },
        {
          label: "旧アナライザーとの後方互換性のための新しい設定。"
        }
      ]
    }
  ]}
/>

無効にすると、親のWITH句内の宣言は、現在のスコープで宣言されたものと同じスコープで動作します。

これは、旧アナライザーで実行可能だった一部の無効なクエリを新しいアナライザーでも実行できるようにするための互換性設定です。


## enable_shared_storage_snapshot_in_query {#enable_shared_storage_snapshot_in_query}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "0" },
        { label: "クエリ内でストレージスナップショットを共有する新しい設定" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.11" },
        { label: "1" },
        { label: "整合性保証の向上。" }
      ]
    }
  ]}
/>

有効にすると、単一のクエリ内のすべてのサブクエリが各テーブルに対して同じStorageSnapshotを共有します。
これにより、同じテーブルに複数回アクセスする場合でも、クエリ全体でデータの一貫したビューが保証されます。

これは、データパーツの内部整合性が重要なクエリに必要です。例:

```sql
SELECT
    count()
FROM events
WHERE (_part, _part_offset) IN (
    SELECT _part, _part_offset
    FROM events
    WHERE user_id = 42
)
```

この設定がない場合、外側と内側のクエリが異なるデータスナップショットで動作する可能性があり、誤った結果につながります。

:::note
この設定を有効にすると、計画段階が完了した後にスナップショットから不要なデータパーツを削除する最適化が無効になります。
その結果、長時間実行されるクエリは実行期間中ずっと古いパーツを保持する可能性があり、パーツのクリーンアップが遅延し、ストレージの負荷が増加します。

この設定は現在、MergeTreeファミリーのテーブルにのみ適用されます。
:::

設定可能な値:

- 0 - 無効
- 1 - 有効


## enable_sharing_sets_for_mutations {#enable_sharing_sets_for_mutations}

<SettingsInfoBlock type='Bool' default_value='1' />

同一ミューテーションの異なるタスク間で、INサブクエリ用に構築されたセットオブジェクトの共有を許可します。これによりメモリ使用量とCPU消費が削減されます


## enable_software_prefetch_in_aggregation {#enable_software_prefetch_in_aggregation}

<SettingsInfoBlock type='Bool' default_value='1' />

集計処理でソフトウェアプリフェッチの使用を有効化します


## enable_unaligned_array_join {#enable_unaligned_array_join}

<SettingsInfoBlock type='Bool' default_value='0' />

異なるサイズの複数の配列に対するARRAY JOINを許可します。この設定を有効にすると、配列は最も長い配列のサイズに合わせてリサイズされます。


## enable_url_encoding {#enable_url_encoding}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "既存設定のデフォルト値を変更" }
      ]
    }
  ]}
/>

[URL](../../engines/table-engines/special/url.md)エンジンテーブルにおいて、URI内のパスのデコード/エンコードを有効化/無効化できます。

デフォルトでは無効化されています。


## enable_vertical_final {#enable_vertical_final}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "1" },
        { label: "バグ修正後、デフォルトで垂直FINALを再度有効化" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.1" },
        { label: "1" },
        { label: "デフォルトで垂直FINALを使用" }
      ]
    }
  ]}
/>

有効にすると、FINAL実行時に重複行をマージする代わりに、行を削除済みとしてマークし後でフィルタリングすることで重複行を削除します


## enable_writes_to_query_cache {#enable_writes_to_query_cache}

<SettingsInfoBlock type='Bool' default_value='1' />

有効にすると、`SELECT`クエリの結果が[クエリキャッシュ](../query-cache.md)に保存されます。

指定可能な値:

- 0 - 無効
- 1 - 有効


## enable_zstd_qat_codec {#enable_zstd_qat_codec}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "0" },
        { label: "新しいZSTD_QATコーデックを追加" }
      ]
    }
  ]}
/>

有効にすると、ZSTD_QATコーデックを使用してカラムを圧縮できます。


## enforce_strict_identifier_format {#enforce_strict_identifier_format}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

有効にすると、英数字とアンダースコアを含む識別子のみが許可されます。


## engine_file_allow_create_multiple_files {#engine_file_allow_create_multiple_files}

<SettingsInfoBlock type='Bool' default_value='0' />

フォーマットにサフィックス（`JSON`、`ORC`、`Parquet`など）がある場合、fileエンジンテーブルへの挿入ごとに新しいファイルを作成するかどうかを制御します。有効にすると、挿入ごとに次のパターンに従った名前で新しいファイルが作成されます：

`data.Parquet` -> `data.1.Parquet` -> `data.2.Parquet`, etc.

設定可能な値：

- 0 — `INSERT`クエリは新しいデータをファイルの末尾に追加します。
- 1 — `INSERT`クエリは新しいファイルを作成します。


## engine_file_empty_if_not_exists {#engine_file_empty_if_not_exists}

<SettingsInfoBlock type='Bool' default_value='0' />

ファイルが存在しない場合でも、ファイルエンジンテーブルからデータを選択できるようにします。

設定可能な値:

- 0 — `SELECT` は例外をスローします。
- 1 — `SELECT` は空の結果を返します。


## engine_file_skip_empty_files {#engine_file_skip_empty_files}

<SettingsInfoBlock type='Bool' default_value='0' />

[File](../../engines/table-engines/special/file.md)エンジンテーブルで空のファイルをスキップするかどうかを設定します。

設定可能な値:

- 0 — 空のファイルが要求された形式と互換性がない場合、`SELECT`は例外をスローします。
- 1 — 空のファイルに対して`SELECT`は空の結果を返します。


## engine_file_truncate_on_insert {#engine_file_truncate_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

[File](../../engines/table-engines/special/file.md)エンジンテーブルにおいて、挿入前のトランケート（切り詰め）を有効化または無効化します。

設定可能な値:

- 0 — `INSERT`クエリは新しいデータをファイルの末尾に追加します。
- 1 — `INSERT`クエリはファイルの既存の内容を新しいデータで置き換えます。


## engine_url_skip_empty_files {#engine_url_skip_empty_files}

<SettingsInfoBlock type='Bool' default_value='0' />

[URL](../../engines/table-engines/special/url.md)エンジンテーブルで空のファイルをスキップするかどうかを設定します。

設定可能な値:

- 0 — 空のファイルが要求された形式と互換性がない場合、`SELECT`は例外をスローします。
- 1 — 空のファイルに対して`SELECT`は空の結果を返します。


## except_default_mode {#except_default_mode}

<SettingsInfoBlock type='SetOperationMode' default_value='ALL' />

EXCEPTクエリのデフォルトモードを設定します。設定可能な値：空文字列、'ALL'、'DISTINCT'。空文字列の場合、モードを指定しないクエリは例外をスローします。


## exclude_materialize_skip_indexes_on_insert {#exclude_materialize_skip_indexes_on_insert}

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "" }, { label: "新しい設定。" }]
    }
  ]}
/>

INSERT実行時に、指定されたスキップインデックスの構築と保存を除外します。除外されたスキップインデックスは、[マージ時](merge-tree-settings.md/#materialize_skip_indexes_on_merge)または明示的な
[MATERIALIZE INDEX](/sql-reference/statements/alter/skipping-index.md/#materialize-index)クエリによって構築および保存されます。

[materialize_skip_indexes_on_insert](#materialize_skip_indexes_on_insert)がfalseの場合は効果がありません。

例:

```sql
CREATE TABLE tab
(
    a UInt64,
    b UInt64,
    INDEX idx_a a TYPE minmax,
    INDEX idx_b b TYPE set(3)
)
ENGINE = MergeTree ORDER BY tuple();

SET exclude_materialize_skip_indexes_on_insert='idx_a'; -- idx_aは挿入時に更新されません
--SET exclude_materialize_skip_indexes_on_insert='idx_a, idx_b'; -- どちらのインデックスも挿入時に更新されません

INSERT INTO tab SELECT number, number / 50 FROM numbers(100); -- idx_bのみが更新されます

-- セッション設定であるため、クエリごとに設定できます
INSERT INTO tab SELECT number, number / 50 FROM numbers(100, 100) SETTINGS exclude_materialize_skip_indexes_on_insert='idx_b';

ALTER TABLE tab MATERIALIZE INDEX idx_a; -- このクエリを使用してインデックスを明示的にマテリアライズできます

SET exclude_materialize_skip_indexes_on_insert = DEFAULT; -- 設定をデフォルトにリセット
```


## execute_exists_as_scalar_subquery {#execute_exists_as_scalar_subquery}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

非相関EXISTSサブクエリをスカラーサブクエリとして実行します。スカラーサブクエリと同様に、キャッシュが使用され、結果に対して定数畳み込みが適用されます。


## external_storage_connect_timeout_sec {#external_storage_connect_timeout_sec}

<SettingsInfoBlock type='UInt64' default_value='10' />

接続タイムアウト(秒単位)。現在MySQLのみサポートされています


## external_storage_max_read_bytes {#external_storage_max_read_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

外部エンジンを使用するテーブルが履歴データをフラッシュする際の最大バイト数を制限します。現在、MySQLテーブルエンジン、データベースエンジン、およびディクショナリのみでサポートされています。0に設定した場合、この設定は無効化されます


## external_storage_max_read_rows {#external_storage_max_read_rows}

<SettingsInfoBlock type='UInt64' default_value='0' />

外部エンジンを使用するテーブルが履歴データをフラッシュする際の最大行数を制限します。現在、MySQLテーブルエンジン、データベースエンジン、およびディクショナリのみでサポートされています。0に設定した場合、この設定は無効化されます


## external_storage_rw_timeout_sec {#external_storage_rw_timeout_sec}

<SettingsInfoBlock type='UInt64' default_value='300' />

読み取り/書き込みのタイムアウト（秒単位）。現在MySQLのみサポートされています


## external_table_functions_use_nulls {#external_table_functions_use_nulls}

<SettingsInfoBlock type='Bool' default_value='1' />

[mysql](../../sql-reference/table-functions/mysql.md)、[postgresql](../../sql-reference/table-functions/postgresql.md)、[odbc](../../sql-reference/table-functions/odbc.md) テーブル関数における Nullable カラムの使用方法を定義します。

設定可能な値:

- 0 — テーブル関数は明示的に Nullable カラムを使用します。
- 1 — テーブル関数は暗黙的に Nullable カラムを使用します。

**使用方法**

この設定を `0` に設定した場合、テーブル関数は Nullable カラムを作成せず、NULL の代わりにデフォルト値を挿入します。これは配列内の NULL 値にも適用されます。


## external_table_strict_query {#external_table_strict_query}

<SettingsInfoBlock type='Bool' default_value='0' />

trueに設定した場合、外部テーブルへのクエリにおいて式のローカルフィルタへの変換が禁止されます。


## extract_key_value_pairs_max_pairs_per_row {#extract_key_value_pairs_max_pairs_per_row}

**エイリアス**: `extract_kvp_max_pairs_per_row`

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "0" },
        {
          label:
            "`extractKeyValuePairs`関数が生成できるペアの最大数。メモリの過剰消費を防ぐための保護機能として使用されます。"
        }
      ]
    }
  ]}
/>

`extractKeyValuePairs`関数が生成できるペアの最大数。メモリの過剰消費を防ぐための保護機能として使用されます。


## extremes {#extremes}

<SettingsInfoBlock type='Bool' default_value='0' />

極値(クエリ結果の列における最小値と最大値)を計算するかどうかを指定します。0または1を指定できます。デフォルトは0(無効)です。
詳細については、「極値」のセクションを参照してください。


## fallback_to_stale_replicas_for_distributed_queries {#fallback_to_stale_replicas_for_distributed_queries}

<SettingsInfoBlock type='Bool' default_value='1' />

更新されたデータが利用できない場合、古いレプリカに対してクエリを実行します。[レプリケーション](../../engines/table-engines/mergetree-family/replication.md)を参照してください。

ClickHouseはテーブルの古いレプリカの中から最も関連性の高いものを選択します。

レプリケートされたテーブルを参照する分散テーブルから`SELECT`を実行する際に使用されます。

デフォルトでは1(有効)です。


## filesystem_cache_allow_background_download {#filesystem_cache_allow_background_download}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1" },
        {
          label:
            "クエリごとにファイルシステムキャッシュのバックグラウンドダウンロードを制御する新しい設定です。"
        }
      ]
    }
  ]}
/>

リモートストレージから読み取られたデータのバックグラウンドダウンロードをファイルシステムキャッシュがキューに登録することを許可します。無効にすると、現在のクエリ/セッションのダウンロードがフォアグラウンドで実行されます。


## filesystem_cache_boundary_alignment {#filesystem_cache_boundary_alignment}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

ファイルシステムキャッシュの境界アライメント。この設定は、非ディスク読み取りの場合にのみ適用されます（例：リモートテーブルエンジン/テーブル関数のキャッシュには適用されますが、MergeTreeテーブルのストレージ設定には適用されません）。値0はアライメントなしを意味します。


## filesystem_cache_enable_background_download_during_fetch {#filesystem_cache_enable_background_download_during_fetch}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "1" }, { label: "新規設定" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。ファイルシステムキャッシュ内の領域予約のためのキャッシュロック待機時間


## filesystem_cache_enable_background_download_for_metadata_files_in_packed_storage {#filesystem_cache_enable_background_download_for_metadata_files_in_packed_storage}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。ファイルシステムキャッシュ内の領域予約のためのキャッシュロック待機時間


## filesystem_cache_max_download_size {#filesystem_cache_max_download_size}

<SettingsInfoBlock type='UInt64' default_value='137438953472' />

単一クエリでダウンロード可能なリモートファイルシステムキャッシュの最大サイズ


## filesystem_cache_name {#filesystem_cache_name}

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "" },
        {
          label:
            "ステートレステーブルエンジンまたはデータレイクで使用するファイルシステムキャッシュ名"
        }
      ]
    }
  ]}
/>

ステートレステーブルエンジンまたはデータレイクで使用するファイルシステムキャッシュ名


## filesystem_cache_prefer_bigger_buffer_size {#filesystem_cache_prefer_bigger_buffer_size}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

ファイルシステムキャッシュが有効な場合、キャッシュパフォーマンスを低下させる小さなファイルセグメントの書き込みを回避するため、より大きなバッファサイズを優先します。ただし、この設定を有効にするとメモリ使用量が増加する可能性があります。


## filesystem_cache_reserve_space_wait_lock_timeout_milliseconds {#filesystem_cache_reserve_space_wait_lock_timeout_milliseconds}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1000" },
        {
          label:
            "ファイルシステムキャッシュの領域予約時にキャッシュをロックするための待機時間"
        }
      ]
    }
  ]}
/>

ファイルシステムキャッシュの領域予約時にキャッシュをロックするための待機時間


## filesystem_cache_segments_batch_size {#filesystem_cache_segments_batch_size}

<SettingsInfoBlock type='UInt64' default_value='20' />

読み取りバッファがキャッシュに要求できるファイルセグメントの単一バッチのサイズ制限。値が低すぎるとキャッシュへの過剰なリクエストが発生し、大きすぎるとキャッシュからの退避が遅くなる可能性があります


## filesystem_cache_skip_download_if_exceeds_per_query_cache_write_limit {#filesystem_cache_skip_download_if_exceeds_per_query_cache_write_limit}

**エイリアス**: `skip_download_if_exceeds_query_cache`

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "1" },
        {
          label: "設定 skip_download_if_exceeds_query_cache_limit の名前変更"
        }
      ]
    }
  ]}
/>

クエリキャッシュサイズを超える場合、リモートファイルシステムからのダウンロードをスキップする


## filesystem_prefetch_max_memory_usage {#filesystem_prefetch_max_memory_usage}

<SettingsInfoBlock type='NonZeroUInt64' default_value='1073741824' />

プリフェッチの最大メモリ使用量。


## filesystem_prefetch_step_bytes {#filesystem_prefetch_step_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

プリフェッチステップのバイト数。ゼロは`auto`を意味し、最適なプリフェッチステップが自動的に推定されますが、必ずしも100%最適とは限りません。実際の値は、filesystem_prefetch_min_bytes_for_single_read_task設定の影響により異なる場合があります


## filesystem_prefetch_step_marks {#filesystem_prefetch_step_marks}

<SettingsInfoBlock type='UInt64' default_value='0' />

マーク単位でのプリフェッチステップ。ゼロは`auto`を意味し、最適に近いプリフェッチステップが自動的に推定されますが、必ずしも100%最適とは限りません。実際の値は設定`filesystem_prefetch_min_bytes_for_single_read_task`により異なる場合があります


## filesystem_prefetches_limit {#filesystem_prefetches_limit}

<SettingsInfoBlock type='UInt64' default_value='200' />

プリフェッチの最大数。0は無制限を意味します。プリフェッチの数を制限する場合は、`filesystem_prefetches_max_memory_usage` 設定の使用を推奨します


## final {#final}

<SettingsInfoBlock type='Bool' default_value='0' />

クエリ内のすべてのテーブルに対して、[FINAL](../../sql-reference/statements/select/from.md/#final-modifier)修飾子が適用可能なテーブル(結合テーブル、サブクエリ内のテーブル、分散テーブルを含む)に[FINAL](../../sql-reference/statements/select/from.md/#final-modifier)修飾子を自動的に適用します。

設定可能な値:

- 0 - 無効
- 1 - 有効

例:

```sql
CREATE TABLE test
(
    key Int64,
    some String
)
ENGINE = ReplacingMergeTree
ORDER BY key;

INSERT INTO test FORMAT Values (1, 'first');
INSERT INTO test FORMAT Values (1, 'second');

SELECT * FROM test;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘
┌─key─┬─some──┐
│   1 │ first │
└─────┴───────┘

SELECT * FROM test SETTINGS final = 1;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘

SET final = 1;
SELECT * FROM test;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘
```


## flatten_nested {#flatten_nested}

<SettingsInfoBlock type='Bool' default_value='1' />

[Nested](../../sql-reference/data-types/nested-data-structures/index.md)カラムのデータ形式を設定します。

設定可能な値:

- 1 — Nestedカラムを個別の配列に平坦化します。
- 0 — Nestedカラムをタプルの単一配列として保持します。

**使用方法**

この設定を`0`にすると、任意のレベルのネストを使用できます。

**例**

クエリ:

```sql
SET flatten_nested = 1;
CREATE TABLE t_nest (`n` Nested(a UInt32, b UInt32)) ENGINE = MergeTree ORDER BY tuple();

SHOW CREATE TABLE t_nest;
```

結果:

```text
┌─statement───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.t_nest
(
    `n.a` Array(UInt32),
    `n.b` Array(UInt32)
)
ENGINE = MergeTree
ORDER BY tuple()
SETTINGS index_granularity = 8192 │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

クエリ:

```sql
SET flatten_nested = 0;

CREATE TABLE t_nest (`n` Nested(a UInt32, b UInt32)) ENGINE = MergeTree ORDER BY tuple();

SHOW CREATE TABLE t_nest;
```

結果:

```text
┌─statement──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.t_nest
(
    `n` Nested(a UInt32, b UInt32)
)
ENGINE = MergeTree
ORDER BY tuple()
SETTINGS index_granularity = 8192 │
└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```


## force_aggregate_partitions_independently {#force_aggregate_partitions_independently}

<SettingsInfoBlock type='Bool' default_value='0' />

最適化が適用可能な場合でも、ヒューリスティックによって使用しないと判断された際に、最適化の使用を強制します


## force_aggregation_in_order {#force_aggregation_in_order}

<SettingsInfoBlock type='Bool' default_value='0' />

この設定は、分散クエリをサポートするためにサーバー自体が使用します。手動で変更すると通常の動作が破壊されるため、変更しないでください。(分散集約時にリモートノードで順序付き集約の使用を強制します)。


## force_data_skipping_indices {#force_data_skipping_indices}

指定されたデータスキップインデックスが使用されなかった場合、クエリの実行を無効にします。

以下の例を考えてみましょう:

```sql
CREATE TABLE data
(
    key Int,
    d1 Int,
    d1_null Nullable(Int),
    INDEX d1_idx d1 TYPE minmax GRANULARITY 1,
    INDEX d1_null_idx assumeNotNull(d1_null) TYPE minmax GRANULARITY 1
)
Engine=MergeTree()
ORDER BY key;

SELECT * FROM data_01515;
SELECT * FROM data_01515 SETTINGS force_data_skipping_indices=''; -- クエリはCANNOT_PARSE_TEXTエラーを発生させます。
SELECT * FROM data_01515 SETTINGS force_data_skipping_indices='d1_idx'; -- クエリはINDEX_NOT_USEDエラーを発生させます。
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='d1_idx'; -- 正常に実行されます。
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='`d1_idx`'; -- 正常に実行されます(完全機能パーサーの例)。
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='`d1_idx`, d1_null_idx'; -- d1_null_idxが使用されていないため、クエリはINDEX_NOT_USEDエラーを発生させます。
SELECT * FROM data_01515 WHERE d1 = 0 AND assumeNotNull(d1_null) = 0 SETTINGS force_data_skipping_indices='`d1_idx`, d1_null_idx'; -- 正常に実行されます。
```


## force_grouping_standard_compatibility {#force_grouping_standard_compatibility}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.9" },
        { label: "1" },
        {
          label:
            "GROUPING関数の出力をSQL標準および他のDBMSと同じにします"
        }
      ]
    }
  ]}
/>

引数が集約キーとして使用されていない場合にGROUPING関数が1を返すようにします


## force_index_by_date {#force_index_by_date}

<SettingsInfoBlock type='Bool' default_value='0' />

日付インデックスが使用できない場合、クエリの実行を無効にします。

MergeTreeファミリーのテーブルで機能します。

`force_index_by_date=1`の場合、ClickHouseはクエリにデータ範囲を制限するための日付キー条件が含まれているかどうかを確認します。適切な条件がない場合は例外をスローします。ただし、その条件が読み取るデータ量を実際に削減するかどうかは確認しません。例えば、`Date != ' 2000-01-01 '`という条件は、テーブル内のすべてのデータに一致する場合(つまり、クエリの実行にフルスキャンが必要な場合)でも許容されます。MergeTreeテーブルのデータ範囲の詳細については、[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)を参照してください。


## force_optimize_projection {#force_optimize_projection}

<SettingsInfoBlock type='Bool' default_value='0' />

プロジェクション最適化が有効な場合に、`SELECT`クエリで[プロジェクション](../../engines/table-engines/mergetree-family/mergetree.md/#projections)の使用を強制するかどうかを設定します([optimize_use_projections](#optimize_use_projections)設定を参照)。

設定可能な値:

- 0 — プロジェクション最適化は強制されません。
- 1 — プロジェクション最適化が強制されます。


## force_optimize_projection_name {#force_optimize_projection_name}

空でない文字列に設定されている場合、このプロジェクションがクエリ内で少なくとも1回使用されていることを確認します。

設定可能な値:

- string: クエリで使用されるプロジェクションの名前


## force_optimize_skip_unused_shards {#force_optimize_skip_unused_shards}

<SettingsInfoBlock type='UInt64' default_value='0' />

[optimize_skip_unused_shards](#optimize_skip_unused_shards)が有効で、未使用シャードのスキップができない場合のクエリ実行を制御します。スキップができず、この設定が有効な場合は例外がスローされます。

設定可能な値:

- 0 — 無効。ClickHouseは例外をスローしません。
- 1 — 有効。テーブルにシャーディングキーがある場合のみクエリ実行が無効化されます。
- 2 — 有効。テーブルにシャーディングキーが定義されているかどうかに関わらずクエリ実行が無効化されます。


## force_optimize_skip_unused_shards_nesting {#force_optimize_skip_unused_shards_nesting}

<SettingsInfoBlock type='UInt64' default_value='0' />

分散クエリのネストレベルに応じて[`force_optimize_skip_unused_shards`](#force_optimize_skip_unused_shards)を制御します(そのため[`force_optimize_skip_unused_shards`](#force_optimize_skip_unused_shards)の設定が引き続き必要です)。これは、ある`Distributed`テーブルが別の`Distributed`テーブルを参照している場合に該当します。

設定可能な値:

- 0 - 無効。`force_optimize_skip_unused_shards`は常に動作します。
- 1 — 第1レベルに対してのみ`force_optimize_skip_unused_shards`を有効にします。
- 2 — 第2レベルまで`force_optimize_skip_unused_shards`を有効にします。


## force_primary_key {#force_primary_key}

<SettingsInfoBlock type='Bool' default_value='0' />

プライマリキーによるインデックスが使用できない場合、クエリの実行を無効化します。

MergeTreeファミリーのテーブルで機能します。

`force_primary_key=1`の場合、ClickHouseはクエリにデータ範囲を制限するために使用可能なプライマリキー条件が含まれているかを確認します。適切な条件が存在しない場合は例外をスローします。ただし、その条件が実際に読み取るデータ量を削減するかどうかは確認しません。MergeTreeテーブルのデータ範囲の詳細については、[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)を参照してください。


## force_remove_data_recursively_on_drop {#force_remove_data_recursively_on_drop}

<SettingsInfoBlock type='Bool' default_value='0' />

DROPクエリでデータを再帰的に削除します。'Directory not empty'エラーを回避しますが、デタッチされたデータが警告なしに削除される可能性があります


## formatdatetime_e_with_space_padding {#formatdatetime_e_with_space_padding}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "MySQL の DATE_FORMAT/STR_TO_DATE との互換性を改善" }
      ]
    }
  ]}
/>

関数 'formatDateTime' のフォーマッタ '%e' は、一桁の日付を先頭にスペースを付けて出力します。例: '2' ではなく ' 2' となります。


## formatdatetime_f_prints_scale_number_of_digits {#formatdatetime_f_prints_scale_number_of_digits}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

関数 'formatDateTime' のフォーマッタ '%f' は、DateTime64 に対して固定の6桁ではなく、スケールで指定された桁数のみを出力します。


## formatdatetime_f_prints_single_zero {#formatdatetime_f_prints_single_zero}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "0" },
        {
          label: "MySQL の DATE_FORMAT()/STR_TO_DATE() との互換性を向上"
        }
      ]
    }
  ]}
/>

関数`formatDateTime`のフォーマッタ`%f`は、フォーマット対象の値に小数秒が含まれない場合、6個のゼロではなく1個のゼロを出力します。


## formatdatetime_format_without_leading_zeros {#formatdatetime_format_without_leading_zeros}

<SettingsInfoBlock type='Bool' default_value='0' />

関数 `formatDateTime` のフォーマッタ `%c`、`%l`、`%k` は、月と時刻を先頭ゼロなしで出力します。


## formatdatetime_parsedatetime_m_is_month_name {#formatdatetime_parsedatetime_m_is_month_name}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "1" },
        { label: "MySQL の DATE_FORMAT/STR_TO_DATE との互換性を向上" }
      ]
    }
  ]}
/>

関数 `formatDateTime` および `parseDateTime` のフォーマッタ `%M` は、分ではなく月名を出力/解析します。


## fsync_metadata {#fsync_metadata}

<SettingsInfoBlock type='Bool' default_value='1' />

`.sql`ファイルの書き込み時に[fsync](http://pubs.opengroup.org/onlinepubs/9699919799/functions/fsync.html)を有効または無効にします。デフォルトでは有効です。

サーバーに常に作成・削除が繰り返される数百万の小さなテーブルが存在する場合、これを無効にすることが推奨されます。


## function_date_trunc_return_type_behavior {#function_date_trunc_return_type_behavior}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "0" },
        {
          label:
            "dateTrunc関数の従来の動作を保持するための新しい設定を追加"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.4" },
        { label: "0" },
        {
          label:
            "負の値に対して正しい結果を得るため、DateTime64/Date32引数に対するdateTrunc関数の戻り値の型を時間単位に関係なくDateTime64/Date32に変更"
        }
      ]
    }
  ]}
/>

`dateTrunc`関数の戻り値の型の動作を変更します。

設定可能な値:

- 0 - 第2引数が`DateTime64/Date32`の場合、第1引数の時間単位に関係なく戻り値の型は`DateTime64/Date32`になります。
- 1 - `Date32`の場合、結果は常に`Date`になります。`DateTime64`の場合、時間単位が`second`以上であれば結果は`DateTime`になります。


## function_implementation {#function_implementation}

特定のターゲットまたはバリアント向けの関数実装を選択します（実験的機能）。空の場合、すべての実装が有効になります。


## function_json_value_return_type_allow_complex {#function_json_value_return_type_allow_complex}

<SettingsInfoBlock type='Bool' default_value='0' />

json_value関数で複合型(struct、array、mapなど)を返すことを許可するかどうかを制御します。

```sql
SELECT JSON_VALUE('{"hello":{"world":"!"}}', '$.hello') settings function_json_value_return_type_allow_complex=true

┌─JSON_VALUE('{"hello":{"world":"!"}}', '$.hello')─┐
│ {"world":"!"}                                    │
└──────────────────────────────────────────────────┘

1 row in set. Elapsed: 0.001 sec.
```

設定可能な値:

- true — 許可します。
- false — 許可しません。


## function_json_value_return_type_allow_nullable {#function_json_value_return_type_allow_nullable}

<SettingsInfoBlock type='Bool' default_value='0' />

JSON_VALUE関数で値が存在しない場合に`NULL`を返すことを許可するかどうかを制御します。

```sql
SELECT JSON_VALUE('{"hello":"world"}', '$.b') settings function_json_value_return_type_allow_nullable=true;

┌─JSON_VALUE('{"hello":"world"}', '$.b')─┐
│ ᴺᵁᴸᴸ                                   │
└────────────────────────────────────────┘

1 row in set. Elapsed: 0.001 sec.
```

使用可能な値:

- true — 許可します。
- false — 許可しません。


## function_locate_has_mysql_compatible_argument_order {#function_locate_has_mysql_compatible_argument_order}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1" },
        { label: "MySQLのlocate関数との互換性を向上させます。" }
      ]
    }
  ]}
/>

関数[locate](../../sql-reference/functions/string-search-functions.md/#locate)の引数の順序を制御します。

設定可能な値:

- 0 — 関数`locate`は引数`(haystack, needle[, start_pos])`を受け取ります。
- 1 — 関数`locate`は引数`(needle, haystack[, start_pos])`を受け取ります(MySQL互換の動作)


## function_range_max_elements_in_block {#function_range_max_elements_in_block}

<SettingsInfoBlock type='UInt64' default_value='500000000' />

関数[range](/sql-reference/functions/array-functions#range)によって生成されるデータ量の安全閾値を設定します。データブロックごとに関数が生成する値の最大数を定義します（ブロック内の各行の配列サイズの合計）。

設定可能な値：

- 正の整数

**関連項目**

- [`max_block_size`](#max_block_size)
- [`min_insert_block_size_rows`](#min_insert_block_size_rows)


## function_sleep_max_microseconds_per_block {#function_sleep_max_microseconds_per_block}

<SettingsInfoBlock type='UInt64' default_value='3000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.7" },
        { label: "3000000" },
        {
          label:
            以前のバージョンでは、最大スリープ時間3秒は`sleep`関数にのみ適用され、`sleepEachRow`関数には適用されませんでした。新しいバージョンでは、この設定が導入されました。以前のバージョンとの互換性を設定した場合、制限は完全に無効化されます。
        }
      ]
    }
  ]}
/>

`sleep`関数が各ブロックに対してスリープできる最大マイクロ秒数です。ユーザーがこれより大きな値で呼び出した場合、例外がスローされます。これは安全性のしきい値です。


## function_visible_width_behavior {#function_visible_width_behavior}

<SettingsInfoBlock type='UInt64' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "1" },
        {
          label:
            "`visibleWidth`のデフォルト動作をより正確に変更しました"
        }
      ]
    }
  ]}
/>

`visibleWidth`の動作バージョン。0 - コードポイント数のみをカウント、1 - ゼロ幅文字と結合文字を正確にカウントし、全角文字を2としてカウント、タブ幅を推定し、削除文字をカウントします。


## geo_distance_returns_float64_on_float64_arguments {#geo_distance_returns_float64_on_float64_arguments}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1" },
        { label: "デフォルトの精度を向上" }
      ]
    }
  ]}
/>

`geoDistance`、`greatCircleDistance`、`greatCircleAngle` 関数の4つの引数がすべてFloat64の場合、Float64を返し、内部計算には倍精度浮動小数点数を使用します。以前のClickHouseバージョンでは、これらの関数は常にFloat32を返していました。


## geotoh3_argument_order {#geotoh3_argument_order}

<BetaBadge />

<SettingsInfoBlock type='GeoToH3ArgumentOrder' default_value='lat_lon' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "lat_lon" },
        {
          label:
            "経度と緯度の引数順序を設定するレガシー動作用の新しい設定"
        }
      ]
    }
  ]}
/>

関数'geoToH3'は、'lon_lat'に設定した場合は(経度, 緯度)を、'lat_lon'に設定した場合は(緯度, 経度)を受け付けます。


## glob_expansion_max_elements {#glob_expansion_max_elements}

<SettingsInfoBlock type='UInt64' default_value='1000' />

許可されるアドレスの最大数（外部ストレージ、テーブル関数などに対して）。


## grace_hash_join_initial_buckets {#grace_hash_join_initial_buckets}

<ExperimentalBadge />

<SettingsInfoBlock type='NonZeroUInt64' default_value='1' />

Grace Hash Join バケットの初期数


## grace_hash_join_max_buckets {#grace_hash_join_max_buckets}

<ExperimentalBadge />

<SettingsInfoBlock type='NonZeroUInt64' default_value='1024' />

グレースハッシュ結合のバケット数の上限


## group_by_overflow_mode {#group_by_overflow_mode}

<SettingsInfoBlock type='OverflowModeGroupBy' default_value='throw' />

集約に使用する一意のキーの数が制限を超えた場合の動作を設定します:

- `throw`: 例外をスローします
- `break`: クエリの実行を停止し、部分的な結果を返します
- `any`: セットに含まれているキーについては集約を継続しますが、新しいキーはセットに追加しません。

'any'を指定すると、GROUP BYの近似計算を実行できます。この近似の精度は、データの統計的特性に依存します。


## group_by_two_level_threshold {#group_by_two_level_threshold}

<SettingsInfoBlock type='UInt64' default_value='100000' />

2レベル集約を開始するキーの数を指定します。0の場合、閾値は設定されません。


## group_by_two_level_threshold_bytes {#group_by_two_level_threshold_bytes}

<SettingsInfoBlock type='UInt64' default_value='50000000' />

集約状態のサイズ（バイト単位）がこの値に達すると、2レベル集約が使用されます。0 - 閾値が設定されていません。2レベル集約は、いずれかの閾値に達した時点で使用されます。


## group_by_use_nulls {#group_by_use_nulls}

<SettingsInfoBlock type='Bool' default_value='0' />

[GROUP BY句](/sql-reference/statements/select/group-by)における集約キーの型の扱い方を変更します。
`ROLLUP`、`CUBE`、または`GROUPING SETS`指定子を使用する場合、一部の集約キーが特定の結果行の生成に使用されないことがあります。
これらのキーに対応する列は、この設定に応じて、該当する行においてデフォルト値または`NULL`で埋められます。

設定可能な値:

- 0 — 欠損値の生成には集約キー型のデフォルト値が使用されます。
- 1 — ClickHouseはSQL標準に準拠して`GROUP BY`を実行します。集約キーの型は[Nullable](/sql-reference/data-types/nullable)に変換されます。対応する集約キーの列は、使用されなかった行において[NULL](/sql-reference/syntax#null)で埋められます。

関連項目:

- [GROUP BY句](/sql-reference/statements/select/group-by)


## h3togeo_lon_lat_result_order {#h3togeo_lon_lat_result_order}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

関数 'h3ToGeo' は true の場合は (lon, lat) を返し、false の場合は (lat, lon) を返します。


## handshake_timeout_ms {#handshake_timeout_ms}

<SettingsInfoBlock type='Milliseconds' default_value='10000' />

ハンドシェイク中にレプリカからHelloパケットを受信する際のタイムアウト(ミリ秒)。


## hdfs_create_new_file_on_insert {#hdfs_create_new_file_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

HDFSエンジンテーブルへの挿入時に毎回新しいファイルを作成するかどうかを設定します。有効にすると、挿入のたびに以下のパターンに従った名前で新しいHDFSファイルが作成されます:

initial: `data.Parquet.gz` -> `data.1.Parquet.gz` -> `data.2.Parquet.gz`, etc.

設定可能な値:

- 0 — `INSERT`クエリは新しいデータをファイルの末尾に追加します。
- 1 — `INSERT`クエリは新しいファイルを作成します。


## hdfs_ignore_file_doesnt_exist {#hdfs_ignore_file_doesnt_exist}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "HDFSテーブルエンジンで、要求されたファイルが存在しない場合に例外をスローせず0行を返すことを許可"
        }
      ]
    }
  ]}
/>

特定のキーを読み取る際に、ファイルが存在しない場合はその不在を無視します。

設定可能な値:

- 1 — `SELECT`は空の結果を返します。
- 0 — `SELECT`は例外をスローします。


## hdfs_replication {#hdfs_replication}

<SettingsInfoBlock type='UInt64' default_value='0' />

HDFSファイル作成時に、実際のレプリケーション数を指定できます。


## hdfs_skip_empty_files {#hdfs_skip_empty_files}

<SettingsInfoBlock type='Bool' default_value='0' />

[HDFS](../../engines/table-engines/integrations/hdfs.md)エンジンテーブルで空のファイルをスキップするかどうかを有効化または無効化します。

設定可能な値:

- 0 — 空のファイルが要求された形式と互換性がない場合、`SELECT`は例外をスローします。
- 1 — 空のファイルに対して`SELECT`は空の結果を返します。


## hdfs_throw_on_zero_files_match {#hdfs_throw_on_zero_files_match}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "HDFSエンジンでListObjectsリクエストがファイルに一致しない場合、空のクエリ結果の代わりにエラーをスローできるようにします"
        }
      ]
    }
  ]}
/>

glob展開ルールに従って一致するファイルが0件の場合、エラーをスローします。

設定可能な値:

- 1 — `SELECT`は例外をスローします。
- 0 — `SELECT`は空の結果を返します。


## hdfs_truncate_on_insert {#hdfs_truncate_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

hdfsエンジンテーブルへの挿入前のトランケート(切り詰め)を有効または無効にします。無効の場合、HDFSにファイルが既に存在する状態で挿入を試みると例外がスローされます。

設定可能な値:

- 0 — `INSERT`クエリは新しいデータをファイルの末尾に追加します。
- 1 — `INSERT`クエリはファイルの既存の内容を新しいデータで置き換えます。


## hedged_connection_timeout_ms {#hedged_connection_timeout_ms}

<SettingsInfoBlock type='Milliseconds' default_value='50' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.4" },
        { label: "50" },
        {
          label:
            "以前の接続タイムアウトに合わせて、hedgedリクエストでの新規接続開始を100ミリ秒から50ミリ秒に変更"
        }
      ]
    }
  ]}
/>

Hedgedリクエストでレプリカとの接続を確立する際の接続タイムアウト


## hnsw_candidate_list_size_for_search {#hnsw_candidate_list_size_for_search}

<SettingsInfoBlock type='UInt64' default_value='256' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "256" },
        {
          label:
            "新しい設定です。以前は、CREATE INDEXでオプションとして指定可能で、デフォルト値は64でした。"
        }
      ]
    }
  ]}
/>

ベクトル類似性インデックスを検索する際の動的候補リストのサイズです。'ef_search'とも呼ばれます。


## hsts_max_age {#hsts_max_age}

<SettingsInfoBlock type='UInt64' default_value='0' />

HSTSの有効期限。0に設定するとHSTSが無効化されます。


## http_connection_timeout {#http_connection_timeout}

<SettingsInfoBlock type='Seconds' default_value='1' />

HTTP接続のタイムアウト時間（秒単位）。

設定可能な値：

- 任意の正の整数
- 0 - 無効（タイムアウトなし）


## http_headers_progress_interval_ms {#http_headers_progress_interval_ms}

<SettingsInfoBlock type='UInt64' default_value='100' />

指定された間隔ごとに、HTTPヘッダー X-ClickHouse-Progress を送信します。この間隔よりも頻繁には送信されません。


## http_make_head_request {#http_make_head_request}

<SettingsInfoBlock type='Bool' default_value='1' />

`http_make_head_request`設定は、HTTPからデータを読み取る際に`HEAD`リクエストを実行して、読み取るファイルのサイズなどの情報を取得します。デフォルトで有効になっているため、サーバーが`HEAD`リクエストをサポートしていない場合は、この設定を無効にすることが推奨されます。


## http_max_field_name_size {#http_max_field_name_size}

<SettingsInfoBlock type='UInt64' default_value='131072' />

HTTPヘッダー内のフィールド名の最大長


## http_max_field_value_size {#http_max_field_value_size}

<SettingsInfoBlock type='UInt64' default_value='131072' />

HTTPヘッダーのフィールド値の最大長


## http_max_fields {#http_max_fields}

<SettingsInfoBlock type='UInt64' default_value='1000000' />

HTTPヘッダー内のフィールドの最大数


## http_max_multipart_form_data_size {#http_max_multipart_form_data_size}

<SettingsInfoBlock type='UInt64' default_value='1073741824' />

multipart/form-dataコンテンツのサイズ上限。この設定はURLパラメータから解析できないため、ユーザープロファイルで設定する必要があります。コンテンツの解析と外部テーブルのメモリ内作成は、クエリ実行開始前に行われることに注意してください。この制限は、その段階で効果を持つ唯一の制限です（最大メモリ使用量と最大実行時間の制限は、HTTPフォームデータの読み取り中には効果がありません）。


## http_max_request_param_data_size {#http_max_request_param_data_size}

<SettingsInfoBlock type='UInt64' default_value='10485760' />

事前定義されたHTTPリクエストにおいて、クエリパラメータとして使用されるリクエストデータのサイズの上限。


## http_max_tries {#http_max_tries}

<SettingsInfoBlock type='UInt64' default_value='10' />

HTTP経由での読み取りの最大試行回数。


## http_max_uri_size {#http_max_uri_size}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

HTTPリクエストのURIの最大長を設定します。

設定可能な値:

- 正の整数


## http_native_compression_disable_checksumming_on_decompress {#http_native_compression_disable_checksumming_on_decompress}

<SettingsInfoBlock type='Bool' default_value='0' />

クライアントからのHTTP POSTデータを解凍する際のチェックサム検証を有効または無効にします。ClickHouseネイティブ圧縮形式でのみ使用されます（`gzip`または`deflate`では使用されません）。

詳細については、[HTTPインターフェースの説明](../../interfaces/http.md)を参照してください。

設定可能な値:

- 0 — 無効。
- 1 — 有効。


## http_receive_timeout {#http_receive_timeout}

<SettingsInfoBlock type='Seconds' default_value='30' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.6" },
        { label: "30" },
        { label: "http_send_timeoutを参照。" }
      ]
    }
  ]}
/>

HTTP受信タイムアウト（秒単位）。

設定可能な値：

- 任意の正の整数
- 0 - 無効（無限タイムアウト）


## http_response_buffer_size {#http_response_buffer_size}

<SettingsInfoBlock type='UInt64' default_value='0' />

HTTPレスポンスをクライアントに送信する前、またはディスクにフラッシュする前（http_wait_end_of_queryが有効な場合）にサーバーメモリにバッファリングするバイト数。


## http_response_headers {#http_response_headers}

<SettingsInfoBlock type='Map' default_value='{}' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.12" }, { label: "" }, { label: "新しい設定。" }]
    }
  ]}
/>

クエリが正常に実行された際に、サーバーがレスポンスで返すHTTPヘッダーを追加または上書きできます。
この設定はHTTPインターフェースにのみ影響します。

ヘッダーがデフォルトで既に設定されている場合、指定された値で上書きされます。
ヘッダーがデフォルトで設定されていない場合、ヘッダーのリストに追加されます。
サーバーによってデフォルトで設定され、この設定で上書きされていないヘッダーは、そのまま保持されます。

この設定では、ヘッダーを定数値に設定できます。現在、ヘッダーを動的に計算された値に設定する方法はありません。

名前と値のいずれもASCII制御文字を含めることはできません。

ユーザーが設定を変更できるUIアプリケーションを実装し、同時に返されたヘッダーに基づいて判断を行う場合は、この設定を読み取り専用に制限することを推奨します。

例: `SET http_response_headers = '{"Content-Type": "image/png"}'`


## http_retry_initial_backoff_ms {#http_retry_initial_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='100' />

HTTP経由の読み取り再試行時のバックオフ最小ミリ秒数


## http_retry_max_backoff_ms {#http_retry_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='10000' />

HTTP経由の読み取り再試行時のバックオフの最大ミリ秒数


## http_send_timeout {#http_send_timeout}

<SettingsInfoBlock type='Seconds' default_value='30' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.6" },
        { label: "30" },
        {
          label:
            "3分は非常に長い値です。これは単一のネットワーク書き込み呼び出しに対するタイムアウトであり、アップロード操作全体に対するものではないことに注意してください。"
        }
      ]
    }
  ]}
/>

HTTP送信タイムアウト（秒単位）。

設定可能な値：

- 任意の正の整数。
- 0 - 無効（タイムアウトなし）。

:::note
この設定はデフォルトプロファイルにのみ適用されます。変更を有効にするには、サーバーの再起動が必要です。
:::


## http_skip_not_found_url_for_globs {#http_skip_not_found_url_for_globs}

<SettingsInfoBlock type='Bool' default_value='1' />

HTTP_NOT_FOUNDエラーが発生したグロブのURLをスキップする


## http_wait_end_of_query {#http_wait_end_of_query}

<SettingsInfoBlock type='Bool' default_value='0' />

サーバー側でHTTPレスポンスのバッファリングを有効にします。


## http_write_exception_in_output_format {#http_write_exception_in_output_format}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "0" },
        { label: "形式間の一貫性のために変更" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "23.9" },
        { label: "1" },
        { label: "HTTPストリーミング中の例外発生時に有効なJSON/XMLを出力" }
      ]
    }
  ]}
/>

例外を出力フォーマットに書き込み、有効な出力を生成します。JSONおよびXML形式で機能します。


## http_zlib_compression_level {#http_zlib_compression_level}

<SettingsInfoBlock type='Int64' default_value='3' />

[enable_http_compression = 1](#enable_http_compression)の場合、HTTPリクエストに対するレスポンスのデータ圧縮レベルを設定します。

指定可能な値: 1から9までの数値。


## iceberg_delete_data_on_drop {#iceberg_delete_data_on_drop}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "New setting" }]
    }
  ]}
/>

ドロップ時にすべてのIcebergファイルを削除するかどうかを指定します。


## iceberg_insert_max_bytes_in_data_file {#iceberg_insert_max_bytes_in_data_file}

<SettingsInfoBlock type='UInt64' default_value='1073741824' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.9" },
        { label: "1073741824" },
        { label: "新しい設定。" }
      ]
    }
  ]}
/>

INSERT操作時のIceberg Parquetデータファイルの最大バイト数。


## iceberg_insert_max_partitions {#iceberg_insert_max_partitions}

<SettingsInfoBlock type='UInt64' default_value='100' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "100" }, { label: "新しい設定。" }]
    }
  ]}
/>

Icebergテーブルエンジンの1回の挿入操作で許可されるパーティション数の上限。


## iceberg_insert_max_rows_in_data_file {#iceberg_insert_max_rows_in_data_file}

<SettingsInfoBlock type='UInt64' default_value='1000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.9" },
        { label: "1000000" },
        { label: "新しい設定。" }
      ]
    }
  ]}
/>

INSERT操作時のIceberg Parquetデータファイルの最大行数。


## iceberg_metadata_compression_method {#iceberg_metadata_compression_method}

<ExperimentalBadge />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "" }, { label: "New setting" }]
    }
  ]}
/>

`.metadata.json` ファイルの圧縮方式。


## iceberg_metadata_log_level {#iceberg_metadata_log_level}

<SettingsInfoBlock type='IcebergMetadataLogLevel' default_value='none' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "none" }, { label: "新しい設定" }]
    }
  ]}
/>

Icebergテーブルのメタデータを`system.iceberg_metadata_log`に記録する際のログレベルを制御します。
通常、この設定はデバッグ目的で変更されます。

設定可能な値:

- none - メタデータログを記録しない
- metadata - ルートmetadata.jsonファイル
- manifest_list_metadata - 上記に加えて、スナップショットに対応するavroマニフェストリストからのメタデータ
- manifest_list_entry - 上記に加えて、avroマニフェストリストのエントリ
- manifest_file_metadata - 上記に加えて、走査されたavroマニフェストファイルからのメタデータ
- manifest_file_entry - 上記に加えて、走査されたavroマニフェストファイルのエントリ


## iceberg_snapshot_id {#iceberg_snapshot_id}

<SettingsInfoBlock type='Int64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

特定のスナップショットIDを使用してIcebergテーブルに対してクエリを実行します。


## iceberg_timestamp_ms {#iceberg_timestamp_ms}

<SettingsInfoBlock type='Int64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

指定したタイムスタンプ時点で有効だったスナップショットを使用してIcebergテーブルをクエリします。


## idle_connection_timeout {#idle_connection_timeout}

<SettingsInfoBlock type='UInt64' default_value='3600' />

指定された秒数経過後にアイドル状態のTCP接続を閉じるタイムアウト。

設定可能な値:

- 正の整数（0 - 0秒後に即座に閉じる）。


## ignore_cold_parts_seconds {#ignore_cold_parts_seconds}

<CloudOnlyBadge />

<SettingsInfoBlock type='Int64' default_value='0' />

ClickHouse Cloudでのみ有効です。新しいデータパーツは、事前ウォームアップされるか（[cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch)を参照）、または指定された秒数が経過するまで、SELECTクエリから除外されます。Replicated-/SharedMergeTreeでのみ利用可能です。


## ignore_data_skipping_indices {#ignore_data_skipping_indices}

クエリで使用される指定されたスキップインデックスを無視します。

以下の例を参照してください:

```sql
CREATE TABLE data
(
    key Int,
    x Int,
    y Int,
    INDEX x_idx x TYPE minmax GRANULARITY 1,
    INDEX y_idx y TYPE minmax GRANULARITY 1,
    INDEX xy_idx (x,y) TYPE minmax GRANULARITY 1
)
Engine=MergeTree()
ORDER BY key;

INSERT INTO data VALUES (1, 2, 3);

SELECT * FROM data;
SELECT * FROM data SETTINGS ignore_data_skipping_indices=''; -- クエリはCANNOT_PARSE_TEXTエラーを生成します。
SELECT * FROM data SETTINGS ignore_data_skipping_indices='x_idx'; -- 正常に動作します。
SELECT * FROM data SETTINGS ignore_data_skipping_indices='na_idx'; -- 正常に動作します。

SELECT * FROM data WHERE x = 1 AND y = 1 SETTINGS ignore_data_skipping_indices='xy_idx',force_data_skipping_indices='xy_idx' ; -- xy_idxが明示的に無視されるため、クエリはINDEX_NOT_USEDエラーを生成します。
SELECT * FROM data WHERE x = 1 AND y = 2 SETTINGS ignore_data_skipping_indices='xy_idx';
```

インデックスを無視しない場合のクエリ:

```sql
EXPLAIN indexes = 1 SELECT * FROM data WHERE x = 1 AND y = 2;

Expression ((Projection + Before ORDER BY))
  Filter (WHERE)
    ReadFromMergeTree (default.data)
    Indexes:
      PrimaryKey
        Condition: true
        Parts: 1/1
        Granules: 1/1
      Skip
        Name: x_idx
        Description: minmax GRANULARITY 1
        Parts: 0/1
        Granules: 0/1
      Skip
        Name: y_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
      Skip
        Name: xy_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
```

`xy_idx`インデックスを無視する場合:

```sql
EXPLAIN indexes = 1 SELECT * FROM data WHERE x = 1 AND y = 2 SETTINGS ignore_data_skipping_indices='xy_idx';

Expression ((Projection + Before ORDER BY))
  Filter (WHERE)
    ReadFromMergeTree (default.data)
    Indexes:
      PrimaryKey
        Condition: true
        Parts: 1/1
        Granules: 1/1
      Skip
        Name: x_idx
        Description: minmax GRANULARITY 1
        Parts: 0/1
        Granules: 0/1
      Skip
        Name: y_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
```

MergeTreeファミリーのテーブルで動作します。


## ignore_drop_queries_probability {#ignore_drop_queries_probability}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "0" },
        {
          label:
            "テスト目的で、指定された確率でサーバーのDROPクエリを無視することを許可します"
        }
      ]
    }
  ]}
/>

有効にすると、サーバーは指定された確率ですべてのDROP TABLEクエリを無視します（MemoryエンジンとJOINエンジンの場合、DROPをTRUNCATEに置き換えます）。テスト目的で使用されます


## ignore_materialized_views_with_dropped_target_table {#ignore_materialized_views_with_dropped_target_table}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "0" },
        {
          label:
            "ターゲットテーブルが削除されたマテリアライズドビューを無視するための新しい設定を追加"
        }
      ]
    }
  ]}
/>

ビューへのプッシュ時に、ターゲットテーブルが削除されたマテリアライズドビューを無視する


## ignore_on_cluster_for_replicated_access_entities_queries {#ignore_on_cluster_for_replicated_access_entities_queries}

<SettingsInfoBlock type='Bool' default_value='0' />

レプリケートされたアクセスエンティティ管理クエリのON CLUSTER句を無視します。


## ignore_on_cluster_for_replicated_named_collections_queries {#ignore_on_cluster_for_replicated_named_collections_queries}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "0" },
        {
          label:
            "レプリケートされた名前付きコレクション管理クエリのON CLUSTER句を無視します。"
        }
      ]
    }
  ]}
/>

レプリケートされた名前付きコレクション管理クエリのON CLUSTER句を無視します。


## ignore_on_cluster_for_replicated_udf_queries {#ignore_on_cluster_for_replicated_udf_queries}

<SettingsInfoBlock type='Bool' default_value='0' />

レプリケートされたUDF管理クエリのON CLUSTER句を無視します。


## implicit_select {#implicit_select}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

先頭のSELECTキーワードなしでシンプルなSELECTクエリを記述できるようにします。これにより、電卓のような使い方が簡単になります。例えば、`1 + 2`が有効なクエリとして扱われます。

`clickhouse-local`ではデフォルトで有効になっており、明示的に無効化できます。


## implicit_table_at_top_level {#implicit_table_at_top_level}

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "" },
        { label: "clickhouse-localで使用される新しい設定" }
      ]
    }
  ]}
/>

空でない場合、トップレベルでFROM句のないクエリは、system.oneの代わりにこのテーブルから読み取ります。

これはclickhouse-localで入力データ処理に使用されます。
この設定はユーザーが明示的に設定することもできますが、そのような使用方法は想定されていません。

サブクエリはこの設定の影響を受けません(スカラーサブクエリ、FROMサブクエリ、INサブクエリのいずれも該当しません)。
UNION、INTERSECT、EXCEPTチェーンのトップレベルにあるSELECTは、括弧によるグループ化に関係なく、一律にこの設定の影響を受けます。
この設定がビューや分散クエリに与える影響は未定義です。

この設定はテーブル名(この場合、テーブルは現在のデータベースから解決されます)、または'database.table'形式の修飾名を受け入れます。
データベース名とテーブル名の両方は引用符で囲まない必要があります - 単純な識別子のみが許可されます。


## implicit_transaction {#implicit_transaction}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

有効化されており、かつトランザクション内にない場合、クエリを完全なトランザクション(begin + commit または rollback)内にラップします


## inject_random_order_for_select_without_order_by {#inject_random_order_for_select_without_order_by}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

有効にすると、ORDER BY句を持たないSELECTクエリに'ORDER BY rand()'を挿入します。
サブクエリの深さが0の場合にのみ適用されます。サブクエリおよびINSERT INTO ... SELECTには影響しません。
最上位の構造がUNIONの場合、'ORDER BY rand()'は各子要素に独立して挿入されます。
テストおよび開発目的でのみ有用です(ORDER BYの欠如は非決定的なクエリ結果の原因となります)。


## input_format_parallel_parsing {#input_format_parallel_parsing}

<SettingsInfoBlock type='Bool' default_value='1' />

データフォーマットの順序保持並列解析を有効または無効にします。[TabSeparated (TSV)](/interfaces/formats/TabSeparated)、[TSKV](/interfaces/formats/TSKV)、[CSV](/interfaces/formats/CSV)、および[JSONEachRow](/interfaces/formats/JSONEachRow)フォーマットでのみサポートされています。

設定可能な値:

- 1 — 有効。
- 0 — 無効。


## insert_allow_materialized_columns {#insert_allow_materialized_columns}

<SettingsInfoBlock type='Bool' default_value='0' />

この設定を有効にすると、INSERT文でマテリアライズドカラムを使用できるようになります。


## insert_deduplicate {#insert_deduplicate}

<SettingsInfoBlock type='Bool' default_value='1' />

`INSERT`のブロック重複排除を有効または無効にします(Replicated\*テーブル用)。

設定可能な値:

- 0 — 無効。
- 1 — 有効。

デフォルトでは、`INSERT`ステートメントによってレプリケーテッドテーブルに挿入されたブロックは重複排除されます([データレプリケーション](../../engines/table-engines/mergetree-family/replication.md)を参照)。
レプリケーテッドテーブルの場合、デフォルトでは各パーティションの最新100ブロックのみが重複排除されます([replicated_deduplication_window](merge-tree-settings.md/#replicated_deduplication_window)、[replicated_deduplication_window_seconds](merge-tree-settings.md/#replicated_deduplication_window_seconds)を参照)。
非レプリケーテッドテーブルについては[non_replicated_deduplication_window](merge-tree-settings.md/#non_replicated_deduplication_window)を参照してください。


## insert_deduplication_token {#insert_deduplication_token}

この設定により、ユーザーはMergeTree/ReplicatedMergeTreeで独自の重複排除セマンティクスを提供できます。
例えば、各INSERT文でこの設定に一意の値を指定することで、
同じ挿入データが重複排除されるのを回避できます。

指定可能な値:

- 任意の文字列

`insert_deduplication_token`は、空でない場合_のみ_重複排除に使用されます。

レプリケートされたテーブルの場合、デフォルトでは各パーティションの最新100件の挿入のみが重複排除されます([replicated_deduplication_window](merge-tree-settings.md/#replicated_deduplication_window)、[replicated_deduplication_window_seconds](merge-tree-settings.md/#replicated_deduplication_window_seconds)を参照)。
レプリケートされていないテーブルについては、[non_replicated_deduplication_window](merge-tree-settings.md/#non_replicated_deduplication_window)を参照してください。

:::note
`insert_deduplication_token`はパーティションレベルで動作します(`insert_deduplication`チェックサムと同様)。複数のパーティションが同じ`insert_deduplication_token`を持つことができます。
:::

例:

```sql
CREATE TABLE test_table
( A Int64 )
ENGINE = MergeTree
ORDER BY A
SETTINGS non_replicated_deduplication_window = 100;

INSERT INTO test_table SETTINGS insert_deduplication_token = 'test' VALUES (1);

-- 次の挿入はinsert_deduplication_tokenが異なるため重複排除されません
INSERT INTO test_table SETTINGS insert_deduplication_token = 'test1' VALUES (1);

-- 次の挿入はinsert_deduplication_tokenが
-- 以前のいずれかと同じであるため重複排除されます
INSERT INTO test_table SETTINGS insert_deduplication_token = 'test' VALUES (2);

SELECT * FROM test_table

┌─A─┐
│ 1 │
└───┘
┌─A─┐
│ 1 │
└───┘
```


## insert_keeper_fault_injection_probability {#insert_keeper_fault_injection_probability}

<SettingsInfoBlock type='Float' default_value='0' />

挿入時のKeeperリクエストが失敗する確率の近似値。有効な値は区間[0.0f, 1.0f]です


## insert_keeper_fault_injection_seed {#insert_keeper_fault_injection_seed}

<SettingsInfoBlock type='UInt64' default_value='0' />

0 - ランダムシード、それ以外は設定値


## insert_keeper_max_retries {#insert_keeper_max_retries}

<SettingsInfoBlock type='UInt64' default_value='20' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.2" },
        { label: "20" },
        {
          label: "INSERT時のKeeperへの再接続を有効化し、信頼性を向上"
        }
      ]
    }
  ]}
/>

この設定は、レプリケートされたMergeTreeへの挿入時におけるClickHouse Keeper(またはZooKeeper)リクエストの最大再試行回数を設定します。ネットワークエラー、Keeperセッションタイムアウト、またはリクエストタイムアウトにより失敗したKeeperリクエストのみが再試行の対象となります。

設定可能な値:

- 正の整数
- 0 — 再試行は無効

Cloudのデフォルト値: `20`

Keeperリクエストの再試行は、一定のタイムアウト後に実行されます。タイムアウトは次の設定によって制御されます: `insert_keeper_retry_initial_backoff_ms`、`insert_keeper_retry_max_backoff_ms`。
最初の再試行は`insert_keeper_retry_initial_backoff_ms`のタイムアウト後に実行されます。以降のタイムアウトは次のように計算されます:

```
timeout = min(insert_keeper_retry_max_backoff_ms, latest_timeout * 2)
```

例えば、`insert_keeper_retry_initial_backoff_ms=100`、`insert_keeper_retry_max_backoff_ms=10000`、`insert_keeper_max_retries=8`の場合、タイムアウトは`100, 200, 400, 800, 1600, 3200, 6400, 10000`となります。

耐障害性に加えて、再試行はより良いユーザー体験を提供することを目的としています。例えば、アップグレードによりKeeperが再起動された場合でも、INSERT実行中にエラーを返すことを回避できます。


## insert_keeper_retry_initial_backoff_ms {#insert_keeper_retry_initial_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='100' />

INSERT クエリ実行中に失敗した Keeper リクエストを再試行するための初期バックオフ時間（ミリ秒単位）

設定可能な値:

- 正の整数
- 0 — バックオフなし


## insert_keeper_retry_max_backoff_ms {#insert_keeper_retry_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='10000' />

INSERT クエリ実行中に失敗した Keeper リクエストを再試行する際の最大タイムアウト（ミリ秒）

設定可能な値:

- 正の整数
- 0 — 最大タイムアウトは制限なし


## insert_null_as_default {#insert_null_as_default}

<SettingsInfoBlock type='Bool' default_value='1' />

[nullable](/sql-reference/data-types/nullable)でないデータ型のカラムに対して、[NULL](/sql-reference/syntax#null)の代わりに[デフォルト値](/sql-reference/statements/create/table#default_values)を挿入するかどうかを有効または無効にします。
カラムの型がnullableでなく、この設定が無効の場合、`NULL`を挿入すると例外が発生します。カラムの型がnullableの場合、この設定に関係なく`NULL`値はそのまま挿入されます。

この設定は[INSERT ... SELECT](../../sql-reference/statements/insert-into.md/#inserting-the-results-of-select)クエリに適用されます。`SELECT`サブクエリは`UNION ALL`句で連結できることに注意してください。

設定可能な値:

- 0 — nullableでないカラムに`NULL`を挿入すると例外が発生します。
- 1 — `NULL`の代わりにカラムのデフォルト値が挿入されます。


## insert_quorum {#insert_quorum}

<SettingsInfoBlock type='UInt64Auto' default_value='0' />

:::note
この設定はSharedMergeTreeには適用されません。詳細については[SharedMergeTreeの一貫性](/cloud/reference/shared-merge-tree#consistency)を参照してください。
:::

クォーラム書き込みを有効にします。

- `insert_quorum < 2`の場合、クォーラム書き込みは無効になります。
- `insert_quorum >= 2`の場合、クォーラム書き込みは有効になります。
- `insert_quorum = 'auto'`の場合、過半数(`number_of_replicas / 2 + 1`)をクォーラム数として使用します。

クォーラム書き込み

`INSERT`は、`insert_quorum_timeout`の期間内にClickHouseが`insert_quorum`で指定された数のレプリカにデータを正しく書き込めた場合にのみ成功します。何らかの理由で書き込みに成功したレプリカの数が`insert_quorum`に達しない場合、書き込みは失敗したと見なされ、ClickHouseはデータが既に書き込まれたすべてのレプリカから挿入されたブロックを削除します。

`insert_quorum_parallel`が無効の場合、クォーラム内のすべてのレプリカは一貫性を保ちます。つまり、以前のすべての`INSERT`クエリからのデータを含んでいます(`INSERT`シーケンスは線形化されます)。`insert_quorum`を使用して書き込まれたデータを読み取る際に`insert_quorum_parallel`が無効の場合、[select_sequential_consistency](#select_sequential_consistency)を使用して`SELECT`クエリの順次一貫性を有効にすることができます。

ClickHouseは次の場合に例外を生成します:

- クエリ実行時に利用可能なレプリカの数が`insert_quorum`未満の場合。
- `insert_quorum_parallel`が無効で、前のブロックがまだ`insert_quorum`で指定された数のレプリカに挿入されていない状態でデータの書き込みが試みられた場合。この状況は、ユーザーが`insert_quorum`を指定した前の`INSERT`クエリが完了する前に、同じテーブルに対して別の`INSERT`クエリを実行しようとした場合に発生する可能性があります。

関連項目:

- [insert_quorum_timeout](#insert_quorum_timeout)
- [insert_quorum_parallel](#insert_quorum_parallel)
- [select_sequential_consistency](#select_sequential_consistency)


## insert_quorum_parallel {#insert_quorum_parallel}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.1" },
        { label: "1" },
        {
          label:
            "デフォルトで並列クォーラム挿入を使用します。順次クォーラム挿入よりも大幅に使いやすくなっています"
        }
      ]
    }
  ]}
/>

:::note
この設定はSharedMergeTreeには適用されません。詳細については[SharedMergeTreeの整合性](/cloud/reference/shared-merge-tree#consistency)を参照してください。
:::

クォーラム`INSERT`クエリの並列実行を有効または無効にします。有効にすると、前のクエリが完了していない間でも追加の`INSERT`クエリを送信できます。無効にすると、同じテーブルへの追加の書き込みは拒否されます。

設定可能な値:

- 0 — 無効。
- 1 — 有効。

関連項目:

- [insert_quorum](#insert_quorum)
- [insert_quorum_timeout](#insert_quorum_timeout)
- [select_sequential_consistency](#select_sequential_consistency)


## insert_quorum_timeout {#insert_quorum_timeout}

<SettingsInfoBlock type='Milliseconds' default_value='600000' />

クォーラムへの書き込みタイムアウトをミリ秒単位で指定します。タイムアウトが経過しても書き込みが完了していない場合、ClickHouseは例外を生成し、クライアントは同じブロックを同じレプリカまたは別のレプリカに書き込むためにクエリを再実行する必要があります。

関連項目：

- [insert_quorum](#insert_quorum)
- [insert_quorum_parallel](#insert_quorum_parallel)
- [select_sequential_consistency](#select_sequential_consistency)


## insert_shard_id {#insert_shard_id}

<SettingsInfoBlock type='UInt64' default_value='0' />

`0`以外の場合、データが同期的に挿入される[Distributed](/engines/table-engines/special/distributed)テーブルのシャードを指定します。

`insert_shard_id`の値が不正な場合、サーバーは例外をスローします。

`requested_cluster`のシャード数を取得するには、サーバー設定を確認するか、以下のクエリを使用します:

```sql
SELECT uniq(shard_num) FROM system.clusters WHERE cluster = 'requested_cluster';
```

設定可能な値:

- 0 — 無効。
- 対応する[Distributed](/engines/table-engines/special/distributed)テーブルの`shards_num`に応じた`1`から`shards_num`までの任意の数値。

**例**

クエリ:

```sql
CREATE TABLE x AS system.numbers ENGINE = MergeTree ORDER BY number;
CREATE TABLE x_dist AS x ENGINE = Distributed('test_cluster_two_shards_localhost', currentDatabase(), x);
INSERT INTO x_dist SELECT * FROM numbers(5) SETTINGS insert_shard_id = 1;
SELECT * FROM x_dist ORDER BY number ASC;
```

結果:

```text
┌─number─┐
│      0 │
│      0 │
│      1 │
│      1 │
│      2 │
│      2 │
│      3 │
│      3 │
│      4 │
│      4 │
└────────┘
```


## interactive_delay {#interactive_delay}

<SettingsInfoBlock type='UInt64' default_value='100000' />

リクエストの実行がキャンセルされたかどうかを確認し、進捗状況を送信する間隔(マイクロ秒単位)。


## intersect_default_mode {#intersect_default_mode}

<SettingsInfoBlock type='SetOperationMode' default_value='ALL' />

INTERSECTクエリのデフォルトモードを設定します。設定可能な値：空文字列、'ALL'、'DISTINCT'。空文字列の場合、モードを指定しないクエリは例外をスローします。


## jemalloc_collect_profile_samples_in_trace_log {#jemalloc_collect_profile_samples_in_trace_log}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

トレースログにjemallocのメモリ割り当ておよび解放のサンプルを収集します。


## jemalloc_enable_profiler {#jemalloc_enable_profiler}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

クエリに対してjemallocプロファイラを有効にします。jemallocはメモリ割り当てをサンプリングし、サンプリングされた割り当てに対するすべての解放をサンプリングします。
プロファイルはSYSTEM JEMALLOC FLUSH PROFILEを使用してフラッシュでき、メモリ割り当ての分析に使用できます。
サンプルは、設定jemalloc_collect_global_profile_samples_in_trace_logを使用するか、クエリ設定jemalloc_collect_profile_samples_in_trace_logを使用してsystem.trace_logに保存することもできます。
[メモリ割り当てプロファイリング](/operations/allocation-profiling)を参照してください


## join_algorithm {#join_algorithm}

<SettingsInfoBlock
  type='JoinAlgorithm'
  default_value='direct,parallel_hash,hash'
/>

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "direct,parallel_hash,hash" },
        {
          label:
            "'default'は明示的に指定された結合アルゴリズムを優先するため非推奨となり、parallel_hashがhashよりも優先されるようになりました"
        }
      ]
    }
  ]}
/>

使用する[JOIN](../../sql-reference/statements/select/join.md)アルゴリズムを指定します。

複数のアルゴリズムを指定でき、特定のクエリに対して結合の種類/厳密性とテーブルエンジンに基づいて利用可能なものが選択されます。

指定可能な値:

- grace_hash

[Grace hash join](https://en.wikipedia.org/wiki/Hash_join#Grace_hash_join)が使用されます。Grace hashは、メモリ使用量を制限しながら高性能な複雑な結合を実現するアルゴリズムオプションです。

grace joinの最初のフェーズでは、右テーブルを読み取り、キー列のハッシュ値に応じてN個のバケットに分割します(初期値として、Nは`grace_hash_join_initial_buckets`です)。これは各バケットが独立して処理できるように行われます。最初のバケットの行はインメモリハッシュテーブルに追加され、その他はディスクに保存されます。ハッシュテーブルがメモリ制限(例えば[`max_bytes_in_join`](/operations/settings/settings#max_bytes_in_join)で設定された値)を超えた場合、バケット数が増加し、各行に割り当てられるバケットが変更されます。現在のバケットに属さない行はフラッシュされ、再割り当てされます。

`INNER/LEFT/RIGHT/FULL ALL/ANY JOIN`をサポートします。

- hash

[Hash joinアルゴリズム](https://en.wikipedia.org/wiki/Hash_join)が使用されます。すべての結合の種類と厳密性の組み合わせ、および`JOIN ON`セクションで`OR`で結合された複数の結合キーをサポートする最も汎用的な実装です。

`hash`アルゴリズムを使用する場合、`JOIN`の右側部分がRAMにロードされます。

- parallel_hash

データをバケットに分割し、1つではなく複数のハッシュテーブルを同時に構築してこのプロセスを高速化する`hash` joinの変種です。

`parallel_hash`アルゴリズムを使用する場合、`JOIN`の右側部分がRAMにロードされます。

- partial_merge

[sort-mergeアルゴリズム](https://en.wikipedia.org/wiki/Sort-merge_join)の変種で、右テーブルのみが完全にソートされます。

`RIGHT JOIN`と`FULL JOIN`は`ALL`厳密性でのみサポートされます(`SEMI`、`ANTI`、`ANY`、`ASOF`はサポートされません)。

`partial_merge`アルゴリズムを使用する場合、ClickHouseはデータをソートしてディスクにダンプします。ClickHouseの`partial_merge`アルゴリズムは、従来の実装とわずかに異なります。まず、ClickHouseはブロック単位で結合キーによって右テーブルをソートし、ソート済みブロックのmin-maxインデックスを作成します。次に、左テーブルの一部を`join key`でソートし、右テーブルと結合します。min-maxインデックスは、不要な右テーブルブロックをスキップするためにも使用されます。

- direct

このアルゴリズムは、右テーブルのストレージがキーバリューリクエストをサポートしている場合に適用できます。

`direct`アルゴリズムは、左テーブルの行をキーとして使用して右テーブルでルックアップを実行します。[Dictionary](/engines/table-engines/special/dictionary)や[EmbeddedRocksDB](../../engines/table-engines/integrations/embedded-rocksdb.md)などの特殊なストレージでのみサポートされ、`LEFT`と`INNER` JOINのみが対象です。

- auto

`auto`に設定すると、最初に`hash` joinが試行され、メモリ制限に違反した場合は実行中に別のアルゴリズムに切り替えられます。

- full_sorting_merge

結合前に結合テーブルを完全にソートする[sort-mergeアルゴリズム](https://en.wikipedia.org/wiki/Sort-merge_join)です。

- prefer_partial_merge

ClickHouseは可能な限り常に`partial_merge` joinを使用しようとし、それ以外の場合は`hash`を使用します。_非推奨_、`partial_merge,hash`と同じです。

- default (deprecated)

レガシー値です。今後は使用しないでください。
`direct,hash`と同じで、direct joinとhash joinを(この順序で)使用しようとします。


## join_any_take_last_row {#join_any_take_last_row}

<SettingsInfoBlock type='Bool' default_value='0' />

`ANY`厳密性を持つ結合操作の動作を変更します。

:::note
この設定は[Join](../../engines/table-engines/special/join.md)エンジンテーブルを使用した`JOIN`操作にのみ適用されます。
:::

設定可能な値:

- 0 — 右側のテーブルに複数の一致する行がある場合、最初に見つかった行のみが結合されます。
- 1 — 右側のテーブルに複数の一致する行がある場合、最後に見つかった行のみが結合されます。

関連項目:

- [JOIN句](/sql-reference/statements/select/join)
- [Joinテーブルエンジン](../../engines/table-engines/special/join.md)
- [join_default_strictness](#join_default_strictness)


## join_default_strictness {#join_default_strictness}

<SettingsInfoBlock type='JoinStrictness' default_value='ALL' />

[JOIN句](/sql-reference/statements/select/join)のデフォルトの厳密性を設定します。

指定可能な値:

- `ALL` — 右側のテーブルに複数の一致する行がある場合、ClickHouseは一致する行から[直積](https://en.wikipedia.org/wiki/Cartesian_product)を作成します。これは標準SQLにおける通常の`JOIN`の動作です。
- `ANY` — 右側のテーブルに複数の一致する行がある場合、最初に見つかった行のみが結合されます。右側のテーブルに一致する行が1つしかない場合、`ANY`と`ALL`の結果は同じになります。
- `ASOF` — 不確実な一致を持つシーケンスを結合する際に使用します。
- `空文字列` — クエリで`ALL`または`ANY`が指定されていない場合、ClickHouseは例外をスローします。


## join_on_disk_max_files_to_merge {#join_on_disk_max_files_to_merge}

<SettingsInfoBlock type='UInt64' default_value='64' />

ディスク上で実行されるMergeJoin操作において、並列ソートに許可されるファイル数を制限します。

設定値を大きくするほど、使用されるRAMは増加し、必要なディスクI/Oは減少します。

設定可能な値:

- 2以上の任意の正の整数。


## join_output_by_rowlist_perkey_rows_threshold {#join_output_by_rowlist_perkey_rows_threshold}

<SettingsInfoBlock type='UInt64' default_value='5' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "5" },
        {
          label:
            "ハッシュ結合において行リストによる出力を行うかどうかを判断するための、右テーブルのキーごとの平均行数の下限値。"
        }
      ]
    }
  ]}
/>

ハッシュ結合において行リストによる出力を行うかどうかを判断するための、右テーブルのキーごとの平均行数の下限値。


## join_overflow_mode {#join_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

以下のいずれかの結合制限に達した際にClickHouseが実行する動作を定義します:

- [max_bytes_in_join](/operations/settings/settings#max_bytes_in_join)
- [max_rows_in_join](/operations/settings/settings#max_rows_in_join)

設定可能な値:

- `THROW` — ClickHouseは例外をスローし、操作を中断します。
- `BREAK` — ClickHouseは操作を中断しますが、例外をスローしません。

デフォルト値: `THROW`

**関連項目**

- [JOIN句](/sql-reference/statements/select/join)
- [Joinテーブルエンジン](/engines/table-engines/special/join)


## join_runtime_bloom_filter_bytes {#join_runtime_bloom_filter_bytes}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='524288' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "524288" }, { label: "新規設定" }]
    }
  ]}
/>

JOINランタイムフィルタとして使用されるブルームフィルタのサイズ(バイト単位)(enable_join_runtime_filters設定を参照してください)。


## join_runtime_bloom_filter_hash_functions {#join_runtime_bloom_filter_hash_functions}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='3' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "3" }, { label: "新しい設定" }]
    }
  ]}
/>

JOINランタイムフィルタとして使用されるブルームフィルタのハッシュ関数の数（enable_join_runtime_filters設定を参照してください）。


## join_runtime_filter_exact_values_limit {#join_runtime_filter_exact_values_limit}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='10000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "10000" }, { label: "New setting" }]
    }
  ]}
/>

ランタイムフィルタ内でセットとしてそのまま格納される要素の最大数。この閾値を超えた場合、ブルームフィルタに切り替わります。


## join_to_sort_maximum_table_rows {#join_to_sort_maximum_table_rows}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='10000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "10000" },
        {
          label:
            "LEFT JOINまたはINNER JOINにおいて、右テーブルをキーで再配置するかどうかを判断するための右テーブルの最大行数"
        }
      ]
    }
  ]}
/>

LEFT JOINまたはINNER JOINにおいて、右テーブルをキーで再配置するかどうかを判断するための右テーブルの最大行数.


## join_to_sort_minimum_perkey_rows {#join_to_sort_minimum_perkey_rows}

<ExperimentalBadge />

<SettingsInfoBlock type='UInt64' default_value='40' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "40" },
        {
          label:
            "左結合または内部結合において、右テーブルをキーで再配置するかどうかを判断するための、右テーブルにおけるキーあたりの平均行数の下限値。この設定により、疎なテーブルキーに対して最適化が適用されないことが保証されます"
        }
      ]
    }
  ]}
/>

左結合または内部結合において、右テーブルをキーで再配置するかどうかを判断するための、右テーブルにおけるキーあたりの平均行数の下限値。この設定により、疎なテーブルキーに対して最適化が適用されないことが保証されます


## join_use_nulls {#join_use_nulls}

<SettingsInfoBlock type='Bool' default_value='0' />

[JOIN](../../sql-reference/statements/select/join.md)の動作タイプを設定します。テーブルを結合する際、空のセルが発生する場合があります。ClickHouseはこの設定に基づいて、それらを異なる方法で埋めます。

設定可能な値:

- 0 — 空のセルは、対応するフィールド型のデフォルト値で埋められます。
- 1 — `JOIN`は標準SQLと同じ動作をします。対応するフィールドの型は[Nullable](/sql-reference/data-types/nullable)に変換され、空のセルは[NULL](/sql-reference/syntax)で埋められます。


## joined_block_split_single_row {#joined_block_split_single_row}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

左テーブルの単一行に対応する行ごとにハッシュ結合結果を分割できるようにします。
右テーブルに多数の一致がある行の場合、メモリ使用量を削減できる可能性がありますが、CPU使用率が増加する場合があります。
この設定を有効にするには、`max_joined_block_size_rows != 0` の指定が必須です。
この設定と `max_joined_block_size_bytes` を組み合わせることで、右テーブルに多数の一致を持つ大きな行を含む偏ったデータの場合に、過度なメモリ使用を回避できます。


## joined_subquery_requires_alias {#joined_subquery_requires_alias}

<SettingsInfoBlock type='Bool' default_value='1' />

結合されたサブクエリとテーブル関数に対して、正しい名前修飾のためにエイリアスを必須とします。


## kafka_disable_num_consumers_limit {#kafka_disable_num_consumers_limit}

<SettingsInfoBlock type='Bool' default_value='0' />

利用可能なCPUコア数に依存する kafka_num_consumers の制限を無効にします。


## kafka_max_wait_ms {#kafka_max_wait_ms}

<SettingsInfoBlock type='Milliseconds' default_value='5000' />

再試行前に[Kafka](/engines/table-engines/integrations/kafka)からメッセージを読み取る際の待機時間(ミリ秒)。

設定可能な値:

- 正の整数
- 0 — 無限タイムアウト

関連項目:

- [Apache Kafka](https://kafka.apache.org/)


## keeper_map_strict_mode {#keeper_map_strict_mode}

<SettingsInfoBlock type='Bool' default_value='0' />

KeeperMapの操作時に追加のチェックを強制します。例：既に存在するキーに対する挿入時に例外をスローします


## keeper_max_retries {#keeper_max_retries}

<SettingsInfoBlock type='UInt64' default_value='10' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "10" },
        { label: "一般的なKeeper操作の最大リトライ回数" }
      ]
    }
  ]}
/>

一般的なKeeper操作の最大リトライ回数


## keeper_retry_initial_backoff_ms {#keeper_retry_initial_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='100' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "100" },
        { label: "一般的なkeeper操作の初期バックオフタイムアウト" }
      ]
    }
  ]}
/>

一般的なkeeper操作の初期バックオフタイムアウト


## keeper_retry_max_backoff_ms {#keeper_retry_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='5000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "5000" },
        { label: "一般的なkeeper操作の最大バックオフタイムアウト" }
      ]
    }
  ]}
/>

一般的なkeeper操作の最大バックオフタイムアウト


## least_greatest_legacy_null_behavior {#least_greatest_legacy_null_behavior}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.12" }, { label: "0" }, { label: "New setting" }]
    }
  ]}
/>

有効にすると、関数 `least` および `greatest` は、いずれかの引数が NULL の場合に NULL を返します。


## legacy_column_name_of_tuple_literal {#legacy_column_name_of_tuple_literal}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.7" },
        { label: "0" },
        {
          label:
            "この設定は互換性のためにのみ追加されます。クラスタをバージョン21.7未満から21.7以降へローリングアップデートする際は、'true'に設定することを推奨します"
        }
      ]
    }
  ]}
/>

大きなタプルリテラルの要素名を、ハッシュではなくカラム名としてすべて列挙します。この設定は互換性のためにのみ存在します。クラスタをバージョン21.7未満から21.7以降へローリングアップデートする際は、'true'に設定することを推奨します。


## lightweight_delete_mode {#lightweight_delete_mode}

<SettingsInfoBlock type='LightweightDeleteMode' default_value='alter_update' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "alter_update" },
        { label: "新しい設定" }
      ]
    }
  ]}
/>

軽量削除の一部として実行される内部更新クエリのモード。

設定可能な値:

- `alter_update` - 重量級ミューテーションを作成する`ALTER UPDATE`クエリを実行します。
- `lightweight_update` - 可能な場合は軽量更新を実行し、それ以外の場合は`ALTER UPDATE`を実行します。
- `lightweight_update_force` - 可能な場合は軽量更新を実行し、それ以外の場合は例外をスローします。


## lightweight_deletes_sync {#lightweight_deletes_sync}

<SettingsInfoBlock type='UInt64' default_value='2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "2" },
        {
          label:
            "'mutation_sync'と同じですが、軽量削除の実行のみを制御します"
        }
      ]
    }
  ]}
/>

[`mutations_sync`](#mutations_sync)と同じですが、軽量削除の実行のみを制御します。

設定可能な値:

| 値 | 説明                                                                                                                                            |
| ----- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `0`   | ミューテーションは非同期で実行されます。                                                                                                                      |
| `1`   | クエリは現在のサーバー上で軽量削除が完了するまで待機します。                                                                         |
| `2`   | クエリはすべてのレプリカ(存在する場合)で軽量削除が完了するまで待機します。                                                               |
| `3`   | クエリはアクティブなレプリカのみを待機します。`SharedMergeTree`でのみサポートされます。`ReplicatedMergeTree`では`mutations_sync = 2`と同じ動作をします。 |

**関連項目**

- [ALTERクエリの同期性](../../sql-reference/statements/alter/index.md/#synchronicity-of-alter-queries)
- [ミューテーション](../../sql-reference/statements/alter/index.md/#mutations)


## limit {#limit}

<SettingsInfoBlock type='UInt64' default_value='0' />

クエリ結果から取得する行の最大数を設定します。[LIMIT](/sql-reference/statements/select/limit)句で設定された値を調整し、クエリで指定された制限値がこの設定で設定された制限値を超えないようにします。

設定可能な値:

- 0 — 行数は制限されません。
- 正の整数


## load_balancing {#load_balancing}

<SettingsInfoBlock type='LoadBalancing' default_value='random' />

分散クエリ処理で使用されるレプリカ選択アルゴリズムを指定します。

ClickHouseは以下のレプリカ選択アルゴリズムをサポートしています:

- [Random](#load_balancing-random) (デフォルト)
- [Nearest hostname](#load_balancing-nearest_hostname)
- [Hostname levenshtein distance](#load_balancing-hostname_levenshtein_distance)
- [In order](#load_balancing-in_order)
- [First or random](#load_balancing-first_or_random)
- [Round robin](#load_balancing-round_robin)

関連項目:

- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)

### Random (デフォルト) {#load_balancing-random}

```sql
load_balancing = random
```

各レプリカのエラー数がカウントされます。クエリは最もエラーが少ないレプリカに送信され、該当するレプリカが複数ある場合はそのいずれかに送信されます。
欠点: サーバーの近接性が考慮されません。レプリカが異なるデータを持つ場合、異なるデータが返されます。

### Nearest Hostname {#load_balancing-nearest_hostname}

```sql
load_balancing = nearest_hostname
```

各レプリカのエラー数がカウントされます。5分ごとにエラー数は2で除算されます。これにより、指数平滑化を用いて直近の時間帯のエラー数が計算されます。最小のエラー数を持つレプリカが1つある場合(つまり、他のレプリカで最近エラーが発生した場合)、クエリはそのレプリカに送信されます。同じ最小エラー数を持つレプリカが複数ある場合、クエリは設定ファイル内のサーバーのホスト名に最も類似したホスト名を持つレプリカに送信されます(両ホスト名の最小長までの同一位置における異なる文字数で判定)。

例えば、example01-01-1とexample01-01-2は1箇所が異なり、example01-01-1とexample01-02-2は2箇所が異なります。
この方法は原始的に見えるかもしれませんが、ネットワークトポロジーに関する外部データを必要とせず、IPv6アドレスでは複雑になるIPアドレスの比較も行いません。

したがって、同等のレプリカがある場合、名前が最も近いものが優先されます。
また、同じサーバーにクエリを送信する場合、障害がなければ分散クエリも同じサーバーに送られると想定できます。そのため、レプリカに異なるデータが配置されていても、クエリはほぼ同じ結果を返します。

### Hostname levenshtein distance {#load_balancing-hostname_levenshtein_distance}

```sql
load_balancing = hostname_levenshtein_distance
```

`nearest_hostname`と同様ですが、ホスト名を[レーベンシュタイン距離](https://en.wikipedia.org/wiki/Levenshtein_distance)で比較します。例:

```text
example-clickhouse-0-0 ample-clickhouse-0-0
1

example-clickhouse-0-0 example-clickhouse-1-10
2

example-clickhouse-0-0 example-clickhouse-12-0
3
```

### In Order {#load_balancing-in_order}

```sql
load_balancing = in_order
```

同じエラー数を持つレプリカは、設定で指定された順序でアクセスされます。
この方法は、どのレプリカが望ましいかを正確に把握している場合に適しています。

### First or Random {#load_balancing-first_or_random}

```sql
load_balancing = first_or_random
```

このアルゴリズムは、セット内の最初のレプリカを選択し、最初のレプリカが利用できない場合はランダムなレプリカを選択します。クロスレプリケーショントポロジー構成では効果的ですが、他の構成では有用ではありません。

`first_or_random`アルゴリズムは`in_order`アルゴリズムの問題を解決します。`in_order`では、1つのレプリカがダウンすると、次のレプリカが2倍の負荷を受け、残りのレプリカは通常量のトラフィックを処理します。`first_or_random`アルゴリズムを使用すると、利用可能なレプリカ間で負荷が均等に分散されます。

`load_balancing_first_offset`設定を使用して、最初のレプリカを明示的に定義することができます。これにより、レプリカ間でクエリワークロードを再分散する制御が強化されます。

### Round Robin {#load_balancing-round_robin}

```sql
load_balancing = round_robin
```

このアルゴリズムは、同じエラー数を持つレプリカ間でラウンドロビンポリシーを使用します(`round_robin`ポリシーを持つクエリのみがカウントされます)。


## load_balancing_first_offset {#load_balancing_first_offset}

<SettingsInfoBlock type='UInt64' default_value='0' />

FIRST_OR_RANDOM負荷分散戦略が使用される場合に、優先的にクエリを送信するレプリカを指定します。


## load_marks_asynchronously {#load_marks_asynchronously}

<SettingsInfoBlock type='Bool' default_value='0' />

MergeTreeマークを非同期で読み込みます


## local_filesystem_read_method {#local_filesystem_read_method}

<SettingsInfoBlock type='String' default_value='pread_threadpool' />

ローカルファイルシステムからデータを読み取る方法。read、pread、mmap、io_uring、pread_threadpoolのいずれかを指定します。

'io_uring'メソッドは実験的機能であり、同時読み取りと書き込みが発生する環境下では、Log、TinyLog、StripeLog、File、Set、Joinテーブル、および追記可能なファイルを持つその他のテーブルでは動作しません。
インターネット上で'io_uring'に関する様々な記事を読んでも、それらに惑わされないでください。大量の小規模なIOリクエストが発生する場合を除き、ファイル読み取りの優れた方法とは言えません。ClickHouseではそのようなケースには該当しません。'io_uring'を有効にする理由はありません。


## local_filesystem_read_prefetch {#local_filesystem_read_prefetch}

<SettingsInfoBlock type='Bool' default_value='0' />

ローカルファイルシステムからデータを読み取る際にプリフェッチを使用するかどうか。


## lock_acquire_timeout {#lock_acquire_timeout}

<SettingsInfoBlock type='Seconds' default_value='120' />

ロック取得要求が失敗するまでの待機時間を秒単位で定義します。

ロックタイムアウトは、テーブルに対する読み取り/書き込み操作の実行中にデッドロックを防ぐために使用されます。タイムアウトが経過してロック要求が失敗すると、ClickHouseサーバーはエラーコード`DEADLOCK_AVOIDED`とともに例外「Locking attempt timed out! Possible deadlock avoided. Client should retry.」をスローします。

設定可能な値:

- 正の整数(秒単位)。
- 0 — ロックタイムアウトなし。


## log_comment {#log_comment}

[system.query_log](../system-tables/query_log.md)テーブルの`log_comment`フィールドの値と、サーバーログのコメントテキストを指定します。

サーバーログの可読性を向上させるために使用できます。また、[clickhouse-test](../../development/tests.md)の実行後に、`system.query_log`からテストに関連するクエリを選択する際にも役立ちます。

設定可能な値:

- [max_query_size](#max_query_size)以下の任意の文字列。max_query_sizeを超えた場合、サーバーは例外をスローします。

**例**

クエリ:

```sql
SET log_comment = 'log_comment test', log_queries = 1;
SELECT 1;
SYSTEM FLUSH LOGS;
SELECT type, query FROM system.query_log WHERE log_comment = 'log_comment test' AND event_date >= yesterday() ORDER BY event_time DESC LIMIT 2;
```

結果:

```text
┌─type────────┬─query─────┐
│ QueryStart  │ SELECT 1; │
│ QueryFinish │ SELECT 1; │
└─────────────┴───────────┘
```


## log_formatted_queries {#log_formatted_queries}

<SettingsInfoBlock type='Bool' default_value='0' />

フォーマット済みクエリを[system.query_log](../../operations/system-tables/query_log.md)システムテーブルに記録します([system.query_log](../../operations/system-tables/query_log.md)の`formatted_query`カラムに格納されます)。

設定可能な値:

- 0 — フォーマット済みクエリはシステムテーブルに記録されません。
- 1 — フォーマット済みクエリはシステムテーブルに記録されます。


## log_processors_profiles {#log_processors_profiles}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.3" }, { label: "1" }, { label: "デフォルトで有効" }]
    }
  ]}
/>

プロセッサが実行中およびデータ待機中に費やした時間を`system.processors_profile_log`テーブルに記録します。

関連項目:

- [`system.processors_profile_log`](../../operations/system-tables/processors_profile_log.md)
- [`EXPLAIN PIPELINE`](../../sql-reference/statements/explain.md/#explain-pipeline)


## log_profile_events {#log_profile_events}

<SettingsInfoBlock type='Bool' default_value='1' />

クエリのパフォーマンス統計を query_log、query_thread_log、および query_views_log に記録します。


## log_queries {#log_queries}

<SettingsInfoBlock type='Bool' default_value='1' />

クエリログを設定します。

この設定を有効にすると、ClickHouseに送信されたクエリは[query_log](../../operations/server-configuration-parameters/settings.md/#query_log)サーバー設定パラメータで定義されたルールに従ってログに記録されます。

例:

```text
log_queries=1
```


## log_queries_cut_to_length {#log_queries_cut_to_length}

<SettingsInfoBlock type='UInt64' default_value='100000' />

クエリの長さが指定された閾値（バイト単位）を超えた場合、クエリログへの書き込み時にクエリを切り詰めます。また、通常のテキストログに出力されるクエリの長さも制限されます。


## log_queries_min_query_duration_ms {#log_queries_min_query_duration_ms}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

有効化された場合（ゼロ以外）、この設定値よりも速く実行されたクエリはログに記録されません（[MySQL Slow Query Log](https://dev.mysql.com/doc/refman/5.7/slow-query-log.html)の`long_query_time`に相当すると考えることができます）。これは、以下のテーブルにこれらのクエリが記録されないことを意味します：

- `system.query_log`
- `system.query_thread_log`

以下のタイプのクエリのみがログに記録されます：

- `QUERY_FINISH`
- `EXCEPTION_WHILE_PROCESSING`

- 型：ミリ秒
- デフォルト値：0（すべてのクエリ）


## log_queries_min_type {#log_queries_min_type}

<SettingsInfoBlock type='LogQueriesType' default_value='QUERY_START' />

`query_log`に記録する最小のタイプ。

指定可能な値:

- `QUERY_START` (`=1`)
- `QUERY_FINISH` (`=2`)
- `EXCEPTION_BEFORE_START` (`=3`)
- `EXCEPTION_WHILE_PROCESSING` (`=4`)

`query_log`に記録されるエンティティを制限するために使用できます。例えば、エラーのみを記録したい場合は、`EXCEPTION_WHILE_PROCESSING`を使用します:

```text
log_queries_min_type='EXCEPTION_WHILE_PROCESSING'
```


## log_queries_probability {#log_queries_probability}

<SettingsInfoBlock type='Float' default_value='1' />

指定された確率でランダムに選択されたクエリのサンプルのみを[query_log](../../operations/system-tables/query_log.md)、[query_thread_log](../../operations/system-tables/query_thread_log.md)、および[query_views_log](../../operations/system-tables/query_views_log.md)システムテーブルに書き込むことを許可します。これにより、1秒あたりの大量のクエリによる負荷を軽減できます。

設定可能な値:

- 0 — クエリはシステムテーブルに記録されません。
- [0..1]の範囲の正の浮動小数点数。例えば、設定値が`0.5`の場合、約半数のクエリがシステムテーブルに記録されます。
- 1 — すべてのクエリがシステムテーブルに記録されます。


## log_query_settings {#log_query_settings}

<SettingsInfoBlock type='Bool' default_value='1' />

クエリ設定を query_log および OpenTelemetry スパンログに記録します。


## log_query_threads {#log_query_threads}

<SettingsInfoBlock type='Bool' default_value='0' />

クエリスレッドのログ記録を設定します。

クエリスレッドは[system.query_thread_log](../../operations/system-tables/query_thread_log.md)テーブルに記録されます。この設定は[log_queries](#log_queries)がtrueの場合にのみ有効です。この設定でClickHouseが実行するクエリのスレッドは、[query_thread_log](/operations/server-configuration-parameters/settings#query_thread_log)サーバー設定パラメータで定義されたルールに従って記録されます。

設定可能な値:

- 0 — 無効。
- 1 — 有効。

**例**

```text
log_query_threads=1
```


## log_query_views {#log_query_views}

<SettingsInfoBlock type='Bool' default_value='1' />

クエリビューのログ記録を設定します。

この設定を有効にしてClickHouseで実行されたクエリに関連するビュー（マテリアライズドビューまたはライブビュー）がある場合、それらは[query_views_log](/operations/server-configuration-parameters/settings#query_views_log)サーバー設定パラメータにログ記録されます。

例：

```text
log_query_views=1
```


## low_cardinality_allow_in_native_format {#low_cardinality_allow_in_native_format}

<SettingsInfoBlock type='Bool' default_value='1' />

[Native](/interfaces/formats/Native)形式で[LowCardinality](../../sql-reference/data-types/lowcardinality.md)データ型の使用を許可または制限します。

`LowCardinality`の使用が制限されている場合、ClickHouseサーバーは`SELECT`クエリでは`LowCardinality`列を通常の列に変換し、`INSERT`クエリでは通常の列を`LowCardinality`列に変換します。

この設定は主に`LowCardinality`データ型をサポートしていないサードパーティクライアントで必要となります。

設定可能な値:

- 1 — `LowCardinality`の使用は制限されません。
- 0 — `LowCardinality`の使用は制限されます。


## low_cardinality_max_dictionary_size {#low_cardinality_max_dictionary_size}

<SettingsInfoBlock type='UInt64' default_value='8192' />

ストレージファイルシステムに書き込み可能な[LowCardinality](../../sql-reference/data-types/lowcardinality.md)データ型の共有グローバル辞書の最大サイズを行数で設定します。この設定により、辞書が無制限に増大した場合のRAM問題を防止できます。最大辞書サイズの制限によりエンコードできないデータは、ClickHouseが通常の方法で書き込みます。

設定可能な値:

- 任意の正の整数


## low_cardinality_use_single_dictionary_for_part {#low_cardinality_use_single_dictionary_for_part}

<SettingsInfoBlock type='Bool' default_value='0' />

データパートに対して単一の辞書を使用するかどうかを切り替えます。

デフォルトでは、ClickHouseサーバーは辞書のサイズを監視し、辞書がオーバーフローした場合は次の辞書への書き込みを開始します。複数の辞書の作成を禁止するには、`low_cardinality_use_single_dictionary_for_part = 1`を設定します。

設定可能な値:

- 1 — データパートに対する複数の辞書の作成が禁止されます。
- 0 — データパートに対する複数の辞書の作成が許可されます。


## low_priority_query_wait_time_ms {#low_priority_query_wait_time_ms}

<BetaBadge />

<SettingsInfoBlock type='Milliseconds' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "1000" }, { label: "新しい設定" }]
    }
  ]}
/>

クエリの優先順位付けメカニズムが有効な場合（設定 `priority` を参照）、低優先度のクエリは高優先度のクエリが完了するまで待機します。この設定は、その待機時間を指定します。


## make_distributed_plan {#make_distributed_plan}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "新しい実験的な設定です。" }
      ]
    }
  ]}
/>

分散クエリプランを作成します。


## materialize_skip_indexes_on_insert {#materialize_skip_indexes_on_insert}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "1" },
        {
          label:
            "INSERT時のスキップインデックスのマテリアライゼーションを無効化する設定を追加"
        }
      ]
    }
  ]}
/>

INSERT時にスキップインデックスを構築して保存するかどうかを指定します。無効にした場合、スキップインデックスは[マージ時](merge-tree-settings.md/#materialize_skip_indexes_on_merge)または明示的な[MATERIALIZE INDEX](/sql-reference/statements/alter/skipping-index.md/#materialize-index)の実行時にのみ構築および保存されます。

関連項目:[exclude_materialize_skip_indexes_on_insert](#exclude_materialize_skip_indexes_on_insert)


## materialize_statistics_on_insert {#materialize_statistics_on_insert}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "1" },
        {
          label:
            "INSERT時の統計情報のマテリアライゼーションを無効化できる新しい設定を追加"
        }
      ]
    }
  ]}
/>

INSERT時に統計情報を構築して挿入するかどうかを制御します。無効にした場合、統計情報はマージ時、または明示的なMATERIALIZE STATISTICS実行時に構築および保存されます


## materialize_ttl_after_modify {#materialize_ttl_after_modify}

<SettingsInfoBlock type='Bool' default_value='1' />

ALTER MODIFY TTL クエリの後、既存データに対してTTLを適用します


## materialized_views_ignore_errors {#materialized_views_ignore_errors}

<SettingsInfoBlock type='Bool' default_value='0' />

MATERIALIZED VIEWのエラーを無視し、MVに関係なく元のブロックをテーブルに配信することを許可します


## materialized_views_squash_parallel_inserts {#materialized_views_squash_parallel_inserts}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.10" },
        { label: "1" },
        { label: "必要に応じて以前の動作を保持するための設定が追加されました。" }
      ]
    }
  ]}
/>

並列挿入による単一のINSERTクエリから、マテリアライズドビューの宛先テーブルへの挿入を圧縮し、生成されるパート数を削減します。
falseに設定され、かつ`parallel_view_processing`が有効な場合、INSERTクエリは`max_insert_thread`ごとに宛先テーブルにパートを生成します。


## max_analyze_depth {#max_analyze_depth}

<SettingsInfoBlock type='UInt64' default_value='5000' />

インタープリターが実行する解析の最大数。


## max_ast_depth {#max_ast_depth}

<SettingsInfoBlock type='UInt64' default_value='1000' />

クエリの構文木の最大ネスト深度。この値を超えると例外がスローされます。

:::note
現時点では、パース中にはチェックされず、クエリのパース後にのみチェックされます。
つまり、パース中に深すぎる構文木が作成される可能性がありますが、
クエリは失敗します。
:::


## max_ast_elements {#max_ast_elements}

<SettingsInfoBlock type='UInt64' default_value='50000' />

クエリの構文木における要素の最大数。この値を超えた場合、例外がスローされます。

:::note
現時点では、パース中にはチェックされず、クエリのパース後にのみチェックされます。
つまり、パース中に深すぎる構文木が作成される可能性がありますが、
その場合クエリは失敗します。
:::


## max_autoincrement_series {#max_autoincrement_series}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "1000" }, { label: "新しい設定" }]
    }
  ]}
/>

`generateSerialID`関数によって作成されるシリーズ数の制限です。

各シリーズはKeeper内のノードを表すため、数百万個を超えないようにすることを推奨します。


## max_backup_bandwidth {#max_backup_bandwidth}

<SettingsInfoBlock type='UInt64' default_value='0' />

サーバー上の特定のバックアップに対する最大読み取り速度(バイト/秒)です。0は無制限を意味します。


## max_block_size {#max_block_size}

<SettingsInfoBlock type='NonZeroUInt64' default_value='65409' />

ClickHouseでは、データはブロック単位で処理されます。ブロックは列パーツの集合です。単一ブロックの内部処理サイクルは効率的ですが、各ブロックの処理には無視できないコストが伴います。

`max_block_size`設定は、テーブルからデータを読み込む際に単一ブロックに含める推奨最大行数を指定します。`max_block_size`サイズのブロックが常にテーブルから読み込まれるわけではありません。ClickHouseが取得すべきデータ量が少ないと判断した場合、より小さいブロックが処理されます。

ブロックサイズは、各ブロックの処理時に無視できないコストが発生しないよう、小さすぎてはいけません。また、LIMIT句を含むクエリが最初のブロックの処理後に迅速に実行されるよう、大きすぎてもいけません。`max_block_size`を設定する際の目標は、複数のスレッドで多数の列を抽出する際にメモリを過度に消費することを避け、少なくともある程度のキャッシュ局所性を維持することです。


## max_bytes_before_external_group_by {#max_bytes_before_external_group_by}

<SettingsInfoBlock type='UInt64' default_value='0' />

Cloudのデフォルト値：レプリカあたりのメモリ量の半分。

外部メモリでの`GROUP BY`句の実行を有効または無効にします。
（[外部メモリでのGROUP BY](/sql-reference/statements/select/group-by#group-by-in-external-memory)を参照してください）

設定可能な値：

- 単一の[GROUP BY](/sql-reference/statements/select/group-by)操作で使用できるRAMの最大容量（バイト単位）。
- `0` — 外部メモリでの`GROUP BY`を無効にします。

:::note
GROUP BY操作中のメモリ使用量がこの閾値（バイト単位）を超えた場合、
「外部集約」モード（データをディスクにスピル）が有効化されます。

推奨値は利用可能なシステムメモリの半分です。
:::


## max_bytes_before_external_sort {#max_bytes_before_external_sort}

<SettingsInfoBlock type='UInt64' default_value='0' />

Cloudのデフォルト値：レプリカあたりのメモリ量の半分。

外部メモリでの`ORDER BY`句の実行を有効または無効にします。[ORDER BY実装の詳細](../../sql-reference/statements/select/order-by.md#implementation-details)を参照してください。
ORDER BY操作中のメモリ使用量がこの閾値（バイト単位）を超えると、「外部ソート」モード（データをディスクにスピル）が有効になります。

設定可能な値：

- 単一の[ORDER BY](../../sql-reference/statements/select/order-by.md)操作で使用できるRAMの最大容量（バイト単位）。
  推奨値は利用可能なシステムメモリの半分です。
- `0` — 外部メモリでの`ORDER BY`を無効にします。


## max_bytes_before_remerge_sort {#max_bytes_before_remerge_sort}

<SettingsInfoBlock type='UInt64' default_value='1000000000' />

ORDER BY と LIMIT を使用する場合、メモリ使用量が指定された閾値を超えると、最終マージの前に追加のブロックマージステップを実行して、上位 LIMIT 行のみを保持します。


## max_bytes_in_distinct {#max_bytes_in_distinct}

<SettingsInfoBlock type='UInt64' default_value='0' />

DISTINCTを使用する際にハッシュテーブルが使用する、メモリ内の状態の最大バイト数（非圧縮バイト）。


## max_bytes_in_join {#max_bytes_in_join}

<SettingsInfoBlock type='UInt64' default_value='0' />

テーブル結合時に使用されるハッシュテーブルの最大サイズ(バイト数)。

この設定は[SELECT ... JOIN](/sql-reference/statements/select/join)操作と[Joinテーブルエンジン](/engines/table-engines/special/join)に適用されます。

クエリに結合が含まれる場合、ClickHouseは各中間結果に対してこの設定を確認します。

制限に達した場合、ClickHouseは異なるアクションを実行できます。アクションを選択するには[join_overflow_mode](/operations/settings/settings#join_overflow_mode)設定を使用します。

設定可能な値:

- 正の整数
- 0 — メモリ制御が無効


## max_bytes_in_set {#max_bytes_in_set}

<SettingsInfoBlock type='UInt64' default_value='0' />

サブクエリから作成されたIN句のセットが使用する最大バイト数（非圧縮データ）。


## max_bytes_ratio_before_external_group_by {#max_bytes_ratio_before_external_group_by}

<SettingsInfoBlock type='Double' default_value='0.5' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "0.5" },
        { label: "デフォルトでディスクへの自動スピルを有効化。" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "24.12" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

`GROUP BY`で使用可能なメモリの比率。この閾値に達すると、
集約処理に外部メモリが使用されます。

例えば、`0.6`に設定した場合、`GROUP BY`は実行開始時に利用可能なメモリ
(サーバー/ユーザー/マージ用)の60%まで使用し、その後は
外部集約を開始します。


## max_bytes_ratio_before_external_sort {#max_bytes_ratio_before_external_sort}

<SettingsInfoBlock type='Double' default_value='0.5' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "0.5" },
        { label: "デフォルトでディスクへの自動スピルを有効化。" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "24.12" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

`ORDER BY`で使用可能なメモリの比率。この値に達すると、外部ソートが使用されます。

例えば、`0.6`に設定した場合、`ORDER BY`は実行開始時に利用可能なメモリ(サーバー/ユーザー/マージ用)の`60%`まで使用でき、それ以降は外部ソートを使用します。

なお、`max_bytes_before_external_sort`は引き続き有効であり、ディスクへのスピルはソートブロックが`max_bytes_before_external_sort`より大きい場合にのみ実行されます。


## max_bytes_to_read {#max_bytes_to_read}

<SettingsInfoBlock type='UInt64' default_value='0' />

クエリ実行時にテーブルから読み取り可能な最大バイト数（非圧縮データ）。
この制限は、処理される各データチャンクに対してチェックされ、最も深いテーブル式にのみ適用されます。リモートサーバーから読み取る場合は、リモートサーバー上でのみチェックされます。


## max_bytes_to_read_leaf {#max_bytes_to_read_leaf}

<SettingsInfoBlock type='UInt64' default_value='0' />

分散クエリの実行時にリーフノード上のローカルテーブルから読み取り可能な最大バイト数(非圧縮データ)です。分散クエリは各シャード(リーフ)に対して複数のサブクエリを発行できますが、この制限はリーフノードでの読み取りステージでのみチェックされ、ルートノードでの結果マージステージでは無視されます。

例えば、2つのシャードで構成されるクラスタがあり、各シャードに100バイトのデータを含むテーブルがある場合を考えます。`max_bytes_to_read=150`の設定で両方のテーブルからすべてのデータを読み取ろうとする分散クエリは、合計200バイトになるため失敗します。一方、`max_bytes_to_read_leaf=150`を設定したクエリは、各リーフノードが最大100バイトしか読み取らないため成功します。

この制限は、処理される各データチャンクごとにチェックされます。

:::note
この設定は`prefer_localhost_replica=1`と併用すると不安定になります。
:::


## max_bytes_to_sort {#max_bytes_to_sort}

<SettingsInfoBlock type='UInt64' default_value='0' />

ソート前の最大バイト数。ORDER BY操作で指定された量を超える非圧縮バイトを処理する必要がある場合、動作は`sort_overflow_mode`によって決定されます。このモードはデフォルトで`throw`に設定されています。


## max_bytes_to_transfer {#max_bytes_to_transfer}

<SettingsInfoBlock type='UInt64' default_value='0' />

GLOBAL IN/JOIN句の実行時に、リモートサーバーに渡すことができる、または一時テーブルに保存できる最大バイト数(非圧縮データ)。


## max_columns_to_read {#max_columns_to_read}

<SettingsInfoBlock type='UInt64' default_value='0' />

単一のクエリでテーブルから読み取ることができる列の最大数。
指定された数を超える列の読み取りが必要な場合、例外が
スローされます。

:::tip
この設定は、過度に複雑なクエリを防ぐのに役立ちます。
:::

`0`は無制限を意味します。


## max_compress_block_size {#max_compress_block_size}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

テーブルへの書き込み時に圧縮する前の非圧縮データブロックの最大サイズ。デフォルトは1,048,576（1 MiB）です。ブロックサイズを小さく指定すると、一般的に圧縮率がわずかに低下しますが、キャッシュの局所性により圧縮および解凍速度がわずかに向上し、メモリ消費量が削減されます。

:::note
これはエキスパートレベルの設定であり、ClickHouseを使い始めたばかりの場合は変更しないでください。
:::

圧縮用のブロック（バイトで構成されるメモリチャンク）とクエリ処理用のブロック（テーブルからの行セット）を混同しないでください。


## max_concurrent_queries_for_all_users {#max_concurrent_queries_for_all_users}

<SettingsInfoBlock type='UInt64' default_value='0' />

この設定値が現在同時に処理されているクエリ数以下の場合、例外がスローされます。

例:`max_concurrent_queries_for_all_users`を全ユーザーに対して99に設定し、データベース管理者は自身に対して100に設定することで、サーバーが過負荷状態でも調査用のクエリを実行できます。

特定のクエリまたはユーザーに対する設定変更は、他のクエリに影響しません。

設定可能な値:

- 正の整数。
- 0 — 制限なし。

**例**

```xml
<max_concurrent_queries_for_all_users>99</max_concurrent_queries_for_all_users>
```

**関連項目**

- [max_concurrent_queries](/operations/server-configuration-parameters/settings#max_concurrent_queries)


## max_concurrent_queries_for_user {#max_concurrent_queries_for_user}

<SettingsInfoBlock type='UInt64' default_value='0' />

ユーザーごとに同時に処理できるクエリの最大数。

設定可能な値:

- 正の整数。
- 0 — 制限なし。

**例**

```xml
<max_concurrent_queries_for_user>5</max_concurrent_queries_for_user>
```


## max_distributed_connections {#max_distributed_connections}

<SettingsInfoBlock type='UInt64' default_value='1024' />

単一のDistributedテーブルに対する単一クエリの分散処理時に、リモートサーバーとの同時接続数の上限を指定します。クラスタ内のサーバー数以上の値に設定することを推奨します。

以下のパラメータはDistributedテーブルの作成時(およびサーバーの起動時)にのみ使用されるため、実行時に変更する必要はありません。


## max_distributed_depth {#max_distributed_depth}

<SettingsInfoBlock type='UInt64' default_value='5' />

[Distributed](../../engines/table-engines/special/distributed.md)テーブルの再帰クエリの最大深度を制限します。

値を超えた場合、サーバーは例外をスローします。

設定可能な値:

- 正の整数。
- 0 — 深度無制限。


## max_download_buffer_size {#max_download_buffer_size}

<SettingsInfoBlock type='UInt64' default_value='10485760' />

各スレッドにおける並列ダウンロード（例: URLエンジン）用バッファの最大サイズ。


## max_download_threads {#max_download_threads}

<SettingsInfoBlock type='MaxThreads' default_value='4' />

データをダウンロードする際の最大スレッド数（例：URLエンジンの場合）。


## max_estimated_execution_time {#max_estimated_execution_time}

<SettingsInfoBlock type='Seconds' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "0" },
        {
          label: "max_execution_timeとmax_estimated_execution_timeを分離"
        }
      ]
    }
  ]}
/>

クエリの推定実行時間の最大値(秒単位)。[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)の期限が切れた後、各データブロックでチェックされます。


## max_execution_speed {#max_execution_speed}

<SettingsInfoBlock type='UInt64' default_value='0' />

1秒あたりに実行される行数の最大値。[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)が経過すると、各データブロックでチェックされます。実行速度が高い場合は、実行速度が制限されます。


## max_execution_speed_bytes {#max_execution_speed_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

1秒あたりの実行バイト数の最大値。[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)が経過すると、各データブロックでチェックされます。実行速度が高い場合は、実行速度が制限されます。


## max_execution_time {#max_execution_time}

<SettingsInfoBlock type='Seconds' default_value='0' />

クエリの最大実行時間を秒単位で指定します。

`max_execution_time`パラメータの動作は少し理解しにくい場合があります。
このパラメータは、現在のクエリ実行速度に基づく推定によって動作します
(この動作は[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)によって制御されます)。

ClickHouseは、推定実行時間が指定された`max_execution_time`を超える場合、クエリを中断します。デフォルトでは、`timeout_before_checking_execution_speed`は10秒に設定されています。これは、クエリ実行開始から10秒後に、ClickHouseが総実行時間の推定を開始することを意味します。例えば、`max_execution_time`が3600秒(1時間)に設定されている場合、推定時間がこの3600秒の制限を超えるとClickHouseはクエリを終了します。`timeout_before_checking_execution_speed`を0に設定すると、ClickHouseは`max_execution_time`の基準として実時間(クロック時間)を使用します。

クエリの実行時間が指定された秒数を超えた場合、その動作は`timeout_overflow_mode`によって決定され、デフォルトでは`throw`に設定されています。

:::note
タイムアウトのチェックは、データ処理中の特定のポイントでのみ行われ、クエリもそこでのみ停止できます。
現在、集約状態のマージ中やクエリ解析中には停止できないため、
実際の実行時間はこの設定値よりも長くなる場合があります。
:::


## max_execution_time_leaf {#max_execution_time_leaf}

<SettingsInfoBlock type='Seconds' default_value='0' />

[`max_execution_time`](#max_execution_time)と意味的には同様ですが、分散クエリまたはリモートクエリのリーフノードにのみ適用されます。

例えば、リーフノードでの実行時間を`10s`に制限したいが、初期ノードには制限を設けない場合、ネストされたサブクエリの設定で`max_execution_time`を指定する代わりに:

```sql
SELECT count()
FROM cluster(cluster, view(SELECT * FROM t SETTINGS max_execution_time = 10));
```

クエリ設定として`max_execution_time_leaf`を使用することができます:

```sql
SELECT count()
FROM cluster(cluster, view(SELECT * FROM t)) SETTINGS max_execution_time_leaf = 10;
```


## max_expanded_ast_elements {#max_expanded_ast_elements}

<SettingsInfoBlock type='UInt64' default_value='500000' />

エイリアスとアスタリスク展開後のクエリ構文木の最大サイズ(ノード数単位)。


## max_fetch_partition_retries_count {#max_fetch_partition_retries_count}

<SettingsInfoBlock type='UInt64' default_value='5' />

別のホストからパーティションを取得する際のリトライ回数。


## max_final_threads {#max_final_threads}

<SettingsInfoBlock type='MaxThreads' default_value="'auto(N)'" />

[FINAL](/sql-reference/statements/select/from#final-modifier)修飾子を使用した`SELECT`クエリのデータ読み取りフェーズで使用する並列スレッドの最大数を設定します。

設定可能な値:

- 正の整数
- 0または1 — 無効。`SELECT`クエリは単一スレッドで実行されます。


## max_http_get_redirects {#max_http_get_redirects}

<SettingsInfoBlock type='UInt64' default_value='0' />

許可されるHTTP GETリダイレクトのホップ数の最大値。悪意のあるサーバーがリクエストを予期しないサービスにリダイレクトすることを防ぐための追加のセキュリティ対策を提供します。\n\n外部サーバーが別のアドレスにリダイレクトする際、そのアドレスが企業のインフラストラクチャ内部のものである場合、内部サーバーにHTTPリクエストを送信することで、認証を回避して内部ネットワークの内部APIにアクセスしたり、RedisやMemcachedなどの他のサービスにクエリを実行したりできる可能性があります。内部インフラストラクチャ(localhostで実行されているものを含む)を持たない場合、またはサーバーを信頼している場合は、リダイレクトを許可しても安全です。ただし、URLがHTTPSではなくHTTPを使用している場合、リモートサーバーだけでなく、ISPや経路上のすべてのネットワークも信頼する必要があることに留意してください。


## max_hyperscan_regexp_length {#max_hyperscan_regexp_length}

<SettingsInfoBlock type='UInt64' default_value='0' />

[hyperscan マルチマッチ関数](/sql-reference/functions/string-search-functions#multiMatchAny)における各正規表現の最大長を定義します。

設定可能な値:

- 正の整数
- 0 - 長さは無制限

**例**

クエリ:

```sql
SELECT multiMatchAny('abcd', ['ab','bcd','c','d']) SETTINGS max_hyperscan_regexp_length = 3;
```

結果:

```text
┌─multiMatchAny('abcd', ['ab', 'bcd', 'c', 'd'])─┐
│                                              1 │
└────────────────────────────────────────────────┘
```

クエリ:

```sql
SELECT multiMatchAny('abcd', ['ab','bcd','c','d']) SETTINGS max_hyperscan_regexp_length = 2;
```

結果:

```text
Exception: Regexp length too large.
```

**関連項目**

- [max_hyperscan_regexp_total_length](#max_hyperscan_regexp_total_length)


## max_hyperscan_regexp_total_length {#max_hyperscan_regexp_total_length}

<SettingsInfoBlock type='UInt64' default_value='0' />

各[hyperscanマルチマッチ関数](/sql-reference/functions/string-search-functions#multiMatchAny)内のすべての正規表現の合計最大長を設定します。

設定可能な値:

- 正の整数
- 0 - 長さは無制限

**例**

クエリ:

```sql
SELECT multiMatchAny('abcd', ['a','b','c','d']) SETTINGS max_hyperscan_regexp_total_length = 5;
```

結果:

```text
┌─multiMatchAny('abcd', ['a', 'b', 'c', 'd'])─┐
│                                           1 │
└─────────────────────────────────────────────┘
```

クエリ:

```sql
SELECT multiMatchAny('abcd', ['ab','bc','c','d']) SETTINGS max_hyperscan_regexp_total_length = 5;
```

結果:

```text
Exception: Total regexp lengths too large.
```

**関連項目**

- [max_hyperscan_regexp_length](#max_hyperscan_regexp_length)


## max_insert_block_size {#max_insert_block_size}

<SettingsInfoBlock type='NonZeroUInt64' default_value='1048449' />

テーブルへの挿入時に形成されるブロックのサイズ（行数）。
この設定は、サーバーがブロックを形成する場合にのみ適用されます。
例えば、HTTPインターフェース経由でINSERTを実行する場合、サーバーがデータ形式を解析し、指定されたサイズのブロックを形成します。
一方、clickhouse-clientを使用する場合は、クライアント側でデータを解析するため、サーバー上の'max_insert_block_size'設定は挿入されるブロックのサイズに影響しません。
また、INSERT SELECTを使用する場合も、SELECT後に形成されたブロックをそのまま使用してデータが挿入されるため、この設定は効果を持ちません。

デフォルト値は`max_block_size`よりわずかに大きくなっています。 これは、特定のテーブルエンジン（`*MergeTree`）が挿入されたブロックごとにディスク上にデータパートを形成し、これがかなり大きな単位となるためです。 同様に、`*MergeTree`テーブルは挿入時にデータをソートするため、十分に大きなブロックサイズにすることでRAM内でより多くのデータをソートできるようになります。


## max_insert_delayed_streams_for_parallel_write {#max_insert_delayed_streams_for_parallel_write}

<SettingsInfoBlock type='UInt64' default_value='0' />

最終パートのフラッシュを遅延させるストリーム(カラム)の最大数。デフォルトは自動(基盤ストレージが並列書き込みをサポートする場合は100、例: S3。それ以外の場合は無効)


## max_insert_threads {#max_insert_threads}

<SettingsInfoBlock type='UInt64' default_value='0' />

`INSERT SELECT`クエリを実行する際の最大スレッド数。

設定可能な値:

- 0（または1）— `INSERT SELECT`を並列実行しない。
- 1より大きい正の整数。

Cloudのデフォルト値:

- 8 GiBメモリのノード: `1`
- 16 GiBメモリのノード: `2`
- それより大きいノード: `4`

並列`INSERT SELECT`は、`SELECT`部分が並列実行される場合にのみ有効です。[`max_threads`](#max_threads)設定を参照してください。
値を大きくすると、メモリ使用量が増加します。


## max_joined_block_size_bytes {#max_joined_block_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='4194304' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "4194304" }, { label: "新しい設定" }]
    }
  ]}
/>

JOIN結果の最大ブロックサイズ(バイト単位)(結合アルゴリズムがサポートしている場合)。0は無制限を意味します。


## max_joined_block_size_rows {#max_joined_block_size_rows}

<SettingsInfoBlock type='UInt64' default_value='65409' />

JOIN結果の最大ブロックサイズ（結合アルゴリズムがサポートしている場合）。0は無制限を意味します。


## max_limit_for_vector_search_queries {#max_limit_for_vector_search_queries}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "1000" }, { label: "新しい設定" }]
    }
  ]}
/>

この設定値を超えるLIMITを指定したSELECTクエリは、ベクトル類似性インデックスを使用できません。ベクトル類似性インデックスでのメモリオーバーフローを防ぐために役立ちます。


## max_local_read_bandwidth {#max_local_read_bandwidth}

<SettingsInfoBlock type='UInt64' default_value='0' />

ローカル読み取りの最大速度(バイト/秒)。


## max_local_write_bandwidth {#max_local_write_bandwidth}

<SettingsInfoBlock type='UInt64' default_value='0' />

ローカル書き込みの最大速度(バイト/秒)。


## max_memory_usage {#max_memory_usage}

<SettingsInfoBlock type='UInt64' default_value='0' />

Cloudのデフォルト値: レプリカのRAM容量に依存します。

単一サーバーでクエリを実行する際に使用できるRAMの最大量です。
`0`を指定すると無制限になります。

この設定は、利用可能なメモリ容量やマシンの総メモリ容量を考慮しません。この制限は、単一サーバー内の単一クエリに適用されます。

`SHOW PROCESSLIST`を使用すると、各クエリの現在のメモリ消費量を確認できます。
ピークメモリ消費量は各クエリごとに追跡され、ログに記録されます。

以下の集約関数では、`String`および`Array`引数の状態に対するメモリ使用量が完全には追跡されません:

- `min`
- `max`
- `any`
- `anyLast`
- `argMin`
- `argMax`

メモリ消費量は、パラメータ[`max_memory_usage_for_user`](/operations/settings/settings#max_memory_usage_for_user)および[`max_server_memory_usage`](/operations/server-configuration-parameters/settings#max_server_memory_usage)によっても制限されます。


## max_memory_usage_for_user {#max_memory_usage_for_user}

<SettingsInfoBlock type='UInt64' default_value='0' />

単一サーバー上でユーザーのクエリを実行する際に使用するRAMの最大量。0は無制限を意味します。

デフォルトでは制限されていません（`max_memory_usage_for_user = 0`）。

[`max_memory_usage`](/operations/settings/settings#max_memory_usage)の説明も参照してください。

例えば、`clickhouse_read`という名前のユーザーに対して`max_memory_usage_for_user`を1000バイトに設定する場合は、次のステートメントを使用します

```sql
ALTER USER clickhouse_read SETTINGS max_memory_usage_for_user = 1000;
```

クライアントからログアウトして再度ログインした後、`getSetting`関数を使用して設定が適用されたことを確認できます：

```sql
SELECT getSetting('max_memory_usage_for_user');
```


## max_network_bandwidth {#max_network_bandwidth}

<SettingsInfoBlock type='UInt64' default_value='0' />

ネットワーク経由のデータ交換速度をバイト毎秒で制限します。この設定はすべてのクエリに適用されます。

設定可能な値:

- 正の整数
- 0 — 帯域幅制御が無効


## max_network_bandwidth_for_all_users {#max_network_bandwidth_for_all_users}

<SettingsInfoBlock type='UInt64' default_value='0' />

ネットワーク経由でデータが交換される速度を1秒あたりのバイト数で制限します。この設定は、サーバー上で同時実行されているすべてのクエリに適用されます。

設定可能な値:

- 正の整数。
- 0 — データ速度の制御が無効化されます。


## max_network_bandwidth_for_user {#max_network_bandwidth_for_user}

<SettingsInfoBlock type='UInt64' default_value='0' />

ネットワーク経由のデータ交換速度をバイト毎秒で制限します。この設定は、単一ユーザーによって同時実行されるすべてのクエリに適用されます。

設定可能な値:

- 正の整数
- 0 — データ速度の制御が無効化されます


## max_network_bytes {#max_network_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

クエリ実行時にネットワーク経由で受信または送信されるデータ量（バイト単位）を制限します。この設定は各クエリに個別に適用されます。

設定可能な値：

- 正の整数
- 0 — データ量の制御が無効になります。


## max_number_of_partitions_for_independent_aggregation {#max_number_of_partitions_for_independent_aggregation}

<SettingsInfoBlock type='UInt64' default_value='128' />

最適化を適用するテーブル内のパーティションの最大数


## max_os_cpu_wait_time_ratio_to_throw {#max_os_cpu_wait_time_ratio_to_throw}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "設定値が変更され、25.4にバックポートされました" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

クエリの拒否を検討する際の、OS CPU待機時間(OSCPUWaitMicrosecondsメトリック)とビジー時間(OSCPUVirtualTimeMicrosecondsメトリック)の最大比率。最小比率と最大比率の間で線形補間を使用して確率を計算し、この時点で確率は1となります。


## max_parallel_replicas {#max_parallel_replicas}

<SettingsInfoBlock type='NonZeroUInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "1000" },
        { label: "デフォルトで最大1000個の並列レプリカを使用します。" }
      ]
    }
  ]}
/>

クエリ実行時の各シャードに対するレプリカの最大数。

設定可能な値:

- 正の整数。

**追加情報**

このオプションは、使用する設定によって異なる結果を生成します。

:::note
この設定は、結合またはサブクエリが含まれており、すべてのテーブルが特定の要件を満たしていない場合、不正確な結果を生成します。詳細については、[分散サブクエリとmax_parallel_replicas](/operations/settings/settings#max_parallel_replicas)を参照してください。
:::

### `SAMPLE`キーを使用した並列処理

クエリは複数のサーバーで並列実行することで高速に処理される場合があります。ただし、以下の場合にはクエリのパフォーマンスが低下する可能性があります:

- パーティショニングキー内のサンプリングキーの位置が効率的な範囲スキャンを許可しない。
- テーブルにサンプリングキーを追加すると、他のカラムによるフィルタリングの効率が低下する。
- サンプリングキーが計算コストの高い式である。
- クラスタのレイテンシ分布がロングテールを持つため、より多くのサーバーにクエリを実行すると全体のレイテンシが増加する。

### [parallel_replicas_custom_key](#parallel_replicas_custom_key)を使用した並列処理

この設定は、すべてのレプリケートされたテーブルに有用です。


## max_parser_backtracks {#max_parser_backtracks}

<SettingsInfoBlock type='UInt64' default_value='1000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1000000" },
        { label: "パーサーの複雑さの制限" }
      ]
    }
  ]}
/>

パーサーのバックトラックの最大回数（再帰下降構文解析プロセスにおいて異なる選択肢を試行する回数）。


## max_parser_depth {#max_parser_depth}

<SettingsInfoBlock type='UInt64' default_value='1000' />

再帰下降パーサーにおける最大再帰深度を制限します。スタックサイズを制御できます。

設定可能な値:

- 正の整数
- 0 — 再帰深度は無制限


## max_parsing_threads {#max_parsing_threads}

<SettingsInfoBlock type='MaxThreads' default_value="'auto(N)'" />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "0" },
        {
          label:
            "ファイルからの並列解析時のスレッド数を制御する個別設定を追加"
        }
      ]
    }
  ]}
/>

並列解析をサポートする入力形式でデータを解析する際の最大スレッド数。デフォルトでは自動的に決定されます。


## max_partition_size_to_drop {#max_partition_size_to_drop}

<SettingsInfoBlock type='UInt64' default_value='50000000000' />

クエリ実行時におけるパーティション削除の制限です。値を `0` に設定すると、制限なしでパーティションを削除できます。

Cloudのデフォルト値: 1 TB

:::note
このクエリ設定は、対応するサーバー設定を上書きします。詳細については [max_partition_size_to_drop](/operations/server-configuration-parameters/settings#max_partition_size_to_drop) を参照してください
:::


## max_partitions_per_insert_block {#max_partitions_per_insert_block}

<SettingsInfoBlock type='UInt64' default_value='100' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "19.5" },
        { label: "100" },
        { label: "1ブロックあたりのパーティション数の上限を追加" }
      ]
    }
  ]}
/>

単一の挿入ブロック内のパーティション数の上限を制限します。
ブロックに含まれるパーティション数が多すぎる場合は例外がスローされます。

- 正の整数。
- `0` — パーティション数無制限。

**詳細**

データ挿入時、ClickHouseは挿入ブロック内のパーティション数を計算します。パーティション数が
`max_partitions_per_insert_block`を超える場合、ClickHouseは`throw_on_max_partitions_per_insert_block`の設定に基づいて
警告をログに記録するか、例外をスローします。例外には
以下のテキストが含まれます:

> "単一のINSERTブロックに対してパーティション数が多すぎます(`partitions_count`個のパーティション、上限は" + toString(max_partitions) + ")。
> この上限は'max_partitions_per_insert_block'設定によって制御されます。
> 多数のパーティションを使用することはよくある誤解です。これは、サーバー起動の遅延、INSERTクエリの遅延、
> SELECTクエリの遅延など、深刻なパフォーマンス低下を引き起こします。テーブルの推奨総パーティション数は
> 1000から10000未満です。パーティショニングはSELECTクエリを高速化するためのものではないことに注意してください
> (ORDER BY キーがあれば範囲クエリを高速化するには十分です)。
> パーティションはデータ操作(DROP PARTITIONなど)を目的としています。"

:::note
多数のパーティションを使用することはよくある誤解であるため、この設定は安全閾値として機能します。
:::


## max_partitions_to_read {#max_partitions_to_read}

<SettingsInfoBlock type='Int64' default_value='-1' />

単一クエリでアクセス可能なパーティションの最大数を制限します。

テーブル作成時に指定された設定値は、クエリレベルの設定で上書きできます。

設定可能な値:

- 正の整数
- `-1` - 無制限(デフォルト)

:::note
MergeTree設定の[`max_partitions_to_read`](/operations/settings/settings#max_partitions_to_read)をテーブルの設定で指定することもできます。
:::


## max_parts_to_move {#max_parts_to_move}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "1000" }, { label: "新しい設定" }]
    }
  ]}
/>

1つのクエリで移動可能なパーツ数を制限します。0は無制限を意味します。


## max_projection_rows_to_use_projection_index {#max_projection_rows_to_use_projection_index}

<SettingsInfoBlock type='UInt64' default_value='1000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1000000" },
        { label: "新しい設定" }
      ]
    }
  ]}
/>

プロジェクションインデックスから読み取る行数がこの閾値以下の場合、ClickHouseはクエリ実行時にプロジェクションインデックスの適用を試みます。


## max_query_size {#max_query_size}

<SettingsInfoBlock type='UInt64' default_value='262144' />

SQLパーサーが解析するクエリ文字列の最大バイト数。
INSERTクエリのVALUES句内のデータは、別のストリームパーサー（O(1)のRAMを消費）で処理されるため、この制限の影響を受けません。

:::note
`max_query_size`はSQLクエリ内で設定できません（例：`SELECT now() SETTINGS max_query_size=10000`）。これは、ClickHouseがクエリを解析するためにバッファを割り当てる必要があり、このバッファサイズは`max_query_size`設定で決定されるためです。この設定はクエリ実行前に構成されている必要があります。
:::


## max_read_buffer_size {#max_read_buffer_size}

<SettingsInfoBlock type='NonZeroUInt64' default_value='1048576' />

ファイルシステムから読み取るバッファーの最大サイズ。


## max_read_buffer_size_local_fs {#max_read_buffer_size_local_fs}

<SettingsInfoBlock type='UInt64' default_value='131072' />

ローカルファイルシステムから読み取るバッファの最大サイズです。0に設定すると、max_read_buffer_sizeが使用されます。


## max_read_buffer_size_remote_fs {#max_read_buffer_size_remote_fs}

<SettingsInfoBlock type='UInt64' default_value='0' />

リモートファイルシステムから読み取るバッファの最大サイズ。0に設定された場合は、max_read_buffer_sizeが使用されます。


## max_recursive_cte_evaluation_depth {#max_recursive_cte_evaluation_depth}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "1000" },
        { label: "再帰的CTE評価深度の最大制限" }
      ]
    }
  ]}
/>

再帰的CTE評価深度の最大制限


## max_remote_read_network_bandwidth {#max_remote_read_network_bandwidth}

<SettingsInfoBlock type='UInt64' default_value='0' />

読み取り時のネットワーク経由のデータ転送の最大速度（バイト/秒単位）。


## max_remote_write_network_bandwidth {#max_remote_write_network_bandwidth}

<SettingsInfoBlock type='UInt64' default_value='0' />

書き込み時のネットワーク経由のデータ交換の最大速度（バイト/秒）。


## max_replica_delay_for_distributed_queries {#max_replica_delay_for_distributed_queries}

<SettingsInfoBlock type='UInt64' default_value='300' />

分散クエリにおいて遅延しているレプリカを無効化します。[レプリケーション](../../engines/table-engines/mergetree-family/replication.md)を参照してください。

時間を秒単位で設定します。レプリカの遅延が設定値以上の場合、そのレプリカは使用されません。

設定可能な値:

- 正の整数
- 0 — レプリカの遅延はチェックされません

ゼロでない遅延を持つレプリカの使用を防ぐには、このパラメータを1に設定してください。

レプリケートされたテーブルを参照する分散テーブルから`SELECT`を実行する際に使用されます。


## max_result_bytes {#max_result_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

結果のサイズをバイト単位(非圧縮)で制限します。閾値に達した場合、クエリはデータブロックの処理後に停止しますが、結果の最後のブロックは切り捨てられないため、結果のサイズが閾値を超える可能性があります。

**注意事項**

この閾値では、メモリ内の結果サイズが考慮されます。
結果のサイズが小さい場合でも、LowCardinality列のディクショナリやAggregateFunction列のアリーナなど、メモリ内のより大きなデータ構造を参照する可能性があるため、結果のサイズが小さくても閾値を超える場合があります。

:::warning
この設定は比較的低レベルであり、慎重に使用する必要があります
:::


## max_result_rows {#max_result_rows}

<SettingsInfoBlock type='UInt64' default_value='0' />

Cloud default value: `0`.

結果の行数を制限します。サブクエリおよび分散クエリの一部をリモートサーバーで実行する際にもチェックされます。
値が`0`の場合は制限が適用されません。

閾値に達した場合、クエリはデータブロックの処理後に停止しますが、結果の最後のブロックは切り捨てられないため、結果のサイズが閾値を超える可能性があります。


## max_reverse_dictionary_lookup_cache_size_bytes {#max_reverse_dictionary_lookup_cache_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='104857600' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "104857600" },
        {
          label:
            "新しい設定。`dictGetKeys`関数で使用されるクエリごとの逆ディクショナリ参照キャッシュの最大サイズ(バイト単位)。このキャッシュは、同一クエリ内でディクショナリを再スキャンしないように、属性値ごとにシリアル化されたキータプルを保存します。"
        }
      ]
    }
  ]}
/>

`dictGetKeys`関数で使用されるクエリごとの逆ディクショナリ参照キャッシュの最大サイズ(バイト単位)。このキャッシュは、同一クエリ内でディクショナリを再スキャンしないように、属性値ごとにシリアル化されたキータプルを保存します。制限に達すると、LRUアルゴリズムによってエントリが削除されます。キャッシュを無効にする場合は0に設定してください。


## max_rows_in_distinct {#max_rows_in_distinct}

<SettingsInfoBlock type='UInt64' default_value='0' />

DISTINCTを使用する際の個別の行の最大数。


## max_rows_in_join {#max_rows_in_join}

<SettingsInfoBlock type='UInt64' default_value='0' />

テーブル結合時に使用されるハッシュテーブルの行数を制限します。

この設定は[SELECT ... JOIN](/sql-reference/statements/select/join)操作と[Join](/engines/table-engines/special/join)テーブルエンジンに適用されます。

クエリに複数の結合が含まれる場合、ClickHouseは各中間結果に対してこの設定を確認します。

制限に達した場合、ClickHouseは異なるアクションを実行できます。アクションを選択するには[`join_overflow_mode`](/operations/settings/settings#join_overflow_mode)設定を使用してください。

設定可能な値:

- 正の整数。
- `0` — 行数無制限。


## max_rows_in_set {#max_rows_in_set}

<SettingsInfoBlock type='UInt64' default_value='0' />

サブクエリから作成されるIN句のデータセットにおける最大行数。


## max_rows_in_set_to_optimize_join {#max_rows_in_set_to_optimize_join}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "0" },
        {
          label:
            "read in order最適化を妨げるため、結合最適化を無効化"
        }
      ]
    }
  ]}
/>

結合前に、互いの行セットで結合対象テーブルをフィルタリングするセットの最大サイズ。

設定可能な値:

- 0 — 無効。
- 任意の正の整数。


## max_rows_to_group_by {#max_rows_to_group_by}

<SettingsInfoBlock type='UInt64' default_value='0' />

集約処理で受け取る一意のキーの最大数です。この設定により、集約時のメモリ消費量を制限できます。

GROUP BY による集約処理が指定された数を超える行数（一意の GROUP BY キー）を生成する場合、動作は 'group_by_overflow_mode' によって決定されます。このモードはデフォルトで `throw` ですが、近似 GROUP BY モードに切り替えることもできます。


## max_rows_to_read {#max_rows_to_read}

<SettingsInfoBlock type='UInt64' default_value='0' />

クエリ実行時にテーブルから読み取り可能な最大行数。
この制限は処理される各データチャンクごとにチェックされ、最も深いテーブル式にのみ適用されます。リモートサーバーから読み取る場合は、リモートサーバー上でのみチェックされます。


## max_rows_to_read_leaf {#max_rows_to_read_leaf}

<SettingsInfoBlock type='UInt64' default_value='0' />

分散クエリの実行時に、リーフノード上のローカルテーブルから読み取り可能な最大行数です。分散クエリは各シャード(リーフ)に対して複数のサブクエリを発行できますが、この制限はリーフノードでの読み取り段階でのみチェックされ、ルートノードでの結果マージ段階では無視されます。

例えば、クラスタが2つのシャードで構成され、各シャードに100行のテーブルが含まれている場合を考えます。`max_rows_to_read=150`の設定で両方のテーブルからすべてのデータを読み取ろうとする分散クエリは、合計で200行になるため失敗します。一方、`max_rows_to_read_leaf=150`を指定したクエリは、各リーフノードが最大100行しか読み取らないため成功します。

この制限は、処理される各データチャンクに対してチェックされます。

:::note
この設定は`prefer_localhost_replica=1`と併用すると不安定になります。
:::


## max_rows_to_sort {#max_rows_to_sort}

<SettingsInfoBlock type='UInt64' default_value='0' />

ソート前の最大行数。これにより、ソート時のメモリ消費量を制限できます。
ORDER BY操作で指定された量を超えるレコードを処理する必要がある場合、
動作は`sort_overflow_mode`によって決定されます。デフォルト値は`throw`です。


## max_rows_to_transfer {#max_rows_to_transfer}

<SettingsInfoBlock type='UInt64' default_value='0' />

GLOBAL IN/JOIN句の実行時にリモートサーバーに渡すことができる、または一時テーブルに保存できる最大サイズ(行数)。


## max_sessions_for_user {#max_sessions_for_user}

<SettingsInfoBlock type='UInt64' default_value='0' />

認証されたユーザーごとのClickHouseサーバーへの同時セッションの最大数。

例:

```xml
<profiles>
    <single_session_profile>
        <max_sessions_for_user>1</max_sessions_for_user>
    </single_session_profile>
    <two_sessions_profile>
        <max_sessions_for_user>2</max_sessions_for_user>
    </two_sessions_profile>
    <unlimited_sessions_profile>
        <max_sessions_for_user>0</max_sessions_for_user>
    </unlimited_sessions_profile>
</profiles>
<users>
    <!-- ユーザーAliceは同時に1つまでClickHouseサーバーに接続できます。 -->
    <Alice>
        <profile>single_session_user</profile>
    </Alice>
    <!-- ユーザーBobは2つの同時セッションを使用できます。 -->
    <Bob>
        <profile>two_sessions_profile</profile>
    </Bob>
    <!-- ユーザーCharlesは任意の数の同時セッションを使用できます。 -->
    <Charles>
        <profile>unlimited_sessions_profile</profile>
    </Charles>
</users>
```

設定可能な値:

- 正の整数
- `0` - 同時セッション数無制限(デフォルト)


## max_size_to_preallocate_for_aggregation {#max_size_to_preallocate_for_aggregation}

<SettingsInfoBlock type='UInt64' default_value='1000000000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "1000000000000" },
        { label: "大規模テーブル向けの最適化を有効化します。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "22.12" },
        { label: "100000000" },
        { label: "パフォーマンスを最適化します" }
      ]
    }
  ]}
/>

集計処理前に全ハッシュテーブルで合計何個の要素に対して領域を事前割り当て可能か


## max_size_to_preallocate_for_joins {#max_size_to_preallocate_for_joins}

<SettingsInfoBlock type='UInt64' default_value='1000000000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "100000000" },
        { label: "新しい設定。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.12" },
        { label: "1000000000000" },
        { label: "より大きなテーブルに対する最適化を有効化。" }
      ]
    }
  ]}
/>

結合処理前に、すべてのハッシュテーブルで合計何個の要素に対して領域の事前割り当てを許可するか


## max_streams_for_merge_tree_reading {#max_streams_for_merge_tree_reading}

<SettingsInfoBlock type='UInt64' default_value='0' />

ゼロ以外の場合、MergeTreeテーブルの読み取りストリーム数を制限します。


## max_streams_multiplier_for_merge_tables {#max_streams_multiplier_for_merge_tables}

<SettingsInfoBlock type='Float' default_value='5' />

Mergeテーブルからの読み取り時に、より多くのストリームを要求します。ストリームは、Mergeテーブルが使用する各テーブルに分散されます。これにより、スレッド間での作業負荷がより均等に分散され、マージ対象のテーブルのサイズが異なる場合に特に有効です。


## max_streams_to_max_threads_ratio {#max_streams_to_max_threads_ratio}

<SettingsInfoBlock type='Float' default_value='1' />

スレッド数よりも多くのソースを使用することで、スレッド間でより均等に作業を分散できるようにします。これは暫定的な解決策と想定されており、将来的にはソース数とスレッド数を等しくし、各ソースが動的に利用可能な作業を選択できるようになる予定です。


## max_subquery_depth {#max_subquery_depth}

<SettingsInfoBlock type='UInt64' default_value='100' />

クエリに指定された数を超えるネストされたサブクエリが含まれる場合、例外がスローされます。

:::tip
これにより、クラスタのユーザーが過度に複雑なクエリを記述するのを防ぐための妥当性チェックを実施できます。
:::


## max_table_size_to_drop {#max_table_size_to_drop}

<SettingsInfoBlock type='UInt64' default_value='50000000000' />

クエリ実行時にテーブルを削除する際の制限です。値が `0` の場合、すべてのテーブルを制限なく削除できます。

Cloudのデフォルト値: 1 TB。

:::note
このクエリ設定は、対応するサーバー設定を上書きします。詳細は [max_table_size_to_drop](/operations/server-configuration-parameters/settings#max_table_size_to_drop) を参照してください
:::


## max_temporary_columns {#max_temporary_columns}

<SettingsInfoBlock type='UInt64' default_value='0' />

クエリ実行時にRAMに同時保持する必要がある一時カラムの最大数です。定数カラムも含まれます。中間計算の結果、クエリが指定された数を超える一時カラムをメモリ内に生成した場合、例外がスローされます。

:::tip
この設定は、過度に複雑なクエリを防ぐのに役立ちます。
:::

`0`は無制限を意味します。


## max_temporary_data_on_disk_size_for_query {#max_temporary_data_on_disk_size_for_query}

<SettingsInfoBlock type='UInt64' default_value='0' />

同時実行中のすべてのクエリに対する、ディスク上の一時ファイルが消費するデータの最大量(バイト単位)。

設定可能な値:

- 正の整数
- `0` — 無制限(デフォルト)


## max_temporary_data_on_disk_size_for_user {#max_temporary_data_on_disk_size_for_user}

<SettingsInfoBlock type='UInt64' default_value='0' />

同時実行中のすべてのユーザークエリに対する、ディスク上の一時ファイルが消費するデータの最大量(バイト単位)。

設定可能な値:

- 正の整数
- `0` — 無制限(デフォルト)


## max_temporary_non_const_columns {#max_temporary_non_const_columns}

<SettingsInfoBlock type='UInt64' default_value='0' />

`max_temporary_columns`と同様に、クエリ実行時にRAMに同時保持する必要がある一時カラムの最大数を指定しますが、定数カラムはカウントされません。

:::note
定数カラムはクエリ実行時に頻繁に生成されますが、必要な計算リソースはほぼゼロです。
:::


## max_threads {#max_threads}

<SettingsInfoBlock type='MaxThreads' default_value="'auto(N)'" />

クエリ処理スレッドの最大数。リモートサーバーからデータを取得するスレッドは含まれません（'max_distributed_connections'パラメータを参照）。

このパラメータは、クエリ処理パイプラインの同一ステージを並列実行するスレッドに適用されます。
例えば、テーブルからの読み取り時に、関数による式の評価、WHEREによるフィルタリング、GROUP BYの事前集計を、少なくとも'max_threads'個のスレッドで並列実行可能な場合、'max_threads'が使用されます。

LIMITにより高速に完了するクエリの場合、より小さい'max_threads'を設定できます。例えば、必要な数のエントリが各ブロックに存在し、max_threads = 8の場合、1つのブロックを読み取るだけで十分であるにもかかわらず、8つのブロックが取得されます。

`max_threads`の値が小さいほど、メモリ消費量は少なくなります。

Cloudのデフォルト値: `auto(3)`


## max_threads_for_indexes {#max_threads_for_indexes}

<SettingsInfoBlock type='UInt64' default_value='0' />

インデックスを処理するスレッドの最大数。


## max_untracked_memory {#max_untracked_memory}

<SettingsInfoBlock type='UInt64' default_value='4194304' />

小規模なメモリの割り当てと解放はスレッドローカル変数にグループ化され、その量(絶対値)が指定された値を超えた場合にのみ追跡またはプロファイリングされます。この値が 'memory_profiler_step' より大きい場合、実質的に 'memory_profiler_step' に引き下げられます。


## memory_overcommit_ratio_denominator {#memory_overcommit_ratio_denominator}

<SettingsInfoBlock type='UInt64' default_value='1073741824' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.5" },
        { label: "1073741824" },
        { label: "メモリオーバーコミット機能をデフォルトで有効化" }
      ]
    }
  ]}
/>

グローバルレベルでハード制限に達した際のソフトメモリ制限を表します。
この値はクエリのオーバーコミット比率の計算に使用されます。
ゼロの場合はクエリをスキップします。
詳細は[メモリオーバーコミット](memory-overcommit.md)を参照してください。


## memory_overcommit_ratio_denominator_for_user {#memory_overcommit_ratio_denominator_for_user}

<SettingsInfoBlock type='UInt64' default_value='1073741824' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.5" },
        { label: "1073741824" },
        { label: "メモリオーバーコミット機能をデフォルトで有効化" }
      ]
    }
  ]}
/>

ユーザーレベルでハード制限に達した際のソフトメモリ制限を表します。
この値は、クエリのオーバーコミット比率の計算に使用されます。
ゼロの場合、クエリはスキップされます。
詳細は[メモリオーバーコミット](memory-overcommit.md)を参照してください。


## memory_profiler_sample_max_allocation_size {#memory_profiler_sample_max_allocation_size}

<SettingsInfoBlock type='UInt64' default_value='0' />

指定された値以下のサイズのランダムなメモリ割り当てを、`memory_profiler_sample_probability`と等しい確率で収集します。0は無効を意味します。この閾値を期待通りに機能させるには、'max_untracked_memory'を0に設定することを推奨します。


## memory_profiler_sample_min_allocation_size {#memory_profiler_sample_min_allocation_size}

<SettingsInfoBlock type='UInt64' default_value='0' />

指定された値以上のサイズのメモリ割り当てを、`memory_profiler_sample_probability`で指定された確率でランダムに収集します。0を指定すると無効になります。この閾値を期待通りに機能させるには、'max_untracked_memory'を0に設定することを推奨します。


## memory_profiler_sample_probability {#memory_profiler_sample_probability}

<SettingsInfoBlock type='Float' default_value='0' />

ランダムなメモリ割り当てと解放を収集し、'MemorySample' trace_typeとしてsystem.trace_logに書き込みます。この確率は割り当てサイズに関係なく、すべてのalloc/freeに対して適用されます(`memory_profiler_sample_min_allocation_size`および`memory_profiler_sample_max_allocation_size`で変更可能)。サンプリングは追跡されていないメモリ量が'max_untracked_memory'を超えた場合にのみ実行されることに注意してください。より細かいサンプリングを行う場合は、'max_untracked_memory'を0に設定することを推奨します。


## memory_profiler_step {#memory_profiler_step}

<SettingsInfoBlock type='UInt64' default_value='4194304' />

メモリプロファイラのステップを設定します。クエリのメモリ使用量がバイト数で次のステップごとに超えるたびに、メモリプロファイラは割り当てスタックトレースを収集し、[trace_log](/operations/system-tables/trace_log)に書き込みます。

設定可能な値:

- 正の整数のバイト数

- メモリプロファイラを無効にする場合は0


## memory_tracker_fault_probability {#memory_tracker_fault_probability}

<SettingsInfoBlock type='Float' default_value='0' />

`例外安全性`のテスト用 - 指定された確率でメモリ割り当て時に例外をスローします。


## memory_usage_overcommit_max_wait_microseconds {#memory_usage_overcommit_max_wait_microseconds}

<SettingsInfoBlock type='UInt64' default_value='5000000' />

ユーザーレベルでメモリオーバーコミットが発生した際に、スレッドがメモリ解放を待機する最大時間。
タイムアウトに達してもメモリが解放されない場合は、例外がスローされます。
詳細は[メモリオーバーコミット](memory-overcommit.md)を参照してください。


## merge_table_max_tables_to_look_for_schema_inference {#merge_table_max_tables_to_look_for_schema_inference}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "1000" }, { label: "新しい設定" }]
    }
  ]}
/>

明示的なスキーマを指定せずに`Merge`テーブルを作成する場合、または`merge`テーブル関数を使用する場合、指定された数を上限として一致するテーブルの和集合からスキーマを推論します。
一致するテーブルがそれより多く存在する場合、最初の指定された数のテーブルからスキーマが推論されます。


## merge_tree_coarse_index_granularity {#merge_tree_coarse_index_granularity}

<SettingsInfoBlock type='UInt64' default_value='8' />

データ検索時、ClickHouseはインデックスファイル内のデータマークをチェックします。必要なキーが特定の範囲内に存在することをClickHouseが検出すると、その範囲を`merge_tree_coarse_index_granularity`個のサブ範囲に分割し、再帰的に必要なキーを検索します。

設定可能な値:

- 任意の正の偶数


## merge_tree_compact_parts_min_granules_to_multibuffer_read {#merge_tree_compact_parts_min_granules_to_multibuffer_read}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='16' />

ClickHouse Cloudでのみ有効です。並列読み取りとプリフェッチをサポートするマルチバッファリーダーを使用する、MergeTreeテーブルのコンパクトパートのストライプ内のグラニュール数を指定します。リモートファイルシステムから読み取る場合、マルチバッファリーダーを使用すると読み取りリクエスト数が増加します。


## merge_tree_determine_task_size_by_prewhere_columns {#merge_tree_determine_task_size_by_prewhere_columns}

<SettingsInfoBlock type='Bool' default_value='1' />

読み取りタスクのサイズを決定する際に、PREWHERE列のサイズのみを使用するかどうかを指定します。


## merge_tree_max_bytes_to_use_cache {#merge_tree_max_bytes_to_use_cache}

<SettingsInfoBlock type='UInt64' default_value='2013265920' />

ClickHouseが1つのクエリで`merge_tree_max_bytes_to_use_cache`バイトを超えるデータを読み取る必要がある場合、非圧縮ブロックのキャッシュを使用しません。

非圧縮ブロックのキャッシュには、クエリ用に抽出されたデータが格納されます。ClickHouseはこのキャッシュを使用して、繰り返し実行される小規模なクエリへの応答を高速化します。この設定により、大量のデータを読み取るクエリによってキャッシュが汚染されることを防ぎます。[uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size)サーバー設定で、非圧縮ブロックのキャッシュのサイズを定義します。

設定可能な値:

- 任意の正の整数


## merge_tree_max_rows_to_use_cache {#merge_tree_max_rows_to_use_cache}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

ClickHouseが1つのクエリで`merge_tree_max_rows_to_use_cache`を超える行数を読み取る場合、非圧縮ブロックのキャッシュは使用されません。

非圧縮ブロックのキャッシュには、クエリ用に抽出されたデータが保存されます。ClickHouseはこのキャッシュを使用して、繰り返し実行される小規模なクエリへの応答を高速化します。この設定により、大量のデータを読み取るクエリによってキャッシュが破棄されることを防ぎます。[uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size)サーバー設定で、非圧縮ブロックのキャッシュのサイズを定義します。

設定可能な値:

- 任意の正の整数


## merge_tree_min_bytes_for_concurrent_read {#merge_tree_min_bytes_for_concurrent_read}

<SettingsInfoBlock type='UInt64' default_value='251658240' />

[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)エンジンテーブルの1つのファイルから読み取るバイト数が`merge_tree_min_bytes_for_concurrent_read`を超えた場合、ClickHouseは複数のスレッドでそのファイルから並行読み取りを試みます。

設定可能な値:

- 正の整数


## merge_tree_min_bytes_for_concurrent_read_for_remote_filesystem {#merge_tree_min_bytes_for_concurrent_read_for_remote_filesystem}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "非推奨の設定" }
      ]
    }
  ]}
/>

リモートファイルシステムから読み取る際に、[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)エンジンが並列読み取りを実行できるようになる前に、1つのファイルから読み取る必要がある最小バイト数。この設定の使用は推奨しません。

設定可能な値:

- 正の整数


## merge_tree_min_bytes_for_seek {#merge_tree_min_bytes_for_seek}

<SettingsInfoBlock type='UInt64' default_value='0' />

1つのファイル内で読み取る2つのデータブロック間の距離が`merge_tree_min_bytes_for_seek`バイト未満の場合、ClickHouseは両方のブロックを含むファイル範囲を順次読み取ることで、余分なシーク操作を回避します。

設定可能な値:

- 任意の正の整数


## merge_tree_min_bytes_per_task_for_remote_reading {#merge_tree_min_bytes_per_task_for_remote_reading}

**エイリアス**: `filesystem_prefetch_min_bytes_for_single_read_task`

<SettingsInfoBlock type='UInt64' default_value='2097152' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.8" },
        { label: "2097152" },
        {
          label:
            "`filesystem_prefetch_min_bytes_for_single_read_task`と値が統合されました"
        }
      ]
    }
  ]}
/>

タスクごとに読み取る最小バイト数。


## merge_tree_min_read_task_size {#merge_tree_min_read_task_size}

<SettingsInfoBlock type='NonZeroUInt64' default_value='8' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "8" }, { label: "新しい設定" }]
    }
  ]}
/>

タスクサイズの厳密な下限値（グラニュール数が少なく、利用可能なスレッド数が多い場合でも、この値より小さいタスクは割り当てられません）


## merge_tree_min_rows_for_concurrent_read {#merge_tree_min_rows_for_concurrent_read}

<SettingsInfoBlock type='UInt64' default_value='163840' />

[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)テーブルのファイルから読み取る行数が`merge_tree_min_rows_for_concurrent_read`を超えた場合、ClickHouseは複数のスレッドでこのファイルからの並行読み取りを実行しようとします。

設定可能な値:

- 正の整数


## merge_tree_min_rows_for_concurrent_read_for_remote_filesystem {#merge_tree_min_rows_for_concurrent_read_for_remote_filesystem}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "この設定は非推奨です" }
      ]
    }
  ]}
/>

リモートファイルシステムから読み取る際に、[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)エンジンが並列読み取りを実行する前に、1つのファイルから読み取る必要がある最小行数です。この設定の使用は推奨されません。

設定可能な値:

- 正の整数


## merge_tree_min_rows_for_seek {#merge_tree_min_rows_for_seek}

<SettingsInfoBlock type='UInt64' default_value='0' />

1つのファイル内で読み取る2つのデータブロック間の距離が `merge_tree_min_rows_for_seek` 行未満の場合、ClickHouseはファイルをシークせずにデータを順次読み取ります。

設定可能な値:

- 任意の正の整数


## merge_tree_read_split_ranges_into_intersecting_and_non_intersecting_injection_probability {#merge_tree_read_split_ranges_into_intersecting_and_non_intersecting_injection_probability}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        {
          label:
            "`PartsSplitter`のテスト用 - 指定された確率でMergeTreeから読み取るたびに、読み取り範囲を交差する範囲と交差しない範囲に分割します。"
        }
      ]
    }
  ]}
/>

`PartsSplitter`のテスト用 - 指定された確率でMergeTreeから読み取るたびに、読み取り範囲を交差する範囲と交差しない範囲に分割します。


## merge_tree_storage_snapshot_sleep_ms {#merge_tree_storage_snapshot_sleep_ms}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "0" },
        {
          label: "クエリ内のストレージスナップショット整合性をデバッグするための新しい設定"
        }
      ]
    }
  ]}
/>

MergeTreeテーブルのストレージスナップショット作成時に人為的な遅延（ミリ秒）を挿入します。
テストおよびデバッグ目的でのみ使用します。

設定可能な値:

- 0 - 遅延なし（デフォルト）
- N - ミリ秒単位の遅延


## merge_tree_use_const_size_tasks_for_remote_reading {#merge_tree_use_const_size_tasks_for_remote_reading}

<SettingsInfoBlock type='Bool' default_value='1' />

リモートテーブルからの読み取りに固定サイズのタスクを使用するかどうか。


## merge_tree_use_deserialization_prefixes_cache {#merge_tree_use_deserialization_prefixes_cache}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.2" },
        { label: "1" },
        {
          label:
            "MergeTreeにおけるデシリアライゼーションプレフィックスキャッシュの使用を制御する新しい設定"
        }
      ]
    }
  ]}
/>

MergeTreeでリモートディスクから読み取る際に、ファイルプレフィックスからのカラムメタデータのキャッシュを有効にします。


## merge_tree_use_prefixes_deserialization_thread_pool {#merge_tree_use_prefixes_deserialization_thread_pool}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.2" },
        { label: "1" },
        {
          label:
            "MergeTreeにおける並列プレフィックスデシリアライゼーション用スレッドプールの使用を制御する新しい設定"
        }
      ]
    }
  ]}
/>

MergeTreeのWideパートにおける並列プレフィックス読み取り用スレッドプールの使用を有効にします。このスレッドプールのサイズは、サーバー設定`max_prefixes_deserialization_thread_pool_size`で制御されます。


## merge_tree_use_v1_object_and_dynamic_serialization {#merge_tree_use_v1_object_and_dynamic_serialization}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "0" },
        { label: "JSONおよびDynamic型の新しいシリアライゼーションバージョンV2を追加" }
      ]
    }
  ]}
/>

有効にすると、MergeTreeにおいてJSONおよびDynamic型のシリアライゼーションバージョンV1がV2の代わりに使用されます。この設定の変更はサーバー再起動後にのみ反映されます。


## metrics_perf_events_enabled {#metrics_perf_events_enabled}

<SettingsInfoBlock type='Bool' default_value='0' />

有効にすると、クエリの実行全体を通じて一部のperfイベントが測定されます。


## metrics_perf_events_list {#metrics_perf_events_list}

クエリの実行中に測定されるperfメトリクスのカンマ区切りリスト。空の場合は全てのイベントが対象となります。利用可能なイベントについては、ソースコード内のPerfEventInfoを参照してください。


## min_bytes_to_use_direct_io {#min_bytes_to_use_direct_io}

<SettingsInfoBlock type='UInt64' default_value='0' />

ストレージディスクへのダイレクトI/Oアクセスを使用するために必要な最小データ量。

ClickHouseは、テーブルからデータを読み取る際にこの設定を使用します。読み取るすべてのデータの合計ストレージ容量が`min_bytes_to_use_direct_io`バイトを超える場合、ClickHouseは`O_DIRECT`オプションを使用してストレージディスクからデータを読み取ります。

設定可能な値:

- 0 — ダイレクトI/Oは無効です。
- 正の整数。


## min_bytes_to_use_mmap_io {#min_bytes_to_use_mmap_io}

<SettingsInfoBlock type='UInt64' default_value='0' />

これは実験的な設定です。カーネルからユーザー空間へのデータコピーを行わずに大きなファイルを読み取る際の最小メモリ量を設定します。[mmap/munmap](https://en.wikipedia.org/wiki/Mmap)は低速であるため、推奨される閾値は約64MBです。この設定は大きなファイルに対してのみ有効であり、データがページキャッシュに存在する場合にのみ効果があります。

設定可能な値:

- 正の整数
- 0 — 大きなファイルをカーネルからユーザー空間へデータをコピーして読み取ります。


## min_chunk_bytes_for_parallel_parsing {#min_chunk_bytes_for_parallel_parsing}

<SettingsInfoBlock type='NonZeroUInt64' default_value='10485760' />

- 型: 符号なし整数
- デフォルト値: 1 MiB

各スレッドが並列解析する最小チャンクサイズ(バイト単位)。


## min_compress_block_size {#min_compress_block_size}

<SettingsInfoBlock type='UInt64' default_value='65536' />

[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)テーブル用の設定です。クエリ処理時のレイテンシを削減するため、次のマークを書き込む際にブロックのサイズが`min_compress_block_size`以上である場合、ブロックが圧縮されます。デフォルト値は65,536です。

非圧縮データが`max_compress_block_size`未満の場合、ブロックの実際のサイズはこの値以上、かつ1マーク分のデータ量以上になります。

例を見てみましょう。テーブル作成時に`index_granularity`が8192に設定されていると仮定します。

UInt32型のカラム(値あたり4バイト)を書き込む場合、8192行を書き込むと合計32KBのデータになります。min_compress_block_size = 65,536であるため、2マークごとに圧縮ブロックが形成されます。

String型のURLカラム(値あたり平均60バイト)を書き込む場合、8192行を書き込むと平均で500KB弱のデータになります。これは65,536より大きいため、マークごとに圧縮ブロックが形成されます。この場合、ディスクから単一マークの範囲のデータを読み取る際に、余分なデータが解凍されることはありません。

:::note
これは上級者向けの設定であり、ClickHouseを使い始めたばかりの場合は変更すべきではありません。
:::


## min_count_to_compile_aggregate_expression {#min_count_to_compile_aggregate_expression}

<SettingsInfoBlock type='UInt64' default_value='3' />

JITコンパイルを開始するために必要な同一の集約式の最小数。[compile_aggregate_expressions](#compile_aggregate_expressions)設定が有効になっている場合にのみ動作します。

設定可能な値:

- 正の整数
- 0 — 同一の集約式は常にJITコンパイルされます


## min_count_to_compile_expression {#min_count_to_compile_expression}

<SettingsInfoBlock type='UInt64' default_value='3' />

式がコンパイルされる前に、同じ式を実行する必要がある最小回数。


## min_count_to_compile_sort_description {#min_count_to_compile_sort_description}

<SettingsInfoBlock type='UInt64' default_value='3' />

JITコンパイルされるまでに必要な同一のソート記述の数


## min_execution_speed {#min_execution_speed}

<SettingsInfoBlock type='UInt64' default_value='0' />

1秒あたりの行数で表される最小実行速度。[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)が期限切れになった時点で、各データブロックに対してチェックされます。実行速度がこの値を下回った場合、例外がスローされます。


## min_execution_speed_bytes {#min_execution_speed_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

1秒あたりの最小実行バイト数。[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)が期限切れになった時点で、各データブロックごとにチェックされます。実行速度がこの値を下回った場合、例外がスローされます。


## min_external_table_block_size_bytes {#min_external_table_block_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='268402944' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "268402944" },
        {
          label:
            "ブロックが十分に大きくない場合、外部テーブルに渡されるブロックを指定されたバイトサイズに統合します。"
        }
      ]
    }
  ]}
/>

ブロックが十分に大きくない場合、外部テーブルに渡されるブロックを指定されたバイトサイズに統合します。


## min_external_table_block_size_rows {#min_external_table_block_size_rows}

<SettingsInfoBlock type='UInt64' default_value='1048449' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1048449" },
        {
          label:
            "ブロックが十分に大きくない場合、外部テーブルに渡されるブロックを指定された行サイズに圧縮します"
        }
      ]
    }
  ]}
/>

ブロックが十分に大きくない場合、外部テーブルに渡されるブロックを指定された行サイズに圧縮します.


## min_free_disk_bytes_to_perform_insert {#min_free_disk_bytes_to_perform_insert}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        {
          label:
            "一時的な書き込みを許可しつつ、挿入時に一定の空きディスク容量(バイト)を維持します。"
        }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

挿入を実行するために必要な最小空きディスク容量(バイト)。


## min_free_disk_ratio_to_perform_insert {#min_free_disk_ratio_to_perform_insert}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        {
          label:
            "一時的な書き込みを許可しつつ、挿入時に総ディスク容量に対する比率として表現される空きディスク容量を維持します。"
        }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

挿入を実行するために必要な最小空きディスク容量比率。


## min_free_disk_space_for_temporary_data {#min_free_disk_space_for_temporary_data}

<SettingsInfoBlock type='UInt64' default_value='0' />

外部ソートおよび集約で使用される一時データを書き込む際に確保すべき最小ディスク容量。


## min_hit_rate_to_use_consecutive_keys_optimization {#min_hit_rate_to_use_consecutive_keys_optimization}

<SettingsInfoBlock type='Float' default_value='0.5' />

集約における連続キー最適化で使用されるキャッシュの最小ヒット率。この値を下回ると最適化が無効になります


## min_insert_block_size_bytes {#min_insert_block_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='268402944' />

`INSERT`クエリによってテーブルに挿入可能なブロックの最小バイト数を設定します。小さいサイズのブロックは大きなブロックに統合されます。

設定可能な値:

- 正の整数
- 0 — 統合無効


## min_insert_block_size_bytes_for_materialized_views {#min_insert_block_size_bytes_for_materialized_views}

<SettingsInfoBlock type='UInt64' default_value='0' />

`INSERT`クエリによってテーブルに挿入できるブロックの最小バイト数を設定します。小さいサイズのブロックは大きなブロックに統合されます。この設定は[マテリアライズドビュー](../../sql-reference/statements/create/view.md)に挿入されるブロックにのみ適用されます。この設定を調整することで、マテリアライズドビューへの書き込み時のブロック統合を制御し、過度なメモリ使用を回避できます。

設定可能な値:

- 任意の正の整数。
- 0 — 統合が無効化されます。

**関連項目**

- [min_insert_block_size_bytes](#min_insert_block_size_bytes)


## min_insert_block_size_rows {#min_insert_block_size_rows}

<SettingsInfoBlock type='UInt64' default_value='1048449' />

`INSERT`クエリによってテーブルに挿入可能なブロック内の最小行数を設定します。小さいサイズのブロックは大きなブロックに統合されます。

設定可能な値:

- 正の整数
- 0 — 統合を無効化


## min_insert_block_size_rows_for_materialized_views {#min_insert_block_size_rows_for_materialized_views}

<SettingsInfoBlock type='UInt64' default_value='0' />

`INSERT`クエリによってテーブルに挿入できるブロック内の最小行数を設定します。小さいサイズのブロックは大きなブロックに統合されます。この設定は[マテリアライズドビュー](../../sql-reference/statements/create/view.md)に挿入されるブロックにのみ適用されます。この設定を調整することで、マテリアライズドビューへのプッシュ時のブロック統合を制御し、過度なメモリ使用を回避できます。

設定可能な値:

- 任意の正の整数。
- 0 — 統合が無効化されます。

**関連項目**

- [min_insert_block_size_rows](#min_insert_block_size_rows)


## min_joined_block_size_bytes {#min_joined_block_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='524288' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "524288" },
        { label: "新しい設定。" }
      ]
    }
  ]}
/>

JOIN の入力および出力ブロックの最小ブロックサイズ(バイト単位)(結合アルゴリズムがサポートしている場合)。小さなブロックは結合されます。0 は無制限を意味します。


## min_joined_block_size_rows {#min_joined_block_size_rows}

<SettingsInfoBlock type='UInt64' default_value='65409' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.7" }, { label: "65409" }, { label: "新しい設定。" }]
    }
  ]}
/>

JOIN の入力および出力ブロックの最小ブロックサイズ（行単位）です（結合アルゴリズムがサポートしている場合）。小さなブロックは統合されます。0 は無制限を意味します。


## min_os_cpu_wait_time_ratio_to_throw {#min_os_cpu_wait_time_ratio_to_throw}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "設定値が変更され、25.4にバックポートされました" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

クエリの拒否を検討する際の、OS CPU待機時間(OSCPUWaitMicrosecondsメトリック)とビジー時間(OSCPUVirtualTimeMicrosecondsメトリック)の最小比率。最小比率と最大比率の間で線形補間を使用して確率を計算します。この時点での確率は0です。


## min_outstreams_per_resize_after_split {#min_outstreams_per_resize_after_split}

<SettingsInfoBlock type='UInt64' default_value='24' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.6" }, { label: "24" }, { label: "新しい設定。" }]
    }
  ]}
/>

パイプライン生成時に分割が実行された後の`Resize`または`StrictResize`プロセッサの出力ストリームの最小数を指定します。結果として得られるストリーム数がこの値未満の場合、分割操作は実行されません。

### Resizeノードとは

`Resize`ノードは、クエリパイプライン内でパイプラインを流れるデータストリームの数を調整するプロセッサです。複数のスレッドやプロセッサ間でワークロードのバランスを取るために、ストリーム数を増減させることができます。例えば、クエリがより高い並列性を必要とする場合、`Resize`ノードは単一のストリームを複数のストリームに分割できます。逆に、複数のストリームをより少ないストリームに統合してデータ処理を集約することも可能です。

`Resize`ノードは、データブロックの構造を維持しながら、データがストリーム間で均等に分散されることを保証します。これにより、リソース使用率の最適化とクエリパフォーマンスの向上に貢献します。

### Resizeノードを分割する必要がある理由

パイプライン実行中、中央ハブ化された`Resize`ノードのExecutingGraph::Node::status_mutexは、特に高コア数環境において激しく競合し、この競合により以下の問題が発生します:

1. ExecutingGraph::updateNodeのレイテンシが増加し、クエリパフォーマンスに直接影響を与える。
2. スピンロック競合(native_queued_spin_lock_slowpath)で過剰なCPUサイクルが浪費され、効率が低下する。
3. CPU使用率が低下し、並列性とスループットが制限される。

### Resizeノードの分割方法

1. 分割が実行可能であることを確認するために出力ストリーム数がチェックされます:各分割プロセッサの出力ストリームが`min_outstreams_per_resize_after_split`の閾値以上である必要があります。
2. `Resize`ノードは、同数のポートを持つより小さな`Resize`ノードに分割され、それぞれが入力ストリームと出力ストリームのサブセットを処理します。
3. 各グループは独立して処理され、ロック競合が軽減されます。

### 任意の入力/出力を持つResizeノードの分割

入力/出力が分割`Resize`ノード数で割り切れない場合、一部の入力は`NullSource`に接続され、一部の出力は`NullSink`に接続されます。これにより、全体的なデータフローに影響を与えることなく分割を実行できます。

### 設定の目的

`min_outstreams_per_resize_after_split`設定は、`Resize`ノードの分割が意味のあるものであることを保証し、非効率的な並列処理につながる可能性のあるストリーム数の過少な作成を回避します。出力ストリームの最小数を強制することで、この設定は並列性とオーバーヘッドのバランスを維持し、ストリームの分割と統合を伴うシナリオにおいてクエリ実行を最適化します。

### 設定の無効化

`Resize`ノードの分割を無効にするには、この設定を0に設定します。これにより、パイプライン生成時の`Resize`ノードの分割が防止され、より小さなノードへの分割なしに元の構造を維持できます。


## min_table_rows_to_use_projection_index {#min_table_rows_to_use_projection_index}

<SettingsInfoBlock type='UInt64' default_value='1000000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1000000" },
        { label: "新しい設定" }
      ]
    }
  ]}
/>

テーブルから読み取る推定行数がこの閾値以上の場合、ClickHouseはクエリ実行時にプロジェクションインデックスの使用を試みます。


## mongodb_throw_on_unsupported_query {#mongodb_throw_on_unsupported_query}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.9" }, { label: "1" }, { label: "新しい設定。" }]
    },
    {
      id: "row-2",
      items: [{ label: "24.10" }, { label: "1" }, { label: "新しい設定。" }]
    }
  ]}
/>

有効にすると、MongoDBクエリを構築できない場合、MongoDBテーブルはエラーを返します。無効の場合、ClickHouseはテーブル全体を読み込み、ローカルで処理します。このオプションは'allow_experimental_analyzer=0'の場合は適用されません。


## move_all_conditions_to_prewhere {#move_all_conditions_to_prewhere}

<SettingsInfoBlock type='Bool' default_value='1' />

WHERE句から適用可能なすべての条件をPREWHERE句に移動します


## move_primary_key_columns_to_end_of_prewhere {#move_primary_key_columns_to_end_of_prewhere}

<SettingsInfoBlock type='Bool' default_value='1' />

プライマリキー列を含むPREWHERE条件をANDチェーンの末尾に移動します。これらの条件はプライマリキー解析時に考慮される可能性が高く、PREWHEREフィルタリングへの寄与度が低いためです。


## multiple_joins_try_to_keep_original_names {#multiple_joins_try_to_keep_original_names}

<SettingsInfoBlock type='Bool' default_value='0' />

複数のJOINの書き換え時に、トップレベルの式リストにエイリアスを追加しません


## mutations_execute_nondeterministic_on_initiator {#mutations_execute_nondeterministic_on_initiator}

<SettingsInfoBlock type='Bool' default_value='0' />

trueの場合、定数非決定的関数（例：`now()`関数）がイニシエーター上で実行され、`UPDATE`および`DELETE`クエリ内でリテラルに置き換えられます。これにより、定数非決定的関数を含むミューテーションの実行時に、レプリカ間でデータの同期が保たれます。デフォルト値：`false`。


## mutations_execute_subqueries_on_initiator {#mutations_execute_subqueries_on_initiator}

<SettingsInfoBlock type='Bool' default_value='0' />

trueの場合、スカラーサブクエリはイニシエーター上で実行され、`UPDATE`および`DELETE`クエリ内でリテラルに置換されます。デフォルト値: `false`。


## mutations_max_literal_size_to_replace {#mutations_max_literal_size_to_replace}

<SettingsInfoBlock type='UInt64' default_value='16384' />

`UPDATE`および`DELETE`クエリで置換するシリアライズされたリテラルの最大サイズ(バイト単位)。上記の2つの設定のうち少なくとも1つが有効になっている場合にのみ適用されます。デフォルト値: 16384 (16 KiB)。


## mutations_sync {#mutations_sync}

<SettingsInfoBlock type='UInt64' default_value='0' />

`ALTER TABLE ... UPDATE|DELETE|MATERIALIZE INDEX|MATERIALIZE PROJECTION|MATERIALIZE COLUMN|MATERIALIZE STATISTICS` クエリ（[mutations](../../sql-reference/statements/alter/index.md/#mutations)）を同期的に実行します。

設定可能な値:

| 値 | 説明                                                                                                                                            |
| ----- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `0`   | Mutationは非同期で実行されます。                                                                                                                      |
| `1`   | クエリは現在のサーバー上のすべてのmutationが完了するまで待機します。                                                                                   |
| `2`   | クエリはすべてのレプリカ（存在する場合）上のすべてのmutationが完了するまで待機します。                                                                         |
| `3`   | クエリはアクティブなレプリカのみ待機します。`SharedMergeTree`でのみサポートされます。`ReplicatedMergeTree`では`mutations_sync = 2`と同じ動作になります。 |


## mysql_datatypes_support_level {#mysql_datatypes_support_level}

MySQLの型を対応するClickHouseの型に変換する方法を定義します。`decimal`、`datetime64`、`date2Date32`、`date2String`を任意に組み合わせたカンマ区切りのリストを指定します。

- `decimal`: 精度が許容される場合、`NUMERIC`型および`DECIMAL`型を`Decimal`型に変換します。
- `datetime64`: 精度が`0`でない場合、`DATETIME`型および`TIMESTAMP`型を`DateTime`型ではなく`DateTime64`型に変換します。
- `date2Date32`: `DATE`型を`Date`型ではなく`Date32`型に変換します。`date2String`より優先されます。
- `date2String`: `DATE`型を`Date`型ではなく`String`型に変換します。`datetime64`によって上書きされます。


## mysql_map_fixed_string_to_text_in_show_columns {#mysql_map_fixed_string_to_text_in_show_columns}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "ClickHouseとBIツールの接続設定を簡素化します。"
        }
      ]
    }
  ]}
/>

有効にすると、ClickHouseの[FixedString](../../sql-reference/data-types/fixedstring.md)データ型が[SHOW COLUMNS](../../sql-reference/statements/show.md/#show_columns)で`TEXT`として表示されます。

MySQLワイヤプロトコル経由で接続している場合にのみ有効です。

- 0 - `BLOB`を使用します。
- 1 - `TEXT`を使用します。


## mysql_map_string_to_text_in_show_columns {#mysql_map_string_to_text_in_show_columns}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "ClickHouseとBIツールの接続における設定作業を軽減します。"
        }
      ]
    }
  ]}
/>

有効にすると、ClickHouseの[String](../../sql-reference/data-types/string.md)データ型が[SHOW COLUMNS](../../sql-reference/statements/show.md/#show_columns)で`TEXT`として表示されます。

MySQLワイヤープロトコル経由で接続している場合にのみ有効です。

- 0 - `BLOB`を使用
- 1 - `TEXT`を使用


## mysql_max_rows_to_insert {#mysql_max_rows_to_insert}

<SettingsInfoBlock type='UInt64' default_value='65536' />

MySQLストレージエンジンのバッチ挿入における最大行数


## network_compression_method {#network_compression_method}

<SettingsInfoBlock type='String' default_value='LZ4' />

クライアント/サーバー間およびサーバー/サーバー間通信を圧縮するコーデック。

設定可能な値:

- `NONE` — 圧縮なし。
- `LZ4` — LZ4コーデックを使用。
- `LZ4HC` — LZ4HCコーデックを使用。
- `ZSTD` — ZSTDコーデックを使用。

**関連項目**

- [network_zstd_compression_level](#network_zstd_compression_level)


## network_zstd_compression_level {#network_zstd_compression_level}

<SettingsInfoBlock type='Int64' default_value='1' />

ZSTD圧縮のレベルを調整します。[network_compression_method](#network_compression_method)が`ZSTD`に設定されている場合にのみ使用されます。

設定可能な値:

- 1から15までの正の整数


## normalize_function_names {#normalize_function_names}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.3" },
        { label: "1" },
        {
          label:
            "関数名を正規名に正規化します。これはプロジェクションクエリのルーティングに必要でした"
        }
      ]
    }
  ]}
/>

関数名を正規名に正規化します


## number_of_mutations_to_delay {#number_of_mutations_to_delay}

<SettingsInfoBlock type='UInt64' default_value='0' />

変更対象のテーブルに少なくともこの数の未完了のミューテーションが含まれている場合、テーブルのミューテーションを意図的に遅延させます。0 - 無効


## number_of_mutations_to_throw {#number_of_mutations_to_throw}

<SettingsInfoBlock type='UInt64' default_value='0' />

変更対象のテーブルに少なくともこの数の未完了のミューテーションが含まれている場合、'Too many mutations ...' 例外をスローします。0 - 無効化


## odbc_bridge_connection_pool_size {#odbc_bridge_connection_pool_size}

<SettingsInfoBlock type='UInt64' default_value='16' />

ODBCブリッジの各接続設定文字列に対するコネクションプールのサイズ。


## odbc_bridge_use_connection_pooling {#odbc_bridge_use_connection_pooling}

<SettingsInfoBlock type='Bool' default_value='1' />

ODBCブリッジで接続プーリングを使用します。falseに設定した場合、毎回新しい接続が作成されます。


## offset {#offset}

<SettingsInfoBlock type='UInt64' default_value='0' />

クエリから行を返し始める前にスキップする行数を設定します。[OFFSET](/sql-reference/statements/select/offset)句で設定されたオフセットを調整し、これら2つの値が合計されます。

設定可能な値:

- 0 — 行はスキップされません。
- 正の整数。

**例**

入力テーブル:

```sql
CREATE TABLE test (i UInt64) ENGINE = MergeTree() ORDER BY i;
INSERT INTO test SELECT number FROM numbers(500);
```

クエリ:

```sql
SET limit = 5;
SET offset = 7;
SELECT * FROM test LIMIT 10 OFFSET 100;
```

結果:

```text
┌───i─┐
│ 107 │
│ 108 │
│ 109 │
└─────┘
```


## opentelemetry_start_trace_probability {#opentelemetry_start_trace_probability}

<SettingsInfoBlock type='Float' default_value='0' />

親[トレースコンテキスト](https://www.w3.org/TR/trace-context/)が提供されていない場合に、ClickHouseが実行されたクエリに対してトレースを開始する確率を設定します。

設定可能な値:

- 0 — すべての実行されたクエリのトレースが無効になります(親トレースコンテキストが提供されていない場合)。
- [0..1]の範囲内の正の浮動小数点数。例えば、設定値が`0.5`の場合、ClickHouseは平均してクエリの半分に対してトレースを開始します。
- 1 — すべての実行されたクエリのトレースが有効になります。


## opentelemetry_trace_cpu_scheduling {#opentelemetry_trace_cpu_scheduling}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "0" },
        { label: "`cpu_slot_preemption`機能をトレースするための新しい設定。" }
      ]
    }
  ]}
/>

ワークロードのプリエンプティブCPUスケジューリングに関するOpenTelemetryスパンを収集します。


## opentelemetry_trace_processors {#opentelemetry_trace_processors}

<SettingsInfoBlock type='Bool' default_value='0' />

プロセッサーのOpenTelemetryスパンを収集します。


## optimize_aggregation_in_order {#optimize_aggregation_in_order}

<SettingsInfoBlock type='Bool' default_value='0' />

[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)テーブルにおいて、データを対応する順序で集約する[SELECT](../../sql-reference/statements/select/index.md)クエリの[GROUP BY](/sql-reference/statements/select/group-by)最適化を有効にします。

設定可能な値:

- 0 — `GROUP BY`最適化は無効です。
- 1 — `GROUP BY`最適化は有効です。

**関連項目**

- [GROUP BY最適化](/sql-reference/statements/select/group-by#group-by-optimization-depending-on-table-sorting-key)


## optimize_aggregators_of_group_by_keys {#optimize_aggregators_of_group_by_keys}

<SettingsInfoBlock type='Bool' default_value='1' />

SELECT句内のGROUP BYキーに対するmin/max/any/anyLast集約関数を除去します


## optimize_and_compare_chain {#optimize_and_compare_chain}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.2" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

AND連鎖における定数比較を展開し、フィルタリング能力を向上させます。演算子 `<`、`<=`、`>`、`>=`、`=` およびそれらの組み合わせをサポートします。例えば、`(a < b) AND (b < c) AND (c < 5)` は `(a < b) AND (b < c) AND (c < 5) AND (b < 5) AND (a < 5)` となります。


## optimize_append_index {#optimize_append_index}

<SettingsInfoBlock type='Bool' default_value='0' />

インデックス条件を追加する際に[制約](../../sql-reference/statements/create/table.md/#constraints)を使用します。デフォルトは`false`です。

使用可能な値:

- true, false


## optimize_arithmetic_operations_in_aggregate_functions {#optimize_arithmetic_operations_in_aggregate_functions}

<SettingsInfoBlock type='Bool' default_value='1' />

集約関数内の算術演算を外部に移動します


## optimize_const_name_size {#optimize_const_name_size}

<SettingsInfoBlock type='Int64' default_value='256' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "256" },
        {
          label:
            "大きな定数をスカラーに置き換え、名前としてハッシュを使用します(サイズは名前の長さで推定されます)"
        }
      ]
    }
  ]}
/>

大きな定数をスカラーに置き換え、名前としてハッシュを使用します(サイズは名前の長さで推定されます)。

設定可能な値:

- 正の整数 - 名前の最大長、
- 0 — 常に、
- 負の整数 - 適用しない。


## optimize_count_from_files {#optimize_count_from_files}

<SettingsInfoBlock type='Bool' default_value='1' />

異なる入力フォーマットのファイルから行数をカウントする最適化を有効または無効にします。テーブル関数/エンジン `file`/`s3`/`url`/`hdfs`/`azureBlobStorage` に適用されます。

設定可能な値:

- 0 — 最適化を無効にします。
- 1 — 最適化を有効にします。


## optimize_distinct_in_order {#optimize_distinct_in_order}

<SettingsInfoBlock type='Bool' default_value='1' />

DISTINCT句内の一部のカラムがソート順の接頭辞を形成する場合、DISTINCT最適化を有効にします。例えば、MergeTreeのソートキーの接頭辞やORDER BY句の接頭辞などです


## optimize_distributed_group_by_sharding_key {#optimize_distributed_group_by_sharding_key}

<SettingsInfoBlock type='Bool' default_value='1' />

イニシエーターサーバーでの負荷の高い集約処理を回避することで、`GROUP BY sharding_key`クエリを最適化します(これにより、イニシエーターサーバーでのクエリのメモリ使用量が削減されます)。

以下のタイプのクエリがサポートされています(およびそれらのすべての組み合わせ):

- `SELECT DISTINCT [..., ]sharding_key[, ...] FROM dist`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...]`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] ORDER BY x`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] LIMIT 1`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] LIMIT 1 BY x`

以下のタイプのクエリはサポートされていません(一部については今後サポートが追加される可能性があります):

- `SELECT ... GROUP BY sharding_key[, ...] WITH TOTALS`
- `SELECT ... GROUP BY sharding_key[, ...] WITH ROLLUP`
- `SELECT ... GROUP BY sharding_key[, ...] WITH CUBE`
- `SELECT ... GROUP BY sharding_key[, ...] SETTINGS extremes=1`

設定可能な値:

- 0 — 無効。
- 1 — 有効。

関連項目:

- [distributed_group_by_no_merge](#distributed_group_by_no_merge)
- [distributed_push_down_limit](#distributed_push_down_limit)
- [optimize_skip_unused_shards](#optimize_skip_unused_shards)

:::note
現在、この設定には`optimize_skip_unused_shards`が必要です(これは、将来デフォルトで有効になる可能性があり、Distributedテーブル経由でデータが挿入された場合、つまりsharding_keyに従ってデータが分散されている場合にのみ正しく動作するためです)。
:::


## optimize_empty_string_comparisons {#optimize_empty_string_comparisons}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "1" }, { label: "新しい設定。" }]
    }
  ]}
/>

`col = ''` または `'' = col` のような式を `empty(col)` に変換し、`col != ''` または `'' != col` を `notEmpty(col)` に変換します。
これは `col` が String 型または FixedString 型の場合にのみ適用されます。


## optimize_extract_common_expressions {#optimize_extract_common_expressions}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "1" },
        {
          label:
            "連言の選言から共通式を抽出することで、WHERE、PREWHERE、ON、HAVING、QUALIFY式を最適化します。"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.12" },
        { label: "0" },
        {
          label:
            "連言の選言から共通式を抽出することで、WHERE、PREWHERE、ON、HAVING、QUALIFY式を最適化する設定を導入します。"
        }
      ]
    }
  ]}
/>

WHERE、PREWHERE、ON、HAVING、QUALIFY式の選言から共通式を抽出できるようにします。`(A AND B) OR (A AND C)`のような論理式は`A AND (B OR C)`に書き換えることができ、以下の活用に役立つ可能性があります。

- 単純なフィルタリング式でのインデックスの利用
- クロス結合から内部結合への最適化


## optimize_functions_to_subcolumns {#optimize_functions_to_subcolumns}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.8" },
        { label: "1" },
        { label: "デフォルトで有効化" }
      ]
    }
  ]}
/>

一部の関数をサブカラムの読み取りに変換することで最適化を有効または無効にします。これにより、読み取るデータ量が削減されます。

以下の関数を変換できます:

- [length](/sql-reference/functions/array-functions#length) を [size0](../../sql-reference/data-types/array.md/#array-size) サブカラムの読み取りに変換します。
- [empty](/sql-reference/functions/array-functions#empty) を [size0](../../sql-reference/data-types/array.md/#array-size) サブカラムの読み取りに変換します。
- [notEmpty](/sql-reference/functions/array-functions#notEmpty) を [size0](../../sql-reference/data-types/array.md/#array-size) サブカラムの読み取りに変換します。
- [isNull](/sql-reference/functions/functions-for-nulls#isNull) を [null](../../sql-reference/data-types/nullable.md/#finding-null) サブカラムの読み取りに変換します。
- [isNotNull](/sql-reference/functions/functions-for-nulls#isNotNull) を [null](../../sql-reference/data-types/nullable.md/#finding-null) サブカラムの読み取りに変換します。
- [count](/sql-reference/aggregate-functions/reference/count) を [null](../../sql-reference/data-types/nullable.md/#finding-null) サブカラムの読み取りに変換します。
- [mapKeys](/sql-reference/functions/tuple-map-functions#mapkeys) を [keys](/sql-reference/data-types/map#reading-subcolumns-of-map) サブカラムの読み取りに変換します。
- [mapValues](/sql-reference/functions/tuple-map-functions#mapvalues) を [values](/sql-reference/data-types/map#reading-subcolumns-of-map) サブカラムの読み取りに変換します。

設定可能な値:

- 0 — 最適化が無効です。
- 1 — 最適化が有効です。


## optimize_group_by_constant_keys {#optimize_group_by_constant_keys}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.9" },
        { label: "1" },
        { label: "デフォルトで定数キーによるグループ化を最適化" }
      ]
    }
  ]}
/>

ブロック内のすべてのキーが定数の場合、GROUP BYを最適化します


## optimize_group_by_function_keys {#optimize_group_by_function_keys}

<SettingsInfoBlock type='Bool' default_value='1' />

GROUP BY句内の他のキーに対する関数を削除します


## optimize_if_chain_to_multiif {#optimize_if_chain_to_multiif}

<SettingsInfoBlock type='Bool' default_value='0' />

if(cond1, then1, if(cond2, ...))の連鎖をmultiIfに置き換えます。現在、数値型では効果がありません。


## optimize_if_transform_strings_to_enum {#optimize_if_transform_strings_to_enum}

<SettingsInfoBlock type='Bool' default_value='0' />

IfおよびTransform関数の文字列型引数を列挙型に置き換えます。分散クエリで不整合な変更が発生し、クエリが失敗する可能性があるため、デフォルトでは無効になっています。


## optimize_injective_functions_in_group_by {#optimize_injective_functions_in_group_by}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "1" },
        {
          label:
            "アナライザーのGROUP BY句において、単射関数をその引数に置き換える"
        }
      ]
    }
  ]}
/>

アナライザーのGROUP BY句において、単射関数をその引数に置き換えます


## optimize_injective_functions_inside_uniq {#optimize_injective_functions_inside_uniq}

<SettingsInfoBlock type='Bool' default_value='1' />

uniq\*() 関数内の単一引数の単射関数を削除します。


## optimize_min_equality_disjunction_chain_length {#optimize_min_equality_disjunction_chain_length}

<SettingsInfoBlock type='UInt64' default_value='3' />

最適化の対象となる式 `expr = x1 OR ... expr = xN` の最小長


## optimize_min_inequality_conjunction_chain_length {#optimize_min_inequality_conjunction_chain_length}

<SettingsInfoBlock type='UInt64' default_value='3' />

最適化の対象となる式 `expr <> x1 AND ... expr <> xN` の最小長


## optimize_move_to_prewhere {#optimize_move_to_prewhere}

<SettingsInfoBlock type='Bool' default_value='1' />

[SELECT](../../sql-reference/statements/select/index.md)クエリにおける自動[PREWHERE](../../sql-reference/statements/select/prewhere.md)最適化を有効または無効にします。

[\*MergeTree](../../engines/table-engines/mergetree-family/index.md)テーブルでのみ機能します。

設定可能な値:

- 0 — 自動`PREWHERE`最適化が無効です。
- 1 — 自動`PREWHERE`最適化が有効です。


## optimize_move_to_prewhere_if_final {#optimize_move_to_prewhere_if_final}

<SettingsInfoBlock type='Bool' default_value='0' />

[FINAL](/sql-reference/statements/select/from#final-modifier)修飾子を持つ[SELECT](../../sql-reference/statements/select/index.md)クエリにおける自動[PREWHERE](../../sql-reference/statements/select/prewhere.md)最適化を有効または無効にします。

[\*MergeTree](../../engines/table-engines/mergetree-family/index.md)テーブルでのみ機能します。

設定可能な値:

- 0 — `FINAL`修飾子を持つ`SELECT`クエリにおける自動`PREWHERE`最適化が無効です。
- 1 — `FINAL`修飾子を持つ`SELECT`クエリにおける自動`PREWHERE`最適化が有効です。

**関連項目**

- [optimize_move_to_prewhere](#optimize_move_to_prewhere)設定


## optimize_multiif_to_if {#optimize_multiif_to_if}

<SettingsInfoBlock type='Bool' default_value='1' />

条件が1つだけの 'multiIf' を 'if' に置き換えます。


## optimize_normalize_count_variants {#optimize_normalize_count_variants}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.3" },
        { label: "1" },
        {
          label:
            "意味的にcount()と等価な集約関数をデフォルトでcount()に書き換える"
        }
      ]
    }
  ]}
/>

意味的にcount()と等価な集約関数をcount()に書き換えます。


## optimize_on_insert {#optimize_on_insert}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.1" },
        { label: "1" },
        {
          label:
            "ユーザーエクスペリエンス向上のため、INSERT時のデータ最適化をデフォルトで有効化"
        }
      ]
    }
  ]}
/>

挿入前のデータ変換を有効または無効にします。テーブルエンジンに応じて、このブロックに対してマージが実行されたかのように動作します。

設定可能な値:

- 0 — 無効
- 1 — 有効

**例**

有効時と無効時の違い:

クエリ:

```sql
SET optimize_on_insert = 1;

CREATE TABLE test1 (`FirstTable` UInt32) ENGINE = ReplacingMergeTree ORDER BY FirstTable;

INSERT INTO test1 SELECT number % 2 FROM numbers(5);

SELECT * FROM test1;

SET optimize_on_insert = 0;

CREATE TABLE test2 (`SecondTable` UInt32) ENGINE = ReplacingMergeTree ORDER BY SecondTable;

INSERT INTO test2 SELECT number % 2 FROM numbers(5);

SELECT * FROM test2;
```

結果:

```text
┌─FirstTable─┐
│          0 │
│          1 │
└────────────┘

┌─SecondTable─┐
│           0 │
│           0 │
│           0 │
│           1 │
│           1 │
└─────────────┘
```

この設定は[マテリアライズドビュー](/sql-reference/statements/create/view#materialized-view)の動作に影響します。


## optimize_or_like_chain {#optimize_or_like_chain}

<SettingsInfoBlock type='Bool' default_value='0' />

複数のOR LIKE条件をmultiMatchAnyに最適化します。この最適化は、一部のケースでインデックス解析を妨げるため、デフォルトでは有効化すべきではありません。


## optimize_qbit_distance_function_reads {#optimize_qbit_distance_function_reads}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

`QBit`データ型の距離関数を、ストレージから計算に必要な列のみを読み取る同等の関数に置き換えます。


## optimize_read_in_order {#optimize_read_in_order}

<SettingsInfoBlock type='Bool' default_value='1' />

[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)テーブルからデータを読み取る[SELECT](../../sql-reference/statements/select/index.md)クエリにおける[ORDER BY](/sql-reference/statements/select/order-by#optimization-of-data-reading)最適化を有効にします。

設定可能な値:

- 0 — `ORDER BY`最適化が無効になります。
- 1 — `ORDER BY`最適化が有効になります。

**関連項目**

- [ORDER BY句](/sql-reference/statements/select/order-by#optimization-of-data-reading)


## optimize_read_in_window_order {#optimize_read_in_window_order}

<SettingsInfoBlock type='Bool' default_value='1' />

MergeTreeテーブルにおいて、ウィンドウ句内のORDER BY最適化を有効にし、対応する順序でデータを読み取ります。


## optimize_redundant_functions_in_order_by {#optimize_redundant_functions_in_order_by}

<SettingsInfoBlock type='Bool' default_value='1' />

引数がORDER BY句に含まれている場合、ORDER BY句から冗長な関数を削除します


## optimize_respect_aliases {#optimize_respect_aliases}

<SettingsInfoBlock type='Bool' default_value='1' />

trueに設定すると、WHERE/GROUP BY/ORDER BY句のエイリアスが考慮されるようになり、パーティションプルーニング、セカンダリインデックス、optimize_aggregation_in_order、optimize_read_in_order、optimize_trivial_countによる最適化が有効になります


## optimize_rewrite_aggregate_function_with_if {#optimize_rewrite_aggregate_function_with_if}

<SettingsInfoBlock type='Bool' default_value='1' />

論理的に等価な場合、if式を引数に持つ集約関数を書き換えます。
例えば、`avg(if(cond, col, null))` は `avgOrNullIf(cond, col)` に書き換えることができます。これによりパフォーマンスが向上する可能性があります。

:::note
アナライザー(`enable_analyzer = 1`)でのみサポートされています。
:::


## optimize_rewrite_array_exists_to_has {#optimize_rewrite_array_exists_to_has}

<SettingsInfoBlock type='Bool' default_value='0' />

論理的に等価な場合、arrayExists() 関数を has() に書き換えます。例えば、arrayExists(x -> x = 1, arr) は has(arr, 1) に書き換えることができます。


## optimize_rewrite_like_perfect_affix {#optimize_rewrite_like_perfect_affix}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

完全な接頭辞または接尾辞を持つLIKE式（例：`col LIKE 'ClickHouse%'`）をstartsWithまたはendsWith関数（例：`startsWith(col, 'ClickHouse')`）に書き換えます。


## optimize_rewrite_regexp_functions {#optimize_rewrite_regexp_functions}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1" }, { label: "A new setting" }]
    }
  ]}
/>

正規表現関連の関数をより単純で効率的な形式に書き換えます


## optimize_rewrite_sum_if_to_count_if {#optimize_rewrite_sum_if_to_count_if}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "1" },
        { label: "アナライザーでのみ利用可能で、正しく動作します" }
      ]
    }
  ]}
/>

論理的に等価な場合、sumIf()およびsum(if())関数をcountIf()関数に書き換えます


## optimize_skip_merged_partitions {#optimize_skip_merged_partitions}

<SettingsInfoBlock type='Bool' default_value='0' />

レベルが0より大きいパートが1つのみ存在し、かつ期限切れのTTLがない場合に、[OPTIMIZE TABLE ... FINAL](../../sql-reference/statements/optimize.md)クエリの最適化を有効または無効にします。

- `OPTIMIZE TABLE ... FINAL SETTINGS optimize_skip_merged_partitions=1`

デフォルトでは、`OPTIMIZE TABLE ... FINAL`クエリは、パートが1つしかない場合でもそのパートを書き換えます。

設定可能な値:

- 1 - 最適化を有効にします。
- 0 - 最適化を無効にします。


## optimize_skip_unused_shards {#optimize_skip_unused_shards}

<SettingsInfoBlock type='Bool' default_value='0' />

`WHERE/PREWHERE`にシャーディングキー条件を含む[SELECT](../../sql-reference/statements/select/index.md)クエリに対して、未使用シャードのスキップを有効化または無効化します(データがシャーディングキーによって分散されていることを前提としており、そうでない場合はクエリが不正確な結果を返します)。

設定可能な値:

- 0 — 無効。
- 1 — 有効。


## optimize_skip_unused_shards_limit {#optimize_skip_unused_shards_limit}

<SettingsInfoBlock type='UInt64' default_value='1000' />

シャーディングキー値の数の上限です。この上限に達すると `optimize_skip_unused_shards` が無効になります。

値が多すぎると処理に多大なリソースを要する可能性がありますが、その効果は疑わしいものです。なぜなら、`IN (...)` に膨大な数の値がある場合、クエリは結局すべてのシャードに送信される可能性が高いためです。


## optimize_skip_unused_shards_nesting {#optimize_skip_unused_shards_nesting}

<SettingsInfoBlock type='UInt64' default_value='0' />

分散クエリのネストレベルに応じて[`optimize_skip_unused_shards`](#optimize_skip_unused_shards)を制御します(そのため[`optimize_skip_unused_shards`](#optimize_skip_unused_shards)の有効化が必要です)。これは、ある`Distributed`テーブルが別の`Distributed`テーブルを参照している場合に該当します。

設定可能な値:

- 0 — 無効。`optimize_skip_unused_shards`は常に動作します。
- 1 — 第1レベルのみで`optimize_skip_unused_shards`を有効にします。
- 2 — 第2レベルまで`optimize_skip_unused_shards`を有効にします。


## optimize_skip_unused_shards_rewrite_in {#optimize_skip_unused_shards_rewrite_in}

<SettingsInfoBlock type='Bool' default_value='1' />

リモートシャードへのクエリ内のIN句を書き換えて、そのシャードに属さない値を除外します（optimize_skip_unused_shardsの設定が必要です）。

設定可能な値:

- 0 — 無効。
- 1 — 有効。


## optimize_sorting_by_input_stream_properties {#optimize_sorting_by_input_stream_properties}

<SettingsInfoBlock type='Bool' default_value='1' />

入力ストリームのソート特性を利用したソートの最適化


## optimize_substitute_columns {#optimize_substitute_columns}

<SettingsInfoBlock type='Bool' default_value='0' />

列の置換に[制約](../../sql-reference/statements/create/table.md/#constraints)を使用します。デフォルト値は`false`です。

設定可能な値:

- true、false


## optimize_syntax_fuse_functions {#optimize_syntax_fuse_functions}

<SettingsInfoBlock type='Bool' default_value='0' />

同一の引数を持つ集約関数の融合を有効にします。[sum](/sql-reference/aggregate-functions/reference/sum)、[count](/sql-reference/aggregate-functions/reference/count)、または[avg](/sql-reference/aggregate-functions/reference/avg)のうち、同一の引数を持つ集約関数を少なくとも2つ含むクエリを[sumCount](/sql-reference/aggregate-functions/reference/sumcount)に書き換えます。

設定可能な値:

- 0 — 同一の引数を持つ関数は融合されません。
- 1 — 同一の引数を持つ関数は融合されます。

**例**

クエリ:

```sql
CREATE TABLE fuse_tbl(a Int8, b Int8) Engine = Log;
SET optimize_syntax_fuse_functions = 1;
EXPLAIN SYNTAX SELECT sum(a), sum(b), count(b), avg(b) from fuse_tbl FORMAT TSV;
```

結果:

```text
SELECT
    sum(a),
    sumCount(b).1,
    sumCount(b).2,
    (sumCount(b).1) / (sumCount(b).2)
FROM fuse_tbl
```


## optimize_throw_if_noop {#optimize_throw_if_noop}

<SettingsInfoBlock type='Bool' default_value='0' />

[OPTIMIZE](../../sql-reference/statements/optimize.md)クエリがマージを実行しなかった場合に例外をスローするかどうかを制御します。

デフォルトでは、`OPTIMIZE`は何も実行しなかった場合でも正常終了します。この設定を有効にすることで、このような状況を区別し、例外メッセージで理由を確認できます。

設定可能な値:

- 1 — 例外のスローを有効にします。
- 0 — 例外のスローを無効にします。


## optimize_time_filter_with_preimage {#optimize_time_filter_with_preimage}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "関数を変換を伴わない等価な比較に変換することで、DateおよびDateTime述語を最適化します(例: toYear(col) = 2023 -> col >= '2023-01-01' AND col <= '2023-12-31')"
        }
      ]
    }
  ]}
/>

Optimize Date and DateTime predicates by converting functions into equivalent comparisons without conversions (e.g. `toYear(col) = 2023 -> col >= '2023-01-01' AND col <= '2023-12-31'`)


## optimize_trivial_approximate_count_query {#optimize_trivial_approximate_count_query}

<SettingsInfoBlock type='Bool' default_value='0' />

EmbeddedRocksDBなど、推定をサポートするストレージに対して、単純なカウント最適化に近似値を使用します。

設定可能な値:

- 0 — 最適化を無効にします。
- 1 — 最適化を有効にします。


## optimize_trivial_count_query {#optimize_trivial_count_query}

<SettingsInfoBlock type='Bool' default_value='1' />

MergeTreeのメタデータを使用して、単純なクエリ`SELECT count() FROM table`を最適化するかどうかを設定します。行レベルセキュリティを使用する必要がある場合は、この設定を無効にしてください。

設定可能な値:

- 0 — 最適化を無効にします。
- 1 — 最適化を有効にします。

関連項目:

- [optimize_functions_to_subcolumns](#optimize_functions_to_subcolumns)


## optimize_trivial_insert_select {#optimize_trivial_insert_select}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "0" },
        { label: "多くの場合、この最適化は効果がありません。" }
      ]
    }
  ]}
/>

単純な 'INSERT INTO table SELECT ... FROM TABLES' クエリを最適化します


## optimize_uniq_to_count {#optimize_uniq_to_count}

<SettingsInfoBlock type='Bool' default_value='1' />

サブクエリにDISTINCT句またはGROUP BY句がある場合、uniq関数とその派生関数（uniqUpToを除く）をcount関数に書き換えます。


## optimize_use_implicit_projections {#optimize_use_implicit_projections}

<SettingsInfoBlock type='Bool' default_value='1' />

SELECTクエリの実行時に暗黙的プロジェクションを自動的に選択します


## optimize_use_projection_filtering {#optimize_use_projection_filtering}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.6" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

SELECTクエリの実行時にプロジェクションが選択されていない場合でも、プロジェクションを使用してパート範囲をフィルタリングできるようにします。


## optimize_use_projections {#optimize_use_projections}

**エイリアス**: `allow_experimental_projection_optimization`

<SettingsInfoBlock type='Bool' default_value='1' />

`SELECT`クエリの処理時に[プロジェクション](../../engines/table-engines/mergetree-family/mergetree.md/#projections)最適化を有効または無効にします。

設定可能な値:

- 0 — プロジェクション最適化を無効にします。
- 1 — プロジェクション最適化を有効にします。


## optimize_using_constraints {#optimize_using_constraints}

<SettingsInfoBlock type='Bool' default_value='0' />

クエリ最適化に[制約](../../sql-reference/statements/create/table.md/#constraints)を使用します。デフォルト値は`false`です。

使用可能な値:

- true, false


## os_threads_nice_value_materialized_view {#os_threads_nice_value_materialized_view}

<SettingsInfoBlock type='Int32' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

マテリアライズドビュースレッドのLinux nice値。値が小さいほどCPU優先度が高くなります。

CAP_SYS_NICE権限が必要です。権限がない場合は何も実行されません。

指定可能な値:-20から19まで。


## os_threads_nice_value_query {#os_threads_nice_value_query}

**エイリアス**: `os_thread_priority`

<SettingsInfoBlock type='Int32' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

クエリ処理スレッドのLinux nice値。値が小さいほどCPU優先度が高くなります。

CAP_SYS_NICE機能が必要です。それ以外の場合は何も実行されません。

使用可能な値: -20から19まで。


## output_format_compression_level {#output_format_compression_level}

<SettingsInfoBlock type='UInt64' default_value='3' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "3" },
        { label: "クエリ出力の圧縮レベルの変更を許可" }
      ]
    }
  ]}
/>

クエリ出力が圧縮される場合のデフォルトの圧縮レベル。この設定は、`SELECT`クエリに`INTO OUTFILE`が指定されている場合、または`file`、`url`、`hdfs`、`s3`、`azureBlobStorage`のテーブル関数への書き込み時に適用されます。

使用可能な値: `1`から`22`


## output_format_compression_zstd_window_log {#output_format_compression_zstd_window_log}

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "0" },
        {
          label:
            "zstd圧縮使用時にクエリ出力のzstdウィンドウログを変更可能にする"
        }
      ]
    }
  ]}
/>

出力圧縮方式が`zstd`の場合に使用できます。`0`より大きい値を指定すると、この設定は圧縮ウィンドウサイズ(`2`のべき乗)を明示的に設定し、zstd圧縮の長距離モードを有効にします。これにより、圧縮率の向上が期待できます。

使用可能な値: 非負の数値。値が小さすぎるか大きすぎる場合、`zstdlib`は例外をスローします。一般的な値は`20`(ウィンドウサイズ = `1MB`)から`30`(ウィンドウサイズ = `1GB`)の範囲です。


## output_format_parallel_formatting {#output_format_parallel_formatting}

<SettingsInfoBlock type='Bool' default_value='1' />

データフォーマットの並列フォーマット処理を有効または無効にします。[TSV](/interfaces/formats/TabSeparated)、[TSKV](/interfaces/formats/TSKV)、[CSV](/interfaces/formats/CSV)、および[JSONEachRow](/interfaces/formats/JSONEachRow)フォーマットでのみサポートされています。

設定可能な値:

- 1 — 有効。
- 0 — 無効。


## page_cache_block_size {#page_cache_block_size}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "1048576" },
        { label: "この設定をクエリごとに調整可能にしました。" }
      ]
    }
  ]}
/>

ユーザー空間ページキャッシュに格納するファイルチャンクのサイズ（バイト単位）。キャッシュを経由するすべての読み取りは、このサイズの倍数に切り上げられます。

この設定はクエリごとに調整できますが、異なるブロックサイズのキャッシュエントリは再利用できません。この設定を変更すると、キャッシュ内の既存のエントリが実質的に無効化されます。

1 MiBのような大きい値は高スループットクエリに適しており、64 KiBのような小さい値は低レイテンシのポイントクエリに適しています。


## page_cache_inject_eviction {#page_cache_inject_eviction}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        { label: "ユーザー空間ページキャッシュを追加" }
      ]
    }
  ]}
/>

ユーザー空間ページキャッシュは、ランダムに一部のページを無効化します。テスト目的で使用されます。


## page_cache_lookahead_blocks {#page_cache_lookahead_blocks}

<SettingsInfoBlock type='UInt64' default_value='16' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "16" },
        { label: "この設定をクエリ単位で調整可能にしました。" }
      ]
    }
  ]}
/>

ユーザー空間ページキャッシュミス時に、基盤となるストレージから一度に読み取る連続ブロックの最大数を指定します(これらのブロックもキャッシュに存在しない場合)。各ブロックはpage_cache_block_sizeバイトです。

高い値は高スループットクエリに適していますが、低レイテンシのポイントクエリは先読みなしで動作させる方が効果的です。


## parallel_distributed_insert_select {#parallel_distributed_insert_select}

<SettingsInfoBlock type='UInt64' default_value='2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.7" },
        { label: "2" },
        { label: "デフォルトで並列分散INSERT SELECTを有効化" }
      ]
    }
  ]}
/>

並列分散`INSERT ... SELECT`クエリを有効にします。

`INSERT INTO distributed_table_a SELECT ... FROM distributed_table_b`クエリを実行する際、両方のテーブルが同じクラスタを使用し、かつ両方のテーブルが[レプリケート](../../engines/table-engines/mergetree-family/replication.md)されているか、またはレプリケートされていない場合、このクエリは各シャードでローカルに処理されます。

設定可能な値:

- `0` — 無効。
- `1` — 分散エンジンの基礎となるテーブルから各シャードで`SELECT`が実行されます。
- `2` — 分散エンジンの基礎となるテーブルから/へ各シャードで`SELECT`と`INSERT`が実行されます。

この設定を使用する際は、`enable_parallel_replicas = 1`の設定が必要です。


## parallel_hash_join_threshold {#parallel_hash_join_threshold}

<SettingsInfoBlock type='UInt64' default_value='100000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "100000" }, { label: "新しい設定" }]
    },
    {
      id: "row-2",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新しい設定" }]
    },
    {
      id: "row-3",
      items: [{ label: "25.3" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

ハッシュベースの結合アルゴリズムが適用される際、この閾値は`hash`と`parallel_hash`のどちらを使用するかの判断に使用されます(右側テーブルのサイズ推定が利用可能な場合のみ)。
前者は、右側テーブルのサイズが閾値未満であることが判明している場合に使用されます。


## parallel_replica_offset {#parallel_replica_offset}

<BetaBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

これは直接使用すべきではない内部設定であり、「並列レプリカ」モードの実装詳細を表します。この設定は、並列レプリカ間でクエリ処理に参加するレプリカのインデックスに対して、イニシエーターサーバーが分散クエリ用に自動的に設定します。


## parallel_replicas_allow_in_with_subquery {#parallel_replicas_allow_in_with_subquery}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1" },
        {
          label:
            "trueの場合、IN句のサブクエリが各フォロワーレプリカで実行されます"
        }
      ]
    }
  ]}
/>

trueの場合、IN句のサブクエリが各フォロワーレプリカで実行されます.


## parallel_replicas_connect_timeout_ms {#parallel_replicas_connect_timeout_ms}

<BetaBadge />

<SettingsInfoBlock type='ミリ秒' default_value='300' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "300" },
        { label: "並列レプリカクエリの接続タイムアウトを分離" }
      ]
    }
  ]}
/>

並列レプリカを使用したクエリ実行時に、リモートレプリカへの接続タイムアウトをミリ秒単位で指定します。タイムアウトが発生した場合、該当するレプリカはクエリ実行に使用されません


## parallel_replicas_count {#parallel_replicas_count}

<BetaBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

これは直接使用すべきではない内部設定であり、「並列レプリカ」モードの実装詳細を表しています。この設定は、分散クエリの処理に参加する並列レプリカの数に基づいて、イニシエーターサーバーによって自動的に設定されます。


## parallel_replicas_custom_key {#parallel_replicas_custom_key}

<BetaBadge />

特定のテーブルに対して、レプリカ間で処理を分散するために使用できる任意の整数式です。
任意の整数式を値として指定できます。

プライマリキーを使用したシンプルな式の使用が推奨されます。

この設定を複数のレプリカを持つ単一シャードで構成されるクラスタで使用する場合、それらのレプリカは仮想シャードに変換されます。
それ以外の場合は、`SAMPLE`キーと同様の動作となり、各シャードの複数のレプリカが使用されます。


## parallel_replicas_custom_key_range_lower {#parallel_replicas_custom_key_range_lower}

<BetaBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "動的シャードで並列レプリカを使用する際の範囲フィルター制御設定を追加"
        }
      ]
    }
  ]}
/>

フィルタータイプ`range`を使用して、カスタム範囲`[parallel_replicas_custom_key_range_lower, INT_MAX]`に基づき、レプリカ間で処理を均等に分散します。

[parallel_replicas_custom_key_range_upper](#parallel_replicas_custom_key_range_upper)と併用することで、範囲`[parallel_replicas_custom_key_range_lower, parallel_replicas_custom_key_range_upper]`に対してレプリカ間で処理を均等に分散できます。

注意: この設定は、クエリ処理中に追加のデータフィルタリングを行うものではありません。並列処理のために範囲フィルターが範囲`[0, INT_MAX]`を分割する位置を変更するものです。


## parallel_replicas_custom_key_range_upper {#parallel_replicas_custom_key_range_upper}

<BetaBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "動的シャードを使用した並列レプリカ利用時に範囲フィルタを制御する設定を追加。値を0に設定すると上限が無効化されます"
        }
      ]
    }
  ]}
/>

フィルタタイプ`range`により、カスタム範囲`[0, parallel_replicas_custom_key_range_upper]`に基づいてレプリカ間で処理を均等に分割できます。値を0に設定すると上限が無効化され、カスタムキー式の最大値が使用されます。

[parallel_replicas_custom_key_range_lower](#parallel_replicas_custom_key_range_lower)と併用することで、範囲`[parallel_replicas_custom_key_range_lower, parallel_replicas_custom_key_range_upper]`に対してレプリカ間で処理を均等に分割できます。

注意: この設定はクエリ処理中に追加のデータフィルタリングを行うものではなく、並列処理のために範囲フィルタが範囲`[0, INT_MAX]`を分割する位置を変更するものです。


## parallel_replicas_for_cluster_engines {#parallel_replicas_for_cluster_engines}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.3" }, { label: "1" }, { label: "新しい設定です。" }]
    }
  ]}
/>

テーブル関数エンジンを対応する -Cluster 代替に置き換えます


## parallel_replicas_for_non_replicated_merge_tree {#parallel_replicas_for_non_replicated_merge_tree}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

trueに設定すると、ClickHouseは非レプリケートMergeTreeテーブルに対してもパラレルレプリカアルゴリズムを使用します


## parallel_replicas_index_analysis_only_on_coordinator {#parallel_replicas_index_analysis_only_on_coordinator}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "1" },
        {
          label:
            "インデックス解析はレプリカコーディネーターでのみ実行され、他のレプリカではスキップされます。parallel_replicas_local_planが有効化されている場合にのみ有効です"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.10" },
        { label: "1" },
        {
          label:
            "インデックス解析はレプリカコーディネーターでのみ実行され、他のレプリカではスキップされます。parallel_replicas_local_planが有効化されている場合にのみ有効です"
        }
      ]
    }
  ]}
/>

Index analysis done only on replica-coordinator and skipped on other replicas. Effective only with enabled parallel_replicas_local_pla


## parallel_replicas_insert_select_local_pipeline {#parallel_replicas_insert_select_local_pipeline}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "1" },
        {
          label:
            "並列レプリカを使用した分散INSERT SELECT実行時にローカルパイプラインを使用します。現在、パフォーマンス上の問題により無効化されています"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.4" },
        { label: "0" },
        {
          label:
            "並列レプリカを使用した分散INSERT SELECT実行時にローカルパイプラインを使用します。現在、パフォーマンス上の問題により無効化されています"
        }
      ]
    }
  ]}
/>

並列レプリカを使用した分散INSERT SELECT実行時にローカルパイプラインを使用します


## parallel_replicas_local_plan {#parallel_replicas_local_plan}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        {
          label:
            "並列レプリカを使用したクエリでローカルレプリカのローカルプランを使用"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.11" },
        { label: "1" },
        {
          label:
            "並列レプリカを使用したクエリでローカルレプリカのローカルプランを使用"
        }
      ]
    },
    {
      id: "row-3",
      items: [
        { label: "24.10" },
        { label: "1" },
        {
          label:
            "並列レプリカを使用したクエリでローカルレプリカのローカルプランを使用"
        }
      ]
    }
  ]}
/>

ローカルレプリカのローカルプランを構築


## parallel_replicas_mark_segment_size {#parallel_replicas_mark_segment_size}

<BetaBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.9" },
        { label: "0" },
        { label: "この設定の値は自動的に決定されるようになりました" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.1" },
        { label: "128" },
        {
          label:
            "新しいパラレルレプリカコーディネーター実装でセグメントサイズを制御する新しい設定を追加"
        }
      ]
    }
  ]}
/>

パーツは並列読み取りのためにレプリカ間で分散されるセグメントに仮想的に分割されます。この設定はこれらのセグメントのサイズを制御します。何をしているのか完全に理解していない限り、変更は推奨されません。値は [128; 16384] の範囲内である必要があります


## parallel_replicas_min_number_of_rows_per_replica {#parallel_replicas_min_number_of_rows_per_replica}

<BetaBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

クエリで使用するレプリカ数を (読み取り予定行数 / min_number_of_rows_per_replica) に制限します。最大値は引き続き 'max_parallel_replicas' によって制限されます


## parallel_replicas_mode {#parallel_replicas_mode}

<BetaBadge />

<SettingsInfoBlock type='ParallelReplicasMode' default_value='read_tasks' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "read_tasks" },
        {
          label:
            "この設定は並列レプリカ機能のベータ版化に伴い導入されました"
        }
      ]
    }
  ]}
/>

並列レプリカでカスタムキーと共に使用するフィルタのタイプ。default - カスタムキーに対してモジュロ演算を使用、range - カスタムキーの値型で取り得るすべての値を使用してカスタムキーに範囲フィルタを適用。


## parallel_replicas_only_with_analyzer {#parallel_replicas_only_with_analyzer}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.2" },
        { label: "1" },
        { label: "並列レプリカはアナライザー有効時のみサポートされます" }
      ]
    }
  ]}
/>

並列レプリカを使用するには、アナライザーを有効にする必要があります。アナライザーが無効の場合、レプリカからの並列読み取りが有効であっても、クエリ実行はローカル実行にフォールバックします。アナライザーを有効にせずに並列レプリカを使用することはサポートされていません


## parallel_replicas_prefer_local_join {#parallel_replicas_prefer_local_join}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "trueの場合、JOINが並列レプリカアルゴリズムで実行可能で、かつ右側のJOIN部分のすべてのストレージが*MergeTreeである場合、GLOBAL JOINの代わりにローカルJOINが使用されます。"
        }
      ]
    }
  ]}
/>

If true, and JOIN can be executed with parallel replicas algorithm, and all storages of right JOIN part are \*MergeTree, local JOIN will be used instead of GLOBAL JOIN.


## parallel_replicas_support_projection {#parallel_replicas_support_projection}

<BetaBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "1" },
        {
          label:
            "新しい設定。並列レプリカでプロジェクションの最適化を適用できます。parallel_replicas_local_planが有効で、aggregation_in_orderが無効な場合にのみ有効です。"
        }
      ]
    }
  ]}
/>

並列レプリカでプロジェクションの最適化を適用できます。parallel_replicas_local_planが有効で、aggregation_in_orderが無効な場合にのみ有効です。


## parallel_view_processing {#parallel_view_processing}

<SettingsInfoBlock type='Bool' default_value='0' />

アタッチされたビューへのデータ送信を、順次実行ではなく並行実行できるようにします。


## parallelize_output_from_storages {#parallelize_output_from_storages}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.5" },
        { label: "1" },
        {
          label:
            "file/url/s3などから読み取るクエリを実行する際の並列処理を許可します。これにより行の順序が変更される場合があります。"
        }
      ]
    }
  ]}
/>

ストレージからの読み取りステップにおける出力を並列化します。可能な場合、ストレージからの読み取り直後のクエリ処理を並列化できます


## parsedatetime_e_requires_space_padding {#parsedatetime_e_requires_space_padding}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "0" },
        { label: "MySQLのDATE_FORMAT/STR_TO_DATEとの互換性を向上" }
      ]
    }
  ]}
/>

関数'parseDateTime'のフォーマッタ'%e'は、1桁の日にちがスペースでパディングされていることを想定しています。例えば、' 2'は受け入れられますが、'2'はエラーになります。


## parsedatetime_parse_without_leading_zeros {#parsedatetime_parse_without_leading_zeros}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.11" },
        { label: "1" },
        { label: "MySQL の DATE_FORMAT/STR_TO_DATE との互換性を改善" }
      ]
    }
  ]}
/>

関数 'parseDateTime' のフォーマッタ '%c'、'%l'、'%k' は、先頭ゼロなしで月と時間を解析します。


## partial_merge_join_left_table_buffer_bytes {#partial_merge_join_left_table_buffer_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

0以外の値を設定すると、部分マージ結合において左側テーブルのブロックをより大きなブロックにグループ化します。結合スレッドごとに指定されたメモリの最大2倍まで使用します。


## partial_merge_join_rows_in_right_blocks {#partial_merge_join_rows_in_right_blocks}

<SettingsInfoBlock type='UInt64' default_value='65536' />

[JOIN](../../sql-reference/statements/select/join.md)クエリにおける部分マージ結合アルゴリズムの右側結合データブロックのサイズを制限します。

ClickHouseサーバー:

1.  右側結合データを指定された行数以下のブロックに分割します。
2.  各ブロックを最小値と最大値でインデックス化します。
3.  可能な場合、準備されたブロックをディスクにアンロードします。

設定可能な値:

- 任意の正の整数。推奨値の範囲: \[1000, 100000\]。


## partial_result_on_first_cancel {#partial_result_on_first_cancel}

<SettingsInfoBlock type='Bool' default_value='0' />

キャンセル後にクエリが部分的な結果を返すことを許可します。


## parts_to_delay_insert {#parts_to_delay_insert}

<SettingsInfoBlock type='UInt64' default_value='0' />

宛先テーブルの単一パーティション内に、この数以上のアクティブなパートが存在する場合、テーブルへの挿入を意図的に遅延させます。


## parts_to_throw_insert {#parts_to_throw_insert}

<SettingsInfoBlock type='UInt64' default_value='0' />

宛先テーブルの単一パーティション内のアクティブなパーツ数がこの値を超えた場合、'Too many parts ...' 例外がスローされます。


## per_part_index_stats {#per_part_index_stats}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "New setting." }]
    }
  ]}
/>

        パートごとのインデックス統計をログに記録します


## poll_interval {#poll_interval}

<SettingsInfoBlock type='UInt64' default_value='10' />

サーバー上のクエリ待機ループにおいて、指定された秒数の間ブロックします。


## postgresql_connection_attempt_timeout {#postgresql_connection_attempt_timeout}

<SettingsInfoBlock type='UInt64' default_value='2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "2" },
        {
          label:
            "PostgreSQL接続の'connect_timeout'パラメータの制御が可能になりました。"
        }
      ]
    }
  ]}
/>

PostgreSQLエンドポイントへの単一接続試行のタイムアウト時間(秒単位)です。
この値は接続URLの`connect_timeout`パラメータとして渡されます。


## postgresql_connection_pool_auto_close_connection {#postgresql_connection_pool_auto_close_connection}

<SettingsInfoBlock type='Bool' default_value='0' />

接続をプールに返す前に接続を閉じます。


## postgresql_connection_pool_retries {#postgresql_connection_pool_retries}

<SettingsInfoBlock type='UInt64' default_value='2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "2" },
        {
          label:
            "PostgreSQL接続プールの再試行回数を制御できるようになりました。"
        }
      ]
    }
  ]}
/>

PostgreSQLテーブルエンジンおよびデータベースエンジンの接続プールにおけるpush/pop操作の再試行回数。


## postgresql_connection_pool_size {#postgresql_connection_pool_size}

<SettingsInfoBlock type='UInt64' default_value='16' />

PostgreSQLテーブルエンジンとデータベースエンジンの接続プールサイズ。


## postgresql_connection_pool_wait_timeout {#postgresql_connection_pool_wait_timeout}

<SettingsInfoBlock type='UInt64' default_value='5000' />

PostgreSQLテーブルエンジンおよびデータベースエンジンにおける、コネクションプールが空の場合のpush/pop操作のタイムアウト。デフォルトでは、プールが空の場合にブロックします。


## postgresql_fault_injection_probability {#postgresql_fault_injection_probability}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.2" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

内部（レプリケーション用）PostgreSQLクエリが失敗する確率の近似値。有効な値は区間 [0.0f, 1.0f] です


## prefer_column_name_to_alias {#prefer_column_name_to_alias}

<SettingsInfoBlock type='Bool' default_value='0' />

クエリ式および句において、エイリアスの代わりに元のカラム名を使用するかどうかを有効または無効にします。エイリアスがカラム名と同じ場合に特に重要です。詳細は[式のエイリアス](/sql-reference/syntax#notes-on-usage)を参照してください。この設定を有効にすると、ClickHouseのエイリアス構文規則が他の多くのデータベースエンジンとの互換性が向上します。

設定可能な値:

- 0 — カラム名がエイリアスで置き換えられます。
- 1 — カラム名がエイリアスで置き換えられません。

**例**

有効時と無効時の違い:

クエリ:

```sql
SET prefer_column_name_to_alias = 0;
SELECT avg(number) AS number, max(number) FROM numbers(10);
```

結果:

```text
Received exception from server (version 21.5.1):
Code: 184. DB::Exception: Received from localhost:9000. DB::Exception: Aggregate function avg(number) is found inside another aggregate function in query: While processing avg(number) AS number.
```

クエリ:

```sql
SET prefer_column_name_to_alias = 1;
SELECT avg(number) AS number, max(number) FROM numbers(10);
```

結果:

```text
┌─number─┬─max(number)─┐
│    4.5 │           9 │
└────────┴─────────────┘
```


## prefer_external_sort_block_bytes {#prefer_external_sort_block_bytes}

<SettingsInfoBlock type='UInt64' default_value='16744704' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.5" },
        { label: "16744704" },
        {
          label:
            "外部ソートの最大ブロックバイト数を優先し、マージ中のメモリ使用量を削減します。"
        }
      ]
    }
  ]}
/>

外部ソートの最大ブロックバイト数を優先し、マージ中のメモリ使用量を削減します。


## prefer_global_in_and_join {#prefer_global_in_and_join}

<SettingsInfoBlock type='Bool' default_value='0' />

`IN`/`JOIN`演算子を`GLOBAL IN`/`GLOBAL JOIN`に置き換える機能を有効にします。

設定可能な値:

- 0 — 無効。`IN`/`JOIN`演算子は`GLOBAL IN`/`GLOBAL JOIN`に置き換えられません。
- 1 — 有効。`IN`/`JOIN`演算子は`GLOBAL IN`/`GLOBAL JOIN`に置き換えられます。

**使用方法**

`SET distributed_product_mode=global`は分散テーブルに対するクエリの動作を変更できますが、ローカルテーブルや外部リソースからのテーブルには適していません。このような場合に`prefer_global_in_and_join`設定が有効です。

例えば、分散に適さないローカルテーブルを含むクエリ処理ノードがある場合、`GLOBAL`キーワード(`GLOBAL IN`/`GLOBAL JOIN`)を使用して分散処理中にデータを動的に分散する必要があります。

`prefer_global_in_and_join`のもう一つの使用例は、外部エンジンによって作成されたテーブルへのアクセスです。この設定により、そのようなテーブルを結合する際の外部ソースへの呼び出し回数を削減できます。クエリごとに1回の呼び出しのみで済みます。

**関連項目:**

- `GLOBAL IN`/`GLOBAL JOIN`の使用方法の詳細については、[分散サブクエリ](/sql-reference/operators/in#distributed-subqueries)を参照してください


## prefer_localhost_replica {#prefer_localhost_replica}

<SettingsInfoBlock type='Bool' default_value='1' />

分散クエリ処理時にlocalhostレプリカを優先的に使用するかどうかを有効化/無効化します。

設定可能な値:

- 1 — localhostレプリカが存在する場合、ClickHouseは常にそのレプリカにクエリを送信します。
- 0 — ClickHouseは[load_balancing](#load_balancing)設定で指定された負荷分散戦略を使用します。

:::note
[parallel_replicas_custom_key](#parallel_replicas_custom_key)を指定せずに[max_parallel_replicas](#max_parallel_replicas)を使用する場合は、この設定を無効化してください。
[parallel_replicas_custom_key](#parallel_replicas_custom_key)が設定されている場合、複数のレプリカを含む複数のシャードで構成されたクラスタで使用する場合にのみ、この設定を無効化してください。
単一のシャードと複数のレプリカで構成されたクラスタで使用する場合、この設定を無効化すると悪影響が生じます。
:::


## prefer_warmed_unmerged_parts_seconds {#prefer_warmed_unmerged_parts_seconds}

<CloudOnlyBadge />

<SettingsInfoBlock type='Int64' default_value='0' />

ClickHouse Cloudでのみ有効です。マージされたパートの作成からの経過時間がこの秒数未満で、かつ事前ウォーム化されていない場合（[cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch)を参照）、すべてのソースパートが利用可能で事前ウォーム化されていれば、SELECTクエリはマージされたパートではなくソースパートから読み取ります。Replicated-/SharedMergeTreeでのみ有効です。注意：この設定はCacheWarmerがパートを処理したかどうかのみを確認します。パートが他の方法でキャッシュにフェッチされた場合、CacheWarmerが処理するまではコールドとみなされます。ウォーム化された後にキャッシュから削除された場合でも、ウォームとみなされます。


## preferred_block_size_bytes {#preferred_block_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='1000000' />

この設定は、クエリ処理時のデータブロックサイズを調整するもので、より粗い設定である'max_block_size'に対する追加の微調整を表します。カラムが大きく、'max_block_size'行でブロックサイズが指定バイト数を超える可能性がある場合、CPUキャッシュの局所性を向上させるためにサイズが縮小されます。


## preferred_max_column_in_block_size_bytes {#preferred_max_column_in_block_size_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

読み取り時のブロック内の最大カラムサイズに対する制限です。キャッシュミスの回数を減らすのに役立ちます。L2キャッシュサイズに近い値に設定してください。


## preferred_optimize_projection_name {#preferred_optimize_projection_name}

空でない文字列に設定すると、ClickHouseはクエリで指定されたプロジェクションの適用を試みます。

設定可能な値:

- string: 優先プロジェクションの名前


## prefetch_buffer_size {#prefetch_buffer_size}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

ファイルシステムから読み取るためのプリフェッチバッファの最大サイズ。


## print_pretty_type_names {#print_pretty_type_names}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "1" },
        { label: "ユーザーエクスペリエンスの向上。" }
      ]
    }
  ]}
/>

`DESCRIBE`クエリおよび`toTypeName()`関数において、深くネストされた型名をインデント付きで整形して表示できるようにします。

例:

```sql
CREATE TABLE test (a Tuple(b String, c Tuple(d Nullable(UInt64), e Array(UInt32), f Array(Tuple(g String, h Map(String, Array(Tuple(i String, j UInt64))))), k Date), l Nullable(String))) ENGINE=Memory;
DESCRIBE TABLE test FORMAT TSVRaw SETTINGS print_pretty_type_names=1;
```

```
a   Tuple(
    b String,
    c Tuple(
        d Nullable(UInt64),
        e Array(UInt32),
        f Array(Tuple(
            g String,
            h Map(
                String,
                Array(Tuple(
                    i String,
                    j UInt64
                ))
            )
        )),
        k Date
    ),
    l Nullable(String)
)
```


## priority {#priority}

<SettingsInfoBlock type='UInt64' default_value='0' />

クエリの優先度。1が最高優先度で、値が大きいほど優先度が低くなります。0は優先度を使用しないことを意味します。


## promql_database {#promql_database}

<ExperimentalBadge />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "" },
        { label: "新しい実験的な設定" }
      ]
    }
  ]}
/>

'promql' ダイアレクトで使用するデータベース名を指定します。空文字列は現在のデータベースを意味します。


## promql_evaluation_time {#promql_evaluation_time}

<ExperimentalBadge />

**エイリアス**: `evaluation_time`

<SettingsInfoBlock type='FloatAuto' default_value='auto' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.9" },
        { label: "auto" },
        {
          label:
            "この設定は名前が変更されました。以前の名前は`evaluation_time`です。"
        }
      ]
    }
  ]}
/>

promql方言で使用する評価時刻を設定します。'auto'は現在時刻を意味します。


## promql_table {#promql_table}

<ExperimentalBadge />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "" },
        { label: "新しい実験的設定" }
      ]
    }
  ]}
/>

'promql'ダイアレクトで使用されるTimeSeriesテーブルの名前を指定します。


## push_external_roles_in_interserver_queries {#push_external_roles_in_interserver_queries}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.11" }, { label: "1" }, { label: "新しい設定。" }]
    }
  ]}
/>

クエリ実行中に、発信元ノードから他のノードへユーザーロールをプッシュすることを有効にします。


## query_cache_compress_entries {#query_cache_compress_entries}

<SettingsInfoBlock type='Bool' default_value='1' />

[クエリキャッシュ](../query-cache.md)内のエントリを圧縮します。クエリキャッシュのメモリ消費量を削減しますが、その代わりに挿入と読み取りの速度が低下します。

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_cache_max_entries {#query_cache_max_entries}

<SettingsInfoBlock type='UInt64' default_value='0' />

現在のユーザーが[クエリキャッシュ](../query-cache.md)に保存できるクエリ結果の最大数。0は無制限を意味します。

設定可能な値:

- 0以上の正の整数


## query_cache_max_size_in_bytes {#query_cache_max_size_in_bytes}

<SettingsInfoBlock type='UInt64' default_value='0' />

現在のユーザーが[クエリキャッシュ](../query-cache.md)に割り当て可能な最大メモリ量（バイト単位）。0は無制限を意味します。

設定可能な値:

- 0以上の正の整数


## query_cache_min_query_duration {#query_cache_min_query_duration}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

クエリの結果を[クエリキャッシュ](../query-cache.md)に保存するために必要な最小実行時間(ミリ秒単位)。

設定可能な値:

- 0以上の正の整数


## query_cache_min_query_runs {#query_cache_min_query_runs}

<SettingsInfoBlock type='UInt64' default_value='0' />

`SELECT`クエリの結果が[クエリキャッシュ](../query-cache.md)に保存されるまでに実行が必要な最小回数。

設定可能な値:

- 0以上の正の整数。


## query_cache_nondeterministic_function_handling {#query_cache_nondeterministic_function_handling}

<SettingsInfoBlock
  type='QueryResultCacheNondeterministicFunctionHandling'
  default_value='throw'
/>

`rand()`や`now()`などの非決定的関数を含む`SELECT`クエリを[クエリキャッシュ](../query-cache.md)がどのように処理するかを制御します。

設定可能な値:

- `'throw'` - 例外をスローし、クエリ結果をキャッシュしません。
- `'save'` - クエリ結果をキャッシュします。
- `'ignore'` - クエリ結果をキャッシュせず、例外もスローしません。


## query_cache_share_between_users {#query_cache_share_between_users}

<SettingsInfoBlock type='Bool' default_value='0' />

有効にすると、[クエリキャッシュ](../query-cache.md)にキャッシュされた`SELECT`クエリの結果を他のユーザーが読み取ることができます。
セキュリティ上の理由から、この設定を有効にすることは推奨されません。

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_cache_squash_partial_results {#query_cache_squash_partial_results}

<SettingsInfoBlock type='Bool' default_value='1' />

部分的な結果ブロックを[max_block_size](#max_block_size)のサイズのブロックに統合します。[クエリキャッシュ](../query-cache.md)への挿入パフォーマンスは低下しますが、キャッシュエントリの圧縮率が向上します([query_cache_compress-entries](#query_cache_compress_entries)を参照)。

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_cache_system_table_handling {#query_cache_system_table_handling}

<SettingsInfoBlock
  type='QueryResultCacheSystemTableHandling'
  default_value='throw'
/>

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "throw" },
        {
          label:
            "クエリキャッシュはシステムテーブルに対するクエリ結果をキャッシュしなくなりました"
        }
      ]
    }
  ]}
/>

[クエリキャッシュ](../query-cache.md)がシステムテーブル(すなわち`system.*`および`information_schema.*`データベース内のテーブル)に対する`SELECT`クエリをどのように処理するかを制御します。

設定可能な値:

- `'throw'` - 例外をスローし、クエリ結果をキャッシュしません。
- `'save'` - クエリ結果をキャッシュします。
- `'ignore'` - クエリ結果をキャッシュせず、例外もスローしません。


## query_cache_tag {#query_cache_tag}

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.8" },
        { label: "" },
        { label: "クエリキャッシュエントリにラベルを付けるための新しい設定。" }
      ]
    }
  ]}
/>

[クエリキャッシュ](../query-cache.md)エントリのラベルとして機能する文字列。
異なるタグを持つ同一のクエリは、クエリキャッシュによって別のクエリとして扱われます。

設定可能な値:

- 任意の文字列


## query_cache_ttl {#query_cache_ttl}

<SettingsInfoBlock type='Seconds' default_value='60' />

この秒数が経過すると、[クエリキャッシュ](../query-cache.md)内のエントリが無効になります。

設定可能な値:

- 0以上の正の整数


## query_condition_cache_store_conditions_as_plaintext {#query_condition_cache_store_conditions_as_plaintext}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

[クエリ条件キャッシュ](/operations/query-condition-cache)のフィルタ条件を平文で保存します。
有効にすると、system.query_condition_cacheにフィルタ条件がそのまま表示されるため、キャッシュに関する問題のデバッグが容易になります。
平文のフィルタ条件により機密情報が露出する可能性があるため、デフォルトでは無効になっています。

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_metric_log_interval {#query_metric_log_interval}

<SettingsInfoBlock type='Int64' default_value='-1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "-1" }, { label: "新しい設定" }]
    }
  ]}
/>

個々のクエリの[query_metric_log](../../operations/system-tables/query_metric_log.md)を収集する間隔をミリ秒単位で指定します。

負の値に設定した場合、[query_metric_log設定](/operations/server-configuration-parameters/settings#query_metric_log)の`collect_interval_milliseconds`の値を使用し、存在しない場合はデフォルトの1000になります。

単一クエリの収集を無効にするには、`query_metric_log_interval`を0に設定します。

デフォルト値: -1


## query_plan_aggregation_in_order {#query_plan_aggregation_in_order}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.12" },
        { label: "1" },
        { label: "クエリプランに関する一部のリファクタリングを有効化" }
      ]
    }
  ]}
/>

集約のインオーダー処理におけるクエリプランレベルの最適化を切り替えます。
[`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 設定が 1 の場合にのみ有効になります。

:::note
これは開発者によるデバッグ目的でのみ使用すべきエキスパートレベルの設定です。この設定は将来的に後方互換性のない形で変更されるか、削除される可能性があります。
:::

設定可能な値:

- 0 - 無効化
- 1 - 有効化


## query_plan_convert_any_join_to_semi_or_anti_join {#query_plan_convert_any_join_to_semi_or_anti_join}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "1" }, { label: "新しい設定。" }]
    }
  ]}
/>

JOIN後のフィルタが、マッチしなかった行またはマッチした行に対して常にfalseと評価される場合、ANY JOINをSEMI JOINまたはANTI JOINに変換することを許可します


## query_plan_convert_join_to_in {#query_plan_convert_join_to_in}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

出力列が左テーブルのみに紐づいている場合、`JOIN`を`IN`を含むサブクエリに変換することを許可します。非ANYのJOIN(例:デフォルトであるALL JOIN)では誤った結果が生じる可能性があります。


## query_plan_convert_outer_join_to_inner_join {#query_plan_convert_outer_join_to_inner_join}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "1" },
        {
          label:
            "JOIN後のフィルタが常にデフォルト値を除外する場合、OUTER JOINをINNER JOINに変換することを許可します"
        }
      ]
    }
  ]}
/>

Allow to convert `OUTER JOIN` to `INNER JOIN` if filter after `JOIN` always filters default values


## query_plan_direct_read_from_text_index {#query_plan_direct_read_from_text_index}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "1" }, { label: "新しい設定です。" }]
    }
  ]}
/>

クエリプランにおいて、転置インデックスのみを使用した全文検索フィルタリングを実行できるようにします。


## query_plan_display_internal_aliases {#query_plan_display_internal_aliases}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

EXPLAIN PLANにおいて、元のクエリで指定されたエイリアスではなく、内部エイリアス（\_\_table1など）を表示します。


## query_plan_enable_multithreading_after_window_functions {#query_plan_enable_multithreading_after_window_functions}

<SettingsInfoBlock type='Bool' default_value='1' />

ウィンドウ関数の評価後にマルチスレッドを有効化し、並列ストリーム処理を可能にします


## query_plan_enable_optimizations {#query_plan_enable_optimizations}

<SettingsInfoBlock type='Bool' default_value='1' />

クエリプランレベルでのクエリ最適化を切り替えます。

:::note
これは開発者がデバッグ目的でのみ使用すべきエキスパートレベルの設定です。この設定は将来的に後方互換性のない方法で変更されるか、削除される可能性があります。
:::

設定可能な値:

- 0 - クエリプランレベルでのすべての最適化を無効化
- 1 - クエリプランレベルでの最適化を有効化(ただし、個別の最適化は各設定で無効化することも可能)


## query_plan_execute_functions_after_sorting {#query_plan_execute_functions_after_sorting}

<SettingsInfoBlock type='Bool' default_value='1' />

ソート処理後に式を移動するクエリプランレベルの最適化を切り替えます。
[`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 設定が 1 の場合にのみ有効になります。

:::note
これは開発者がデバッグ目的でのみ使用すべきエキスパートレベルの設定です。この設定は将来的に後方互換性のない変更が加えられるか、削除される可能性があります。
:::

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_plan_filter_push_down {#query_plan_filter_push_down}

<SettingsInfoBlock type='Bool' default_value='1' />

実行プラン内でフィルタを下位に移動させるクエリプランレベルの最適化を切り替えます。
[query_plan_enable_optimizations](#query_plan_enable_optimizations) 設定が 1 の場合のみ有効になります。

:::note
これは開発者がデバッグ目的でのみ使用すべき上級者向けの設定です。この設定は将来的に後方互換性のない形で変更されるか、削除される可能性があります。
:::

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_plan_join_shard_by_pk_ranges {#query_plan_join_shard_by_pk_ranges}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

結合キーが両方のテーブルのプライマリキーの接頭辞を含む場合、JOINに対してシャーディングを適用します。hash、parallel_hash、full_sorting_mergeアルゴリズムでサポートされています。通常、クエリの高速化には寄与しませんが、メモリ消費量を削減できる可能性があります。


## query_plan_join_swap_table {#query_plan_join_swap_table}

<SettingsInfoBlock type='BoolAuto' default_value='auto' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "auto" },
        { label: "新しい設定。以前は常に右側のテーブルが選択されていました。" }
      ]
    }
  ]}
/>

    クエリプランにおいて、結合のどちら側をビルドテーブル(内部テーブルとも呼ばれ、ハッシュ結合のためにハッシュテーブルに挿入されるテーブル)にするかを決定します。この設定は、`JOIN ON`句を使用した`ALL`結合厳密性でのみサポートされます。設定可能な値:
    - 'auto': プランナーがビルドテーブルとして使用するテーブルを決定します。
    - 'false': テーブルを入れ替えません(右側のテーブルがビルドテーブルになります)。
    - 'true': 常にテーブルを入れ替えます(左側のテーブルがビルドテーブルになります)。


## query_plan_lift_up_array_join {#query_plan_lift_up_array_join}

<SettingsInfoBlock type='Bool' default_value='1' />

実行プラン内でARRAY JOINを上位に移動するクエリプランレベルの最適化を切り替えます。
[query_plan_enable_optimizations](#query_plan_enable_optimizations)設定が1の場合のみ有効です。

:::note
これは開発者がデバッグ目的でのみ使用すべきエキスパートレベルの設定です。この設定は将来的に後方互換性のない形で変更されるか、削除される可能性があります。
:::

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_plan_lift_up_union {#query_plan_lift_up_union}

<SettingsInfoBlock type='Bool' default_value='1' />

クエリプランの大きなサブツリーをユニオンに移動し、さらなる最適化を可能にするクエリプランレベルの最適化を切り替えます。
[`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 設定が 1 の場合にのみ有効になります。

:::note
これは開発者がデバッグ目的でのみ使用すべきエキスパートレベルの設定です。この設定は将来、後方互換性のない方法で変更されるか、削除される可能性があります。
:::

使用可能な値:

- 0 - 無効
- 1 - 有効


## query_plan_max_limit_for_lazy_materialization {#query_plan_max_limit_for_lazy_materialization}

<SettingsInfoBlock type='UInt64' default_value='100' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.4" },
        { label: "10" },
        {
          label:
            "遅延マテリアライゼーション最適化でクエリプランを使用可能にする最大制限値を制御する新しい設定を追加しました。ゼロの場合は制限なし"
        }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "25.11" }, { label: "100" }, { label: "より最適" }]
    }
  ]}
/>

遅延マテリアライゼーション最適化でクエリプランを使用可能にする最大制限値を制御します。ゼロの場合は制限なしです。


## query_plan_max_optimizations_to_apply {#query_plan_max_optimizations_to_apply}

<SettingsInfoBlock type='UInt64' default_value='10000' />

クエリプランに適用される最適化の総数を制限します。設定 [query_plan_enable_optimizations](#query_plan_enable_optimizations) を参照してください。
複雑なクエリで最適化処理に長時間かかることを回避するために有用です。
EXPLAIN PLANクエリでは、この制限に達した後は最適化の適用を停止し、プランをそのまま返します。
通常のクエリ実行では、実際の最適化数がこの設定を超えた場合、例外がスローされます。

:::note
これは開発者がデバッグ目的でのみ使用すべきエキスパートレベルの設定です。この設定は将来的に後方互換性のない方法で変更されるか、削除される可能性があります。
:::


## query_plan_max_step_description_length {#query_plan_max_step_description_length}

<SettingsInfoBlock type='UInt64' default_value='500' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "500" }, { label: "New setting" }]
    }
  ]}
/>

EXPLAIN PLANのステップ説明の最大長。


## query_plan_merge_expressions {#query_plan_merge_expressions}

<SettingsInfoBlock type='Bool' default_value='1' />

連続するフィルタをマージするクエリプランレベルの最適化を切り替えます。
設定 [query_plan_enable_optimizations](#query_plan_enable_optimizations) が 1 の場合のみ有効になります。

:::note
これは開発者がデバッグ目的でのみ使用すべきエキスパートレベルの設定です。この設定は将来的に後方互換性のない方法で変更されるか、削除される可能性があります。
:::

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_plan_merge_filter_into_join_condition {#query_plan_merge_filter_into_join_condition}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.4" },
        { label: "1" },
        { label: "フィルタをJOIN条件にマージする新しい設定を追加しました" }
      ]
    }
  ]}
/>

フィルタを`JOIN`条件にマージし、`CROSS JOIN`を`INNER`に変換することを許可します。


## query_plan_merge_filters {#query_plan_merge_filters}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "0" },
        { label: "クエリプランでのフィルタのマージを許可" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.11" },
        { label: "1" },
        {
          label:
            "クエリプランでのフィルタのマージを許可します。新しいアナライザでフィルタプッシュダウンを適切にサポートするために必要です。"
        }
      ]
    }
  ]}
/>

クエリプランでのフィルタのマージを許可します。


## query_plan_optimize_join_order_limit {#query_plan_optimize_join_order_limit}

<SettingsInfoBlock type='UInt64' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

    同一サブクエリ内の結合順序を最適化します。現在、非常に限定的なケースのみサポートされています。
    値は最適化対象とするテーブルの最大数です。


## query_plan_optimize_lazy_materialization {#query_plan_optimize_lazy_materialization}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.4" },
        { label: "1" },
        {
          label:
            "遅延マテリアライゼーション最適化にクエリプランを使用するための新しい設定を追加"
        }
      ]
    }
  ]}
/>

遅延マテリアライゼーション最適化にクエリプランを使用します。


## query_plan_optimize_prewhere {#query_plan_optimize_prewhere}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "サポートされているストレージに対してフィルタをPREWHERE式にプッシュダウンすることを許可"
        }
      ]
    }
  ]}
/>

サポートされているストレージに対してフィルタをPREWHERE式にプッシュダウンすることを許可


## query_plan_push_down_limit {#query_plan_push_down_limit}

<SettingsInfoBlock type='Bool' default_value='1' />

実行計画内でLIMIT句を下位に移動させるクエリプランレベルの最適化を切り替えます。
[query_plan_enable_optimizations](#query_plan_enable_optimizations)設定が1の場合のみ有効です。

:::note
これは開発者がデバッグ目的でのみ使用すべきエキスパートレベルの設定です。この設定は将来的に後方互換性のない変更が加えられるか、削除される可能性があります。
:::

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_plan_read_in_order {#query_plan_read_in_order}

<SettingsInfoBlock type='Bool' default_value='1' />

読み取り順序最適化のクエリプランレベルでの最適化を切り替えます。
[`query_plan_enable_optimizations`](#query_plan_enable_optimizations)設定が1の場合のみ有効です。

:::note
これは開発者がデバッグ目的でのみ使用すべきエキスパートレベルの設定です。この設定は将来的に後方互換性のない変更が加えられるか、削除される可能性があります。
:::

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_plan_remove_redundant_distinct {#query_plan_remove_redundant_distinct}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.2" },
        { label: "1" },
        { label: "クエリプラン内の冗長なDistinctステップを削除" }
      ]
    }
  ]}
/>

冗長なDISTINCTステップを削除するクエリプランレベルの最適化を切り替えます。
[`query_plan_enable_optimizations`](#query_plan_enable_optimizations)設定が1の場合のみ有効になります。

:::note
これは開発者がデバッグ目的でのみ使用すべき上級者向けの設定です。この設定は将来的に後方互換性のない方法で変更されるか、削除される可能性があります。
:::

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_plan_remove_redundant_sorting {#query_plan_remove_redundant_sorting}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.1" },
        { label: "1" },
        {
          label:
            "クエリプランにおける冗長なソート処理を削除します。例えば、サブクエリ内のORDER BY句に関連するソート処理など"
        }
      ]
    }
  ]}
/>

クエリプランレベルの最適化を切り替え、冗長なソート処理（例：サブクエリ内）を削除します。
設定[`query_plan_enable_optimizations`](#query_plan_enable_optimizations)が1の場合のみ有効になります。

:::note
これは開発者によるデバッグ目的でのみ使用すべきエキスパートレベルの設定です。この設定は将来的に後方互換性のない方法で変更されるか、削除される可能性があります。
:::

設定可能な値：

- 0 - 無効
- 1 - 有効


## query_plan_remove_unused_columns {#query_plan_remove_unused_columns}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1" },
        {
          label:
            "新しい設定。クエリプランから未使用のカラムを削除する最適化を追加しました。"
        }
      ]
    }
  ]}
/>

クエリプランレベルの最適化を切り替えます。この最適化は、クエリプランの各ステップから未使用のカラム(入力カラムと出力カラムの両方)を削除します。
[query_plan_enable_optimizations](#query_plan_enable_optimizations) 設定が 1 の場合にのみ有効です。

:::note
これは開発者がデバッグ目的でのみ使用すべき上級者向けの設定です。この設定は将来的に後方互換性のない形で変更されるか、削除される可能性があります。
:::

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_plan_reuse_storage_ordering_for_window_functions {#query_plan_reuse_storage_ordering_for_window_functions}

<SettingsInfoBlock type='Bool' default_value='1' />

ウィンドウ関数のソート時にストレージのソート順を利用するクエリプランレベルの最適化を切り替えます。
設定 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations) が 1 の場合にのみ有効です。

:::note
これは開発者がデバッグ目的でのみ使用すべき上級者向けの設定です。この設定は将来的に後方互換性のない変更が加えられるか、削除される可能性があります。
:::

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_plan_split_filter {#query_plan_split_filter}

<SettingsInfoBlock type='Bool' default_value='1' />

:::note
これはエキスパートレベルの設定であり、開発者がデバッグを行う場合にのみ使用してください。この設定は将来的に後方互換性のない形で変更されるか、削除される可能性があります。
:::

フィルタを式に分割するクエリプランレベルの最適化を切り替えます。
[query_plan_enable_optimizations](#query_plan_enable_optimizations) 設定が 1 の場合にのみ有効になります。

設定可能な値:

- 0 - 無効
- 1 - 有効


## query_plan_try_use_vector_search {#query_plan_try_use_vector_search}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "1" }, { label: "新しい設定。" }]
    }
  ]}
/>

ベクトル類似性インデックスの使用を試みるクエリプランレベルの最適化を切り替えます。
[`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 設定が 1 の場合にのみ有効になります。

:::note
これは開発者がデバッグ目的でのみ使用すべき上級者向けの設定です。この設定は将来的に後方互換性のない方法で変更されるか、削除される可能性があります。
:::

使用可能な値:

- 0 - 無効
- 1 - 有効


## query_plan_use_new_logical_join_step {#query_plan_use_new_logical_join_step}

**エイリアス**: `query_plan_use_logical_join_step`

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.2" }, { label: "1" }, { label: "新しいステップを有効化" }]
    },
    {
      id: "row-2",
      items: [
        { label: "25.1" },
        { label: "0" },
        { label: "新しいjoinステップ、内部変更" }
      ]
    }
  ]}
/>

クエリプランで論理joinステップを使用します。
注意: 設定 `query_plan_use_new_logical_join_step` は非推奨です。代わりに `query_plan_use_logical_join_step` を使用してください。


## query_profiler_cpu_time_period_ns {#query_profiler_cpu_time_period_ns}

<SettingsInfoBlock type='UInt64' default_value='1000000000' />

[クエリプロファイラ](../../operations/optimizing-performance/sampling-query-profiler.md)のCPUクロックタイマーの周期を設定します。このタイマーはCPU時間のみを計測します。

設定可能な値:

- ナノ秒単位の正の整数。

  推奨値:

            - 単一クエリの場合は10000000(1秒間に100回)ナノ秒以上。
            - クラスタ全体のプロファイリングの場合は1000000000(1秒に1回)。

- タイマーを無効にする場合は0。

**ClickHouse Cloudでは一時的に無効化されています。**

関連項目:

- システムテーブル [trace_log](/operations/system-tables/trace_log)


## query_profiler_real_time_period_ns {#query_profiler_real_time_period_ns}

<SettingsInfoBlock type='UInt64' default_value='1000000000' />

[クエリプロファイラ](../../operations/optimizing-performance/sampling-query-profiler.md)のリアルタイムクロックタイマーの周期を設定します。リアルタイムクロックタイマーは実際の経過時間(ウォールクロック時間)を計測します。

設定可能な値:

- 正の整数(ナノ秒単位)。

  推奨値:

            - 単一クエリの場合は10000000(1秒間に100回)ナノ秒以下。
            - クラスタ全体のプロファイリングの場合は1000000000(1秒間に1回)。

- タイマーを無効にする場合は0。

**ClickHouse Cloudでは一時的に無効化されています。**

関連項目:

- システムテーブル [trace_log](/operations/system-tables/trace_log)


## queue_max_wait_ms {#queue_max_wait_ms}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

同時実行リクエスト数が最大値を超えた場合、リクエストキューでの待機時間。


## rabbitmq_max_wait_ms {#rabbitmq_max_wait_ms}

<SettingsInfoBlock type='Milliseconds' default_value='5000' />

RabbitMQからの読み取りを再試行するまでの待機時間。


## read_backoff_max_throughput {#read_backoff_max_throughput}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

読み取り速度が遅い場合にスレッド数を削減するための設定です。読み取り帯域幅が1秒あたりこの値（バイト数）未満になった場合にイベントをカウントします。


## read_backoff_min_concurrency {#read_backoff_min_concurrency}

<SettingsInfoBlock type='UInt64' default_value='1' />

読み取りが遅い場合に、最小スレッド数を維持しようとする設定。


## read_backoff_min_events {#read_backoff_min_events}

<SettingsInfoBlock type='UInt64' default_value='2' />

読み取り速度が低下した場合にスレッド数を削減するための設定です。この値は、スレッド数を削減する前に発生する必要があるイベントの数を指定します。


## read_backoff_min_interval_between_events_ms {#read_backoff_min_interval_between_events_ms}

<SettingsInfoBlock type='Milliseconds' default_value='1000' />

読み取り速度が低下した場合にスレッド数を削減するための設定です。前回のイベントから指定された時間が経過していない場合、そのイベントは考慮されません。


## read_backoff_min_latency_ms {#read_backoff_min_latency_ms}

<SettingsInfoBlock type='Milliseconds' default_value='1000' />

読み取りが遅い場合にスレッド数を削減するための設定です。この時間以上かかった読み取りのみが対象となります。


## read_from_distributed_cache_if_exists_otherwise_bypass_cache {#read_from_distributed_cache_if_exists_otherwise_bypass_cache}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。read_from_filesystem_cache_if_exists_otherwise_bypass_cacheと同じですが、分散キャッシュ用です。


## read_from_filesystem_cache_if_exists_otherwise_bypass_cache {#read_from_filesystem_cache_if_exists_otherwise_bypass_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

ファイルシステムキャッシュをパッシブモードで使用できるようにします。既存のキャッシュエントリを活用しますが、新しいエントリはキャッシュに追加しません。この設定を負荷の高いアドホッククエリに対して有効にし、短時間のリアルタイムクエリに対しては無効のままにすることで、負荷の高いクエリによるキャッシュスラッシングを回避し、システム全体の効率を向上させることができます。


## read_from_page_cache_if_exists_otherwise_bypass_cache {#read_from_page_cache_if_exists_otherwise_bypass_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        { label: "ユーザー空間ページキャッシュを追加しました" }
      ]
    }
  ]}
/>

read_from_filesystem_cache_if_exists_otherwise_bypass_cacheと同様に、ユーザー空間ページキャッシュをパッシブモードで使用します。


## read_in_order_two_level_merge_threshold {#read_in_order_two_level_merge_threshold}

<SettingsInfoBlock type='UInt64' default_value='100' />

プライマリキーの順序でマルチスレッド読み取りを行う際に、事前マージステップを実行するために読み取る必要のある最小パート数。


## read_in_order_use_buffering {#read_in_order_use_buffering}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.7" },
        { label: "1" },
        {
          label:
            "プライマリキーの順序で読み取る際、マージ前にバッファリングを使用"
        }
      ]
    }
  ]}
/>

プライマリキーの順序で読み取る際、マージ前にバッファリングを使用します。これによりクエリ実行の並列性が向上します


## read_in_order_use_virtual_row {#read_in_order_use_virtual_row}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "0" },
        {
          label:
            "プライマリキーまたはその単調関数の順序でデータを読み取る際に仮想行を使用します。複数のパートを検索する場合、関連するパートのみがアクセスされるため有用です。"
        }
      ]
    }
  ]}
/>

プライマリキーまたはその単調関数の順序でデータを読み取る際に仮想行を使用します。複数のパートを検索する場合、関連するパートのみがアクセスされるため有用です。


## read_overflow_mode {#read_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

制限を超過した場合の動作を指定します。


## read_overflow_mode_leaf {#read_overflow_mode_leaf}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

読み取るデータ量がリーフ制限のいずれかを超えた場合の動作を設定します。

設定可能なオプション:

- `throw`: 例外をスローします（デフォルト）。
- `break`: クエリの実行を停止し、部分的な結果を返します。


## read_priority {#read_priority}

<SettingsInfoBlock type='Int64' default_value='0' />

ローカルファイルシステムまたはリモートファイルシステムからのデータ読み取りの優先度。ローカルファイルシステムでは 'pread_threadpool' メソッド、リモートファイルシステムでは `threadpool` メソッドでのみサポートされます。


## read_through_distributed_cache {#read_through_distributed_cache}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "ClickHouse Cloud用の設定" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ効果があります。分散キャッシュからの読み取りを許可します


## readonly {#readonly}

<SettingsInfoBlock type='UInt64' default_value='0' />

0 - 読み取り専用の制限なし。1 - 読み取りリクエストのみ、および明示的に許可された設定の変更が可能。2 - 読み取りリクエストのみ、および'readonly'設定を除く設定の変更が可能。


## receive_data_timeout_ms {#receive_data_timeout_ms}

<SettingsInfoBlock type='Milliseconds' default_value='2000' />

レプリカから最初のデータパケットまたは正常な進行状況を示すパケットを受信するための接続タイムアウト


## receive_timeout {#receive_timeout}

<SettingsInfoBlock type='Seconds' default_value='300' />

ネットワークからのデータ受信タイムアウト(秒単位)。この期間内にデータが受信されなかった場合、例外がスローされます。クライアント側でこの設定を行うと、サーバー側の対応する接続エンドのソケットに対しても 'send_timeout' が設定されます。


## regexp_max_matches_per_row {#regexp_max_matches_per_row}

<SettingsInfoBlock type='UInt64' default_value='1000' />

1行あたりの単一の正規表現に対するマッチ数の最大値を設定します。[extractAllGroupsHorizontal](/sql-reference/functions/string-search-functions#extractAllGroupsHorizontal)関数で貪欲な正規表現を使用する際に、メモリ過負荷を防ぐために使用します。

設定可能な値:

- 正の整数


## reject_expensive_hyperscan_regexps {#reject_expensive_hyperscan_regexps}

<SettingsInfoBlock type='Bool' default_value='1' />

hyperscanで評価する際に高コストになる可能性が高いパターンを拒否します(NFA状態爆発が原因)


## remerge_sort_lowered_memory_bytes_ratio {#remerge_sort_lowered_memory_bytes_ratio}

<SettingsInfoBlock type='Float' default_value='2' />

再マージ後のメモリ使用量がこの比率で削減されない場合、再マージは無効になります。


## remote_filesystem_read_method {#remote_filesystem_read_method}

<SettingsInfoBlock type='String' default_value='threadpool' />

リモートファイルシステムからデータを読み取る方法。read または threadpool のいずれかを指定します。


## remote_filesystem_read_prefetch {#remote_filesystem_read_prefetch}

<SettingsInfoBlock type='Bool' default_value='1' />

リモートファイルシステムからデータを読み取る際にプリフェッチを使用するかどうかを指定します。


## remote_fs_read_backoff_max_tries {#remote_fs_read_backoff_max_tries}

<SettingsInfoBlock type='UInt64' default_value='5' />

バックオフを使用した読み取りの最大試行回数


## remote_fs_read_max_backoff_ms {#remote_fs_read_max_backoff_ms}

<SettingsInfoBlock type='UInt64' default_value='10000' />

リモートディスクからデータを読み取ろうとする際の最大待機時間


## remote_read_min_bytes_for_seek {#remote_read_min_bytes_for_seek}

<SettingsInfoBlock type='UInt64' default_value='4194304' />

リモート読み取り（url、s3）でシーク操作を実行するために必要な最小バイト数。この値未満の場合は、データをスキップしながら読み取りを行います。


## rename_files_after_processing {#rename_files_after_processing}

- **型:** String

- **デフォルト値:** 空文字列

この設定では、`file`テーブル関数で処理されるファイルの名前変更パターンを指定できます。このオプションを設定すると、`file`テーブル関数で読み取られたすべてのファイルは、処理が成功した場合にのみ、プレースホルダーを含む指定されたパターンに従って名前が変更されます。

### プレースホルダー

- `%a` — 完全な元のファイル名(例:「sample.csv」)
- `%f` — 拡張子を除いた元のファイル名(例:「sample」)
- `%e` — ドット付きの元のファイル拡張子(例:「.csv」)
- `%t` — タイムスタンプ(マイクロ秒単位)
- `%%` — パーセント記号(「%」)

### 例

- オプション: `--rename_files_after_processing="processed_%f_%t%e"`

- クエリ: `SELECT * FROM file('sample.csv')`

`sample.csv`の読み取りが成功すると、ファイルは`processed_sample_1683473210851438.csv`に名前変更されます。


## replace_running_query {#replace_running_query}

<SettingsInfoBlock type='Bool' default_value='0' />

HTTPインターフェースを使用する際、`query_id`パラメータを渡すことができます。これはクエリ識別子として機能する任意の文字列です。
同じユーザーから同じ`query_id`を持つクエリが既に実行中の場合、動作は`replace_running_query`パラメータによって決まります。

`0`(デフォルト)– 例外をスローします(同じ`query_id`を持つクエリが既に実行中の場合、クエリの実行を許可しません)。

`1` – 古いクエリをキャンセルし、新しいクエリの実行を開始します。

セグメンテーション条件のサジェスト機能を実装する場合は、このパラメータを1に設定してください。次の文字を入力した際、古いクエリがまだ完了していない場合は、キャンセルされるべきです。


## replace_running_query_max_wait_ms {#replace_running_query_max_wait_ms}

<SettingsInfoBlock type='Milliseconds' default_value='5000' />

[replace_running_query](#replace_running_query)設定が有効な場合、同じ`query_id`を持つ実行中のクエリが終了するまでの待機時間。

設定可能な値:

- 正の整数。
- 0 — サーバーが既に同じ`query_id`を持つクエリを実行している場合、新しいクエリの実行を許可せず例外をスローします。


## replication_wait_for_inactive_replica_timeout {#replication_wait_for_inactive_replica_timeout}

<SettingsInfoBlock type='Int64' default_value='120' />

非アクティブなレプリカが[`ALTER`](../../sql-reference/statements/alter/index.md)、[`OPTIMIZE`](../../sql-reference/statements/optimize.md)、または[`TRUNCATE`](../../sql-reference/statements/truncate.md)クエリを実行するのを待機する時間(秒単位)を指定します。

設定可能な値:

- `0` — 待機しない。
- 負の整数 — 無制限に待機する。
- 正の整数 — 待機する秒数。


## restore_replace_external_dictionary_source_to_null {#restore_replace_external_dictionary_source_to_null}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.10" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

復元時に外部ディクショナリソースをNullに置き換えます。テスト目的に有用です


## restore_replace_external_engines_to_null {#restore_replace_external_engines_to_null}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.8" }, { label: "0" }, { label: "新しい設定です。" }]
    }
  ]}
/>

テスト目的で使用します。外部接続を開始しないように、すべての外部エンジンをNullに置き換えます。


## restore_replace_external_table_functions_to_null {#restore_replace_external_table_functions_to_null}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.8" }, { label: "0" }, { label: "新しい設定です。" }]
    }
  ]}
/>

テスト目的で使用します。外部接続を開始しないように、すべての外部テーブル関数をNullに置き換えます。


## restore_replicated_merge_tree_to_shared_merge_tree {#restore_replicated_merge_tree_to_shared_merge_tree}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.2" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

RESTORE実行時にテーブルエンジンをReplicated*MergeTreeからShared*MergeTreeに置き換えます。


## result_overflow_mode {#result_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

Cloud default value: `throw`

結果のサイズが制限値のいずれかを超えた場合の動作を設定します。

設定可能な値:

- `throw`: 例外をスローします（デフォルト）。
- `break`: クエリの実行を停止し、ソースデータが尽きた場合と同様に部分的な結果を返します。

'break'の使用はLIMITの使用に似ています。`Break`はブロックレベルでのみ実行を中断します。これは、返される行数が[`max_result_rows`](/operations/settings/settings#max_result_rows)より大きく、[`max_block_size`](/operations/settings/settings#max_block_size)の倍数であり、[`max_threads`](/operations/settings/settings#max_threads)に依存することを意味します。

**例**

```sql title="クエリ"
SET max_threads = 3, max_block_size = 3333;
SET max_result_rows = 3334, result_overflow_mode = 'break';

SELECT *
FROM numbers_mt(100000)
FORMAT Null;
```

```text title="結果"
6666 rows in set. ...
```


## rewrite_count_distinct_if_with_count_distinct_implementation {#rewrite_count_distinct_if_with_count_distinct_implementation}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.8" },
        { label: "1" },
        {
          label:
            "count_distinct_implementation設定によるcountDistinctIfの書き換え"
        }
      ]
    }
  ]}
/>

[count_distinct_implementation](#count_distinct_implementation)設定を使用して`countDistcintIf`を書き換えることができます。

設定可能な値:

- true — 許可します。
- false — 許可しません。


## rewrite_in_to_join {#rewrite_in_to_join}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.10" },
        { label: "0" },
        { label: "新しい実験的設定" }
      ]
    }
  ]}
/>

'x IN subquery' のような式を JOIN に書き換えます。これは、結合順序の最適化によってクエリ全体を最適化する際に有用です。


## s3_allow_multipart_copy {#s3_allow_multipart_copy}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.2" }, { label: "1" }, { label: "新しい設定です。" }]
    }
  ]}
/>

S3でマルチパートコピーを許可します。


## s3_allow_parallel_part_upload {#s3_allow_parallel_part_upload}

<SettingsInfoBlock type='Bool' default_value='1' />

S3マルチパートアップロードで複数のスレッドを使用します。メモリ使用量がわずかに増加する可能性があります


## s3_check_objects_after_upload {#s3_check_objects_after_upload}

<SettingsInfoBlock type='Bool' default_value='0' />

アップロードが成功したことを確認するために、S3にアップロードされた各オブジェクトをHEADリクエストで検証します


## s3_connect_timeout_ms {#s3_connect_timeout_ms}

<SettingsInfoBlock type='UInt64' default_value='1000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1000" },
        { label: "S3接続タイムアウトの専用設定を導入" }
      ]
    }
  ]}
/>

S3ディスクからのホストへの接続タイムアウト。


## s3_create_new_file_on_insert {#s3_create_new_file_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

s3エンジンテーブルへの挿入時に毎回新しいファイルを作成するかどうかを有効または無効にします。有効にすると、挿入のたびに次のパターンに類似したキーで新しいS3オブジェクトが作成されます:

初期: `data.Parquet.gz` -> `data.1.Parquet.gz` -> `data.2.Parquet.gz`、など

設定可能な値:

- 0 — `INSERT`クエリは新しいファイルを作成するか、ファイルが存在しs3_truncate_on_insertが設定されていない場合は失敗します。
- 1 — `INSERT`クエリは、s3_truncate_on_insertが設定されていない場合、接尾辞を使用して(2回目以降)挿入のたびに新しいファイルを作成します。

詳細は[こちら](/integrations/s3#inserting-data)を参照してください。


## s3_disable_checksum {#s3_disable_checksum}

<SettingsInfoBlock type='Bool' default_value='0' />

S3へのファイル送信時にチェックサムを計算しません。これにより、ファイルに対する過剰な処理パスを回避し、書き込みが高速化されます。MergeTreeテーブルのデータはClickHouseによってチェックサムが計算されており、HTTPSでS3にアクセスする場合はTLS層がネットワーク転送中の整合性を既に提供しているため、ほぼ安全です。ただし、S3上の追加のチェックサムは多層防御を提供します。


## s3_ignore_file_doesnt_exist {#s3_ignore_file_doesnt_exist}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "0" },
        {
          label:
            "S3テーブルエンジンで、要求されたファイルが存在しない場合に例外をスローせず0行を返すことを許可"
        }
      ]
    }
  ]}
/>

特定のキーを読み取る際に、ファイルが存在しない場合はその不在を無視します。

設定可能な値:

- 1 — `SELECT`は空の結果を返します。
- 0 — `SELECT`は例外をスローします。


## s3_list_object_keys_size {#s3_list_object_keys_size}

<SettingsInfoBlock type='UInt64' default_value='1000' />

ListObjectリクエストでバッチ処理により返されるファイルの最大数


## s3_max_connections {#s3_max_connections}

<SettingsInfoBlock type='UInt64' default_value='1024' />

サーバーごとの最大接続数。


## s3_max_get_burst {#s3_max_get_burst}

<SettingsInfoBlock type='UInt64' default_value='0' />

1秒あたりのリクエスト制限に到達する前に同時発行可能なリクエストの最大数。デフォルト(0)の場合、`s3_max_get_rps`と同じ値になります


## s3_max_get_rps {#s3_max_get_rps}

<SettingsInfoBlock type='UInt64' default_value='0' />

スロットリング前の1秒あたりのS3 GETリクエスト数の上限。0は無制限を意味します。


## s3_max_inflight_parts_for_one_file {#s3_max_inflight_parts_for_one_file}

<SettingsInfoBlock type='UInt64' default_value='20' />

マルチパートアップロードリクエストにおける同時にロードされるパーツの最大数。0は無制限を意味します。


## s3_max_part_number {#s3_max_part_number}

<SettingsInfoBlock type='UInt64' default_value='10000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "10000" },
        { label: "S3アップロードパートの最大パート番号" }
      ]
    }
  ]}
/>

S3アップロードパートの最大パート番号.


## s3_max_put_burst {#s3_max_put_burst}

<SettingsInfoBlock type='UInt64' default_value='0' />

1秒あたりのリクエスト制限に達する前に同時発行可能なリクエストの最大数。デフォルト(0)では`s3_max_put_rps`と等しくなります


## s3_max_put_rps {#s3_max_put_rps}

<SettingsInfoBlock type='UInt64' default_value='0' />

スロットリング前の1秒あたりのS3 PUTリクエストレートの制限。0は無制限を意味します。


## s3_max_single_operation_copy_size {#s3_max_single_operation_copy_size}

<SettingsInfoBlock type='UInt64' default_value='33554432' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "33554432" },
        { label: "S3における単一コピー操作の最大サイズ" }
      ]
    }
  ]}
/>

S3における単一操作コピーの最大サイズ。この設定は s3_allow_multipart_copy が true の場合にのみ使用されます。


## s3_max_single_part_upload_size {#s3_max_single_part_upload_size}

<SettingsInfoBlock type='UInt64' default_value='33554432' />

S3へシングルパートアップロードでアップロードできるオブジェクトの最大サイズ。


## s3_max_single_read_retries {#s3_max_single_read_retries}

<SettingsInfoBlock type='UInt64' default_value='4' />

単一のS3読み取り操作における最大リトライ回数。


## s3_max_unexpected_write_error_retries {#s3_max_unexpected_write_error_retries}

<SettingsInfoBlock type='UInt64' default_value='4' />

S3への書き込み中に予期しないエラーが発生した場合の最大再試行回数。


## s3_max_upload_part_size {#s3_max_upload_part_size}

<SettingsInfoBlock type='UInt64' default_value='5368709120' />

S3へのマルチパートアップロード中にアップロードするパートの最大サイズ。


## s3_min_upload_part_size {#s3_min_upload_part_size}

<SettingsInfoBlock type='UInt64' default_value='16777216' />

S3へのマルチパートアップロード中にアップロードするパートの最小サイズ。


## s3_request_timeout_ms {#s3_request_timeout_ms}

<SettingsInfoBlock type='UInt64' default_value='30000' />

S3との間でデータを送受信する際のアイドルタイムアウト。単一のTCP読み取りまたは書き込み呼び出しがこの時間ブロックされた場合は失敗します。


## s3_skip_empty_files {#s3_skip_empty_files}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "1" },
        { label: "より良いユーザーエクスペリエンスの提供を目指しています" }
      ]
    }
  ]}
/>

[S3](../../engines/table-engines/integrations/s3.md)エンジンテーブルにおいて、空のファイルのスキップを有効化または無効化します。

設定可能な値:

- 0 — 空のファイルが要求された形式と互換性がない場合、`SELECT`は例外をスローします。
- 1 — 空のファイルに対して`SELECT`は空の結果を返します。


## s3_slow_all_threads_after_network_error {#s3_slow_all_threads_after_network_error}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

`true`に設定すると、いずれかのS3リクエストがソケットタイムアウトなどの再試行可能なネットワークエラーに遭遇した後、同じバックアップエンドポイントに対してS3リクエストを実行しているすべてのスレッドが減速されます。
`false`に設定すると、各スレッドは他のスレッドとは独立してS3リクエストのバックオフを処理します。


## s3_strict_upload_part_size {#s3_strict_upload_part_size}

<SettingsInfoBlock type='UInt64' default_value='0' />

S3へのマルチパートアップロード時にアップロードするパートの厳密なサイズ（一部の実装では可変サイズのパートに対応していません）。


## s3_throw_on_zero_files_match {#s3_throw_on_zero_files_match}

<SettingsInfoBlock type='Bool' default_value='0' />

ListObjectsリクエストがいずれのファイルとも一致しない場合にエラーをスローします


## s3_truncate_on_insert {#s3_truncate_on_insert}

<SettingsInfoBlock type='Bool' default_value='0' />

s3エンジンテーブルへの挿入前のtruncateを有効または無効にします。無効にした場合、S3オブジェクトが既に存在する状態で挿入を試みると例外がスローされます。

設定可能な値:

- 0 — `INSERT`クエリは新しいファイルを作成します。ファイルが既に存在し、s3_create_new_file_on_insertが設定されていない場合は失敗します。
- 1 — `INSERT`クエリは既存のファイルの内容を新しいデータで置き換えます。

詳細は[こちら](/integrations/s3#inserting-data)を参照してください。


## s3_upload_part_size_multiply_factor {#s3_upload_part_size_multiply_factor}

<SettingsInfoBlock type='UInt64' default_value='2' />

S3への単一の書き込みでs3_multiply_parts_count_threshold個のパートがアップロードされるたびに、s3_min_upload_part_sizeにこの係数を乗算します。


## s3_upload_part_size_multiply_parts_count_threshold {#s3_upload_part_size_multiply_parts_count_threshold}

<SettingsInfoBlock type='UInt64' default_value='500' />

この数のパートがS3にアップロードされるごとに、s3_min_upload_part_sizeにs3_upload_part_size_multiply_factorが乗算されます。


## s3_use_adaptive_timeouts {#s3_use_adaptive_timeouts}

<SettingsInfoBlock type='Bool' default_value='1' />

`true`に設定すると、すべてのS3リクエストに対して最初の2回の試行が低い送信および受信タイムアウトで実行されます。
`false`に設定すると、すべての試行が同一のタイムアウトで実行されます。


## s3_validate_request_settings {#s3_validate_request_settings}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.6" },
        { label: "1" },
        { label: "S3リクエスト設定の検証を無効化可能に" }
      ]
    }
  ]}
/>

S3リクエスト設定の検証を有効化します。
設定可能な値:

- 1 — 設定を検証する。
- 0 — 設定を検証しない。


## s3queue_default_zookeeper_path {#s3queue_default_zookeeper_path}

<SettingsInfoBlock type='String' default_value='/clickhouse/s3queue/' />

S3QueueエンジンのデフォルトZooKeeperパスプレフィックス


## s3queue_enable_logging_to_s3queue_log {#s3queue_enable_logging_to_s3queue_log}

<SettingsInfoBlock type='Bool' default_value='0' />

system.s3queue_logへの書き込みを有効にします。この値は、テーブル設定を使用してテーブルごとに上書きできます


## s3queue_keeper_fault_injection_probability {#s3queue_keeper_fault_injection_probability}

<SettingsInfoBlock type='Float' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "New setting." }]
    }
  ]}
/>

S3QueueのKeeperフォールトインジェクション確率。


## s3queue_migrate_old_metadata_to_buckets {#s3queue_migrate_old_metadata_to_buckets}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

S3Queueテーブルの古いメタデータ構造を新しい構造に移行する


## schema_inference_cache_require_modification_time_for_url {#schema_inference_cache_require_modification_time_for_url}

<SettingsInfoBlock type='Bool' default_value='1' />

最終更新時刻の検証を伴うURLに対してキャッシュからスキーマを使用します（Last-Modifiedヘッダーを持つURLが対象）


## schema_inference_use_cache_for_azure {#schema_inference_use_cache_for_azure}

<SettingsInfoBlock type='Bool' default_value='1' />

Azureテーブル関数使用時のスキーマ推論でキャッシュを使用する


## schema_inference_use_cache_for_file {#schema_inference_use_cache_for_file}

<SettingsInfoBlock type='Bool' default_value='1' />

ファイルテーブル関数使用時のスキーマ推論でキャッシュを使用する


## schema_inference_use_cache_for_hdfs {#schema_inference_use_cache_for_hdfs}

<SettingsInfoBlock type='Bool' default_value='1' />

hdfsテーブル関数使用時にスキーマ推論でキャッシュを使用する


## schema_inference_use_cache_for_s3 {#schema_inference_use_cache_for_s3}

<SettingsInfoBlock type='Bool' default_value='1' />

s3テーブル関数使用時のスキーマ推論でキャッシュを使用


## schema_inference_use_cache_for_url {#schema_inference_use_cache_for_url}

<SettingsInfoBlock type='Bool' default_value='1' />

url テーブル関数使用時にスキーマ推論でキャッシュを使用する


## secondary_indices_enable_bulk_filtering {#secondary_indices_enable_bulk_filtering}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.5" },
        { label: "1" },
        { label: "データスキッピングインデックスによるフィルタリングの新しいアルゴリズム" }
      ]
    }
  ]}
/>

インデックスに対するバルクフィルタリングアルゴリズムを有効にします。常に優れたパフォーマンスが期待されますが、互換性と制御のためにこの設定が用意されています。


## select_sequential_consistency {#select_sequential_consistency}

<SettingsInfoBlock type='UInt64' default_value='0' />

:::note
この設定はSharedMergeTreeとReplicatedMergeTreeで動作が異なります。SharedMergeTreeにおける`select_sequential_consistency`の動作の詳細については、[SharedMergeTree consistency](/cloud/reference/shared-merge-tree#consistency)を参照してください。
:::

`SELECT`クエリのシーケンシャル一貫性を有効または無効にします。`insert_quorum_parallel`を無効にする必要があります(デフォルトでは有効)。

設定可能な値:

- 0 — 無効。
- 1 — 有効。

使用方法

シーケンシャル一貫性が有効な場合、ClickHouseは`insert_quorum`で実行された以前のすべての`INSERT`クエリのデータを含むレプリカに対してのみ、クライアントが`SELECT`クエリを実行することを許可します。クライアントが部分的なレプリカを参照する場合、ClickHouseは例外を生成します。SELECTクエリには、クォーラムのレプリカにまだ書き込まれていないデータは含まれません。

`insert_quorum_parallel`が有効な場合(デフォルト)、`select_sequential_consistency`は機能しません。これは、並列`INSERT`クエリが異なるクォーラムレプリカのセットに書き込まれる可能性があるため、単一のレプリカがすべての書き込みを受信する保証がないためです。

関連項目:

- [insert_quorum](#insert_quorum)
- [insert_quorum_timeout](#insert_quorum_timeout)
- [insert_quorum_parallel](#insert_quorum_parallel)


## send_logs_level {#send_logs_level}

<SettingsInfoBlock type='LogsLevel' default_value='fatal' />

指定された最小レベル以上のサーバーテキストログをクライアントに送信します。有効な値：'trace'、'debug'、'information'、'warning'、'error'、'fatal'、'none'


## send_logs_source_regexp {#send_logs_source_regexp}

ログソース名に一致する正規表現を指定して、サーバーテキストログを送信します。空の場合は、すべてのソースが対象となります。


## send_profile_events {#send_profile_events}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.11" },
        { label: "1" },
        { label: "新しい設定。プロファイルイベントをクライアントに送信するかどうか。" }
      ]
    }
  ]}
/>

クライアントへの[ProfileEvents](/native-protocol/server.md#profile-events)パケットの送信を有効または無効にします。

プロファイルイベントが不要なクライアントのネットワークトラフィックを削減するために無効化できます。

設定可能な値:

- 0 — 無効。
- 1 — 有効。


## send_progress_in_http_headers {#send_progress_in_http_headers}

<SettingsInfoBlock type='Bool' default_value='0' />

`clickhouse-server`のレスポンスにおける`X-ClickHouse-Progress` HTTPレスポンスヘッダーを有効または無効にします。

詳細については、[HTTPインターフェースの説明](../../interfaces/http.md)を参照してください。

設定可能な値:

- 0 — 無効。
- 1 — 有効。


## send_timeout {#send_timeout}

<SettingsInfoBlock type='Seconds' default_value='300' />

ネットワークへのデータ送信のタイムアウト(秒単位)。クライアントがデータを送信する必要があるにもかかわらず、この間隔内に一切のバイトを送信できない場合、例外がスローされます。この設定をクライアント側で設定した場合、サーバー側の対応する接続エンドでソケットの 'receive_timeout' も設定されます。


## serialize_query_plan {#serialize_query_plan}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "0" }, { label: "NewSetting" }]
    }
  ]}
/>

分散処理用のクエリプランをシリアライズする


## session_timezone {#session_timezone}

<BetaBadge />

現在のセッションまたはクエリの暗黙的なタイムゾーンを設定します。
暗黙的なタイムゾーンとは、タイムゾーンが明示的に指定されていないDateTime/DateTime64型の値に適用されるタイムゾーンです。
この設定は、グローバルに設定された(サーバーレベルの)暗黙的なタイムゾーンよりも優先されます。
''(空文字列)の値は、現在のセッションまたはクエリの暗黙的なタイムゾーンが[サーバータイムゾーン](../server-configuration-parameters/settings.md/#timezone)と等しいことを意味します。

セッションタイムゾーンとサーバータイムゾーンを取得するには、`timeZone()`および`serverTimeZone()`関数を使用できます。

使用可能な値:

- `system.time_zones`からの任意のタイムゾーン名、例:`Europe/Berlin`、`UTC`、または`Zulu`

例:

```sql
SELECT timeZone(), serverTimeZone() FORMAT CSV

"Europe/Berlin","Europe/Berlin"
```

```sql
SELECT timeZone(), serverTimeZone() SETTINGS session_timezone = 'Asia/Novosibirsk' FORMAT CSV

"Asia/Novosibirsk","Europe/Berlin"
```

タイムゾーンが明示的に指定されていない内部のDateTimeにセッションタイムゾーン'America/Denver'を割り当てます:

```sql
SELECT toDateTime64(toDateTime64('1999-12-12 23:23:23.123', 3), 3, 'Europe/Zurich') SETTINGS session_timezone = 'America/Denver' FORMAT TSV

1999-12-13 07:23:23.123
```

:::warning
DateTime/DateTime64を解析するすべての関数が`session_timezone`を考慮するわけではありません。これにより、微妙なエラーが発生する可能性があります。
以下の例と説明を参照してください。
:::

```sql
CREATE TABLE test_tz (`d` DateTime('UTC')) ENGINE = Memory AS SELECT toDateTime('2000-01-01 00:00:00', 'UTC');

SELECT *, timeZone() FROM test_tz WHERE d = toDateTime('2000-01-01 00:00:00') SETTINGS session_timezone = 'Asia/Novosibirsk'
0 rows in set.

SELECT *, timeZone() FROM test_tz WHERE d = '2000-01-01 00:00:00' SETTINGS session_timezone = 'Asia/Novosibirsk'
┌───────────────────d─┬─timeZone()───────┐
│ 2000-01-01 00:00:00 │ Asia/Novosibirsk │
└─────────────────────┴──────────────────┘
```

これは異なる解析パイプラインによって発生します:

- 最初の`SELECT`クエリで使用される、タイムゾーンが明示的に指定されていない`toDateTime()`は、`session_timezone`設定とグローバルタイムゾーンを考慮します。
- 2番目のクエリでは、DateTimeが文字列から解析され、既存の列`d`の型とタイムゾーンを継承します。したがって、`session_timezone`設定とグローバルタイムゾーンは考慮されません。

**関連項目**

- [timezone](../server-configuration-parameters/settings.md/#timezone)


## set_overflow_mode {#set_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

データ量がいずれかの制限を超えた場合の動作を設定します。

設定可能な値:

- `throw`: 例外をスローします（デフォルト）。
- `break`: クエリの実行を停止し、ソースデータが尽きた場合と同様に部分的な結果を返します。


## shared_merge_tree_sync_parts_on_partition_operations {#shared_merge_tree_sync_parts_on_partition_operations}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "1" },
        { label: "新しい設定。デフォルトでは、パーツは常に同期されます" }
      ]
    }
  ]}
/>

SMTテーブルにおけるMOVE|REPLACE|ATTACHパーティション操作後、データパーツのセットを自動的に同期します。ClickHouse Cloudのみ


## short_circuit_function_evaluation {#short_circuit_function_evaluation}

<SettingsInfoBlock
  type='ShortCircuitFunctionEvaluation'
  default_value='enable'
/>

[if](../../sql-reference/functions/conditional-functions.md/#if)、[multiIf](../../sql-reference/functions/conditional-functions.md/#multiIf)、[and](/sql-reference/functions/logical-functions#and)、[or](/sql-reference/functions/logical-functions#or)関数を[短絡評価](https://en.wikipedia.org/wiki/Short-circuit_evaluation)方式で計算できるようにします。これにより、これらの関数内の複雑な式の実行を最適化し、予期しない例外(ゼロ除算など)の発生を防ぐことができます。

設定可能な値:

- `enable` — 短絡評価に適した関数(例外をスローする可能性がある関数や計算負荷の高い関数)に対して短絡評価を有効にします。
- `force_enable` — すべての関数に対して短絡評価を有効にします。
- `disable` — 短絡評価を無効にします。


## short_circuit_function_evaluation_for_nulls {#short_circuit_function_evaluation_for_nulls}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "1" },
        {
          label:
            "すべての引数が非NULL値である行でのみ、Nullable引数を持つ関数の実行を許可"
        }
      ]
    }
  ]}
/>

いずれかの引数がNULLの場合にNULLを返す関数の評価を最適化します。関数の引数におけるNULL値の割合がshort_circuit_function_evaluation_for_nulls_thresholdを超えた場合、システムは行ごとの関数評価をスキップします。代わりに、すべての行に対して即座にNULLを返すことで、不要な計算を回避します。


## short_circuit_function_evaluation_for_nulls_threshold {#short_circuit_function_evaluation_for_nulls_threshold}

<SettingsInfoBlock type='Double' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "1" },
        {
          label:
            "Nullable引数を持つ関数を、すべての引数が非NULL値の行でのみ実行するためのNULL値比率の閾値。設定short_circuit_function_evaluation_for_nullsが有効な場合に適用されます。"
        }
      ]
    }
  ]}
/>

Nullable引数を持つ関数を、すべての引数が非NULL値の行でのみ実行するためのNULL値比率の閾値。設定short_circuit_function_evaluation_for_nullsが有効な場合に適用されます。
NULL値を含む行の比率が総行数に対してこの閾値を超えた場合、NULL値を含む行は評価されません。


## show_data_lake_catalogs_in_system_tables {#show_data_lake_catalogs_in_system_tables}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "1" }, { label: "新しい設定" }]
    },
    {
      id: "row-2",
      items: [
        { label: "25.10" },
        { label: "0" },
        { label: "デフォルトでシステムテーブルのカタログを無効化" }
      ]
    }
  ]}
/>

システムテーブルにデータレイクカタログの表示を有効にします。


## show_processlist_include_internal {#show_processlist_include_internal}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

`SHOW PROCESSLIST`クエリの出力に内部補助プロセスを表示します。

内部プロセスには、ディクショナリの再読み込み、リフレッシュ可能なマテリアライズドビューの再読み込み、`SHOW ...`クエリで実行される補助`SELECT`、破損したテーブルに対応するために内部的に実行される補助`CREATE DATABASE ...`クエリなどが含まれます。


## show_table_uuid_in_table_create_query_if_not_nil {#show_table_uuid_in_table_create_query_if_not_nil}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "20.7" },
        { label: "0" },
        {
          label:
            "Engine=AtomicのCREATEクエリにおけるテーブルUIDの表示を停止"
        }
      ]
    }
  ]}
/>

`SHOW TABLE`クエリの表示形式を設定します。

設定可能な値:

- 0 — テーブルUUIDを含めずにクエリを表示します。
- 1 — テーブルUUIDを含めてクエリを表示します。


## single_join_prefer_left_table {#single_join_prefer_left_table}

<SettingsInfoBlock type='Bool' default_value='1' />

単一のJOINで識別子が曖昧な場合、左側のテーブルを優先する


## skip_redundant_aliases_in_udf {#skip_redundant_aliases_in_udf}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "0" },
        {
          label:
            "有効にすると、同じテーブル内の複数のマテリアライズドカラムに対して同じユーザー定義関数を複数回使用できるようになります。"
        }
      ]
    }
  ]}
/>

使用を簡素化するため、ユーザー定義関数内では冗長なエイリアスが使用(置換)されません。

設定可能な値:

- 1 — UDF内でエイリアスがスキップ(置換)されます。
- 0 — UDF内でエイリアスがスキップ(置換)されません。

**例**

有効時と無効時の違い:

クエリ:

```sql
SET skip_redundant_aliases_in_udf = 0;
CREATE FUNCTION IF NOT EXISTS test_03274 AS ( x ) -> ((x + 1 as y, y + 2));

EXPLAIN SYNTAX SELECT test_03274(4 + 2);
```

結果:

```text
SELECT ((4 + 2) + 1 AS y, y + 2)
```

クエリ:

```sql
SET skip_redundant_aliases_in_udf = 1;
CREATE FUNCTION IF NOT EXISTS test_03274 AS ( x ) -> ((x + 1 as y, y + 2));

EXPLAIN SYNTAX SELECT test_03274(4 + 2);
```

結果:

```text
SELECT ((4 + 2) + 1, ((4 + 2) + 1) + 2)
```


## skip_unavailable_shards {#skip_unavailable_shards}

<SettingsInfoBlock type='Bool' default_value='0' />

利用不可能なシャードを通知なしでスキップする機能を有効または無効にします。

すべてのレプリカが利用不可能な場合、そのシャードは利用不可能とみなされます。レプリカが利用不可能となるのは以下の場合です:

- 何らかの理由でClickHouseがレプリカに接続できない場合。

  レプリカへの接続時、ClickHouseは複数回の接続試行を実行します。これらの試行がすべて失敗した場合、そのレプリカは利用不可能とみなされます。

- DNSを通じてレプリカを解決できない場合。

  レプリカのホスト名がDNSを通じて解決できない場合、以下の状況を示している可能性があります:
  - レプリカのホストにDNSレコードが存在しない場合。これは動的DNSを使用するシステム、例えば[Kubernetes](https://kubernetes.io)などで発生する可能性があります。このようなシステムでは、ダウンタイム中にノードが解決不可能になることがありますが、これはエラーではありません。

  - 設定エラー。ClickHouse設定ファイルに誤ったホスト名が含まれている場合。

設定可能な値:

- 1 — スキップが有効。

  シャードが利用不可能な場合、ClickHouseは部分的なデータに基づいて結果を返し、ノードの可用性に関する問題を報告しません。

- 0 — スキップが無効。

  シャードが利用不可能な場合、ClickHouseは例外をスローします。


## sleep_after_receiving_query_ms {#sleep_after_receiving_query_ms}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

TCPHandlerでクエリを受信後にスリープする時間


## sleep_in_send_data_ms {#sleep_in_send_data_ms}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

TCPHandlerでのデータ送信時のスリープ時間


## sleep_in_send_tables_status_ms {#sleep_in_send_tables_status_ms}

<SettingsInfoBlock type='Milliseconds' default_value='0' />

TCPHandlerでテーブルステータス応答を送信する際のスリープ時間


## sort_overflow_mode {#sort_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

ソート前に受信した行数が制限値のいずれかを超えた場合の動作を設定します。

設定可能な値:

- `throw`: 例外をスローします。
- `break`: クエリの実行を停止し、部分的な結果を返します。


## split_intersecting_parts_ranges_into_layers_final {#split_intersecting_parts_ranges_into_layers_final}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "FINAL最適化時に交差するパーツ範囲のレイヤー分割を許可"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.1" },
        { label: "1" },
        {
          label:
            "FINAL最適化時に交差するパーツ範囲のレイヤー分割を許可"
        }
      ]
    }
  ]}
/>

FINAL最適化時に交差するパーツ範囲をレイヤーに分割


## split_parts_ranges_into_intersecting_and_non_intersecting_final {#split_parts_ranges_into_intersecting_and_non_intersecting_final}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.2" },
        { label: "1" },
        {
          label:
            "FINAL最適化時にパーツ範囲を交差するものと交差しないものに分割することを許可します"
        }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.1" },
        { label: "1" },
        {
          label:
            "FINAL最適化時にパーツ範囲を交差するものと交差しないものに分割することを許可します"
        }
      ]
    }
  ]}
/>

FINAL最適化時にパーツ範囲を交差するものと交差しないものに分割します


## splitby_max_substrings_includes_remaining_string {#splitby_max_substrings_includes_remaining_string}

<SettingsInfoBlock type='Bool' default_value='0' />

引数 `max_substrings` > 0 を指定した関数 [splitBy\*()](../../sql-reference/functions/splitting-merging-functions.md) が、結果配列の最後の要素に残りの文字列を含めるかどうかを制御します。

設定可能な値:

- `0` - 残りの文字列は結果配列の最後の要素に含まれません。
- `1` - 残りの文字列は結果配列の最後の要素に含まれます。これはSparkの [`split()`](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.split.html) 関数およびPythonの ['string.split()'](https://docs.python.org/3/library/stdtypes.html#str.split) メソッドの動作に相当します。


## stop_refreshable_materialized_views_on_startup {#stop_refreshable_materialized_views_on_startup}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

サーバー起動時に、SYSTEM STOP VIEWSを実行した場合と同様に、リフレッシュ可能なマテリアライズドビューのスケジューリングを防止します。その後、`SYSTEM START VIEWS`または`SYSTEM START VIEW <name>`を使用して手動で開始できます。新しく作成されたビューにも適用されます。リフレッシュ不可能なマテリアライズドビューには影響を与えません。


## storage_file_read_method {#storage_file_read_method}

<SettingsInfoBlock type='LocalFSReadMethod' default_value='pread' />

ストレージファイルからデータを読み取る方法を指定します。`read`、`pread`、`mmap`のいずれかを選択できます。mmap方式はclickhouse-serverには適用されません（clickhouse-local向けです）。


## storage_system_stack_trace_pipe_read_timeout_ms {#storage_system_stack_trace_pipe_read_timeout_ms}

<SettingsInfoBlock type='Milliseconds' default_value='100' />

`system.stack_trace`テーブルをクエリする際に、スレッドから情報を受信するパイプからの読み取りの最大時間。この設定はテスト目的で使用され、ユーザーが変更することは想定されていません。


## stream_flush_interval_ms {#stream_flush_interval_ms}

<SettingsInfoBlock type='Milliseconds' default_value='7500' />

ストリーミングを使用するテーブルにおいて、タイムアウト発生時、またはスレッドが[max_insert_block_size](#max_insert_block_size)行を生成した時に機能します。

デフォルト値は7500です。

値が小さいほど、データがテーブルにフラッシュされる頻度が高くなります。値を低く設定しすぎると、パフォーマンスが低下します。


## stream_like_engine_allow_direct_select {#stream_like_engine_allow_direct_select}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.12" },
        { label: "0" },
        {
          label:
            "デフォルトではKafka/RabbitMQ/FileLogに対する直接的なSELECTを許可しない"
        }
      ]
    }
  ]}
/>

Kafka、RabbitMQ、FileLog、Redis Streams、NATSエンジンに対する直接的なSELECTクエリを許可します。マテリアライズドビューがアタッチされている場合は、この設定が有効になっていてもSELECTクエリは許可されません。


## stream_like_engine_insert_queue {#stream_like_engine_insert_queue}

ストリーム型エンジンが複数のキューから読み取る場合、書き込み時にユーザーは挿入先となるキューを1つ選択する必要があります。Redis StreamsおよびNATSで使用されます。


## stream_poll_timeout_ms {#stream_poll_timeout_ms}

<SettingsInfoBlock type='Milliseconds' default_value='500' />

ストリーミングストレージからのデータポーリング、またはストリーミングストレージへのデータポーリングのタイムアウト。


## system_events_show_zero_values {#system_events_show_zero_values}

<SettingsInfoBlock type='Bool' default_value='0' />

[`system.events`](../../operations/system-tables/events.md)から値が0のイベントを選択できるようにします。

一部の監視システムでは、メトリック値が0であっても、各チェックポイントですべてのメトリック値を渡す必要があります。

設定可能な値:

- 0 — 無効。
- 1 — 有効。

**例**

クエリ

```sql
SELECT * FROM system.events WHERE event='QueryMemoryLimitExceeded';
```

結果

```text
Ok.
```

クエリ

```sql
SET system_events_show_zero_values = 1;
SELECT * FROM system.events WHERE event='QueryMemoryLimitExceeded';
```

結果

```text
┌─event────────────────────┬─value─┬─description───────────────────────────────────────────┐
│ QueryMemoryLimitExceeded │     0 │ クエリのメモリ制限を超えた回数。 │
└──────────────────────────┴───────┴───────────────────────────────────────────────────────┘
```


## table_engine_read_through_distributed_cache {#table_engine_read_through_distributed_cache}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.7" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。テーブルエンジン/テーブル関数（s3、azureなど）経由で分散キャッシュからの読み取りを許可します


## table_function_remote_max_addresses {#table_function_remote_max_addresses}

<SettingsInfoBlock type='UInt64' default_value='1000' />

[remote](../../sql-reference/table-functions/remote.md)関数でパターンから生成されるアドレスの最大数を設定します。

使用可能な値:

- 正の整数


## tcp_keep_alive_timeout {#tcp_keep_alive_timeout}

<SettingsInfoBlock type='Seconds' default_value='290' />

TCPがキープアライブプローブの送信を開始するまでに、接続がアイドル状態である必要がある時間(秒単位)


## temporary_data_in_cache_reserve_space_wait_lock_timeout_milliseconds {#temporary_data_in_cache_reserve_space_wait_lock_timeout_milliseconds}

<SettingsInfoBlock type='UInt64' default_value='600000' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.4" },
        { label: "600000" },
        {
          label:
            "ファイルシステムキャッシュ内の一時データ用の領域予約時におけるキャッシュロックの待機時間"
        }
      ]
    }
  ]}
/>

ファイルシステムキャッシュ内の一時データ用の領域予約時におけるキャッシュロックの待機時間


## temporary_files_buffer_size {#temporary_files_buffer_size}

<SettingsInfoBlock type='UInt64' default_value='1048576' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.10" },
        { label: "1048576" },
        { label: "新しい設定" }
      ]
    }
  ]}
/>

一時ファイル書き込み用のバッファサイズ。バッファサイズを大きくすると、システムコールの回数は減少しますが、メモリ消費量は増加します。


## temporary_files_codec {#temporary_files_codec}

<SettingsInfoBlock type='String' default_value='LZ4' />

ディスク上でのソート操作および結合操作に使用される一時ファイルの圧縮コーデックを設定します。

設定可能な値:

- LZ4 — [LZ4](<https://en.wikipedia.org/wiki/LZ4_(compression_algorithm)>) 圧縮が適用されます。
- NONE — 圧縮は適用されません。


## text_index_use_bloom_filter {#text_index_use_bloom_filter}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "1" }, { label: "新しい設定。" }]
    }
  ]}
/>

テスト目的で、テキストインデックスにおけるブルームフィルターの使用を有効または無効にします。


## throw_if_deduplication_in_dependent_materialized_views_enabled_with_async_insert {#throw_if_deduplication_in_dependent_materialized_views_enabled_with_async_insert}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "1" },
        {
          label:
            "依存マテリアライズドビューでの重複排除は非同期インサートと併用できません。"
        }
      ]
    }
  ]}
/>

`deduplicate_blocks_in_dependent_materialized_views`設定が`async_insert`と共に有効になっている場合、INSERTクエリで例外をスローします。これらの機能は併用できないため、正確性を保証します。


## throw_if_no_data_to_insert {#throw_if_no_data_to_insert}

<SettingsInfoBlock type='Bool' default_value='1' />

空のINSERTを許可または禁止します。デフォルトで有効になっており、空のINSERTに対してエラーをスローします。[`clickhouse-client`](/interfaces/cli)または[gRPCインターフェース](/interfaces/grpc)を使用したINSERTにのみ適用されます。


## throw_on_error_from_cache_on_write_operations {#throw_on_error_from_cache_on_write_operations}

<SettingsInfoBlock type='Bool' default_value='0' />

書き込み操作（INSERT、マージ）時のキャッシュ処理でキャッシュからのエラーを無視します


## throw_on_max_partitions_per_insert_block {#throw_on_max_partitions_per_insert_block}

<SettingsInfoBlock type='Bool' default_value='1' />

`max_partitions_per_insert_block`に到達した際の動作を制御します。

設定可能な値:

- `true` - 挿入ブロックが`max_partitions_per_insert_block`に到達すると、例外が発生します。
- `false` - `max_partitions_per_insert_block`に到達すると、警告がログに記録されます。

:::tip
[`max_partitions_per_insert_block`](/operations/settings/settings#max_partitions_per_insert_block)を変更する際のユーザーへの影響を把握する場合に有用です。
:::


## throw_on_unsupported_query_inside_transaction {#throw_on_unsupported_query_inside_transaction}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='1' />

トランザクション内でサポートされていないクエリが使用された場合に例外をスローする


## timeout_before_checking_execution_speed {#timeout_before_checking_execution_speed}

<SettingsInfoBlock type='Seconds' default_value='10' />

指定された秒数が経過した後、実行速度が遅すぎないこと（`min_execution_speed` 以上であること）を確認します。


## timeout_overflow_mode {#timeout_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

クエリの実行時間が `max_execution_time` を超えた場合、または推定実行時間が `max_estimated_execution_time` を超えた場合の動作を設定します。

設定可能な値:

- `throw`: 例外をスローします(デフォルト)。
- `break`: クエリの実行を停止し、ソースデータが尽きた場合と同様に部分的な結果を返します。


## timeout_overflow_mode_leaf {#timeout_overflow_mode_leaf}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

リーフノードでのクエリ実行時間が `max_execution_time_leaf` を超えた場合の動作を設定します。

設定可能な値:

- `throw`: 例外をスローします(デフォルト)。
- `break`: クエリの実行を停止し、ソースデータが尽きた場合と同様に部分的な結果を返します。


## totals_auto_threshold {#totals_auto_threshold}

<SettingsInfoBlock type='Float' default_value='0.5' />

`totals_mode = 'auto'` のしきい値。
「WITH TOTALS 修飾子」のセクションを参照してください。


## totals_mode {#totals_mode}

<SettingsInfoBlock type='TotalsMode' default_value='after_having_exclusive' />

HAVING句が存在する場合、およびmax_rows_to_group_byとgroup_by_overflow_mode = 'any'が設定されている場合のTOTALSの計算方法を指定します。
詳細は「WITH TOTALS修飾子」のセクションを参照してください。


## trace_profile_events {#trace_profile_events}

<SettingsInfoBlock type='Bool' default_value='0' />

プロファイルイベントの更新ごとに、プロファイルイベント名と増分値とともにスタックトレースを収集し、[trace_log](/operations/system-tables/trace_log)に送信するかどうかを有効または無効にします。

設定可能な値:

- 1 — プロファイルイベントのトレースを有効にします。
- 0 — プロファイルイベントのトレースを無効にします。


## transfer_overflow_mode {#transfer_overflow_mode}

<SettingsInfoBlock type='OverflowMode' default_value='throw' />

データ量がいずれかの制限を超えた場合の動作を設定します。

設定可能な値:

- `throw`: 例外をスローします（デフォルト）。
- `break`: クエリの実行を停止し、ソースデータが尽きた場合と同様に部分的な結果を返します。


## transform_null_in {#transform_null_in}

<SettingsInfoBlock type='Bool' default_value='0' />

[IN](../../sql-reference/operators/in.md)演算子における[NULL](/sql-reference/syntax#null)値の等価性を有効にします。

デフォルトでは、`NULL`は未定義の値を意味するため、`NULL`値を比較することはできません。したがって、`expr = NULL`という比較は常に`false`を返します。この設定を有効にすると、`IN`演算子において`NULL = NULL`は`true`を返すようになります。

設定可能な値:

- 0 — `IN`演算子における`NULL`値の比較は`false`を返します。
- 1 — `IN`演算子における`NULL`値の比較は`true`を返します。

**例**

`null_in`テーブルを考えます:

```text
┌──idx─┬─────i─┐
│    1 │     1 │
│    2 │  NULL │
│    3 │     3 │
└──────┴───────┘
```

クエリ:

```sql
SELECT idx, i FROM null_in WHERE i IN (1, NULL) SETTINGS transform_null_in = 0;
```

結果:

```text
┌──idx─┬────i─┐
│    1 │    1 │
└──────┴──────┘
```

クエリ:

```sql
SELECT idx, i FROM null_in WHERE i IN (1, NULL) SETTINGS transform_null_in = 1;
```

結果:

```text
┌──idx─┬─────i─┐
│    1 │     1 │
│    2 │  NULL │
└──────┴───────┘
```

**関連項目**

- [IN演算子におけるNULL処理](/sql-reference/operators/in#null-processing)


## traverse_shadow_remote_data_paths {#traverse_shadow_remote_data_paths}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        {
          label:
            "system.remote_data_pathsをクエリする際にシャドウディレクトリを走査します。"
        }
      ]
    }
  ]}
/>

system.remote_data_pathsをクエリする際に、実際のテーブルデータに加えて凍結されたデータ(シャドウディレクトリ)を走査します。


## union_default_mode {#union_default_mode}

`SELECT`クエリ結果を結合するモードを設定します。この設定は、`UNION ALL`または`UNION DISTINCT`を明示的に指定せずに[UNION](../../sql-reference/statements/select/union.md)を使用する場合にのみ適用されます。

設定可能な値:

- `'DISTINCT'` — ClickHouseは重複行を削除し、クエリを結合した結果の行を出力します。
- `'ALL'` — ClickHouseは重複行を含む、クエリを結合した結果のすべての行を出力します。
- `''` — ClickHouseは`UNION`と共に使用された場合に例外を生成します。

例については[UNION](../../sql-reference/statements/select/union.md)を参照してください。


## unknown_packet_in_send_data {#unknown_packet_in_send_data}

<SettingsInfoBlock type='UInt64' default_value='0' />

N番目のデータパケットの代わりに未知のパケットを送信する


## update_parallel_mode {#update_parallel_mode}

<SettingsInfoBlock type='UpdateParallelMode' default_value='auto' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "auto" }, { label: "新しい設定" }]
    }
  ]}
/>

並行して実行される更新クエリの動作を決定します。

設定可能な値：

- `sync` - すべての`UPDATE`クエリを順次実行します。
- `auto` - あるクエリで更新される列と別のクエリの式で使用される列との間に依存関係がある`UPDATE`クエリのみを順次実行します。
- `async` - 更新クエリを同期しません。


## update_sequential_consistency {#update_sequential_consistency}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

trueの場合、更新の実行前にパーツのセットが最新バージョンに更新されます。


## use_async_executor_for_materialized_views {#use_async_executor_for_materialized_views}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "24.12" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

マテリアライズドビュークエリの非同期実行およびマルチスレッド実行を使用します。INSERT時のビュー処理を高速化できますが、メモリ消費量が増加します。


## use_cache_for_count_from_files {#use_cache_for_count_from_files}

<SettingsInfoBlock type='Bool' default_value='1' />

テーブル関数 `file`/`s3`/`url`/`hdfs`/`azureBlobStorage` でファイルから行数をカウントする際に、行数のキャッシュを有効にします。

デフォルトで有効です。


## use_client_time_zone {#use_client_time_zone}

<SettingsInfoBlock type='Bool' default_value='0' />

DateTime文字列値の解釈において、サーバーのタイムゾーンではなく、クライアントのタイムゾーンを使用します。


## use_compact_format_in_distributed_parts_names {#use_compact_format_in_distributed_parts_names}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.1" },
        { label: "1" },
        {
          label:
            "Distributedテーブルへの非同期INSERTでデフォルトでコンパクト形式を使用"
        }
      ]
    }
  ]}
/>

`Distributed`エンジンを使用するテーブルへのバックグラウンド（`distributed_foreground_insert`）INSERT時に、ブロックの保存にコンパクト形式を使用します。

設定可能な値:

- 0 — `user[:password]@host:port#default_database`ディレクトリ形式を使用します。
- 1 — `[shard{shard_index}[_replica{replica_index}]]`ディレクトリ形式を使用します。

:::note

- `use_compact_format_in_distributed_parts_names=0`の場合、クラスタ定義の変更はバックグラウンドINSERTに適用されません。
- `use_compact_format_in_distributed_parts_names=1`の場合、クラスタ定義内のノードの順序を変更すると`shard_index`/`replica_index`が変更されるため注意してください。
  :::


## use_concurrency_control {#use_concurrency_control}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.12" },
        { label: "1" },
        { label: "デフォルトで並行性制御を有効化" }
      ]
    }
  ]}
/>

サーバーの並行性制御に従います（グローバルサーバー設定の `concurrent_threads_soft_limit_num` および `concurrent_threads_soft_limit_ratio_to_cores` を参照してください）。無効にした場合、サーバーが過負荷状態であってもより多くのスレッドを使用できるようになります（通常の使用では非推奨であり、主にテスト用途で必要となります）。


## use_hedged_requests {#use_hedged_requests}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "21.9" },
        { label: "1" },
        { label: "Hedged Requests機能をデフォルトで有効化" }
      ]
    }
  ]}
/>

リモートクエリに対するヘッジドリクエストロジックを有効にします。これにより、クエリに対して異なるレプリカとの複数の接続を確立できます。
既存のレプリカとの接続が`hedged_connection_timeout`以内に確立されなかった場合、または`receive_data_timeout`以内にデータが受信されなかった場合に、新しい接続が有効になります。クエリは、空でない進行状況パケット(または`allow_changing_replica_until_first_data_packet`が有効な場合はデータパケット)を最初に送信した接続を使用します。
他の接続はキャンセルされます。`max_parallel_replicas > 1`のクエリがサポートされています。

デフォルトで有効です。

Cloudのデフォルト値: `1`


## use_hive_partitioning {#use_hive_partitioning}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.1" },
        { label: "1" },
        { label: "デフォルトで有効化されました。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "24.8" },
        { label: "0" },
        {
          label:
            "File、URL、S3、AzureBlobStorage、HDFSエンジンでHiveパーティショニングを使用できるようになりました。"
        }
      ]
    }
  ]}
/>

有効にすると、ClickHouseはファイル系テーブルエンジン[File](/sql-reference/table-functions/file#hive-style-partitioning)/[S3](/sql-reference/table-functions/s3#hive-style-partitioning)/[URL](/sql-reference/table-functions/url#hive-style-partitioning)/[HDFS](/sql-reference/table-functions/hdfs#hive-style-partitioning)/[AzureBlobStorage](/sql-reference/table-functions/azureBlobStorage#hive-style-partitioning)のパス内でHive形式のパーティショニング（`/name=value/`）を検出し、クエリ内でパーティションカラムを仮想カラムとして使用できるようにします。これらの仮想カラムは、パーティション化されたパスと同じ名前を持ちますが、先頭に`_`が付きます。


## use_iceberg_metadata_files_cache {#use_iceberg_metadata_files_cache}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.4" }, { label: "1" }, { label: "新しい設定" }]
    }
  ]}
/>

有効にすると、icebergテーブル関数とicebergストレージはicebergメタデータファイルキャッシュを利用できます。

設定可能な値:

- 0 - 無効
- 1 - 有効


## use_iceberg_partition_pruning {#use_iceberg_partition_pruning}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "1" },
        { label: "Icebergパーティションプルーニングをデフォルトで有効化します。" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.1" },
        { label: "0" },
        { label: "Icebergパーティションプルーニングの新しい設定です。" }
      ]
    }
  ]}
/>

IcebergテーブルでIcebergパーティションプルーニングを使用します


## use_index_for_in_with_subqueries {#use_index_for_in_with_subqueries}

<SettingsInfoBlock type='Bool' default_value='1' />

IN演算子の右辺にサブクエリまたはテーブル式がある場合、インデックスの使用を試みます。


## use_index_for_in_with_subqueries_max_values {#use_index_for_in_with_subqueries_max_values}

<SettingsInfoBlock type='UInt64' default_value='0' />

フィルタリングにテーブルインデックスを使用する際の、IN演算子の右辺における集合の最大サイズです。大規模なクエリで追加のデータ構造を準備する際に発生するパフォーマンスの低下とメモリ使用量の増加を回避できます。0は制限なしを意味します。


## use_join_disjunctions_push_down {#use_join_disjunctions_push_down}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.10" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

JOIN条件のOR接続された部分を対応する入力側にプッシュダウンすることを有効にします（「部分的プッシュダウン」）。
これにより、ストレージエンジンがより早期にフィルタリングを行うことができ、読み取るデータ量を削減できます。
この最適化はセマンティクスを保持し、各トップレベルのOR分岐がターゲット側に対して少なくとも1つの決定論的述語を提供する場合にのみ適用されます。


## use_legacy_to_time {#use_legacy_to_time}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "1" },
        {
          label:
            "新しい設定。toTimeWithFixedDateとして動作する従来のtoTime関数ロジックの使用を可能にします。"
        }
      ]
    }
  ]}
/>

有効にすると、日時を特定の固定日付に変換しつつ時刻を保持する従来のtoTime関数を使用できます。
無効の場合は、異なる型のデータをTime型に変換する新しいtoTime関数を使用します。
従来の関数はtoTimeWithFixedDateとして常にアクセス可能です。


## use_page_cache_for_disks_without_file_cache {#use_page_cache_for_disks_without_file_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.3" },
        { label: "0" },
        { label: "ユーザースペースページキャッシュを追加" }
      ]
    }
  ]}
/>

ファイルシステムキャッシュが有効になっていないリモートディスクに対して、ユーザースペースページキャッシュを使用します。


## use_page_cache_with_distributed_cache {#use_page_cache_with_distributed_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.3" }, { label: "0" }, { label: "New setting" }]
    }
  ]}
/>

分散キャッシュ使用時にユーザー空間ページキャッシュを使用します。


## use_paimon_partition_pruning {#use_paimon_partition_pruning}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

Paimonテーブル関数でPaimonパーティションプルーニングを使用する


## use_query_cache {#use_query_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

有効にすると、`SELECT`クエリで[クエリキャッシュ](../query-cache.md)を利用できるようになります。パラメータ[enable_reads_from_query_cache](#enable_reads_from_query_cache)および[enable_writes_to_query_cache](#enable_writes_to_query_cache)により、キャッシュの使用方法をより詳細に制御できます。

設定可能な値:

- 0 - 無効
- 1 - 有効


## use_query_condition_cache {#use_query_condition_cache}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.4" },
        { label: "1" },
        { label: "新しい最適化" }
      ]
    },
    {
      id: "row-2",
      items: [{ label: "25.3" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

[クエリ条件キャッシュ](/operations/query-condition-cache)を有効にします。このキャッシュは、`WHERE`句の条件を満たさないデータパート内のグラニュールの範囲を保存し、この情報を後続のクエリのための一時的なインデックスとして再利用します。

設定可能な値:

- 0 - 無効
- 1 - 有効


## use_roaring_bitmap_iceberg_positional_deletes {#use_roaring_bitmap_iceberg_positional_deletes}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

Iceberg位置削除にRoaring Bitmapを使用します。


## use_skip_indexes {#use_skip_indexes}

<SettingsInfoBlock type='Bool' default_value='1' />

クエリ実行時にデータスキップインデックスを使用します。

設定可能な値:

- 0 — 無効
- 1 — 有効


## use_skip_indexes_if_final {#use_skip_indexes_if_final}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "1" },
        { label: "設定のデフォルト値の変更" }
      ]
    }
  ]}
/>

FINAL修飾子を使用したクエリ実行時に、スキップインデックスを使用するかどうかを制御します。

スキップインデックスは最新データを含む行（グラニュール）を除外する可能性があり、FINAL修飾子を使用したクエリで不正確な結果を招く恐れがあります。この設定を有効にすると、FINAL修飾子使用時でもスキップインデックスが適用され、パフォーマンスが向上する可能性がありますが、最新の更新を見逃すリスクがあります。この設定は、use_skip_indexes_if_final_exact_mode設定（デフォルトは有効）と同期して有効にする必要があります。

設定可能な値:

- 0 — 無効。
- 1 — 有効。


## use_skip_indexes_if_final_exact_mode {#use_skip_indexes_if_final_exact_mode}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.6" },
        { label: "1" },
        { label: "設定のデフォルト値の変更" }
      ]
    },
    {
      id: "row-2",
      items: [
        { label: "25.5" },
        { label: "0" },
        {
          label:
            "スキップインデックスを使用したFINALクエリが正確な結果を返すために、この設定が導入されました"
        }
      ]
    }
  ]}
/>

FINALモディファイアを使用したクエリ実行時に正確な結果を返すために、スキップインデックスによって返されるグラニュールを新しいパートで展開するかどうかを制御します。

スキップインデックスを使用すると、最新のデータを含む行(グラニュール)が除外され、不正確な結果につながる可能性があります。この設定を有効にすると、スキップインデックスによって返される範囲と重複する新しいパートをスキャンすることで、正確な結果が返されることを保証できます。この設定は、スキップインデックスの参照に基づく近似結果がアプリケーションで許容される場合にのみ無効にしてください。

使用可能な値:

- 0 — 無効。
- 1 — 有効。


## use_skip_indexes_on_data_read {#use_skip_indexes_on_data_read}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.9" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

データ読み取り時にデータスキップインデックスの使用を有効にします。

有効にすると、スキップインデックスはクエリ実行開始前に事前分析されるのではなく、各データグラニュールの読み取り時に動的に評価されます。これによりクエリの起動レイテンシを削減できます。

使用可能な値:

- 0 — 無効。
- 1 — 有効。


## use_statistics_cache {#use_statistics_cache}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

クエリで統計キャッシュを使用して、全パートの統計読み込みのオーバーヘッドを回避します


## use_structure_from_insertion_table_in_table_functions {#use_structure_from_insertion_table_in_table_functions}

<SettingsInfoBlock type='UInt64' default_value='2' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "22.11" },
        { label: "2" },
        {
          label:
            "テーブル関数における挿入先テーブルの構造使用を改善"
        }
      ]
    }
  ]}
/>

データからのスキーマ推論の代わりに挿入先テーブルの構造を使用します。設定可能な値: 0 - 無効、1 - 有効、2 - 自動


## use_text_index_dictionary_cache {#use_text_index_dictionary_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

デシリアライズされたテキストインデックスディクショナリブロックのキャッシュを使用するかどうかを指定します。
テキストインデックスディクショナリブロックキャッシュを使用すると、大量のテキストインデックスクエリを処理する際のレイテンシを大幅に削減し、スループットを向上させることができます。


## use_text_index_header_cache {#use_text_index_header_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

デシリアライズされたテキストインデックスヘッダーのキャッシュを使用するかどうかを指定します。
テキストインデックスヘッダーキャッシュを使用すると、大量のテキストインデックスクエリを処理する際のレイテンシを大幅に削減し、スループットを向上させることができます。


## use_text_index_postings_cache {#use_text_index_postings_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.11" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

デシリアライズされたテキストインデックスのポスティングリストのキャッシュを使用するかどうかを指定します。
テキストインデックスのポスティングキャッシュを使用すると、大量のテキストインデックスクエリを処理する際のレイテンシを大幅に削減し、スループットを向上させることができます。


## use_uncompressed_cache {#use_uncompressed_cache}

<SettingsInfoBlock type='Bool' default_value='0' />

非圧縮ブロックのキャッシュを使用するかどうかを指定します。0または1を指定します。デフォルトは0(無効)です。
非圧縮キャッシュ(MergeTreeファミリーのテーブルのみ対象)を使用すると、多数の短いクエリを処理する際にレイテンシを大幅に削減し、スループットを向上させることができます。頻繁に短いリクエストを送信するユーザーに対してこの設定を有効にしてください。また、[uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size)設定パラメータ(設定ファイルでのみ設定)にも注意してください。これは非圧縮キャッシュブロックのサイズを指定します。デフォルトは8 GiBです。非圧縮キャッシュは必要に応じて充填され、最も使用頻度の低いデータが自動的に削除されます。

ある程度大量のデータ(100万行以上)を読み取るクエリの場合、真に小規模なクエリのためのスペースを確保するために、非圧縮キャッシュは自動的に無効化されます。つまり、'use_uncompressed_cache'設定を常に1に設定しておくことができます。


## use_variant_as_common_type {#use_variant_as_common_type}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.1" },
        { label: "0" },
        {
          label: "共通型が存在しない場合にif/multiIfでVariantの使用を許可"
        }
      ]
    }
  ]}
/>

引数の型に共通型が存在しない場合、[if](../../sql-reference/functions/conditional-functions.md/#if)/[multiIf](../../sql-reference/functions/conditional-functions.md/#multiIf)/[array](../../sql-reference/functions/array-functions.md)/[map](../../sql-reference/functions/tuple-map-functions.md)関数の結果型として`Variant`型の使用を許可します。

例:

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(if(number % 2, number, range(number))) as variant_type FROM numbers(1);
SELECT if(number % 2, number, range(number)) as variant FROM numbers(5);
```

```text
┌─variant_type───────────────────┐
│ Variant(Array(UInt64), UInt64) │
└────────────────────────────────┘
┌─variant───┐
│ []        │
│ 1         │
│ [0,1]     │
│ 3         │
│ [0,1,2,3] │
└───────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(multiIf((number % 4) = 0, 42, (number % 4) = 1, [1, 2, 3], (number % 4) = 2, 'Hello, World!', NULL)) AS variant_type FROM numbers(1);
SELECT multiIf((number % 4) = 0, 42, (number % 4) = 1, [1, 2, 3], (number % 4) = 2, 'Hello, World!', NULL) AS variant FROM numbers(4);
```

```text
─variant_type─────────────────────────┐
│ Variant(Array(UInt8), String, UInt8) │
└──────────────────────────────────────┘

┌─variant───────┐
│ 42            │
│ [1,2,3]       │
│ Hello, World! │
│ ᴺᵁᴸᴸ          │
└───────────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(array(range(number), number, 'str_' || toString(number))) as array_of_variants_type from numbers(1);
SELECT array(range(number), number, 'str_' || toString(number)) as array_of_variants FROM numbers(3);
```

```text
┌─array_of_variants_type────────────────────────┐
│ Array(Variant(Array(UInt64), String, UInt64)) │
└───────────────────────────────────────────────┘

┌─array_of_variants─┐
│ [[],0,'str_0']    │
│ [[0],1,'str_1']   │
│ [[0,1],2,'str_2'] │
└───────────────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(map('a', range(number), 'b', number, 'c', 'str_' || toString(number))) as map_of_variants_type from numbers(1);
SELECT map('a', range(number), 'b', number, 'c', 'str_' || toString(number)) as map_of_variants FROM numbers(3);
```

```text
┌─map_of_variants_type────────────────────────────────┐
│ Map(String, Variant(Array(UInt64), String, UInt64)) │
└─────────────────────────────────────────────────────┘

┌─map_of_variants───────────────┐
│ {'a':[],'b':0,'c':'str_0'}    │
│ {'a':[0],'b':1,'c':'str_1'}   │
│ {'a':[0,1],'b':2,'c':'str_2'} │
└───────────────────────────────┘
```


## use_with_fill_by_sorting_prefix {#use_with_fill_by_sorting_prefix}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "23.5" },
        { label: "1" },
        {
          label:
            "ORDER BY句でWITH FILL列より前に配置された列がソートプレフィックスを形成します。ソートプレフィックスの値が異なる行は、それぞれ独立して補完されます"
        }
      ]
    }
  ]}
/>

ORDER BY句でWITH FILL列より前に配置された列がソートプレフィックスを形成します。ソートプレフィックスの値が異なる行は、それぞれ独立して補完されます


## validate_enum_literals_in_operators {#validate_enum_literals_in_operators}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.1" }, { label: "0" }, { label: "新しい設定" }]
    }
  ]}
/>

有効にすると、`IN`、`NOT IN`、`==`、`!=` などの演算子で使用される列挙型リテラルが列挙型として妥当かどうかを検証し、リテラルが有効な列挙型の値でない場合は例外をスローします。


## validate_mutation_query {#validate_mutation_query}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.11" },
        { label: "1" },
        { label: "ミューテーションクエリをデフォルトで検証する新しい設定。" }
      ]
    }
  ]}
/>

ミューテーションクエリを受け入れる前に検証します。ミューテーションはバックグラウンドで実行されるため、無効なクエリを実行するとミューテーションが停止し、手動での介入が必要になります。

後方互換性のないバグが発生した場合にのみ、この設定を変更してください。


## validate_polygons {#validate_polygons}

<SettingsInfoBlock type='Bool' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "20.4" },
        { label: "1" },
        {
          label:
            "pointInPolygon関数において、誤った結果を返す可能性がある代わりに、ポリゴンが無効な場合はデフォルトで例外をスローするようになりました"
        }
      ]
    }
  ]}
/>

ポリゴンが自己交差または自己接線の場合に、[pointInPolygon](/sql-reference/functions/geo/coordinates#pointinpolygon)関数で例外をスローするかどうかを有効または無効にします。

設定可能な値:

- 0 — 例外のスローが無効になります。`pointInPolygon`は無効なポリゴンを受け入れ、誤った結果を返す可能性があります。
- 1 — 例外のスローが有効になります。


## vector_search_filter_strategy {#vector_search_filter_strategy}

<SettingsInfoBlock type='VectorSearchFilterStrategy' default_value='auto' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.5" }, { label: "auto" }, { label: "新しい設定" }]
    }
  ]}
/>

ベクトル検索クエリにWHERE句が含まれる場合、この設定は、WHERE句を先に評価するか(プレフィルタリング)、ベクトル類似度インデックスを先にチェックするか(ポストフィルタリング)を決定します。設定可能な値:

- 'auto' - ポストフィルタリング(正確なセマンティクスは将来変更される可能性があります)。
- 'postfilter' - ベクトル類似度インデックスを使用して最近傍を特定し、その後他のフィルタを適用します
- 'prefilter' - 他のフィルタを先に評価し、その後ブルートフォース検索を実行して近傍を特定します。


## vector_search_index_fetch_multiplier {#vector_search_index_fetch_multiplier}

**エイリアス**: `vector_search_postfilter_multiplier`

<SettingsInfoBlock type='Float' default_value='1' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "25.8" },
        { label: "1" },
        { label: "設定 'vector_search_postfilter_multiplier' のエイリアス" }
      ]
    }
  ]}
/>

ベクトル類似度インデックスから取得する最近傍の数に、この数値を乗算します。他の述語を用いたポストフィルタリング時、または設定 'vector_search_with_rescoring = 1' の場合にのみ適用されます。


## vector_search_with_rescoring {#vector_search_with_rescoring}

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "新しい設定。" }]
    }
  ]}
/>

ベクトル類似性インデックスを使用するクエリに対してClickHouseが再スコアリングを実行するかどうかを指定します。
再スコアリングを行わない場合、ベクトル類似性インデックスは最適な一致を含む行を直接返します。
再スコアリングを行う場合、行はグラニュールレベルまで拡張され、グラニュール内のすべての行が再度チェックされます。
ほとんどの状況において、再スコアリングは精度をわずかに向上させるのみですが、ベクトル検索クエリのパフォーマンスを著しく低下させます。
注意: 再スコアリングなしで並列レプリカを有効にして実行されたクエリは、再スコアリングにフォールバックする場合があります。


## wait_changes_become_visible_after_commit_mode {#wait_changes_become_visible_after_commit_mode}

<ExperimentalBadge />

<SettingsInfoBlock
  type='TransactionsWaitCSNMode'
  default_value='wait_unknown'
/>

コミットされた変更が最新のスナップショットで実際に可視になるまで待機します


## wait_for_async_insert {#wait_for_async_insert}

<SettingsInfoBlock type='Bool' default_value='1' />

trueの場合、非同期挿入の処理完了を待機します


## wait_for_async_insert_timeout {#wait_for_async_insert_timeout}

<SettingsInfoBlock type='Seconds' default_value='120' />

非同期挿入の処理待機のタイムアウト


## wait_for_window_view_fire_signal_timeout {#wait_for_window_view_fire_signal_timeout}

<ExperimentalBadge />

<SettingsInfoBlock type='Seconds' default_value='10' />

イベント時間処理においてウィンドウビューの起動シグナルを待機するタイムアウト


## window_view_clean_interval {#window_view_clean_interval}

<ExperimentalBadge />

<SettingsInfoBlock type='Seconds' default_value='60' />

古いデータを解放するためのウィンドウビューのクリーンアップ間隔（秒単位）。


## window_view_heartbeat_interval {#window_view_heartbeat_interval}

<ExperimentalBadge />

<SettingsInfoBlock type='Seconds' default_value='15' />

ウォッチクエリが稼働中であることを示すハートビート間隔(秒単位)。


## workload {#workload}

<SettingsInfoBlock type='String' default_value='default' />

リソースアクセスに使用するワークロードの名前


## write_full_path_in_iceberg_metadata {#write_full_path_in_iceberg_metadata}

<ExperimentalBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.8" }, { label: "0" }, { label: "New setting." }]
    }
  ]}
/>

Icebergメタデータファイルに完全なパス（s3://を含む）を書き込みます。


## write_through_distributed_cache {#write_through_distributed_cache}

<CloudOnlyBadge />

<SettingsInfoBlock type='Bool' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [
        { label: "24.10" },
        { label: "0" },
        { label: "ClickHouse Cloud用の設定" }
      ]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。分散キャッシュへの書き込みを許可します（S3への書き込みも分散キャッシュによって実行されます）


## write_through_distributed_cache_buffer_size {#write_through_distributed_cache_buffer_size}

<CloudOnlyBadge />

<SettingsInfoBlock type='UInt64' default_value='0' />

<VersionHistory
  rows={[
    {
      id: "row-1",
      items: [{ label: "25.7" }, { label: "0" }, { label: "新しいクラウド設定" }]
    }
  ]}
/>

ClickHouse Cloudでのみ有効です。ライトスルー分散キャッシュのバッファサイズを設定します。0の場合、分散キャッシュが存在しない場合に使用されるバッファサイズが使用されます。


## zstd_window_log_max {#zstd_window_log_max}

<SettingsInfoBlock type='Int64' default_value='0' />

ZSTDの最大ウィンドウログを選択できます（MergeTreeファミリーでは使用されません）
