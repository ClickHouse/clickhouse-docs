---
slug: '/academic_overview'
title: 'アーキテクチャ概要'
description: '2024年のVLDB論文のドキュメント版'
keywords: ['アーキテクチャ']
---

import useBrokenLinks from "@docusaurus/useBrokenLinks";
import image_01 from '@site/static/images/managing-data/core-concepts/_vldb2024_1_Figure_0.png'
import image_02 from '@site/static/images/managing-data/core-concepts/_vldb2024_2_Figure_0.png'
import image_03 from '@site/static/images/managing-data/core-concepts/_vldb2024_2_Figure_5.png'
import image_04 from '@site/static/images/managing-data/core-concepts/_vldb2024_3_Figure_7.png'
import image_05 from '@site/static/images/managing-data/core-concepts/_vldb2024_4_Figure_6.png'
import image_06 from '@site/static/images/managing-data/core-concepts/_vldb2024_5_Figure_8.png'
import image_07 from '@site/static/images/managing-data/core-concepts/_vldb2024_6_Figure_0.png'
import image_08 from '@site/static/images/managing-data/core-concepts/_vldb2024_7_Figure_1.png'
import image_09 from '@site/static/images/managing-data/core-concepts/_vldb2024_8_Figure_7.png'
import image_10 from '@site/static/images/managing-data/core-concepts/_vldb2024_10_Figure_14.png'
import image_11 from '@site/static/images/managing-data/core-concepts/_vldb2024_10_Figure_0.png'
import image_12 from '@site/static/images/managing-data/core-concepts/_vldb2024_10_Figure_12.png'
import image_13 from '@site/static/images/managing-data/core-concepts/_vldb2024_10_Figure_13.png'

<!-- needed as docusaurus cannot resolve links to span ids, we need a custom span -->
export function Anchor(props) {
    useBrokenLinks().collectAnchor(props.id);
    return <span style={{scrollMarginTop: "var(--ifm-navbar-height)"}} {...props}/>;
}

This is the web version of our [VLDB 2024 scientific paper](https://www.vldb.org/pvldb/vol17/p3731-schulze.pdf). We also [blogged](https://clickhouse.com/blog/first-clickhouse-research-paper-vldb-lightning-fast-analytics-for-everyone) about its background and journey, and recommend watching the VLDB 2024 presentation by ClickHouse CTO and creator, Alexey Milovidov:

<iframe width="768" height="432" src="https://www.youtube.com/embed/7QXKBKDOkJE?si=5uFerjqPSXQWqDkF" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
## ABSTRACT {#abstract}

過去数十年の間に、ストレージおよび分析されるデータの量は指数関数的に増加しました。業種やセクターにわたる企業は、このデータを利用して製品を改善し、パフォーマンスを評価し、ビジネスクリティカルな意思決定を行うことに依存し始めています。しかし、データのボリュームがインターネット規模になっていく中で、企業は歴史的データと新しいデータをコスト効率的かつスケーラブルな方法で管理し、高い同時クエリ数を使用してリアルタイムのレイテンシ（使用ケースによっては1秒未満）を期待しつつ分析しなければなりません。

この論文では、ペタバイト規模のデータセットに対して高性能な分析を目的として設計された人気のオープンソースOLAPデータベースであるClickHouseの概要を紹介します。そのストレージレイヤーは、従来のログ構造マージ（LSM）ツリーに基づくデータ形式と、バックグラウンドでの歴史的データの継続的変換（集約やアーカイブなど）を組み合わせたものです。クエリは便利なSQLダイアレクトで書かれ、最先端のベクトル化されたクエリ実行エンジンによって処理され、オプションでコードのコンパイルが行われます。ClickHouseは、クエリ内で無関係なデータを評価するのを避けるために、積極的にプルーニング技術を使用します。他のデータ管理システムは、テーブル関数、テーブルエンジン、またはデータベースエンジンレベルで統合できます。実際のベンチマークから、ClickHouseは市場で最も高速な分析データベースのひとつであることが示されています。
## 1 INTRODUCTION  {#1-introduction}

この論文では、数兆行と数百カラムを対象とした高性能分析クエリ用に設計された列指向OLAPデータベースであるClickHouseを説明します。ClickHouseは[2009年に](https://clickhou.se/evolution)ウェブスケールのログファイルデータのフィルタと集約演算子として始まり、2016年にオープンソースとして公開されました。[Figure 1](#page-1-0)は、この論文で説明される主要な機能がClickHouseに導入された時期を示しています。

ClickHouseは、現代の分析データ管理の5つの主要な課題に対応するように設計されています。

1. **高い取り込みレートを持つ巨大データセット**。ウェブ分析、金融、電子商取引などの業界における多くのデータ駆動型アプリケーションは、大量かつ継続的に増加するデータ量が特徴です。巨大データセットを扱うために、分析データベースは効率的なインデクシングと圧縮戦略を提供するだけでなく、単一のサーバーが数十テラバイトのストレージに制限されているため、複数のノード（スケールアウト）にデータを分散できる必要があります。さらに、最近のデータは歴史的データよりもリアルタイムの洞察にとってはるかに重要です。このため、分析データベースは、新しいデータを一貫して高いレートでまたはバーストで取り込む能力が必要であり、同時にパラレル報告クエリを遅延させずに歴史データを常に「優先度を下げる」必要があります（e.g. 集約、アーカイブ等）。

2. **低レイテンシを期待する多数の同時クエリ**。クエリは一般的に、アドホック（e.g. 探索的データ分析）または定期的（e.g. 定期的なダッシュボードクエリ）に分類できます。使用ケースがインタラクティブであればあるほど、クエリのレイテンシは低くなることが期待され、これがクエリの最適化や実行において課題を引き起こします。定期的なクエリは、ワークロードに合わせて物理データベースレイアウトを適応させる機会も提供します。その結果、データベースは、頻繁に実行されるクエリを最適化できるプルーニング技術を提供する必要があります。クエリの優先度に応じて、データベースはCPU、メモリ、ディスク、およびネットワークI/Oなどの共有システムリソースへの平等または優先的なアクセスを保証しなければなりません。

3. **多様なデータストア、ストレージ場所、およびフォーマット**。既存のデータアーキテクチャと統合するために、最新の分析データベースは、任意のシステム、場所、またはフォーマットで外部データを読み書きする高いオープン性を示すことが求められます。

4. **パフォーマンスのインストロスペクションをサポートする便利なクエリ言語**。OLAPデータベースの実際の使用は、追加の「ソフト」要件を示します。例えば、特異なプログラミング言語の代わりに、ユーザーはしばしばネストされたデータ型と幅広い通常の集約およびウィンドウ関数を使用して、表現力豊かなSQLダイアレクトでデータベースとインターフェースを持ちたいと考えます。分析データベースはまた、システムまたは個々のクエリのパフォーマンスを分析するための洗練されたツールも提供すべきです。

5. **業界標準の堅牢性と多様なデプロイ**。コモディティハードウェアは信頼性が低いため、データベースはノード障害に対する堅牢性のためのデータレプリケーションを提供しなければなりません。また、データベースは古いラップトップから強力なサーバーまで、あらゆるハードウェアで動作する必要があります。最後に、JVMベースのプログラムでガベージコレクションのオーバーヘッドを避け、ベアメタルパフォーマンス（e.g. SIMD）を可能にするために、データベースはターゲットプラットフォーム向けのネイティブバイナリとしてデプロイされるのが理想的です。

<Anchor id="page-1-0"/><img src={image_01}/>

Figure 1: ClickHouseのタイムライン。
## 2 ARCHITECTURE {#2-architecture}

<Anchor id="page-2-0"/><img src={image_02}/>

Figure 2: ClickHouseデータベースエンジンの高レベルアーキテクチャ。

[Figure 2](#page-2-0)に示されているように、ClickHouseエンジンは3つの主要な層に分かれています：クエリ処理層（[Section 4](#page-6-0)で説明）、ストレージ層（[Section 3](#page-1-1)）、および統合層（[Section 5](#page-9-0)）。これに加え、アクセス層はユーザーセッションを管理し、異なるプロトコルを介してアプリケーションと通信します。スレッド処理、キャッシング、ロールベースのアクセス制御、バックアップ、および継続的監視のための独立したコンポーネントがあります。ClickHouseは、C++で構築され、依存関係のない単一の静的リンクバイナリとして提供されます。

クエリ処理は、受信したクエリの解析、論理および物理クエリプランの構築と最適化、実行という従来のパラダイムに従います。ClickHouseは、MonetDB/X100 [\[11\]](#page-12-0)と類似のベクトル化された実行モデルを使用しており、機会主義的なコードコンパイル [\[53\]](#page-13-0) と組み合わせています。クエリは、機能が豊富なSQLダイアレクトで記述、PRQL [\[76\]](#page-13-1)、またはKustoのKQL [\[50\]](#page-13-2)で処理できます。

ストレージ層は、テーブルデータの形式と場所をカプセル化した異なるテーブルエンジンで構成されています。テーブルエンジンは、3つのカテゴリに分類されます：最初のカテゴリは、ClickHouseでの主要な永続性形式を表すMergeTree*エンジンのファミリーです。LSMツリー [\[60\]](#page-13-3)のアイデアに基づき、テーブルは横方向にソートされたパーツに分割され、バックグラウンドプロセスによって連続的にマージされます。個々のMergeTree*テーブルエンジンは、その入力パーツから行を合わせる方法において異なります。例えば、行は集約されるか、古くなった場合は置き換えられます。

2番目のカテゴリは、クエリ実行を高速化または分散するために使用される特別な目的のテーブルエンジンです。このカテゴリには、内部または外部データソースに対して定期的に実行されるクエリの結果をキャッシュする辞書と呼ばれるメモリ内のキー値テーブルエンジンが含まれます。[辞書](https://clickhou.se/dictionaries)は、データの鮮度が優先されるシナリオで、アクセスレイテンシを大幅に低下させます。他の特別目的のテーブルエンジンの例には、テンポラリーテーブル用の純粋なメモリ内エンジンや、透明なデータシャーディングのための分散テーブルエンジンが含まれます。

3番目のカテゴリのテーブルエンジンは、関係データベース（e.g. PostgreSQL、MySQL）、パブリッシュ/サブスクライブシステム（e.g. Kafka、RabbitMQ [\[24\]](#page-12-1)）、またはキー/値ストア（e.g. Redis）との双方向データ交換のための仮想テーブルエンジンです。仮想エンジンは、データレイク（e.g. Iceberg、DeltaLake、Hudi [\[36\]](#page-12-2)）やオブジェクトストレージ内のファイル（e.g. AWS S3、Google GCP）とも対話できます。

ClickHouseは、スケーラビリティと可用性のために、複数のクラスターノードにわたるテーブルのシャーディングとレプリケーションをサポートしています。シャーディングは、シャーディング式に従ってテーブルを一連のテーブルシャードに分割します。各シャードは独立したテーブルであり、通常は異なるノードに配置されています。クライアントは、シャードに直接読み書きでき、つまりそれらを別々のテーブルとして扱うことができ、あるいはすべてのテーブルシャードのグローバルビューを提供する分散特別テーブルエンジンも使用できます。シャーディングの主な目的は、個々のノードの容量を超えるデータセットを処理することです（通常は数十テラバイトのデータ）。シャーディングの別の用途は、テーブルの読み書き負荷を複数のノードに分散させ、つまり負荷分散を行うことです。それとは別に、シャードはノード障害に対する耐障害性のために複数のノードに複製できます。このために、各Merge-Tree*テーブルエンジンには対応するReplicatedMergeTree*エンジンがあり、Raftコンセンサスに基づくマルチマスター調整方式を利用します [\[59\]](#page-13-4) （Apache Zookeeperの代替品としてC++で書かれた[Keeper](https://clickhou.se/keeper)に実装されています）を利用して、各シャードが常に設定可能な数のレプリカを持つことを保証します。[Section 3.6](#page-5-0)では、レプリケーションメカニズムについて詳しく説明します。例えば、[Figure 2](#page-2-0)は、2つのシャードがあり、各シャードが2つのノードにレプリケートされるテーブルを示しています。

最後に、ClickHouseデータベースエンジンは、オンプレミス、クラウド、スタンドアロン、またはプロセス内モードで操作できます。オンプレミスモードでは、ユーザーはClickHouseを単一のサーバーまたは複数のノードクラスタとしてローカルにセットアップし、シャーディングおよび/またはレプリケーションを行います。クライアントは、ネイティブ、MySQL、PostgreSQLのバイナリワイヤプロトコル、またはHTTP REST APIを介してデータベースと通信します。クラウドモードは、完全に管理され、自動スケーリングされるDBaaS提供のClickHouse Cloudが含まれます。この論文はオンプレミスモードに焦点を当てていますが、ClickHouse Cloudのアーキテクチャを次回の発表で説明する予定です。[スタンドアロンモード](https://clickhou.se/local-fastest-tool)では、ClickHouseをファイルの分析と変換のためのコマンドラインユーティリティに変えることができ、catやgrepのようなUnixツールに対するSQLベースの代替手段となります。この設定には事前の構成が不要ですが、スタンドアロンモードは単一のサーバーに制限されています。最近、Jupyterノートブック [\[37\]](#page-12-4) やPandasデータフレーム [\[61\]](#page-13-5)のようなインタラクティブなデータ分析使用ケースのために、chDBと呼ばれるプロセス内モードが開発されました [\[15\]](#page-12-3)。DuckDB [\[67\]](#page-13-6)からインスパイアを受けて、[chDB](https://clickhou.se/chdb-rocket-engine) はClickHouseをホストプロセスに高性能OLAPエンジンとして組み込みます。他のモードと比較して、これにより、データベースエンジンとアプリケーション間でソースおよび結果データを効率良く渡すことが可能になり、同じアドレス空間内で実行されます。
## <Anchor id="page-1-1"/>3 STORAGE LAYER {#3-storage-layer}

このセクションでは、ClickHouseのネイティブストレージ形式としてのMergeTree*テーブルエンジンについて説明します。ディスク上の表現を説明し、ClickHouseにおける3つのデータプルーニング技術について議論します。その後、同時挿入に影響を与えずにデータを継続的に変換するためのマージ戦略を紹介します。最後に、更新や削除がどのように実装されているか、データの重複排除、データレプリケーション、ACID準拠について説明します。
### <Anchor id="page-2-2"/>3.1 On-Disk Format {#3-1-on-disk-format}

MergeTree*テーブルエンジンの各テーブルは、不変のテーブルパーツのコレクションとして整理されています。パートは、行のセットがテーブルに挿入されるたびに作成されます。パーツは自己完結型であり、追加の中央カタログのルックアップなしに、その内容を解釈するために必要なすべてのメタデータを含みます。テーブルごとにパーツの数を低く保つために、バックグラウンドマージジョブが定期的に複数の小さなパーツを結合して、設定可能なパーツサイズに達するまで大きなパーツにします（デフォルトは150 GB）。パーツはテーブルの主キー列によってソートされているため（[Section 3.2](#page-3-0)参照）、効率的なk-wayマージソート [\[40\]](#page-12-5)がマージに使用されます。ソースパーツは非アクティブとしてマークされ、最終的に参照カウントがゼロ（すなわち、もうそれらから読み取るクエリがない）になると削除されます。

行は二つのモードで挿入できます：同期挿入モードでは、各INSERT文が新しいパートを作成し、テーブルに追加します。マージのオーバーヘッドを最小限に抑えるために、データベースクライアントは一度に例として20,000行を一括で挿入することが奨励されます。しかし、クライアント側のバッチ処理によって引き起こされる遅延は、データをリアルタイムで分析する必要がある場合にはしばしば受け入れられません。例えば、可観測性の使用ケースは、通常、数千のモニタリングエージェントが小さなイベントおよびメトリクスデータを継続的に送信することが含まれます。このようなシナリオでは、ClickHouseが複数の受信INSERTからの行を同じテーブルにバッファリングし、バッファサイズが設定可能なしきい値を超えるかタイムアウトが期限切れになるまで新しいパートを作成しない非同期挿入モードを利用できます。

<Anchor id="page-2-1"/><img src={image_03}/>

Figure 3: MergeTree*-エンジンテーブルの挿入とマージ。

[Figure 3](#page-2-1)は、MergeTree*-エンジンテーブルへの4つの同期および2つの非同期挿入を示しています。2つのマージによって、アクティブなパーツの数は最初の5から2に減少しました。

LSMツリー [\[58\]](#page-13-7)およびそれらのさまざまなデータベースにおける実装 [\[13,](#page-12-6) [26,](#page-12-7) [56\]](#page-13-8) と比較して、ClickHouseはすべてのパーツを等しく扱い、階層を形成しません。その結果、マージの制限は同じレベルのパーツに留まらなくなります。これはパーツの暗黙の時間的順序付けも放棄するため、トゥームストーンに基づく更新および削除の代替メカニズムが必要です（[Section 3.4](#page-4-0)参照）。ClickHouseは、挿入をディスクに直接書き込みますが、他のLSMツリーに基づくストアは通常、先行書き込みログを使用します（[Section 3.7](#page-5-1)参照）。

一つのパートはディスク上のディレクトリに対応し、各カラムのための1つのファイルを含みます。最適化として、小さなパート（デフォルトでは10 MB未満）のカラムは、読み書きの空間的局所性を高めるために、単一のファイルに連続して保存されます。パートの行はさらに8192のレコードのグループに論理的に分割され、これは「グラニュール」と呼ばれます。グラニュールは、ClickHouseにおけるスキャンおよびインデックスルックアップオペレーターによって処理される最小の分割不可能なデータユニットを表します。ただし、ディスク上のデータの読み取りおよび書き込みは、グラニュールレベルではなく、カラム内の隣接するグラニュールを結合するブロックの粒度で行われます。新しいブロックは設定可能なバイトサイズごとに形成されます（デフォルトは1 MB）、すなわち、ブロック内のグラニュールの数は可変で、カラムのデータ型および分布に依存します。ブロックはさらに、そのサイズとI/Oコストを削減するために圧縮されます。デフォルトでは、ClickHouseは一般的な圧縮アルゴリズムとしてLZ4 [\[75\]](#page-13-9)を使用しますが、ユーザーはGorilla [\[63\]](#page-13-10)やFPC [\[12\]](#page-12-8)のような特殊なコーデックを浮動小数点データ用に指定することもできます。圧縮アルゴリズムはチェーン化することもできます。例えば、最初に数値の論理的冗長性をデルタコーディング [\[23\]](#page-12-9) を使用して削減し、次に重みのある圧縮を実行し、最後にAESコーデックを使用してデータを暗号化することが可能です。ブロックは、ディスクからメモリにロードされる際にリアルタイムで解凍されます。圧縮にもかかわらず個々のグラニュールへの迅速なランダムアクセスを可能にするために、ClickHouseはまた、各カラムに対して、すべてのグラニュールIDをカラムファイル内の圧縮ブロックのオフセットおよび未圧縮ブロック内のグラニュールのオフセットに関連付けるマッピングを保存します。

カラムはさらに辞書エンコード [\[2,](#page-12-10) [77,](#page-13-11) [81\]](#page-13-12) されるか、Nullableを使用して作成可能です：LowCardinality(T) は、元のカラム値を整数IDに置き換え、ユニークな値が少ないデータのストレージオーバーヘッドを大幅に削減します。Nullable(T) は、カラムTに対して、カラム値がNULLかどうかを表す内部ビットマップを追加します。

最後に、テーブルは範囲、ハッシュ、またはラウンドロビンで、任意の分割式を使用してパーティション分割できます。パーティションプルーニングを可能にするために、ClickHouseはさらに各パーティションのパーティショニング式の最小値と最大値を保存します。ユーザーは、ハイパーログログ [\[30\]](#page-12-11) やt-digest [\[28\]](#page-12-12)統計などのより高度なカラム統計（例えば、基数推定を提供するもの）をオプションで作成できます。
### <Anchor id="page-3-0"/>3.2 Data Pruning {#3-2-data-pruning}

ほとんどの使用ケースでは、ペタバイトのデータをスキャンして単一のクエリに回答するのは遅すぎて高価です。ClickHouseは、検索中に大多数の行をスキップできる3つのデータプルーニング技術をサポートしています。

最初に、ユーザーはテーブルのために**主キーインデックス**を定義できます。主キー列は、各パート内の行のソート順序を決定し、すなわちインデックスはローカルにクラスタリングされます。ClickHouseはさらに、各グラニュールの最初の行の主キー列値からグラニュールのIDへのマッピングを各パートのために保存します。すなわち、インデックスはスパースです [\[31\]](#page-12-13)。結果として得られるデータ構造は通常、すべてをメモリ内に保持できる程度に小さく、例えば8.1百万の行をインデックス化するのにわずか1000エントリが必要です。主キーの主な目的は、頻繁にフィルタされる列に対する等価性と範囲の述語を、逐次スキャンの代わりにバイナリ検索を使用して評価することです（[Section 4.4](#page-7-0)参照）。また、ローカルソートは、パートマージやクエリ最適化に利用可能であり、例えば、ソートベースの集約や、主キー列がソート列の接頭辞を形成する場合には、物理実行計画からソートオペレーターを取り除くことができます。

[Figure 4](#page-3-1)は、ページインプレッション統計のテーブルに対する列EventTimeの主キーインデックスを示しています。クエリ中の範囲述語に一致するグラニュールは、EventTimeを逐次スキャンする代わりに主キーインデックスでバイナリ検索することによって見つけることができます。

<Anchor id="page-3-1"/><img src={image_04}/>

Figure 4: 主キーインデックスによるフィルタ評価。

次に、ユーザーは**テーブルプロジェクション**を作成できます。すなわち、異なる主キーによってソートされている同じ行を含むテーブルの別バージョンです [\[71\]](#page-13-13)。プロジェクションは、主テーブルの主キーとは異なる列でフィルタリングされるクエリを高速化し、挿入、マージ、スペース消費のオーバーヘッドを増加させます。デフォルトでは、プロジェクションは主テーブルへの新しい挿入からのみ遅延的に生成され、ユーザーがプロジェクションを完全に具現化しない限り既存のパーツからは生成されません。クエリオプティマイザーは、推定I/Oコストに基づいて主テーブルまたはプロジェクションのいずれから読むかを選択します。あるパートに対するプロジェクションが存在しない場合、クエリ実行は対応する主テーブルパートにフォールバックします。

第三に、**スキップインデックス**は、プロジェクションに対する軽量の代替手段を提供します。スキップインデックスのアイデアは、無関係な行のスキャンを避けることができる小さなメタデータを複数の連続するグラニュールのレベルで保存することです。スキップインデックスは、任意のインデックス式のために作成でき、設定可能なグラニュラリティ、すなわちスキップインデックスブロック内のグラニュール数を使用できます。利用可能なスキップインデックスタイプには、1. min-maxインデックス [\[51\]](#page-13-14) があり、これは各インデックスブロックのインデックス式の最小値と最大値を保存します。このインデックスタイプは、絶対的な範囲が小さなローカルクラスタデータに対してよく機能します。2. 固定数のユニークインデックスブロック値を保存するセットインデックス。これらのインデックスは、ローカル基数が小さい、すなわち「集中的にまとめられた」値を持つデータで最も良く使用されます。3. トークンやn-グラム値に対して設定可能な偽陽性率で構築されたブルームフィルターインデックス [\[9\]](#page-12-14)。これらのインデックスはテキスト検索をサポートしますが [\[73\]](#page-13-15)、min-maxおよびセットインデックスとは異なり、範囲または負の述語には使用できません。
### <Anchor id="page-4-3"/>3.3 Merge-time Data Transformation {#3-3-merge-time-data-transformation}

ビジネスインテリジェンスや可観測性の使用ケースは、高率またはバーストで生成されるデータを処理する必要があります。そして、最近生成されたデータは通常、歴史的データよりも意味のあるリアルタイムの洞察に関連性が高いです。このような使用ケースでは、データベースは高いデータ取り込みレートを維持しながら、集約やデータの老朽化といった技術を通じて歴史的データのボリュームを継続的に削減する必要があります。ClickHouseは、さまざまなマージ戦略を使用して、既存のデータを継続的にインクリメンタル変換することを可能にします。マージ時のデータ変換はINSERT文のパフォーマンスを妨げることはありませんが、テーブルが常に不要な（e.g. 古いまたは集約されていない）値を含まないことを保証することはできません。必要に応じて、すべてのマージ時変換はSELECT文でFINALキーワードを指定することで、クエリ時に適用できます。

**置き換えマージ**は、含まれるパートの作成タイムスタンプに基づいて、タプルの最も最近挿入されたバージョンのみを保持し、古いバージョンは削除されます。タプルは、同じ主キー列値を持っている場合に等価と見なされます。どのタプルが保持されるかを明示的に制御するために、比較のための特別なバージョンカラムを指定することも可能です。置き換えマージは、通常、頻繁に更新される使用ケースでのマージ時アップデートメカニズムとして、あるいは挿入時のデータ重複排除の代替手段として使用されます（[Section 3.5](#page-5-2)参照）。

**集約マージ**は、同じ主キー列値を持つ行を集約された行にまとめます。非主キー列は、要約値を保持する部分的集約状態である必要があります。平均（avg()）のための合計とカウントなど、2つの部分的集約状態を新しい部分的集約状態に結合します。集約マージは、通常のテーブルではなく、マテリアライズドビューで使用されます。マテリアライズドビューは、ソーステーブルに対する変換クエリに基づいてポピュレートされます。他のデータベースとは異なり、ClickHouseはマテリアライズドビューをソーステーブルの全内容で周期的に更新しません。代わりに、マテリアライズドビューは、新しいパートがソーステーブルに挿入されたときに、変換クエリの結果でインクリメンタルに更新されます。

[Figure 5](#page-4-1)は、ページインプレッション統計のテーブルに対して定義されたマテリアライズドビューを示します。ソーステーブルに挿入された新しいパートについて、変換クエリは、地域ごとに最大及び平均レイテンシを計算し、その結果をマテリアライズドビューに挿入します。集約関数avg()およびmax()は、実際の結果の代わりに部分的集約状態を返します。マテリアライズドビューのために定義された集約マージは異なるパーツ内の部分的集約状態を継続的に結合します。最終的な結果を得るために、ユーザーはavg()およびmax()を使用してマテリアライズドビュー内の部分的集約状態を統合します。

<Anchor id="page-4-1"/><img src={image_05}/>

Figure 5: マテリアライズドビュー内の集約マージ。

**有効期限（TTL）マージ**は、歴史的データの老朽化を提供します。削除マージや集約マージとは異なり、TTLマージは一度に1つのパートのみを処理します。TTLマージは、トリガーとアクションを持つルールの観点で定義されます。トリガーは、各行のためのタイムスタンプを計算する式であり、TTLマージが実行される時間と比較されます。これにより、ユーザーは行の粒度でアクションを制御できますが、条件を満たす行がすべて満たしているかどうかを確認し、パート全体にアクションを実行することが十分であると認識しました。可能なアクションには、1. パートを他のボリュームに移動する（例：安価で遅いストレージ）、2. パートを再圧縮する（例：より重いコーデックで）、3. パートを削除する、4. ロールアップ（すなわち、グルーピングキーおよび集約関数を使用して行を集約する）が含まれます。

例えば、[Listing 1](#page-4-2)に見られるロギングテーブル定義を考えましょう。ClickHouseは、タイムスタンプ列の値が1週間以上古いパーツを遅いが安価なS3オブジェクトストレージに移動します。
<Anchor id="page-4-2"/>
```
1 CREATE TABLE tab ( ts DateTime , msg String )
2 ENGINE MergeTree PRIMARY KEY ts
3 TTL ( ts + INTERVAL 1 WEEK ) TO VOLUME 's3 '
```
Listing 1: 1週間後にパートをオブジェクトストレージに移動。
### <Anchor id="page-4-0"/>3.4 Updates and Deletes {#3-4-updates-and-deletes}

MergeTree*テーブルエンジンの設計は、追加専用のワークロードを優先していますが、一部の使用ケースでは時折既存データを変更する必要があります。更新または削除のデータには、どちらも並行挿入をブロックせずに行う二つのアプローチがあります。

**ミューテーション**は、テーブル内のすべてのパーツをインプレースで再書き込みます。テーブル（削除）やカラム（更新）が一時的にサイズを倍増するのを防ぐため、この操作は非原子的です。すなわち、並行実行のSELECT文は、変異したパーツと未変異のパーツを読むことができます。ミューテーションは、操作の終了時にデータが物理的に変更されることを保証します。ただし、削除ミューテーションは、すべてのカラムをすべてのパーツに書き直すため、依然として高コストです。

代替手段として、**軽量削除**は、行が削除されているかどうかを示す内部ビットマップカラムのみを更新します。ClickHouseは、削除された行を結果から除外するために、ビットマップカラムに対する追加フィルタを使用してSELECTクエリを修正します。削除された行は、将来の未指定の時間に通常のマージによって物理的に削除されます。カラム数に応じて、軽量削除はミューテーションよりもはるかに高速で行うことができ、SELECTは遅くなります。

同じテーブルに対する更新および削除操作は、論理的な矛盾を避けるために、まれで直列化されることが期待されます。
### <Anchor id="page-5-2"/>3.5 Idempotent Inserts {#3-5-idempotent-inserts}

実際に頻繁に発生する問題の一つは、クライアントがデータをテーブルに挿入するためにサーバーに送信した後の接続タイムアウトをどのように処理するかです。この状況では、クライアントはデータが正常に挿入されたかどうかを区別するのが難しくなります。この問題は、クライアントからサーバーへのデータの再送信によって解決され、主キーまたはユニーク制約によって重複した挿入を拒否することに依存しています。データベースは、バイナリツリー [\[39,](#page-12-15) [68\]](#page-13-16)、基数木 [\[45\]](#page-13-17)、またはハッシュテーブル [\[29\]](#page-12-16) に基づいたインデックス構造を使用して、必要なポイントルックアップを迅速に実行します。これらのデータ構造は各タプルをインデックス化するため、そのスペースおよび更新オーバーヘッドは大規模なデータセットおよび高取り込みレートでは過剰になります。

ClickHouseは、各挿入が最終的にパーツを作成するという事実に基づいた軽量の代替手段を提供します。具体的には、サーバーは最後に挿入されたN個のパーツのハッシュを保持し（例としてN=100）、既知のハッシュを持つパーツの再挿入を無視します。非レプリケートテーブルとレプリケートテーブルのハッシュは、それぞれKeeperにローカルに保存されます。その結果、挿入は冪等になります。すなわち、クライアントはタイムアウト後に同じ行のバッチを再送信するだけで、サーバーが重複排除を処理することが期待できます。重複排除プロセスをより厳密に制御するために、クライアントはオプションでパートハッシュとして機能する挿入トークンを提供することができます。ハッシュベースの重複排除は、新しい行をハッシュ化する際のオーバーヘッドを伴いますが、ハッシュを保存して比較するコストは無視できるものです。
```
```yaml
title: 'データレプリケーション'
sidebar_label: '3.6 データレプリケーション'
keywords: 'ClickHouse, レプリケーション, データベース, 高可用性, 冗長性'
description: 'ClickHouseにおけるデータレプリケーションのメカニズム、最適化の手法、ACID準拠などを解説します。'
```

### <Anchor id="page-5-0"/>3.6 データレプリケーション {#3-6-data-replication}

レプリケーションは高可用性（ノードの障害に対する耐障害性）に必要不可欠ですが、負荷分散やゼロダウンタイムアップグレードのためにも使用されます [\[14\]](#page-12-17)。ClickHouseでは、レプリケーションはテーブルの状態という概念に基づいており、この状態はテーブルパーツのセット（セクション [3.1)](#page-2-2) と、カラム名やタイプなどのテーブルメタデータで構成されています。ノードは、以下の3つの操作を使用してテーブルの状態を進めます：1. 挿入は状態に新しいパーツを追加、2. マージは新しいパーツを追加し、状態から既存のパーツを削除、3. ミューテーションやDDLステートメントはパーツの追加、削除、およびテーブルメタデータの変更を行います。操作は単一ノード上でローカルに実行され、その状態遷移はグローバルなレプリケーションログに記録されます。

レプリケーションログは通常3つのClickHouse Keeperプロセスのアンサンブルによって維持され、Raft合意アルゴリズム [\[59\]](#page-13-4) を利用して、ClickHouseノードのクラスターに対する分散型で耐障害性のある調整層を提供します。すべてのクラスターノードは最初にレプリケーションログの同じ位置を指します。ノードはローカルな挿入、マージ、ミューテーション、DDLステートメントを実行する間、レプリケーションログは他のすべてのノードで非同期的に再生されます。その結果、レプリケートされたテーブルは最終的には一貫性があります。つまり、ノードは最新の状態に収束している間、一時的に古いテーブルの状態を読み取ることができます。前述のほとんどの操作は、ノードの過半数（例：大多数のノードまたはすべてのノード）が新しい状態を採用するまで同期的に実行されることもあります。

例として、[図6](#page-5-3)は3つのClickHouseノードのクラスター内に存在する初期状態の空のレプリケートテーブルを示しています。ノード1は最初に2つのINSERTステートメントを受け取り、これをレプリケーションログ（1 2）に記録します。次に、ノード2は最初のログエントリーを取得して再生し（3）、ノード1から新しいパーツをダウンロードします（4）。ノード3は両方のログエントリーを再生します（3 4 5 6）。最後に、ノード3は両方のパーツを新しいパーツにマージし、入力パーツを削除し、レプリケーションログにマージエントリーを記録します（7）。

<Anchor id="page-5-3"/><img src={image_06}/>

図6: 三つのノードのクラスターにおけるレプリケーション。

同期化をスピードアップするための3つの最適化があります。まず、クラスターに追加された新しいノードは、レプリケーションログを最初から再生するのではなく、最後のレプリケーションログエントリーを書いたノードの状態を単にコピーします。次に、マージはローカルで繰り返すことによって再生されるか、別のノードから結果パーツを取得することによって行われます。正確な動作は構成可能で、CPUの消費とネットワークI/Oのバランスを取ることができます。例えば、クロスデータセンターレプリケーションは通常、運用コストを最小限に抑えるためにローカルマージを好みます。3つ目に、ノードは互いに独立したレプリケーションログエントリーを並行して再生します。これにより、例えば、同じテーブルに連続して挿入された新しいパーツの取得や、異なるテーブルに対する操作が含まれます。
### <Anchor id="page-5-1"/>3.7 ACID準拠 {#3-7-acid-compliance}

同時読み取りと書き込み操作のパフォーマンスを最大化するために、ClickHouseはロックをできるだけ避けます。クエリは、クエリの開始時に作成されたすべての関与するテーブルのすべてのパーツのスナップショットに対して実行されます。これにより、並行 INSERT やマージによって挿入された新しいパーツ（セクション [3.1)](#page-2-2) が実行に参加しないことが保証されます。パーツが同時に変更または削除されるのを防ぐために（セクション [3.4)](#page-4-0)、処理されたパーツの参照カウントはクエリの実行中に増加します。形式的には、これはバージョン管理されたパーツに基づくMVCCバリアントによって実現されたスナップショット隔離に対応します [\[6\]](#page-12-18)。その結果、ステートメントは一般にACID準拠ではなく、スナップショットが取得された時点で行われる同時書き込みが単一のパーツにのみ影響する稀なケースを除きます。

実際には、ClickHouseの書き込みが多い意思決定のユースケースのほとんどは、停電の際に新しいデータを失うリスクを小さく許容します。データベースは、デフォルトで新しく挿入されたパーツをディスクにコミット（fsync）することを強制せず、カーネルに書き込みをバッチ処理させ、原子性を犠牲にすることによってこれを活用します。
## <Anchor id="page-6-0"/>4 クエリ処理層 {#4-query-processing-layer}

<Anchor id="page-6-1"/><img src={image_07}/>

図7: SIMDユニット、コア、およびノード間での並列化。

[図7](#page-6-1)によって示されているように、ClickHouseはデータ要素、データチャンク、およびテーブルシャードのレベルでクエリを並列化します。複数のデータ要素は、SIMD命令を使用してオペレーター内で同時に処理できます。単一ノード上では、クエリエンジンが複数のスレッドでこれらのオペレーターを同時に実行します。ClickHouseは、MonetDB/X100 [\[11\]](#page-12-0) と同じベクトル化モデルを使用しており、即ちオペレーターは単一の行ではなく複数の行（データチャンク）を生成、渡し、消費して、仮想関数呼び出しのオーバーヘッドを最小限に抑えます。ソーステーブルが分離されたテーブルシャードに分割されている場合、複数のノードがシャードを同時にスキャンできます。その結果、すべてのハードウェアリソースが完全に活用され、ノードを追加することによって水平に、コアを追加することによって垂直にクエリ処理をスケールできます。

このセクションの残りでは、まずデータ要素、データチャンク、およびシャードの粒度での並列処理をより詳細に説明します。次に、クエリパフォーマンスを最大化するための主要な最適化をいくつか紹介します。最後に、ClickHouseが同時クエリの存在下で共有システムリソースをどのように管理するかについて説明します。
### 4.1 SIMD並列化 {#4-1-simd-parallelization}

オペレーター間で複数行を渡すことは、ベクトル化の機会を生み出します。ベクトル化は、手動で書かれたインストリンシック [\[64,](#page-13-18) [80\]](#page-13-19) またはコンパイラの自動ベクトル化 [\[25\]](#page-12-19) に基づいています。ベクトル化の恩恵を受けるコードは異なるコンピュートカーネルにコンパイルされます。例えば、クエリオペレーターの内部ホットループは、非ベクトル化カーネル、自動ベクトル化AVX2カーネル、手動でベクトル化されたAVX-512カーネルに基づいて実装することができます。最も速いカーネルは、`cpuid` 命令に基づいてランタイムで選ばれます。このアプローチにより、ClickHouseは15年前の古いシステムでも動作可能（その最低要件はSSE 4.2）でありながら、最近のハードウェア上での著しい速度向上を提供します。
### 4.2 マルチコア並列化 {#4-2-multi-core-parallelization}

<Anchor id="page-7-1"/><img src={image_08}/>

図8: 三つのレーンを持つ物理オペレーター計画。

ClickHouseは、SQLクエリを物理計画オペレーターの指向グラフに変換する従来のアプローチ [\[31\]](#page-12-13) に従っています。オペレーター計画の入力は、ネイティブまたはサポートされているいずれかの外部形式からデータを読み取る特別なソースオペレーターによって表されます（セクション [5)](#page-9-0) 参照）。同様に、特別なシンクオペレーターは結果を希望の出力形式に変換します。物理オペレーター計画は、クエリコンパイル時に、構成可能な最大ワーカースレッド数（デフォルトではコアの数）とソーステーブルのサイズに基づいて、独立した実行レーンに展開されます。レーンは、並列オペレーターによって処理されるデータを重複しない範囲に分解します。並列処理の機会を最大化するために、レーンはできるだけ遅くマージされます。

例として、[図8](#page-7-1)のノード1のボックスは、ページインプレッション統計テーブルに対する典型的なOLAPクエリのオペレーターグラフを示しています。最初のステージでは、ソーステーブルの3つの不連続範囲が同時にフィルタリングされます。リパーティション交換オペレーターは、処理スレッドの均一な利用を維持するために、結果チャンクを第一および第二のステージの間で動的にルーティングします。スキャンされた範囲が著しく異なる選好性を持っている場合、第一ステージ後にレーンが不均衡になる可能性があります。第二ステージでは、フィルターを生き残った行がRegionIDごとにグループ化されます。アグリゲートオペレーターは、RegionIDをグループカラムとして、各グループの合計とカウントを部分的な集計状態として維持します。ローカル集計結果は最終的にグローバル集計結果に向けてGroupStateMergeオペレーターによってマージされます。このオペレーターはパイプラインブレイカーでもあり、集計結果が完全に計算されるまで第三のステージは開始できません。第三のステージでは、結果グループはまずリパーティション交換オペレーターによって3つの等しい不連続パーティションに分割され、その後AvgLatencyでソートされます。ソートは3つのステップで実行されます。最初に、ChunkSortオペレーターが各パーティションの個々のチャンクをソートします。次に、StreamSortオペレーターがローカルなソート済み結果を維持し、2-wayマージソートを使用して新しいソート済みチャンクと組み合わせます。最後に、MergeSortオペレーターがローカル結果をk-wayソートを使用して組み合わせ、最終結果を得ます。

オペレーターは状態マシンであり、入力ポートと出力ポートを介して互いに接続されています。オペレーターの3つの可能な状態はneed-chunk、ready、doneです。need-chunkからreadyに移動するには、チャンクがオペレーターの入力ポートに配置されます。readyからdoneに移動するには、オペレーターが入力チャンクを処理し、出力チャンクを生成します。doneからneed-chunkに移動するには、出力チャンクがオペレーターの出力ポートから削除されます。2つの接続されたオペレーターにおける最初と第三の状態遷移は、結合ステップでのみ行われます。ソースオペレーター（シンクオペレーター）は、状態としてreadyとdone（need-chunkとdone）しか持ちません。

ワーカースレッドは物理オペレーター計画を継続的に移動し、状態遷移を実行します。CPUキャッシュをホットに保つために、計画には同じスレッドが同じレーン内の連続したオペレーターを処理すべきであるというヒントが含まれています。並列処理は、ステージ内の重複しない入力間で水平方向に行われ（例：[図8](#page-7-1) ではアグリゲートオペレーターが同時に実行）、パイプラインブレイカーにより分離されないステージを通じて垂直方向にも行われます（例：[図8](#page-7-1) では同じレーン内のフィルターとアグリゲートオペレーターが同時に実行できます）。新しいクエリが開始されたときや、同時クエリが終了したときに過剰または不足のサブスクリプションを避けるために、並列度はクエリ開始時に指定されたワーカースレッドの最大数との間で変更可能です（セクション [4.5)](#page-9-1) 参照）。

オペレーターはさらに、ランタイムでクエリの実行に影響を与える2つの方法でも動作します。第一に、オペレーターは新しいオペレーターを動的に作成し接続することができます。これは、メモリ消費が構成可能な閾値を超えた場合にクエリをキャンセルするのではなく、外部の集計、ソート、または結合アルゴリズムに切り替えるために主に使われます。第二に、オペレーターはワーカースレッドに非同期キューに移動するようリクエストすることができます。これにより、リモートデータを待機する際にワーカースレッドをより効果的に活用できます。

ClickHouseのクエリ実行エンジンとモーセルトリブン並列性 [\[44\]](#page-12-20) は、通常、レーンが異なるコア / NUMAソケットで実行され、ワーカースレッドが他のレーンからタスクを盗むことができるという点で類似しています。さらに、中央のスケジューリングコンポーネントは存在せず、ワーカースレッドは物理オペレーター計画を継続的に走査することによって個別にタスクを選択します。モーセルトリブン並列性とは異なり、ClickHouseは最大の並列度を計画に組み込み、デフォルトのモーセルサイズ（約100,000行）と比較してソーステーブルをパーティション分割するためにはるかに大きな範囲を使用します。この場合、一部ではスタールが発生する可能性があります（例：異なるレーンのフィルターオペレーターのランタイムが大きく異なる場合）が、リパーティションなどの交換オペレーターを自由に使用することで、少なくともそのような不均衡がステージ間で蓄積することを避けることができます。
### 4.3 マルチノード並列化 {#4-3-multi-node-parallelization}

クエリのソーステーブルがシャーディングされている場合、クエリを受け取ったノード（イニシエータノード）のクエリオプティマイザは、他のノードでできるだけ多くの作業を実行しようとします。他のノードからの結果は、クエリ計画の異なるポイントに統合できます。クエリに応じて、リモートノードは以下のいずれかを実行します：1. 生のソーステーブルカラムをイニシエータノードにストリーム、2. ソースカラムをフィルタリングし、生き残った行を送信、3. フィルタリングと集計ステップを実行し、ローカル結果グループを部分的な集計状態と共に送信、または4. フィルター、集計、およびソートを含む全クエリを実行。

[図8](#page-7-1)のノード2 ... Nは、ヒットテーブルのシャードを保持している他のノードで実行される計画フラグメントを示しています。これらのノードはローカルデータをフィルタリングし、グループ化し、結果をイニシエータノードに送信します。ノード1のGroupStateMergeオペレーターは、ローカルおよびリモート結果をマージしてから、結果グループを最終的にソートします。
### <Anchor id="page-7-0"/>4.4 全体的パフォーマンス最適化 {#4-4-holistic-performance-optimization}

このセクションでは、クエリ実行の異なるステージに適用される選択された主要なパフォーマンス最適化を示します。

**クエリ最適化**。最初の最適化セットは、クエリのASTから取得された意味論的クエリ表現の上に適用されます。このような最適化の例には、定数フォールディング（例：concat(lower('a'),upper('b')) は 'aB' になる）、特定の集計関数からスカラーの抽出（例：sum(a*2) は 2 * sum(a) になる）、共通部分式の排除、および等価フィルターの論理和をINリストに変換すること（例：x=c OR x=d は x IN (c,d) になる）があります。最適化された意味論的クエリ表現は、論理オペレーター計画に変換されます。論理計画の上に適用される最適化には、フィルタープッシュダウン、関数評価とソートステップの順序の再配置が含まれますが、よりコストが高いと推定されるものに基づきます。最終的に、論理クエリ計画は物理オペレーター計画に変換されます。この変換は、関与するテーブルエンジンの特性を利用することができます。例えば、MergeTree*-テーブルエンジンの場合、ORDER BYカラムが主キーのプレフィックスを形成するなら、データをディスク順に読み取ることができ、ソートオペレーターを計画から除去することができます。また、集約でのグループ化カラムが主キーのプレフィックスを形成する場合、ClickHouseはソート集約 [\[33\]](#page-12-21) を使用できます。すなわち、事前にソートされた入力中で同じ値の集約実行を直接行います。ハッシュ集約と比較して、ソート集約は記憶容量を大幅に軽減し、集約値は実行が完了した後すぐに次のオペレーターに渡されます。

**クエリコンパイル**。ClickHouseは[LLVMに基づくクエリコンパイル](https://clickhou.se/jit)を採用し、隣接する計画オペレーターを動的に融合します [\[38,](#page-12-22) [53\]](#page-13-0)。例えば、式a * b + c + 1は、三つのオペレーターではなく単一のオペレーターに結合できます。式だけでなく、ClickHouseは同時に複数の集計関数を評価するため（つまり、GROUP BYに対して）のコンパイルや、二つ以上のソートキーでのソートにもコンパイルを使用します。クエリコンパイルは、仮想呼び出しの数を減少させ、データをレジスタやCPUキャッシュに保持し、コードが必要のない分岐予測を助けます。さらに、ランタイムコンパイルにより、論理最適化やコンパイラに実装されたピー プホール最適化の豊富なセットが可能になり、利用可能な最速のローカルCPU命令へのアクセスも可能になります。コンパイルは、同じ通常、集約、またはソート式が構成可能な回数よりも多く異なるクエリで実行されるときだけ開始されます。コンパイルされたクエリオペレーターはキャッシュされ、将来のクエリに再利用することができます。[7]

**主キーインデックス評価**。ClickHouseは、条件の論理積正規形においてフィルタークローズのサブセットが主キーのカラムのプレフィックスを構成する場合、主キーインデックスを使用してWHERE条件を評価します。主キーインデックスは、キー値が辞書式にソートされた範囲に対して、左から右に分析されます。主キーのカラムに対応するフィルター条件は三値論理を使用して評価されます-すべて真、すべて偽、または範囲内の値に対して混合の真偽です。後者の場合、範囲は再帰的に分析するためにサブ範囲に分割されます。フィルター条件における関数のための追加最適化があります。まず、関数はその単調性を記述する特性を持っており、例えば、toDayOfMonth(date)は月内で部分的に単調です。単調性特性により、ソートされた入力キー値範囲に対して、関数がソートされた結果を生成するかどうかを推測することができます。第二に、いくつかの関数は、与えられた関数結果の原像を計算することができます。これは、定数の比較を主キーのカラムに対する関数呼び出しと置き換えるために、キーコラムの値を原像と比較するために使用されます。例えば、toYear(k) = 2024は k >= 2024-01-01 && k < 2025-01-01 に置き換えることができます。

**データスキッピング**。ClickHouseは、セクション [3.2.](#page-3-0) で紹介したデータ構造を使用して、クエリ実行時のデータ読み込みを回避しようとします。さらに、異なるカラムのフィルターは、推定選好性の降順の順に従って、ヒューリスティックスおよび（オプションの）カラム統計に基づいて逐次評価されます。1つ以上の一致する行が含まれるデータチャンクのみが次の述部に渡されます。これにより、読み取るデータ量と各述部から実行される計算量が徐々に減少します。この最適化は、少なくとも1つの高選好の述部が存在する場合にのみ適用されます。そうでない場合、すべての述部を並行して評価するよりもクエリのレイテンシが悪化するからです。

**ハッシュテーブル**。ハッシュテーブルは、集計とハッシュ結合のための基本的なデータ構造です。適切なタイプのハッシュテーブルを選択することはパフォーマンスにとって重要です。ClickHouseは[ハッシュテーブル](https://clickhou.se/hashtables)を多様にインスタンス化します（2024年3月時点で30以上）。これは、ハッシュ関数、アロケーター、セルタイプ、リサイズポリシーを変数ポイントとして持つ一般的なハッシュテーブルテンプレートから生成されます。グループ化カラムのデータ型、推定されるハッシュテーブルのカーディナリティ、その他の要因に応じて、各クエリオペレーターのために最速のハッシュテーブルが選択されます。ハッシュテーブルに対して実装されたさらなる最適化には、次のようなものがあります：

- 256のサブテーブルを持つ二重レイアウト（ハッシュの最初のバイトに基づく）として、巨大なキーセットをサポート、
- 文字列ハッシュテーブル [\[79\]](#page-13-20) が文字列長ごとに異なるハッシュ関数を持つ4つのサブテーブルを持つ、
- キーが少数の場合、バケットインデックスとしてキーを直接使用するルックアップテーブル（すなわちハッシュなし）、
- 比較が高コストである際に衝突解決を高速化するための埋め込まれたハッシュを持つ値（例えば、文字列、AST）、
- ランタイムの統計から予測されるサイズに基づいてハッシュテーブルを作成し、不要なリサイズを避けること、
- 単一メモリスラブ内で作成・破棄ライフサイクルが同じ多数の小規模ハッシュテーブルの割り当て、
- ハッシュテーブルの再利用のために、パーハッシュマップおよびパーセルバージョンカウンタによる即時クリアリング、
- ハッシュしたキーの値を取得する際のスピードアップのためのCPUプリフェッチ（__builtin_prefetch）の使用。

**結合**。ClickHouseは当初結合を初歩的にしかサポートしていなかったため、多くのユースケースは歴史的に非正規化テーブルに頼っていました。今日、データベースはSQLで利用可能なすべての結合タイプ（内側、左/右/完全外側、クロス、一致時）を[提供](https://clickhou.se/joins)し、ハッシュ結合（ナイーブ、グレース）、ソートマージ結合、迅速なキー-バリュー検索のためのインデックス結合などの異なる結合アルゴリズムも提供しています。

結合はデータベース操作の中で最もコストがかかるため、古典的な結合アルゴリズムの並列バリアントを提供することが重要です。理想的には、調整可能なスペース/時間のトレードオフを持つことです。ClickHouseは、[\[7\]](#page-12-23) からの非ブロッキング、共有パーティションアルゴリズムをハッシュ結合に実装しています。例えば、[図9](#page-8-3) のクエリは、ページヒット統計テーブルでURL間のユーザー移動を自己結合を用いて計算します。結合のビルドフェーズは、ソーステーブルの3つの不連続範囲をカバーする3つのレーンに分割されます。グローバルハッシュテーブルの代わりに、パーティション化されたハッシュテーブルが使用されます。（通常3つの）ワーカースレッドは、ハッシュ関数のモジュロを計算することによってビルド側の各入力行のターゲットパーティションを決定します。ハッシュテーブルのパーティションへのアクセスは、Gather交換オペレーターを使用して同期されます。プローブフェーズは、入力タプルのターゲットパーティションを同様に見つけます。このアルゴリズムは、各タプルごとに2つの追加のハッシュ計算を導入しますが、ビルドフェーズにおけるロックの衝突を大幅に削減します。これは、ハッシュテーブルのパーティション数に依存します。

<Anchor id="page-8-3"/><img src={image_09}/>

図9: 三つのハッシュテーブルパーティションを持つ並列ハッシュ結合。
### <Anchor id="page-9-1"/>4.5 ワークロード隔離 {#4-5-workload-isolation}

ClickHouseは並行制御、メモリ使用制限、およびI/Oスケジューリングを提供し、ユーザーがクエリをワークロードクラスに隔離できるようにします。特定のワークロードクラスに対して共有リソース（CPUコア、DRAM、ディスクおよびネットワークのI/O）に制限を設定することによって、これらのクエリが他の重要なビジネスクエリに影響を及ぼさないようにします。

並行制御は、高い数の同時クエリがあるシナリオでスレッドの過剰サブスクリプションを防ぎます。より具体的には、クエリごとのワーカースレッドの数は、利用可能なCPUコア数に対する指定された比率に基づいて動的に調整されます。

ClickHouseは、サーバー、ユーザー、およびクエリレベルでのメモリアロケーションのバイトサイズを追跡し、それによって柔軟なメモリ使用制限を設定することを可能にします。メモリオーバーコミットにより、他のクエリに対するメモリ制限を保証しながら、保証されたメモリを超える追加の未使用メモリをクエリが使用できるようになります。さらに、集計、ソート、結合句に対するメモリ使用量を制限することができ、メモリ制限を超えた場合に外部アルゴリズムへのフォールバックが発生します。

最後に、I/Oスケジューリングにより、ユーザーはワークロードクラスのためにローカルおよびリモートディスクアクセスを最大帯域幅、リクエストの混在、ポリシー（例：FIFO、SFC [\[32\]](#page-12-24)）に基づいて制限できます。
### <Anchor id="page-9-0"/>5 統合層 {#5-integration-layer}

リアルタイムの意思決定アプリケーションはしばしば、複数の場所におけるデータへの効率的で低レイテンシアクセスを必要とします。外部データをOLAPデータベースで利用可能にするためには2つのアプローチがあります。プッシュベースのデータアクセスでは、サードパーティコンポーネントがデータベースと外部データストアを橋渡しします。これに対するひとつの例は、リモートデータを目的のシステムにプッシュする特殊な抽出-変換-ロード（ETL）ツールです。プルベースモデルでは、データベース自体がリモートデータソースに接続し、クエリ用にローカルテーブルにデータをプルダウンするか、リモートシステムにデータをエクスポートします。プッシュベースのアプローチはより柔軟性がありますが、アーキテクチャのフットプリントが大きく、スケーラビリティのボトルネックを伴います。それに対して、データベース内のリモート接続は、ローカルデータとリモートデータ間の結合などの興味深い機能を提供し、全体のアーキテクチャをシンプルに保ちながら洞察への時間を短縮します。

このセクションの残りでは、リモートの場所にあるデータにアクセスすることを目的としたClickHouseのプルベースのデータ統合方法を探索します。SQLデータベースにおけるリモート接続のアイデアは新しくありません。例えば、SQL/MED標準 [\[35\]](#page-12-25) は、2001年に導入され、2011年からPostgreSQLによって実装されていますが、外部データを管理するための統一インターフェースとして外国データラッパーを提案しています。他のデータストアおよびストレージフォーマットとの最大の相互運用性は、ClickHouseの設計目標の1つです。2024年3月時点で、ClickHouseは、すべての分析データベースにおいて、私たちの知識の範囲内で最も組み込まれたデータ統合オプションを提供します。

外部接続。ClickHouseは、外部システムやストレージ場所との接続のために、ODBC、MySQL、PostgreSQL、SQLite、Kafka、Hive、MongoDB、Redis、S3/GCP/Azureオブジェクトストアおよびさまざまなデータレイクを含む[50以上の](https://clickhou.se/query-integrations) 統合テーブル関数とエンジンを提供します。これらは次のボーナス図によってさらに分類されます（元のVLDB論文には含まれていません）。

<Anchor id="bonus-figure"/><img src={image_10}/>

ボーナス図: ClickBenchの相互運用性オプション。

統合**テーブル関数**による一時的なアクセス。テーブル関数は、SELECTクエリのFROM句で呼び出して、探索的アドホッククエリのためにリモートデータを読み取ることができます。あるいは、INSERT INTO TABLE FUNCTIONステートメントを使用して、リモートストアへの書き込みに使用することもできます。

保持されたアクセス。リモートデータストアや処理システムとの永続的な接続を作成するためには、三つの方法があります。

第一に、統合**テーブルエンジン**は、MySQLテーブルのようなリモートデータソースを永続的なローカルテーブルとして表現します。ユーザーはCREATE TABLE AS構文を使用してテーブル定義を保存し、SELECTクエリとテーブル関数と組み合わせます。リモートカラムのサブセットのみを参照するカスタムスキーマを指定することや、カラム名と同等のClickHouseタイプを自動的に決定するためにスキーマ推論を使用することも可能です。また、受動的および能動的なランタイム動作を区別します。受動的テーブルエンジンは、クエリをリモートシステムに転送し、結果でローカルプロキシテーブルを埋めます。この対照的に、能動的テーブルエンジンは、リモートシステムから定期的にデータをプルするか、リモート変更にサブスクライブします。例えば、PostgreSQLの論理レプリケーションプロトコルを通じて取得されます。その結果、ローカルテーブルにはリモートテーブルの完全なコピーが含まれます。

第二に、統合**データベースエンジン**は、リモートデータストア内のテーブルスキーマのすべてのテーブルをClickHouseにマッピングします。前者とは異なり、一般にリモートデータストアがリレーショナルデータベースであることが要求され、DDLステートメントに対して限定的なサポートを提供します。

第三に、**ディクショナリ**は、対応する統合テーブル関数またはエンジンを用いて、ほぼすべての可能なデータソースに対する任意のクエリを使用して埋め込むことができます。ランタイム動作は能動的であり、データはリモートストレージから定常的な間隔でプルされます。

データフォーマット。3rdパーティシステムと対話するために、現代の分析データベースは、あらゆる形式のデータを処理できる必要があります。ClickHouseは、ネイティブ形式のほかに、[90以上の](https://clickhou.se/query-formats)形式をサポートしています。これにより、CSV、JSON、Parquet、Avro、ORC、Arrow、Protobufなどが含まれます。各形式は、ClickHouseが読み取ることができる入力形式であるか（ClickHouseがエクスポートできる）、またはその両方であることができます。Parquetのような分析志向の形式のいくつかは、クエリ処理と統合されており、最適化器が埋め込まれた統計を活用でき、圧縮データ上でフィルターを直接評価できます。

互換性インターフェース。ネイティブバイナリワイヤプロトコルとHTTPのほか、クライアントはMySQLまたはPostgreSQLワイヤプロトコル互換のインターフェースを介してClickHouseと対話できます。この互換性機能は、ベンダーがまだネイティブなClickHouse接続を実装していない独自のアプリケーション（例：特定のビジネスインテリジェンスツール）からのアクセスを有効にするために便利です。
## 6 パフォーマンスを特徴とする {#6-performance-as-a-feature}

このセクションでは、パフォーマンス分析のためのビルトインツールを紹介し、実際のクエリおよびベンチマーククエリを使用してパフォーマンスを評価します。
### 6.1 ビルトインパフォーマンス分析ツール {#6-1-built-in-performance-analysis-tools}

個々のクエリやバックグラウンド操作におけるパフォーマンスボトルネックを調査するために、多様なツールが利用可能です。ユーザーは、システムテーブルに基づく統一インターフェースを介してすべてのツールと相互作用します。

**サーバーおよびクエリメトリック**。アクティブパート数、ネットワークスループット、キャッシュヒット率などのサーバーレベルの統計は、読み取られたブロックの数やインデックス使用統計などのクエリごとの統計によって補完されます。メトリックは、リクエスト時に同期的（任意に）または構成可能な間隔で非同期的に計算されます。

**サンプリングプロファイラー**。サーバースレッドのコールスタックは、サンプリングプロファイラーを使用して収集できます。その結果は、オプションでフレームグラフビジュアライザーなどの外部ツールにエクスポートできます。

**OpenTelemetry統合**。OpenTelemetryは、複数のデータ処理システム間でデータ行をトレースするためのオープンスタンダードです [\[8\]](#page-12-26)。ClickHouseは、すべてのクエリ処理ステップに対して構成可能な粒度でOpenTelemetryログスパンを生成し、他のシステムからOpenTelemetryログスパンを収集・分析できます。

**クエリの説明**。他のデータベースと同様に、SELECTクエリは、クエリのAST、論理および物理オペレーター計画、実行時の動作に関する詳細な洞察のためにEXPLAINによって前置されることができます。
### 6.2 ベンチマーク {#6-2-benchmarks}

ベンチマークは、現実的でないという批判を受けている [\[10,](#page-12-27) [52,](#page-13-22) [66,](#page-13-23) [74\]](#page-13-24)ものの、データベースの強みや弱みを特定するためには依然有用です。以下では、ClickHouseのパフォーマンスを評価するためにベンチマークがいかに使用されるかを議論します。
```

#### 6.2.1 非正規化テーブル {#6-2-1-denormalized-tables}

非正規化ファクトテーブルに対するフィルタおよび集計クエリは、ClickHouseの主なユースケースを歴史的に代表しています。私たちは、クリックストリームやトラフィック分析で使用されるその場でのレポーティングクエリと定期的なレポーティングクエリをシミュレートした、ClickBenchという典型的なワークロードの実行時間を報告しています。ベンチマークは、世界最大の分析プラットフォームの1つから取得した1億件の匿名化されたページヒットを持つテーブルに対して実行される43のクエリから構成されています。オンラインダッシュボード [\[17\]](#page-12-28) は、2024年6月時点で45以上の商業および研究データベースの測定値（コールド/ホット実行時間、データインポート時間、ディスク上のサイズ）を示します。結果は、公開されているデータセットとクエリに基づいて独立した寄稿者によって提出されます [\[16\]](#page-12-29)。これらのクエリは、逐次的およびインデックススキャンのアクセスパスをテストし、CPU、IO、またはメモリに制約されたリレーショナルオペレーターを定期的に露出させます。

[Figure 10](#page-10-0) は、分析用に頻繁に使用されるデータベース内で、すべてのClickBenchクエリを逐次実行した場合の総相対コールドおよびホット実行時間を示しています。測定は、16 vCPU、32 GB RAM、および5000 IOPS / 1000 MiB/sのディスクを持つ単一ノードのAWS EC2 c6a.4xlargeインスタンスで行われました。Redshift（[ra3.4xlarge](https://clickhou.se/redshift-sizes)、12 vCPU、96 GB RAM）およびSnowfake（[warehouse size S](https://clickhou.se/snowflake-sizes)：2x8 vCPU、2x16 GB RAM）には同様のシステムが使用されました。物理データベース設計はわずかに調整されており、主キーを指定していますが、個々のカラムの圧縮を変更したり、プロジェクションを作成したり、スキッピングインデックスを作成したりはありません。また、各コールドクエリ実行の前にLinuxページキャッシュをフラッシュしますが、データベースやオペレーティングシステムのノブは調整しません。各クエリについて、データベース間での最速の実行時間が基準として使用されます。他のデータベースの相対クエリ実行時間は、( + 10)/(_ + 10)として計算されます。データベースの総相対実行時間は、各クエリの比率の幾何平均です。研究データベースUmbra [\[54\]](#page-13-25) が全体のホット実行時間で最高の性能を達成していますが、ClickHouseはホットおよびコールド実行時間の点で他のすべての商用グレードのデータベースを上回っています。

<Anchor id="page-10-0"/><img src={image_11}/>

Figure 10: ClickBenchの相対コールドおよびホット実行時間。

SELECTのパフォーマンスを多様なワークロードに渡って追跡するために、私たちは [use](https://clickhou.se/performance-over-years) 「VersionsBench」と呼ばれる4つのベンチマークの組み合わせを使用しています [\[19\]](#page-12-30)。このベンチマークは、新しいリリースが公開されるたびに月に1回実行され、そのパフォーマンス [\[20\]](#page-12-31) を評価し、パフォーマンスを低下させた可能性のあるコード変更を特定します：個別のベンチマークには、1. 上記のClickBench、2. 15 MgBench [\[21\]](#page-12-32) クエリ、3. 6億行の非正規化スター スキーマ ベンチマーク [\[57\]](#page-13-26) ファクトテーブルに対する13のクエリ。4. 34億行 [\[70\]](#page-13-27) を持つ [NYC Taxi Rides](https://clickhou.se/nyc-taxi-rides-benchmark) に対する4つのクエリ。

[Figure 11](#page-10-5) は、2018年3月から2024年3月までの77のClickHouseバージョンにおけるVersionsBenchの実行時間の推移を示しています。個々のクエリの相対実行時間の違いを補うために、私たちは幾何平均を使用して、すべてのバージョンにわたる最小クエリ実行時間への比率を重みとして実行時間を正規化します。VersionBenchのパフォーマンスは、過去6年間で1.72倍向上しました。長期サポート（LTS）のリリース日がx軸にマークされています。いくつかの期間においてパフォーマンスが一時的に低下したものの、LTSリリースは一般に前のLTSバージョンと比較して同等かそれ以上のパフォーマンスを持っています。2022年8月の大幅な改善は、セクション [4.4.](#page-7-0) で説明されているカラムごとのフィルター評価技術によって引き起こされました。

<Anchor id="page-10-5"/><img src={image_12}/>

Figure 11: VersionsBench 2018-2024の相対ホット実行時間。
#### 6.2.2 正規化テーブル {#6-2-2-normalized-tables}

古典的なデータウェアハウジングでは、データはしばしばスターまたはスノーフレークスキーマを使用してモデルされます。私たちは、TPC-Hクエリ（スケールファクター100）の実行時間を示しますが、正規化テーブルがClickHouseにとって新興のユースケースであることを指摘します。[Figure 12](#page-10-6) は、セクション [4.4.](#page-7-0) で説明されている平行ハッシュジョインアルゴリズムに基づくTPC-Hクエリのホット実行時間を示しています。測定は、64 vCPUs、128 GB RAM、および5000 IOPS / 1000 MiB/sのディスクを持つ単一ノードのAWS EC2 c6i.16xlargeインスタンスで行われました。5回の実行の中で最速のものが記録されました。参考までに、同じサイズのSnowfakeシステム（ウェアハウスサイズL、8x8 vCPUs、8x16 GB RAM）で同様の測定を行いました。11のクエリの結果はテーブルから除外されています：クエリQ2、Q4、Q13、Q17、およびQ20-22は、ClickHouse v24.6 の時点でサポートされていない相関サブクエリを含んでいます。クエリQ7-Q9およびQ19は、ジョインのためのジョイン再順序付けやジョイン発生条件のプッシュダウンなど、計画レベルの最適化に依存しており（ClickHouse v24.6時点ではどちらも欠落しています）、実行時間を達成するためには必要です。自動サブクエリデコリレーションとジョインのためのよりよいオプティマイザサポートが2024年の実装に向けて計画されています [\[18\]](#page-12-33)。残りの11のクエリのうち、5（6）のクエリがClickHouse（Snowfake）でより早く実行されました。前述の最適化はパフォーマンスにとって重要であることが知られているため [\[27\]](#page-12-34)、実装されるとこれらのクエリの実行時間がさらに改善されると予想されます。

<Anchor id="page-10-6"/><img src={image_13}/>

Figure 12: TPC-Hクエリのホット実行時間（秒単位）。
## 7 関連研究 {#7-related-work}

分析データベースは、近年の数十年間にわたり、学術的および商業的に大きな関心を集めてきました [\[1\]](#page-12-35)。Sybase IQ [\[48\]](#page-13-28)、Teradata [\[72\]](#page-13-29)、Vertica [\[42\]](#page-12-36)、およびGreenplum [\[47\]](#page-13-30)のような初期のシステムは、高価なバッチETLジョブと、オンプレミスとしての性質から生じる制限された弾力性を特徴としていました。2010年代初頭には、Snowfake [\[22\]](#page-12-37)、BigQuery [\[49\]](#page-13-31)、およびRedshift [\[4\]](#page-12-38)のようなクラウドネイティブなデータウェアハウスおよびデータベース・アズ・ア・サービス（DBaaS）オファリングの出現により、組織の分析にかかるコストと複雑さが劇的に削減され、高可用性と自動的なリソーススケーリングの利点が得られました。最近では、分析実行カーネル（例えば、Photon [\[5\]](#page-12-39)やVelox [\[62\]](#page-13-32)）が、異なる分析、ストリーミング、機械学習アプリケーションで使用するための修正されたデータ処理を提供しています。

ClickHouseと目標および設計原則の点で最も類似するデータベースは、Druid [\[78\]](#page-13-33)およびPinot [\[34\]](#page-12-40)です。両方のシステムは、高いデータインジェスションレートを持つリアルタイム分析をターゲットとしています。ClickHouseと同様に、テーブルはセグメントと呼ばれる水平パーツに分割されます。ClickHouseは、より小さなパーツを継続的にマージし、オプションでセクション [3.3,](#page-4-3) の技術を使用してデータボリュームを削減しますが、DruidおよびPinotではパーツは永遠に不変であり続けます。また、DruidおよびPinotでは、テーブルの作成、変更、検索に特別なノードが必要ですが、ClickHouseはこれらのタスクに対して単一のバイナリを使用します。

Snowfake [\[22\]](#page-12-37)は、共有ディスクアーキテクチャに基づく人気のあるプロプライエタリなクラウドデータウェアハウスです。テーブルをマイクロパーティションに分割するアプローチは、ClickHouseにおけるパーツの概念に似ています。Snowfakeは持続性のためにハイブリッドPAXページを使用しますが、ClickHouseのストレージ形式は厳密に列指向です。Snowfakeは、良好なパフォーマンスのソースとして自動的に作成された軽量インデックスを使用して、ローカルキャッシュとデータプルーニングを強調します [\[31,](#page-12-13) [51\]](#page-13-14)。ClickHouseの主キーと同様に、ユーザーはオプションで同じ値を持つデータを共置するためにクラスタ化インデックスを作成できます。

Photon [\[5\]](#page-12-39)とVelox [\[62\]](#page-13-32)は、複雑なデータ管理システムのコンポーネントとして使用されるように設計されたクエリ実行エンジンです。両方のシステムは、クエリプランを入力として受け取り、それをParquet（Photon）またはArrow（Velox）ファイル上でローカルノードで実行します [\[46\]](#page-13-34)。ClickHouseはこれらの一般的な形式でデータを消費し生成できますが、ストレージにはネイティブファイル形式を好みます。VeloxとPhotonはクエリプランを最適化せず（Veloxは基本的な式の最適化を実行しますが）、データ特性に基づいて計算カーネルを動的に切り替えるなど、実行時適応技術を利用します。同様に、ClickHouseのプランオペレーターは、クエリのメモリ消費に基づいて、主に外部集計またはジョインオペレーターに切り替えるために、実行時に他のオペレーターを作成できます。Photonの論文は、コード生成デザイン [\[38,](#page-12-22) [41,](#page-12-42) [53\]](#page-13-0) が、解釈されたベクトル化デザイン [\[11\]](#page-12-0) よりも開発およびデバッグが難しいことを指摘しています。Veloxのビルドにおけるコード生成の（実験的な）サポートは、実行時に生成されたC++コードから生成された共有ライブラリを構築してリンクしますが、ClickHouseはLLVMのリクエストベースのコンパイルAPIと直接やり取りします。

DuckDB [\[67\]](#page-13-6)もホストプロセスによって埋め込まれることを意図していますが、クエリ最適化とトランザクションも提供しています。OLAPクエリと時折のOLTPステートメントを混ぜたものとして設計されました。したがってDuckDBは、ハイブリッドワークロードでの優れたパフォーマンスを達成するために、順序を保持する辞書や参照フレーム [\[2\]](#page-12-10) などの軽量圧縮手法を利用するDataBlocks [\[43\]](#page-12-43) ストレージ形式を選択しました。それに対して、ClickHouseは追加のみのユースケース、すなわち、更新や削除のない、またはごく稀なユースケースに最適化されています。ブロックはLZ4のような重い技術を用いて圧縮されており、ユーザーが頻繁なクエリを迅速化するためにデータプルーニングを多用し、残りのクエリに対してはI/Oコストが解凍コストを上回ることを想定しています。DuckDBはHyperのMVCCスキームに基づくシリアライズ可能なトランザクションを提供します [\[55\]](#page-13-35)。一方、ClickHouseはスナップショットアイソレーションのみを提供します。
## 8 結論と展望 {#8-conclusion-and-outlook}

私たちは、オープンソースの高性能OLAPデータベースであるClickHouseのアーキテクチャを紹介しました。書き込み最適化されたストレージ層と最新のベクトル化クエリエンジンを基盤に、ClickHouseはペタバイト規模のデータセットに対するリアルタイム分析を高いインジェスションレートで実現します。データをバックグラウンドで非同期にマージおよび変換することにより、ClickHouseはデータメンテナンスと並列挿入を効率的に切り離します。ストレージ層は、スパース主インデックス、スキッピングインデックス、プロジェクションテーブルを使用して積極的なデータプルーニングを可能にします。私たちはClickHouseの更新と削除の実装、冪等挿入、および高可用性のためのノード間データレプリケーションを説明しました。クエリ処理層は、多くのテクニックを使用してクエリを最適化し、サーバーおよびクラスターリソース全体での実行を並列化します。統合テーブルエンジンおよび関数は、他のデータ管理システムやデータ形式とシームレスに対話するための便利な方法を提供します。ベンチマークを通じて、ClickHouseが市場で最も高速な分析データベースの一つであることを示し、ClickHouseの実世界でのデプロイメントでの典型的なクエリのパフォーマンスにおける重大な改善を示しました。

2024年に計画されているすべての機能と改善については、公開ロードマップ [\[18\]](#page-12-33) で確認できます。計画されている改善には、ユーザートランザクションのサポート、PromQL [\[69\]](#page-13-36) の代替クエリ言語、新しいデータ型（たとえば、JSON）の半構造化データのための新しいデータ型、ジョインの計画レベルの最適化の改善、および軽量削除を補完するための軽量更新の実装が含まれます。
## お礼 {#acknowledgements}

バージョン24.6に従い、SELECT * FROM system.contributors はClickHouseに貢献した1994の個人を返します。ClickHouse Inc.のエンジニアリングチーム全体と、このデータベースを一緒に構築するために尽力している素晴らしいオープンソースコミュニティに感謝いたします。
```
```md
## REFERENCES {#references}

- <Anchor id="page-12-35"/>[1] Daniel Abadi, Peter Boncz, Stavros Harizopoulos, Stratos Idreaos, and Samuel Madden. 2013. 現代の列指向データベースシステムの設計と実装. https://doi.org/10.1561/9781601987556
- <Anchor id="page-12-10"/>[2] Daniel Abadi, Samuel Madden, and Miguel Ferreira. 2006. 列指向データベースシステムにおける圧縮と実行の統合. In Proceedings of the 2006 ACM SIGMOD International Conference on Management of Data (SIGMOD '06). 671–682.https://doi.org/10.1145/1142473.1142548
- <Anchor id="page-12-41"/>[3] Anastassia Ailamaki, David J. DeWitt, Mark D. Hill, and Marios Skounakis. 2001. キャッシュパフォーマンスのための関係の織り交ぜ. In Proceedings of the 27th International Conference on Very Large Data Bases (VLDB '01). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 169–180.
- <Anchor id="page-12-38"/>[4] Nikos Armenatzoglou, Sanuj Basu, Naga Bhanoori, Mengchu Cai, Naresh Chainani, Kiran Chinta, Venkatraman Govindaraju, Todd J. Green, Monish Gupta, Sebastian Hillig, Eric Hotinger, Yan Leshinksy, Jintian Liang, Michael McCreedy, Fabian Nagel, Ippokratis Pandis, Panos Parchas, Rahul Pathak, Orestis Polychroniou, Foyzur Rahman, Gaurav Saxena, Gokul Soundararajan, Sriram Subramanian, and Doug Terry. 2022. Amazon Redshiftの再発明. In Proceedings of the 2022 International Conference on Management of Data (Philadelphia, PA, USA) (SIGMOD '22). Association for Computing Machinery, New York, NY, USA, 2205–2217. https://doi.org/10.1145/3514221.3526045
- <Anchor id="page-12-39"/>[5] Alexander Behm, Shoumik Palkar, Utkarsh Agarwal, Timothy Armstrong, David Cashman, Ankur Dave, Todd Greenstein, Shant Hovsepian, Ryan Johnson, Arvind Sai Krishnan, Paul Leventis, Ala Luszczak, Prashanth Menon, Mostafa Mokhtar, Gene Pang, Sameer Paranjpye, Greg Rahn, Bart Samwel, Tom van Bussel, Herman van Hovell, Maryann Xue, Reynold Xin, and Matei Zaharia. 2022. Photon: レイクハウスシステムのための高速クエリエンジン (SIGMOD '22). Association for Computing Machinery, New York, NY, USA, 2326–2339. [https://doi.org/10.1145/3514221.](https://doi.org/10.1145/3514221.3526054) [3526054](https://doi.org/10.1145/3514221.3526054)
- <Anchor id="page-12-18"/>[6] Philip A. Bernstein and Nathan Goodman. 1981. 分散データベースシステムにおける同時実行制御. ACM Computing Survey 13, 2 (1981), 185–221. https://doi.org/10.1145/356842.356846
- <Anchor id="page-12-23"/>[7] Spyros Blanas, Yinan Li, and Jignesh M. Patel. 2011. マルチコアCPU用のメインメモリハッシュ結合アルゴリズムの設計と評価. In Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data (Athens, Greece) (SIGMOD '11). Association for Computing Machinery, New York, NY, USA, 37–48. https://doi.org/10.1145/1989323.1989328
- <Anchor id="page-12-26"/><Anchor id="page-12-14"/>[8] Daniel Gomez Blanco. 2023. 実践的OpenTelemetry. Springer Nature.
- [9] Burton H. Bloom. 1970. 許容誤差でのハッシュコーディングにおける空間/時間トレードオフ. Commun. ACM 13, 7 (1970), 422–426. [https://doi.org/10.1145/362686.](https://doi.org/10.1145/362686.362692) [362692](https://doi.org/10.1145/362686.362692)
- <Anchor id="page-12-27"/>[10] Peter Boncz, Thomas Neumann, and Orri Erling. 2014. TPC-Hの分析: 影に隠れたメッセージと影響力のあるベンチマークから学んだ教訓. In Performance Characterization and Benchmarking. 61–76. [https://doi.org/10.1007/978-3-319-](https://doi.org/10.1007/978-3-319-04936-6_5) [04936-6_5](https://doi.org/10.1007/978-3-319-04936-6_5)
- <Anchor id="page-12-0"/>[11] Peter Boncz, Marcin Zukowski, and Niels Nes. 2005. MonetDB/X100: ハイパーパイプライニングクエリ実行. In CIDR.
- <Anchor id="page-12-8"/>[12] Martin Burtscher and Paruj Ratanaworabhan. 2007. 倍精度浮動小数点データの高スループット圧縮. In Data Compression Conference (DCC). 293–302. https://doi.org/10.1109/DCC.2007.44
- <Anchor id="page-12-6"/>[13] Jef Carpenter and Eben Hewitt. 2016. Cassandra: 定義ガイド (第2版). O'Reilly Media, Inc.
- <Anchor id="page-12-17"/>[14] Bernadette Charron-Bost, Fernando Pedone, and André Schiper (Eds.). 2010. レプリケーション: 理論と実践. Springer-Verlag.
- <Anchor id="page-12-3"/>[15] chDB. 2024. chDB - 埋め込みOLAP SQLエンジン. 2024-06-20にhttps://github.com/chdb-io/chdbから取得
- <Anchor id="page-12-29"/>[16] ClickHouse. 2024. ClickBench: 分析データベースのベンチマーク. 2024-06-20にhttps://github.com/ClickHouse/ClickBenchから取得
- <Anchor id="page-12-28"/>[17] ClickHouse. 2024. ClickBench: 比較測定. 2024-06-20にhttps://benchmark.clickhouse.comから取得
- <Anchor id="page-12-33"/>[18] ClickHouse. 2024. ClickHouseロードマップ2024 (GitHub). 2024-06-20にhttps://github.com/ClickHouse/ClickHouse/issues/58392から取得
- <Anchor id="page-12-30"/>[19] ClickHouse. 2024. ClickHouseバージョンベンチマーク. 2024-06-20にhttps://github.com/ClickHouse/ClickBench/tree/main/versionsから取得
- <Anchor id="page-12-31"/>[20] ClickHouse. 2024. ClickHouseバージョンベンチマーク結果. 2024-06-20にhttps://benchmark.clickhouse.com/versions/から取得
- <Anchor id="page-12-32"/>[21] Andrew Crotty. 2022. MgBench. 2024-06-20にhttps://github.com/から取得 [https://github.com/andrewcrotty/mgbench](https://github.com/andrewcrotty/mgbench)
- <Anchor id="page-12-37"/>[22] Benoit Dageville, Thierry Cruanes, Marcin Zukowski, Vadim Antonov, Artin Avanes, Jon Bock, Jonathan Claybaugh, Daniel Engovatov, Martin Hentschel, Jiansheng Huang, Allison W. Lee, Ashish Motivala, Abdul Q. Munir, Steven Pelley, Peter Povinec, Greg Rahn, Spyridon Triantafyllis, and Philipp Unterbrunner. 2016. Snowfake Elastic Data Warehouse. In Proceedings of the 2016 International Conference on Management of Data (San Francisco, California, USA) (SIGMOD '16). Association for Computing Machinery, New York, NY, USA, 215–226. [https:](https://doi.org/10.1145/2882903.2903741) [//doi.org/10.1145/2882903.2903741](https://doi.org/10.1145/2882903.2903741)
- <Anchor id="page-12-9"/>[23] Patrick Damme, Annett Ungethüm, Juliana Hildebrandt, Dirk Habich, and Wolfgang Lehner. 2019. 総合実験調査から軽量整数圧縮アルゴリズムのコストベースセレクション戦略への移行. ACM Trans. Database Syst. 44, 3, Article 9 (2019), 46ページ. https://doi.org/10.1145/3323991
- <Anchor id="page-12-1"/>[24] Philippe Dobbelaere and Kyumars Sheykh Esmaili. 2017. Kafka対RabbitMQ: 2つの業界の参照プロデュース/サブスクライブ実装の比較研究: 業界論文 (DEBS '17). Association for Computing Machinery, New York, NY, USA, 227–238. https://doi.org/10.1145/3093742.3093908
- <Anchor id="page-12-19"/>[25] LLVM documentation. 2024. LLVMにおける自動ベクタ化. 2024-06-20にhttps://llvm.org/docs/Vectorizers.htmlから取得
- <Anchor id="page-12-7"/>[26] Siying Dong, Andrew Kryczka, Yanqin Jin, and Michael Stumm. 2021. RocksDB: 大規模アプリケーションにサービスを提供するキーバリューストアの開発優先度の進化. ACM Transactions on Storage 17, 4, Article 26 (2021), 32ページ. https://doi.org/10.1145/3483840
- <Anchor id="page-12-34"/>[27] Markus Dreseler, Martin Boissier, Tilmann Rabl, and Matthias Ufacker. 2020. TPC-Hボトルネックの定量化と最適化. Proc. VLDB Endow. 13, 8 (2020), 1206–1220. https://doi.org/10.14778/3389133.3389138
- <Anchor id="page-12-12"/>[28] Ted Dunning. 2021. t-digest: 分布の効率的な推定. Software Impacts 7 (2021). https://doi.org/10.1016/j.simpa.2020.100049
- <Anchor id="page-12-16"/>[29] Martin Faust, Martin Boissier, Marvin Keller, David Schwalb, Holger Bischof, Katrin Eisenreich, Franz Färber, and Hasso Plattner. 2016. SAP HANAにおけるハッシュインデックスを用いたフットプリント削減と一意性強制. In Database and Expert Systems Applications. 137–151. [https://doi.org/10.1007/978-3-319-44406-](https://doi.org/10.1007/978-3-319-44406-2_11) [2_11](https://doi.org/10.1007/978-3-319-44406-2_11)
- <Anchor id="page-12-11"/>[30] Philippe Flajolet, Eric Fusy, Olivier Gandouet, and Frederic Meunier. 2007. HyperLogLog: ほぼ最適な基数推定アルゴリズムの分析. In AofA: Algorithmsの分析, Vol. DMTCS Proceedings vol. AH, 2007年のアルゴリズム分析に関する会議 (AofA 07). Discrete Mathematics and Theoretical Computer Science, 137–156. https://doi.org/10.46298/dmtcs.3545
- <Anchor id="page-12-13"/>[31] Hector Garcia-Molina, Jefrey D. Ullman, and Jennifer Widom. 2009. データベースシステム - 完全版 (第2版).
- <Anchor id="page-12-24"/>[32] Pawan Goyal, Harrick M. Vin, and Haichen Chen. 1996. 開始時公平キューイング: 統合サービスパケットスイッチングネットワークのためのスケジューリングアルゴリズム. 26, 4 (1996), 157–168. https://doi.org/10.1145/248157.248171
- <Anchor id="page-12-21"/>[33] Goetz Graefe. 1993. 大規模データベースのためのクエリ評価技術. ACM Comput. Surv. 25, 2 (1993), 73–169. https://doi.org/10.1145/152610.152611
- <Anchor id="page-12-40"/>[34] Jean-François Im, Kishore Gopalakrishna, Subbu Subramaniam, Mayank Shrivastava, Adwait Tumbde, Xiaotian Jiang, Jennifer Dai, Seunghyun Lee, Neha Pawar, Jialiang Li, and Ravi Aringunram. 2018. Pinot: 5億人のユーザー向けのリアルタイムOLAP. In Proceedings of the 2018 International Conference on Management of Data (Houston, TX, USA) (SIGMOD '18). Association for Computing Machinery, New York, NY, USA, 583–594. https://doi.org/10.1145/3183713.3190661
- <Anchor id="page-12-25"/>[35] ISO/IEC 9075-9:2001 2001. 情報技術 — データベース言語 — SQL — 部分9: 外部データの管理 (SQL/MED). 標準. International Organization for Standardization.
- <Anchor id="page-12-2"/>[36] Paras Jain, Peter Kraft, Conor Power, Tathagata Das, Ion Stoica, and Matei Zaharia. 2023. レイクハウスストレージシステムの分析と比較. CIDR.
- <Anchor id="page-12-4"/>[37] Project Jupyter. 2024. Jupyterノートブック. 2024-06-20に[https:](https://jupyter.org/) [//jupyter.org/](https://jupyter.org/)から取得
- <Anchor id="page-12-22"/>[38] Timo Kersten, Viktor Leis, Alfons Kemper, Thomas Neumann, Andrew Pavlo, and Peter Boncz. 2018. コンパイルされたベクタ化クエリに関する全ての質問. Proc. VLDB Endow. 11, 13 (sep 2018), 2209–2222. https://doi.org/10.14778/3275366.3284966
- <Anchor id="page-12-15"/>[39] Changkyu Kim, Jatin Chhugani, Nadathur Satish, Eric Sedlar, Anthony D. Nguyen, Tim Kaldewey, Victor W. Lee, Scott A. Brandt, and Pradeep Dubey. 2010. FAST: 現代のCPUおよびGPU上での高速アーキテクチャ感度のあるツリー検索. In Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data (Indianapolis, Indiana, USA) (SIGMOD '10). Association for Computing Machinery, New York, NY, USA, 339–350. https://doi.org/10.1145/1807167.1807206
- <Anchor id="page-12-5"/>[40] Donald E. Knuth. 1973. コンピュータプログラミングの技法, 第3巻: ソートと検索. Addison-Wesley.
- <Anchor id="page-12-42"/>[41] André Kohn, Viktor Leis, and Thomas Neumann. 2018. コンパイルクエリの適応実行. In 2018 IEEE 34th International Conference on Data Engineering (ICDE). 197–208. https://doi.org/10.1109/ICDE.2018.00027
- <Anchor id="page-12-36"/>[42] Andrew Lamb, Matt Fuller, Ramakrishna Varadarajan, Nga Tran, Ben Vandiver, Lyric Doshi, and Chuck Bear. 2012. Vertica分析データベース: C-Store 7年後. Proc. VLDB Endow. 5, 12 (aug 2012), 1790–1801. [https://doi.org/10.](https://doi.org/10.14778/2367502.2367518) [14778/2367502.2367518](https://doi.org/10.14778/2367502.2367518)
- <Anchor id="page-12-43"/>[43] Harald Lang, Tobias Mühlbauer, Florian Funke, Peter A. Boncz, Thomas Neumann, and Alfons Kemper. 2016. データブロック: 圧縮ストレージを使用したハイブリッドOLTPおよびOLAP (ベクタ化とコンパイルの両方を使用). In Proceedings of the 2016 International Conference on Management of Data (San Francisco, California, USA) (SIGMOD '16). Association for Computing Machinery, New York, NY, USA, 311–326. https://doi.org/10.1145/2882903.2882925
- <Anchor id="page-12-20"/>[44] Viktor Leis, Peter Boncz, Alfons Kemper, and Thomas Neumann. 2014. モーセルドリブンパラレリズム: マルチコア時代のNUMA意識のあるクエリ評価フレームワーク. In Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data (Snowbird, Utah, USA) (SIGMOD '14). Association for Computing Machinery, New York, NY, USA, 743–754. [https://doi.org/10.1145/2588555.](https://doi.org/10.1145/2588555.2610507) [2610507](https://doi.org/10.1145/2588555.2610507)
- <Anchor id="page-13-17"/>[45] Viktor Leis, Alfons Kemper, and Thomas Neumann. 2013. 適応型ラジックスツリー: メインメモリデータベースのためのARTfulインデキシング. In 2013 IEEE 29th International Conference on Data Engineering (ICDE). 38–49. [https://doi.org/10.1109/ICDE.](https://doi.org/10.1109/ICDE.2013.6544812) [2013.6544812](https://doi.org/10.1109/ICDE.2013.6544812)
- <Anchor id="page-13-34"/>[46] Chunwei Liu, Anna Pavlenko, Matteo Interlandi, and Brandon Haynes. 2023. 分析DBMSのための一般的なオープンフォーマットの深堀り. 16, 11 (jul 2023), 3044–3056. https://doi.org/10.14778/3611479.3611507
- <Anchor id="page-13-30"/>[47] Zhenghua Lyu, Huan Hubert Zhang, Gang Xiong, Gang Guo, Haozhou Wang, Jinbao Chen, Asim Praveen, Yu Yang, Xiaoming Gao, Alexandra Wang, Wen Lin, Ashwin Agrawal, Junfeng Yang, Hao Wu, Xiaoliang Li, Feng Guo, Jiang Wu, Jesse Zhang, and Venkatesh Raghavan. 2021. Greenplum: トランザクショナルおよび分析ワークロードのためのハイブリッドデータベース (SIGMOD '21). Association for Computing Machinery, New York, NY, USA, 2530–2542. [https:](https://doi.org/10.1145/3448016.3457562) [//doi.org/10.1145/3448016.3457562](https://doi.org/10.1145/3448016.3457562)
- <Anchor id="page-13-28"/>[48] Roger MacNicol and Blaine French. 2004. Sybase IQ Multiplex - 分析のために設計. In Proceedings of the Thirtieth International Conference on Very Large Data Bases - Volume 30 (Toronto, Canada) (VLDB '04). VLDB Endowment, 1227–1230.
- <Anchor id="page-13-31"/>[49] Sergey Melnik, Andrey Gubarev, Jing Jing Long, Geofrey Romer, Shiva Shivakumar, Matt Tolton, Theo Vassilakis, Hossein Ahmadi, Dan Delorey, Slava Min, Mosha Pasumansky, and Jef Shute. 2020. Dremel: WebスケールでのインタラクティブSQL分析の10年. Proc. VLDB Endow. 13, 12 (aug 2020), 3461–3472. https://doi.org/10.14778/3415478.3415568
- <Anchor id="page-13-2"/>[50] Microsoft. 2024. Kustoクエリ言語. 2024-06-20に[https:](https://github.com/microsoft/Kusto-Query-Language) [//github.com/microsoft/Kusto-Query-Language](https://github.com/microsoft/Kusto-Query-Language)から取得
- <Anchor id="page-13-14"/>[51] Guido Moerkotte. 1998. 小さな物化集計: データウェアハウジングのための軽量インデックス構造. In Proceedings of the 24rd International Conference on Very Large Data Bases (VLDB '98). 476–487.
- <Anchor id="page-13-22"/>[52] Jalal Mostafa, Sara Wehbi, Suren Chilingaryan, and Andreas Kopmann. 2022. SciTS: 科学実験と工業インターネットオブシングスにおける時系列データベースのベンチマーク. In Proceedings of the 34th International Conference on Scientific and Statistical Database Management (SSDBM '22). Article 12. [https:](https://doi.org/10.1145/3538712.3538723) [//doi.org/10.1145/3538712.3538723](https://doi.org/10.1145/3538712.3538723)
- <Anchor id="page-13-0"/>[53] Thomas Neumann. 2011. 現代のハードウェア用の効率的なクエリプランのコンパイル. Proc. VLDB Endow. 4, 9 (jun 2011), 539–550. [https://doi.org/10.14778/](https://doi.org/10.14778/2002938.2002940) [2002938.2002940](https://doi.org/10.14778/2002938.2002940)
- <Anchor id="page-13-25"/>[54] Thomas Neumann and Michael J. Freitag. 2020. Umbra: メモリ内性能を持つディスクベースシステム. In 10th Conference on Innovative Data Systems Research, CIDR 2020, Amsterdam, The Netherlands, January 12-15, 2020, Online Proceedings. www.cidrdb.org. [http://cidrdb.org/cidr2020/papers/p29-neumann](http://cidrdb.org/cidr2020/papers/p29-neumann-cidr20.pdf)[cidr20.pdf](http://cidrdb.org/cidr2020/papers/p29-neumann-cidr20.pdf)
- <Anchor id="page-13-35"/>[55] Thomas Neumann, Tobias Mühlbauer, and Alfons Kemper. 2015. メインメモリデータベースシステムのための高速直列化可能なマルチバージョン同時実行制御. In Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data (Melbourne, Victoria, Australia) (SIGMOD '15). Association for Computing Machinery, New York, NY, USA, 677–689. [https://doi.org/10.1145/2723372.](https://doi.org/10.1145/2723372.2749436) [2749436](https://doi.org/10.1145/2723372.2749436)
- <Anchor id="page-13-8"/>[56] LevelDB on GitHub. 2024. LevelDB. 2024-06-20に[https://github.](https://github.com/google/leveldb) [com/google/leveldb](https://github.com/google/leveldb)から取得
- <Anchor id="page-13-26"/>[57] Patrick O'Neil, Elizabeth O'Neil, Xuedong Chen, and Stephen Revilak. 2009. スターシェマベンチマークと拡張ファクトテーブルインデキシング. In Performance Evaluation and Benchmarking. Springer Berlin Heidelberg, 237–252. [https:](https://doi.org/10.1007/978-3-642-10424-4_17) [//doi.org/10.1007/978-3-642-10424-4_17](https://doi.org/10.1007/978-3-642-10424-4_17)
- <Anchor id="page-13-7"/>[58] Patrick E. O'Neil, Edward Y. C. Cheng, Dieter Gawlick, and Elizabeth J. O'Neil. 1996. ログ構造マージツリー (LSMツリー). Acta Informatica 33 (1996), 351–385. https://doi.org/10.1007/s002360050048
- <Anchor id="page-13-4"/>[59] Diego Ongaro and John Ousterhout. 2014. 理解可能なコンセンサスアルゴリズムの探索. In Proceedings of the 2014 USENIX Conference on USENIX Annual Technical Conference (USENIX ATC'14). 305–320. [https://doi.org/doi/10.](https://doi.org/doi/10.5555/2643634.2643666) [5555/2643634.2643666](https://doi.org/doi/10.5555/2643634.2643666)
- <Anchor id="page-13-3"/>[60] Patrick O'Neil, Edward Cheng, Dieter Gawlick, and Elizabeth O'Neil. 1996. ログ構造マージツリー (LSM-ツリー). Acta Inf. 33, 4 (1996), 351–385. [https:](https://doi.org/10.1007/s002360050048) [//doi.org/10.1007/s002360050048](https://doi.org/10.1007/s002360050048)
- <Anchor id="page-13-5"/>[61] Pandas. 2024. Pandas Dataframes. 2024-06-20に[https://pandas.](https://pandas.pydata.org/) [pydata.org/](https://pandas.pydata.org/)から取得
- <Anchor id="page-13-32"/>[62] Pedro Pedreira, Orri Erling, Masha Basmanova, Kevin Wilfong, Laith Sakka, Krishna Pai, Wei He, and Biswapesh Chattopadhyay. 2022. Velox: メタの統一された実行エンジン. Proc. VLDB Endow. 15, 12 (aug 2022), 3372–3384. [https:](https://doi.org/10.14778/3554821.3554829) [//doi.org/10.14778/3554821.3554829](https://doi.org/10.14778/3554821.3554829)
- <Anchor id="page-13-10"/>[63] Tuomas Pelkonen, Scott Franklin, Justin Teller, Paul Cavallaro, Qi Huang, Justin Meza, and Kaushik Veeraraghavan. 2015. Gorilla: 高速でスケーラブルなメモリ内時系列データベース. Proceedings of the VLDB Endowment 8, 12 (2015), 1816–1827. https://doi.org/10.14778/2824032.2824078
- <Anchor id="page-13-18"/>[64] Orestis Polychroniou, Arun Raghavan, and Kenneth A. Ross. 2015. メモリ内データベースのためのSIMDベクタ化の再考. In Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data (SIGMOD '15). 1493–1508. https://doi.org/10.1145/2723372.2747645
- <Anchor id="page-13-21"/>[65] PostgreSQL. 2024. PostgreSQL - 外部データラッパー. 2024-06-20にhttps://wiki.postgresql.org/wiki/Foreign_data_wrappersから取得
- <Anchor id="page-13-23"/>[66] Mark Raasveldt, Pedro Holanda, Tim Gubner, and Hannes Mühleisen. 2018. 公平なベンチマーキングは難しい: データベースパフォーマンステストにおける一般的な落とし穴. In Proceedings of the Workshop on Testing Database Systems (Houston, TX, USA) (DBTest'18). Article 2, 6ページ. https://doi.org/10.1145/3209950.3209955
- <Anchor id="page-13-6"/>[67] Mark Raasveldt and Hannes Mühleisen. 2019. DuckDB: 埋め込み可能な分析データベース (SIGMOD '19). Association for Computing Machinery, New York, NY, USA, 1981–1984. https://doi.org/10.1145/3299869.3320212
- <Anchor id="page-13-16"/>[68] Jun Rao and Kenneth A. Ross. 1999. メインメモリにおける意思決定支援のためのキャッシュ意識のあるインデキシング. In Proceedings of the 25th International Conference on Very Large Data Bases (VLDB '99). San Francisco, CA, USA, 78–89.
- <Anchor id="page-13-36"/>[69] Navin C. Sabharwal and Piyush Kant Pandey. 2020. Prometheusクエリ言語 (PromQL) の利用. In Monitoring Microservices and Containerized Applications. https://doi.org/10.1007/978-1-4842-6216-0_5
- <Anchor id="page-13-27"/>[70] Todd W. Schneider. 2022. ニューヨーク市タクシーおよび有料車両データ. 2024-06-20にhttps://github.com/toddwschneider/nyc-taxi-dataから取得
- <Anchor id="page-13-13"/>[71] Mike Stonebraker, Daniel J. Abadi, Adam Batkin, Xuedong Chen, Mitch Cherniack, Miguel Ferreira, Edmond Lau, Amerson Lin, Sam Madden, Elizabeth O'Neil, Pat O'Neil, Alex Rasin, Nga Tran, and Stan Zdonik. 2005. C-Store: 列指向DBMS. In Proceedings of the 31st International Conference on Very Large Data Bases (VLDB '05). 553–564.
- <Anchor id="page-13-29"/>[72] Teradata. 2024. Teradata Database. 2024-06-20に[https://www.](https://www.teradata.com/resources/datasheets/teradata-database) [teradata.com/resources/datasheets/teradata-database](https://www.teradata.com/resources/datasheets/teradata-database)から取得
- <Anchor id="page-13-15"/>[73] Frederik Transier. 2010. メモリ内テキスト検索エンジンのためのアルゴリズムとデータ構造. Ph.D. 論文. https://doi.org/10.5445/IR/1000015824
- <Anchor id="page-13-24"/>[74] Adrian Vogelsgesang, Michael Haubenschild, Jan Finis, Alfons Kemper, Viktor Leis, Tobias Muehlbauer, Thomas Neumann, and Manuel Then. 2018. 現実を見ろ: ベンチマークが現実世界を表さない理由. In Proceedings of the Workshop on Testing Database Systems (Houston, TX, USA) (DBTest'18). Article 1, 6ページ. https://doi.org/10.1145/3209950.3209952
- <Anchor id="page-13-9"/>[75] LZ4 website. 2024. LZ4. 2024-06-20にhttps://lz4.org/から取得
- <Anchor id="page-13-11"/><Anchor id="page-13-1"/>[76] PRQL website. 2024. PRQL. 2024-06-20にhttps://prql-lang.orgから取得
- [77] Till Westmann, Donald Kossmann, Sven Helmer, and Guido Moerkotte. 2000. 圧縮データベースの実装とパフォーマンス. SIGMOD Rec.
- <Anchor id="page-13-33"/>29, 3 (sep 2000), 55–67. https://doi.org/10.1145/362084.362137 [78] Fangjin Yang, Eric Tschetter, Xavier Léauté, Nelson Ray, Gian Merlino, and Deep Ganguli. 2014. Druid: リアルタイム分析データストア. In Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data (Snowbird, Utah, USA) (SIGMOD '14). Association for Computing Machinery, New York, NY, USA, 157–168. https://doi.org/10.1145/2588555.2595631
- <Anchor id="page-13-20"/>[79] Tianqi Zheng, Zhibin Zhang, and Xueqi Cheng. 2020. SAHA: 分析データベースのための文字列適応ハッシュテーブル. Applied Sciences 10, 6 (2020). [https:](https://doi.org/10.3390/app10061915) [//doi.org/10.3390/app10061915](https://doi.org/10.3390/app10061915)
- <Anchor id="page-13-19"/>[80] Jingren Zhou and Kenneth A. Ross. 2002. SIMD命令を使用したデータベース操作の実装. In Proceedings of the 2002 ACM SIGMOD International Conference on Management of Data (SIGMOD '02). 145–156. [https://doi.org/10.](https://doi.org/10.1145/564691.564709) [1145/564691.564709](https://doi.org/10.1145/564691.564709)
- <Anchor id="page-13-12"/>[81] Marcin Zukowski, Sandor Heman, Niels Nes, and Peter Boncz. 2006. スーパー・スカラーRAM-CPUキャッシュ圧縮. In Proceedings of the 22nd International Conference on Data Engineering (ICDE '06). 59. [https://doi.org/10.1109/ICDE.](https://doi.org/10.1109/ICDE.2006.150) [2006.150](https://doi.org/10.1109/ICDE.2006.150)
