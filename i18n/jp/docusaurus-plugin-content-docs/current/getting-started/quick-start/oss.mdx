---
'slug': '/getting-started/quick-start/oss'
'sidebar_label': 'OSS'
'sidebar_position': 2
'keywords':
- 'getting started'
- 'quick start'
- 'beginner-friendly'
'title': 'ClickHouse OSS クイックスタート'
'description': 'ClickHouse クイックスタート ガイド'
'show_related_blogs': true
'doc_type': 'guide'
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';
import {VerticalStepper} from '@clickhouse/click-ui/bundled';


# ClickHouse OSS クイックスタート

> このクイックスタートチュートリアルでは、OSS ClickHouse を 8 ステップでセットアップします。適切なバイナリをダウンロードし、ClickHouse サーバーを実行し、ClickHouse クライアントを使用してテーブルを作成し、データを挿入してクエリを実行してそのデータを選択します。

<VerticalStepper>

## ClickHouse をダウンロード {#download-the-binary}

ClickHouse は Linux、FreeBSD と macOS 上でネイティブに動作し、Windows では [WSL](https://learn.microsoft.com/en-us/windows/wsl/about) を介して実行されます。ClickHouse をローカルにダウンロードする最も簡単な方法は、次の `curl` コマンドを実行することです。このコマンドは、オペレーティングシステムがサポートされているかどうかを判断し、適切な ClickHouse バイナリをダウンロードします。

:::note
バイナリがあるディレクトリに最初に ClickHouse サーバーを実行する際にいくつかの構成ファイルが作成されるため、新しい空のサブディレクトリで下のコマンドを実行することをお勧めします。
:::

```bash
curl https://clickhouse.com/ | sh
```

これにより次のように表示されるはずです：

```
Successfully downloaded the ClickHouse binary, you can run it as:
    ./clickhouse

You can also install it:
sudo ./clickhouse install
```

この段階では、`install` コマンドを実行するように言われても無視して構いません。

:::note
Mac ユーザーへ：バイナリの開発者を確認できないというエラーが表示される場合は、["MacOS の開発者検証エラーを修正する"](https://clickhouse.com/docs/knowledgebase/fix-developer-verification-error-in-macos)を参照してください。
:::

## サーバーを起動

次のコマンドを実行して、ClickHouse サーバーを起動します：

```bash
./clickhouse server
```

ターミナルがログ記録で埋まるのを見るはずです。これは予期されることです。ClickHouse では、[デフォルトのログレベル](https://clickhouse.com/docs/knowledgebase/why_default_logging_verbose)が `trace` に設定されています。

## クライアントを起動

`clickhouse-client` を使用して ClickHouse サービスに接続します。新しいターミナルを開き、`clickhouse` バイナリが保存されているディレクトリに移動し、次のコマンドを実行します：

```bash
./clickhouse client
```

サービスが localhost で実行されていると接続され、笑顔の顔が表示されるはずです：

```response
my-host :)
```

## テーブルを作成

`CREATE TABLE` を使用して新しいテーブルを定義します。一般的な SQL DDL コマンドは、ClickHouse でも動作しますが、1 つの追加が必要です - ClickHouse のテーブルには `ENGINE` 句が必要です。ClickHouse のパフォーマンスの利点を活かすために [`MergeTree`](/engines/table-engines/mergetree-family/mergetree) を使用します：

```sql
CREATE TABLE my_first_table
(
    user_id UInt32,
    message String,
    timestamp DateTime,
    metric Float32
)
ENGINE = MergeTree
PRIMARY KEY (user_id, timestamp)
```

## データを挿入

ClickHouse では、慣れ親しんだ `INSERT INTO TABLE` コマンドを使用できますが、`MergeTree` テーブルに挿入するたびに ClickHouse で **part** がストレージに作成されることを理解することが重要です。これらの ^^parts^^ は後で ClickHouse によってバックグラウンドでマージされます。

ClickHouse では、行を一度に多数（数万行または数百万行）バルク挿入することを試み、バックグラウンドプロセスでマージする必要がある [**parts**](/parts) の数を最小限に抑えます。

このガイドでは、まだそのことを心配する必要はありません。次のコマンドを実行して、テーブルにいくつかの行のデータを挿入します：

```sql
INSERT INTO my_first_table (user_id, message, timestamp, metric) VALUES
    (101, 'Hello, ClickHouse!',                                 now(),       -1.0    ),
    (102, 'Insert a lot of rows per batch',                     yesterday(), 1.41421 ),
    (102, 'Sort your data based on your commonly-used queries', today(),     2.718   ),
    (101, 'Granules are the smallest chunks of data read',      now() + 5,   3.14159 )
```

## 新しいテーブルをクエリ

SQL データベースと同様に `SELECT` クエリを記述できます：

```sql
SELECT *
FROM my_first_table
ORDER BY timestamp
```
レスポンスが見やすいテーブル形式で返ってくることに注意してください：

```text
┌─user_id─┬─message────────────────────────────────────────────┬───────────timestamp─┬──metric─┐
│     102 │ Insert a lot of rows per batch                     │ 2022-03-21 00:00:00 │ 1.41421 │
│     102 │ Sort your data based on your commonly-used queries │ 2022-03-22 00:00:00 │   2.718 │
│     101 │ Hello, ClickHouse!                                 │ 2022-03-22 14:04:09 │      -1 │
│     101 │ Granules are the smallest chunks of data read      │ 2022-03-22 14:04:14 │ 3.14159 │
└─────────┴────────────────────────────────────────────────────┴─────────────────────┴─────────┘

4 rows in set. Elapsed: 0.008 sec.
```

## 自分のデータを挿入

次のステップは、自分のデータを ClickHouse に取り込むことです。[table functions](/sql-reference/table-functions/index.md) や [integrations](/integrations) が多数あり、データを取り込むためのサポートがあります。次のタブにいくつかの例がありますが、ClickHouse と統合されている技術の長いリストについては、[Integrations](/integrations) ページを確認できます。

<Tabs groupId="read_data">
    <TabItem value="S3" label="S3" default>

        [`s3` table function](/sql-reference/table-functions/s3.md) を使用して S3 のファイルを読み取ります。これはテーブル関数です - 結果はテーブルであり、次のことができます：

        1. `SELECT` クエリのソースとして使用する（データを S3 に残しながら任意のクエリを実行できます）、または...
        2. `MergeTree` テーブルに結果のテーブルを挿入する（データを ClickHouse に移動する準備ができたとき）

        任意のクエリは次のようになります：

```sql
SELECT
passenger_count,
avg(toFloat32(total_amount))
FROM s3(
'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
'TabSeparatedWithNames'
)
GROUP BY passenger_count
ORDER BY passenger_count;
```

        データを ClickHouse テーブルに移動する場合は、次のようになります。ここで `nyc_taxi` は `MergeTree` テーブルです：

```sql
INSERT INTO nyc_taxi
SELECT * FROM s3(
'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
'TabSeparatedWithNames'
)
SETTINGS input_format_allow_errors_num=25000;
```

        S3 と ClickHouse を使用する際の詳細や例については、[AWS S3 ドキュメントページのコレクション](/integrations/data-ingestion/s3/index.md)を参照してください。
        <br/>
    </TabItem>
    <TabItem value="GCS" label="GCS">

        AWS S3 でのデータの読み取りに使用される [`s3` table function](/sql-reference/table-functions/s3.md) は、Google Cloud Storage のファイルにも適用できます。

        例えば：

```sql
SELECT
*
FROM s3(
'https://storage.googleapis.com/my-bucket/trips.parquet',
'MY_GCS_HMAC_KEY',
'MY_GCS_HMAC_SECRET_KEY',
'Parquet'
)
LIMIT 1000
```

        [`s3` table function page](/sql-reference/table-functions/s3.md) で詳細を見つけてください。
        <br/>
    </TabItem>
    <TabItem value="URL" label="Web">

        [`url` table function](/sql-reference/table-functions/url) は、ウェブからアクセス可能なファイルを読み取ります：

```sql
--By default, ClickHouse prevents redirects to protect from SSRF attacks.
--The URL below requires a redirect, so we must set max_http_get_redirects > 0.
SET max_http_get_redirects=10;

SELECT *
FROM url(
'http://prod2.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv',
'CSV'
);
```

        [`url` table function page](/sql-reference/table-functions/url) で詳細を見つけてください。
        <br/>
    </TabItem>
    <TabItem value="local_file" label="Local">

        [`file` table engine](/sql-reference/table-functions/file) を使用してローカルファイルを読み取ります。簡単にするために、そのファイルを `user_files` ディレクトリにコピーしてください（これは ClickHouse バイナリをダウンロードしたディレクトリにあります）。

```sql
DESCRIBE TABLE file('comments.tsv')

Query id: 8ca9b2f9-65a2-4982-954a-890de710a336

┌─name──────┬─type────────────────────┐
│ id        │ Nullable(Int64)         │
│ type      │ Nullable(String)        │
│ author    │ Nullable(String)        │
│ timestamp │ Nullable(DateTime64(9)) │
│ comment   │ Nullable(String)        │
│ children  │ Array(Nullable(Int64))  │
└───────────┴─────────────────────────┘
```

        ClickHouse は、大量の行を分析することでカラムの名前とデータ型を推測します。ClickHouse がファイル名からファイル形式を特定できない場合は、2 番目の引数として指定できます：

```sql
SELECT count()
FROM file(
'comments.tsv',
'TabSeparatedWithNames'
)
```

        詳細については、[`file` table function](/sql-reference/table-functions/file) のドキュメントページを確認してください。
        <br/>
    </TabItem>
    <TabItem value="PostgreSQL" label="PostgreSQL">

        [`postgresql` table function](/sql-reference/table-functions/postgresql) を使用して、PostgreSQL のテーブルからデータを読み取ります：

```sql
SELECT *
FROM
postgresql(
'localhost:5432',
'my_database',
'my_table',
'postgresql_user',
'password')
;
```

        詳細については、[`postgresql` table function](/sql-reference/table-functions/postgresql) のドキュメントページを参照してください。
        <br/>
    </TabItem>
    <TabItem value="MySQL" label="MySQL">

        [`mysql` table function](/sql-reference/table-functions/mysql) を使用して MySQL のテーブルからデータを読み取ります：

```sql
SELECT *
FROM
mysql(
'localhost:3306',
'my_database',
'my_table',
'mysql_user',
'password')
;
```

        詳細については、[`mysql` table function](/sql-reference/table-functions/mysql) のドキュメントページを参照してください。
        <br/>
    </TabItem>
    <TabItem value="Other DBMS" label="ODBC/JDBC">

        ClickHouse は、任意の ODBC または JDBC データソースからデータを読み取ることができます：

```sql
SELECT *
FROM
odbc(
'DSN=mysqlconn',
'my_database',
'my_table'
);
```

        詳細については、[`odbc` table function](/sql-reference/table-functions/odbc) と [`jdbc` table function](/sql-reference/table-functions/jdbc) のドキュメントページを参照してください。
        <br/>
    </TabItem>
    <TabItem value="messagequeue" label="Message Queues">

        メッセージキューは、対応するテーブルエンジンを使用して ClickHouse にデータをストリーミングできます。これには以下が含まれます：

        - **Kafka**: [`Kafka` table engine](/engines/table-engines/integrations/kafka) を使用して Kafka と統合
        - **Amazon MSK**: [Amazon Managed Streaming for Apache Kafka (MSK)](/integrations/kafka/cloud/amazon-msk/) と統合
        - **RabbitMQ**: [`RabbitMQ` table engine](/engines/table-engines/integrations/rabbitmq) を使用して RabbitMQ と統合
        <br/>
    </TabItem>
    <TabItem value="datalake" label="Data Lakes">

        ClickHouse には、以下のソースからデータを読み取るためのテーブル関数があります：

        - **Hadoop**: [`hdfs` table function](/sql-reference/table-functions/hdfs) を使用して Apache Hadoop と統合
        - **Hudi**: [`hudi` table function](/sql-reference/table-functions/hudi) を使用して S3 の既存の Apache Hudi テーブルから読み取る
        - **Iceberg**: [`iceberg` table function](/sql-reference/table-functions/iceberg) を使用して S3 の既存の Apache Iceberg テーブルから読み取る
        - **DeltaLake**: [`deltaLake` table function](/sql-reference/table-functions/deltalake) を使用して S3 の既存の Delta Lake テーブルから読み取る
        <br/>
    </TabItem>
    <TabItem value="Other" label="Other">

        お使いの既存のフレームワークやデータソースを ClickHouse に接続する方法については、[ClickHouse 統合の長いリスト](/integrations) をチェックしてください。
        <br/>
    </TabItem>
</Tabs>

## 探索

- [Core Concepts](/managing-data/core-concepts) セクションをチェックして、ClickHouse の内部がどのように動作するかの基本を学びましょう。
- [Advanced Tutorial](tutorial.md) をチェックして、ClickHouse の主要な概念と機能をより深く掘り下げて理解しましょう。
- [ClickHouse Academy](https://learn.clickhouse.com/visitor_class_catalog) で提供される無料のオンデマンドトレーニングコースを受けて学び続けてください。
- 挿入方法に関する説明と共に、[example datasets](/getting-started/example-datasets/) のリストがあります。
- 外部ソースからデータが来る場合は、メッセージキュー、データベース、パイプラインなどへの接続に関する [integration guides](/integrations/) のコレクションを参照してください。
- UI/BI ビジュアライゼーションツールを使用している場合は、ClickHouse に UI を接続するための [user guides](/integrations/data-visualization/) をチェックしてください。
- [primary keys](/guides/best-practices/sparse-primary-indexes.md) に関するユーザーガイドは、主キーに関する必要なすべての情報を提供します。

</VerticalStepper>
