---
description: 'この関数は、値 `x` とそれらの繰り返し回数 `y` に基づき、区間 `[min_x, max_x]` 上の度数ヒストグラムをプロットします。'
sidebar_label: 'sparkbar'
slug: /sql-reference/aggregate-functions/reference/sparkbar
title: 'sparkbar'
doc_type: 'reference'
---

{/*AUTOGENERATED_START*/ }

## sparkbar \{#sparkbar\}

導入バージョン: v21.11

この関数は、値 `x` と、その値の出現回数（頻度）を表す `y` に対して、区間 `[min_x, max_x]` 上で度数ヒストグラムをプロットします。
同じバケットに入るすべての `x` の出現回数（頻度）`y` は平均化されるため、データは事前に集約されている必要があります。
`y` の負の値は無視されます。

区間が指定されていない場合、最小の `x` が区間の開始として、最大の `x` が区間の終了として使用されます。
区間が指定されている場合は、その区間外の値は無視されます。

**構文**

```sql
sparkbar(buckets[, min_x, max_x])(x, y)
```

**別名**: `sparkBar`

**パラメータ**

* `buckets` — セグメント数。[`(U)Int*`](/sql-reference/data-types/int-uint)
* `min_x` — 省略可能。区間の開始値。[`(U)Int*`](/sql-reference/data-types/int-uint) または [`Float*`](/sql-reference/data-types/float) または [`Decimal`](/sql-reference/data-types/decimal)
* `max_x` — 省略可能。区間の終了値。[`(U)Int*`](/sql-reference/data-types/int-uint) または [`Float*`](/sql-reference/data-types/float) または [`Decimal`](/sql-reference/data-types/decimal)

**引数**

* `x` — 値を持つフィールド。[`const String`](/sql-reference/data-types/string)
* `y` — 値の頻度を示すフィールド。[`const String`](/sql-reference/data-types/string)

**返される値**

度数ヒストグラムを返します。[`String`](/sql-reference/data-types/string)

**例**

**区間を指定しない場合**

```sql title=Query
CREATE TABLE spark_bar_data (`value` Int64, `event_date` Date) ENGINE = MergeTree ORDER BY event_date;

INSERT INTO spark_bar_data VALUES (1,'2020-01-01'), (3,'2020-01-02'), (4,'2020-01-02'), (-3,'2020-01-02'), (5,'2020-01-03'), (2,'2020-01-04'), (3,'2020-01-05'), (7,'2020-01-06'), (6,'2020-01-07'), (8,'2020-01-08'), (2,'2020-01-11');

SELECT sparkbar(9)(event_date, cnt) FROM (SELECT sum(value) AS cnt, event_date FROM spark_bar_data GROUP BY event_date);
```

```response title=Response
┌─sparkbar(9)(event_date, cnt)─┐
│ ▂▅▂▃▆█  ▂                    │
└──────────────────────────────┘
```

**区間を指定した場合**

```sql title=Query
SELECT sparkbar(9, toDate('2020-01-01'), toDate('2020-01-10'))(event_date, cnt) FROM (SELECT sum(value) AS cnt, event_date FROM spark_bar_data GROUP BY event_date);
```

```response title=Response
┌─sparkbar(9, toDate('2020-01-01'), toDate('2020-01-10'))(event_date, cnt)─┐
│ ▂▅▂▃▇▆█                                                                  │
└──────────────────────────────────────────────────────────────────────────┘
```

{/*AUTOGENERATED_END*/ }
