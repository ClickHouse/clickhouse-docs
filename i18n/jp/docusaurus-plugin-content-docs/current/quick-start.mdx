---
slug: /getting-started/quick-start
sidebar_label: クイックスタート
sidebar_position: 1
keywords: [clickhouse, install, getting started, quick start]
pagination_next: 'getting-started/index'
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

## 概要

ClickHouseのセットアップを迅速に行います。オペレーティングシステムに適したバイナリをダウンロードし、ClickHouseサーバーを起動し、テーブルを作成してデータを挿入し、ClickHouseクライアントを使用してテーブルをクエリします。

### 前提条件

ClickHouseバイナリを取得するために、curlまたは他のコマンドラインHTTPクライアントが必要です。

## バイナリのダウンロード

ClickHouseは、Linux、FreeBSD、macOS上でネイティブに動作し、Windowsでは[WSL](https://learn.microsoft.com/en-us/windows/wsl/about)を介して動作します。ClickHouseをローカルにダウンロードする最も簡単な方法は、以下の`curl`コマンドを実行することです。このコマンドは、使用しているオペレーティングシステムがサポートされているかどうかを判断し、適切なClickHouseバイナリをダウンロードします。

:::note
以下のコマンドは、新しく空のサブディレクトリで実行することをお勧めします。なぜなら、ClickHouseサーバーが初めて実行されるときに、そのバイナリが存在するディレクトリにいくつかの構成ファイルが作成されるからです。
:::

```bash
curl https://clickhouse.com/ | sh
```

次のような表示がされます:

```
ClickHouseバイナリが正常にダウンロードされました。次のように実行できます:
    ./clickhouse

また、インストールもできます:
sudo ./clickhouse install
```

この段階では、`install`コマンドを実行するように促されても無視してかまいません。

:::note
Macユーザーへ: バイナリの開発者が確認できないというエラーが表示される場合は、["macOSでの開発者確認エラーを修正する方法"](https://clickhouse.com/docs/knowledgebase/fix-developer-verification-error-in-macos)を参照してください。
:::


## サーバーを起動する

以下のコマンドを実行して、ClickHouseサーバーを起動します:

```bash
./clickhouse server
```

ターミナルにログが表示され始めるはずです。これは期待される動作です。ClickHouseでは、[デフォルトのログレベル](https://clickhouse.com/docs/knowledgebase/why_default_logging_verbose)が`trace`に設定されています。

## クライアントを起動する

`clickhouse-client`を使用してClickHouseサービスに接続します。新しいターミナルを開き、`clickhouse`バイナリが保存されているディレクトリに移動し、次のコマンドを実行します:

```bash
./clickhouse client
```

サービスに接続すると、以下のように笑顔の絵文字が表示されるはずです:

```response
my-host :)
```

## テーブルを作成する

`CREATE TABLE`を使用して新しいテーブルを定義します。典型的なSQL DDLコマンドはClickHouseでも動作しますが、一つだけ追加があります - ClickHouseのテーブルには`ENGINE`句が必要です。[`MergeTree`](/engines/table-engines/mergetree-family/mergetree)を使用して、ClickHouseのパフォーマンスの利点を活用します:

```sql
CREATE TABLE my_first_table
(
    user_id UInt32,
    message String,
    timestamp DateTime,
    metric Float32
)
ENGINE = MergeTree
PRIMARY KEY (user_id, timestamp)
```

## データを挿入する

ClickHouseでは、既知の`INSERT INTO TABLE`コマンドを使用できますが、`MergeTree`テーブルへの各挿入が、ClickHouse内で**パーツ**が作成されることを理解することが重要です。これらのパーツは、後でClickHouseによってバックグラウンドでマージされます。

ClickHouseでは、一度に大量の行（数万行または数百万行）をバルク挿入して、バックグラウンドプロセスでマージされる必要がある[**パーツ**](/parts)の数を最小限に抑えようとしています。

このガイドでは、それを心配する必要はありません。以下のコマンドを実行して、テーブルに数行のデータを挿入します:

```sql
INSERT INTO my_first_table (user_id, message, timestamp, metric) VALUES
    (101, 'Hello, ClickHouse!',                                 now(),       -1.0    ),
    (102, 'Insert a lot of rows per batch',                     yesterday(), 1.41421 ),
    (102, 'Sort your data based on your commonly-used queries', today(),     2.718   ),
    (101, 'Granules are the smallest chunks of data read',      now() + 5,   3.14159 )
```

## 新しいテーブルをクエリする

他のSQLデータベースと同様に、`SELECT`クエリを書くことができます:

```sql
SELECT *
FROM my_first_table
ORDER BY timestamp
```
結果が美しいテーブル形式で返されることに気付くでしょう:

```response
┌─user_id─┬─message────────────────────────────────────────────┬───────────timestamp─┬──metric─┐
│     102 │ Insert a lot of rows per batch                     │ 2022-03-21 00:00:00 │ 1.41421 │
│     102 │ Sort your data based on your commonly-used queries │ 2022-03-22 00:00:00 │   2.718 │
│     101 │ Hello, ClickHouse!                                 │ 2022-03-22 14:04:09 │      -1 │
│     101 │ Granules are the smallest chunks of data read      │ 2022-03-22 14:04:14 │ 3.14159 │
└─────────┴────────────────────────────────────────────────────┴─────────────────────┴─────────┘

4 rows in set. Elapsed: 0.008 sec.
```

## 自分のデータを挿入する

次のステップは、自分のデータをClickHouseに入れることです。我々はデータを取り込むためにたくさんの[テーブル関数](/sql-reference/table-functions/index.md)や[統合](/integrations)を持っています。下のタブにはいくつかの例がありますが、ClickHouseと統合する技術の長いリストをチェックするために、[統合](/integrations)のページを確認することもできます。

<Tabs groupId="read_data">
<TabItem value="S3" label="S3" default>

[`s3`テーブル関数](/sql-reference/table-functions/s3.md)を使用して、S3からファイルを読み取ります。これはテーブル関数であり、結果は次のように使うことができます:

1. `SELECT`クエリのソースとして使用する（データをS3に保ちながら即席のクエリを実行可能）、または...
2. 結果のテーブルを`MergeTree`テーブルに挿入する（ClickHouseにデータを移動する準備ができたとき）

即席のクエリの例は次のようになります:

```sql
SELECT
   passenger_count,
   avg(toFloat32(total_amount))
FROM s3(
    'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
    'TabSeparatedWithNames'
)
GROUP BY passenger_count
ORDER BY passenger_count;
```

データをClickHouseテーブルに移動する場合は、次のようになります。ここで、`nyc_taxi`は`MergeTree`テーブルです:

```sql
INSERT INTO nyc_taxi
   SELECT * FROM s3(
    'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
    'TabSeparatedWithNames'
)
SETTINGS input_format_allow_errors_num=25000;
```

ClickHouseとS3を使用するための詳細および例については、[AWS S3ドキュメントページのコレクション](/integrations/data-ingestion/s3/index.md)を参照してください。
<br/>
</TabItem>
<TabItem value="GCS" label="GCS">

AWS S3のデータを読み取るのに使われる[`s3`テーブル関数](/sql-reference/table-functions/s3.md)は、Google Cloud Storage内のファイルにも対応しています。

例えば:

```sql
SELECT
   *
FROM s3(
  'https://storage.googleapis.com/my-bucket/trips.parquet',
  'MY_GCS_HMAC_KEY',
  'MY_GCS_HMAC_SECRET_KEY',
  'Parquet'
)
LIMIT 1000
```

[`s3`テーブル関数ページ](/sql-reference/table-functions/s3.md)でさらに詳細を見つけてください。
<br/>
</TabItem>
<TabItem value="URL" label="Web">

[`url`テーブル関数](/sql-reference/table-functions/url)は、ウェブからアクセス可能なファイルを読み取ります:

```sql
--デフォルトでは、ClickHouseはSSRF攻撃を防ぐためにリダイレクトを防止します。
--以下のURLはリダイレクトが必要なので、max_http_get_redirects > 0を設定する必要があります。
SET max_http_get_redirects=10;

SELECT *
FROM url(
    'http://prod2.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv',
    'CSV'
  );
```

[`url`テーブル関数ページ](/sql-reference/table-functions/url)でさらに詳細を見つけてください。
<br/>
</TabItem>
<TabItem value="local_file" label="ローカル">

[`file`テーブルエンジン](/sql-reference/table-functions/file)を使用してローカルファイルを読み取ります。簡単にするために、ファイルをClickHouseバイナリをダウンロードしたディレクトリにある`user_files`ディレクトリにコピーします。

```sql
DESCRIBE TABLE file('comments.tsv')

Query id: 8ca9b2f9-65a2-4982-954a-890de710a336

┌─name──────┬─type────────────────────┬─default_type─┬─default_expression─┬─comment─┬─codec_expression─┬─ttl_expression─┐
│ id        │ Nullable(Int64)         │              │                    │         │                  │                │
│ type      │ Nullable(String)        │              │                    │         │                  │                │
│ author    │ Nullable(String)        │              │                    │         │                  │                │
│ timestamp │ Nullable(DateTime64(9)) │              │                    │         │                  │                │
│ comment   │ Nullable(String)        │              │                    │         │                  │                │
│ children  │ Array(Nullable(Int64))  │              │                    │         │                  │                │
└───────────┴─────────────────────────┴──────────────┴────────────────────┴─────────┴──────────────────┴────────────────┘
```

ClickHouseは大量の行を分析することによって、カラムの名前やデータ型を推測します。ClickHouseがファイル名からストレージタイプを特定できない場合は、2番目の引数としてそれを指定することができます:

```sql
SELECT count()
FROM file(
  'comments.tsv',
  'TabSeparatedWithNames'
)
```

さらに詳細については、[`file`テーブル関数](/sql-reference/table-functions/file)のドキュメントページを参照してください。
<br/>
</TabItem>
<TabItem value="PostgreSQL" label="PostgreSQL">

[`postgresql`テーブル関数](/sql-reference/table-functions/postgresql)を使用して、PostgreSQLのテーブルからデータを読み取ります:

```sql
SELECT *
FROM
   postgresql(
    'localhost:5432',
    'my_database',
    'my_table',
    'postgresql_user',
    'password')
;
```

さらに詳細については、[`postgresql`テーブル関数](/sql-reference/table-functions/postgresql)のドキュメントページを参照してください。
<br/>
</TabItem>
<TabItem value="MySQL" label="MySQL">

[`mysql`テーブル関数](/sql-reference/table-functions/mysql)を使用して、MySQLのテーブルからデータを読み取ります:

```sql
SELECT *
FROM
   mysql(
    'localhost:3306',
    'my_database',
    'my_table',
    'postgresql_user',
    'password')
;
```

さらに詳細については、[`mysql`テーブル関数](/sql-reference/table-functions/mysql)のドキュメントページを参照してください。
<br/>
</TabItem>
<TabItem value="Other DBMS" label="ODBC/JDBC">

ClickHouseは、任意のODBCまたはJDBCデータソースからデータを読み取ることができます:

```sql
SELECT *
FROM
   odbc(
    'DSN=mysqlconn',
    'my_database',
    'my_table'
  );
```

さらに詳細については、[`odbc`テーブル関数](/sql-reference/table-functions/odbc)および[`jdbc`テーブル関数](/sql-reference/table-functions/jdbc)のドキュメントページを参照してください。
<br/>
</TabItem>
<TabItem value="messagequeue" label="メッセージキュー">

メッセージキューは、対応するテーブルエンジンを使用してClickHouseにデータをストリーミングできます。以下を含みます:

- **Kafka**: [`Kafka`テーブルエンジン](/engines/table-engines/integrations/kafka)を使用してKafkaと統合
- **Amazon MSK**: [Amazon Managed Streaming for Apache Kafka (MSK)](/integrations/kafka/cloud/amazon-msk/)との統合
- **RabbitMQ**: [`RabbitMQ`テーブルエンジン](/engines/table-engines/integrations/rabbitmq)を使用してRabbitMQと統合
<br/>
</TabItem>
<TabItem value="datalake" label="データレイク">

ClickHouseには、以下のソースからのデータを読み取るためのテーブル関数があります:

- **Hadoop**: [`hdfs`テーブル関数](/sql-reference/table-functions/hdfs)を使用してApache Hadoopと統合
- **Hudi**: [`hudi`テーブル関数](/sql-reference/table-functions/hudi)を使用してS3内の既存のApache Hudiテーブルから読み取る
- **Iceberg**: [`iceberg`テーブル関数](/sql-reference/table-functions/iceberg)を使用してS3内の既存のApache Icebergテーブルから読み取る
- **DeltaLake**: [`deltaLake`テーブル関数](/sql-reference/table-functions/deltalake)を使用してS3内の既存のDelta Lakeテーブルから読み取る
<br/>
</TabItem>
<TabItem value="Other" label="その他">

我々の[長いClickHouse統合リスト](/integrations)をチェックして、既存のフレームワークやデータソースをClickHouseに接続する方法を見つけてください。
<br/>
</TabItem>
</Tabs>

## 次のステップ

- [コアコンセプト](/managing-data/core-concepts)セクションをチェックして、ClickHouseの基本的な仕組みについて学んでください。
- [高度なチュートリアル](tutorial.md)をチェックして、ClickHouseの主要な概念と機能に深く掘り下げてください。
- [ClickHouse Academy](https://learn.clickhouse.com/visitor_class_catalog)で、無料のオンデマンドトレーニングコースを受講して学び続けてください。
- 挿入方法の指示が含まれた[例データセット](/getting-started/example-datasets/)のリストがあります。
- 外部ソースからデータが来ている場合、メッセージキュー、データベース、パイプラインなどへの接続のための[統合ガイドのコレクション](/integrations/)を参照してください。
- UI/BIビジュアリゼーションツールを使用している場合は、[ClickHouseへのUI接続のユーザーガイド](/integrations/data-visualization/)を確認してください。
- [主キー](/guides/best-practices/sparse-primary-indexes.md)に関するユーザーガイドでは、主キーに関するすべてと、それを定義する方法を知ることができます。
