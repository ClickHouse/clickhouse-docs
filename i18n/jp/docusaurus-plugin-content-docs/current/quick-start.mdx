---
'slug': '/getting-started/quick-start'
'sidebar_label': 'クイックスタート'
'sidebar_position': 1
'keywords':
- 'clickhouse'
- 'install'
- 'getting started'
- 'quick start'
'pagination_next': 'getting-started/index'
'title': 'クイックスタート'
'description': 'ClickHouse クイックスタートガイド'
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';
import {VerticalStepper} from '@clickhouse/click-ui/bundled';

**ClickHouseへようこそ！**

このクイックスタートチュートリアルでは、8つの簡単なステップでセットアップを行います。適切なバイナリをOSにダウンロードし、ClickHouseサーバーを実行する方法を学び、ClickHouseクライアントを使用してテーブルを作成し、データを挿入し、そのデータを選択するクエリを実行します。

さあ、始めましょう？

<VerticalStepper>

## ClickHouseをダウンロードする {#download-the-binary}

ClickHouseは、Linux、FreeBSD、macOS上でネイティブに動作し、Windowsでは[WSL](https://learn.microsoft.com/en-us/windows/wsl/about)を介して実行されます。ClickHouseをローカルにダウンロードする最も簡単な方法は、以下の`curl`コマンドを実行することです。このコマンドは、オペレーティングシステムがサポートされているかどうかを判定し、適切なClickHouseバイナリをダウンロードします。

:::note
以下のコマンドは、新しく空のサブディレクトリから実行することをお勧めします。なぜなら、ClickHouseサーバーが初めて実行されると、バイナリが保存されているディレクトリにいくつかの設定ファイルが作成されるからです。
:::

```bash
curl https://clickhouse.com/ | sh
```

あなたは次のようなメッセージを見るべきです：

```
Successfully downloaded the ClickHouse binary, you can run it as:
    ./clickhouse

You can also install it:
sudo ./clickhouse install
```

この段階では、`install`コマンドを実行するように求められても無視して構いません。

:::note
Macユーザーの皆さんへ：バイナリの開発者を確認できないとのエラーが表示される場合は、["MacOSの開発者認証エラーの修正"](https://clickhouse.com/docs/knowledgebase/fix-developer-verification-error-in-macos)をご覧ください。
:::


## サーバーを起動する

以下のコマンドを実行してClickHouseサーバーを起動します：

```bash
./clickhouse server
```

ターミナルがログで埋まるのを見るはずです。これは予想されることです。ClickHouseでは、[デフォルトのログレベル](https://clickhouse.com/docs/knowledgebase/why_default_logging_verbose)が`trace`に設定されています。

## クライアントを起動する

`clickhouse-client`を使用してClickHouseサービスに接続します。新しいターミナルを開き、`clickhouse`バイナリが保存されているディレクトリに移動して、以下のコマンドを実行します：

```bash
./clickhouse client
```

あなたは、ローカルホストで実行されているサービスに接続する際に、笑顔の顔を見るはずです：

```response
my-host :)
```

## テーブルを作成する

`CREATE TABLE`を使用して新しいテーブルを定義します。典型的なSQLのDDLコマンドはClickHouseでも動作しますが、1つの追加点があります – ClickHouseのテーブルには`ENGINE`句が必要です。ClickHouseのパフォーマンスの利点を利用するために[`MergeTree`](/engines/table-engines/mergetree-family/mergetree)を使用します：

```sql
CREATE TABLE my_first_table
(
    user_id UInt32,
    message String,
    timestamp DateTime,
    metric Float32
)
ENGINE = MergeTree
PRIMARY KEY (user_id, timestamp)
```

## データを挿入する

ClickHouseでは、慣れ親しんだ`INSERT INTO TABLE`コマンドを使用できますが、`MergeTree`テーブルへの各挿入が、ClickHouse内で**part**を作成することを理解することが重要です。これらのパーツは後でClickHouseによってバックグラウンドでマージされます。

ClickHouseでは、バックグラウンドプロセスでマージする必要のある[**parts**](/parts)の数を最小化するために、一度に多くの行（数万または場合によっては数百万）を一括挿入しようとしています。

このガイドでは、そのことについてはまだ心配しません。以下のコマンドを実行して、テーブルに数行のデータを挿入します：

```sql
INSERT INTO my_first_table (user_id, message, timestamp, metric) VALUES
    (101, 'Hello, ClickHouse!',                                 now(),       -1.0    ),
    (102, 'Insert a lot of rows per batch',                     yesterday(), 1.41421 ),
    (102, 'Sort your data based on your commonly-used queries', today(),     2.718   ),
    (101, 'Granules are the smallest chunks of data read',      now() + 5,   3.14159 )
```

## 新しいテーブルをクエリする

他のSQLデータベースと同様に`SELECT`クエリを書くことができます：

```sql
SELECT *
FROM my_first_table
ORDER BY timestamp
```
レスポンスがきれいなテーブル形式で戻ってくることに注意してください：

```text
┌─user_id─┬─message────────────────────────────────────────────┬───────────timestamp─┬──metric─┐
│     102 │ Insert a lot of rows per batch                     │ 2022-03-21 00:00:00 │ 1.41421 │
│     102 │ Sort your data based on your commonly-used queries │ 2022-03-22 00:00:00 │   2.718 │
│     101 │ Hello, ClickHouse!                                 │ 2022-03-22 14:04:09 │      -1 │
│     101 │ Granules are the smallest chunks of data read      │ 2022-03-22 14:04:14 │ 3.14159 │
└─────────┴────────────────────────────────────────────────────┴─────────────────────┴─────────┘

4 rows in set. Elapsed: 0.008 sec.
```

## 自分のデータを挿入する

次のステップは、自分のデータをClickHouseに入れることです。データを取り込むためのたくさんの[テーブル関数](/sql-reference/table-functions/index.md)と[統合](/integrations)があります。以下のタブにいくつかの例がありますが、ClickHouseと統合するテクノロジーの長いリストについては[統合](/integrations)ページをご覧ください。

<Tabs groupId="read_data">
    <TabItem value="S3" label="S3" default>

        [`s3`テーブル関数](/sql-reference/table-functions/s3.md)を使用してS3からファイルを読み取ります。これはテーブル関数であり、結果は次のように使用できます：

        1. `SELECT`クエリのソースとして使用する（これにより、アドホッククエリを実行し、データをS3に保持できます）、または…
        2. 結果のテーブルを`MergeTree`テーブルに挿入します（ClickHouseにデータを移動する準備ができたら）

        アドホッククエリは次のようになります：

```sql
        SELECT
        passenger_count,
        avg(toFloat32(total_amount))
        FROM s3(
        'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
        'TabSeparatedWithNames'
        )
        GROUP BY passenger_count
        ORDER BY passenger_count;
```

        データをClickHouseのテーブルに移動する場合は、次のようになり、`nyc_taxi`は`MergeTree`テーブルです：

```sql
        INSERT INTO nyc_taxi
        SELECT * FROM s3(
        'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
        'TabSeparatedWithNames'
        )
        SETTINGS input_format_allow_errors_num=25000;
```

        S3でClickHouseを使用する際の詳細と例については、[AWS S3ドキュメントページのコレクション](/integrations/data-ingestion/s3/index.md)をご覧ください。
        <br/>
    </TabItem>
    <TabItem value="GCS" label="GCS">

        AWS S3からデータを読み取るために使用される[`s3`テーブル関数](/sql-reference/table-functions/s3.md)は、Google Cloud Storage内のファイルにも対応しています。

        例えば：

```sql
        SELECT
        *
        FROM s3(
        'https://storage.googleapis.com/my-bucket/trips.parquet',
        'MY_GCS_HMAC_KEY',
        'MY_GCS_HMAC_SECRET_KEY',
        'Parquet'
        )
        LIMIT 1000
```

        [`s3`テーブル関数ページ](/sql-reference/table-functions/s3.md)で詳細を確認してください。
        <br/>
    </TabItem>
    <TabItem value="URL" label="Web">

        [`url`テーブル関数](/sql-reference/table-functions/url)は、ウェブからアクセス可能なファイルを読み取ります：

```sql
        --By default, ClickHouse prevents redirects to protect from SSRF attacks.
        --The URL below requires a redirect, so we must set max_http_get_redirects > 0.
        SET max_http_get_redirects=10;

        SELECT *
        FROM url(
        'http://prod2.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv',
        'CSV'
        );
```

        [`url`テーブル関数ページ](/sql-reference/table-functions/url)で詳細を確認してください。
        <br/>
    </TabItem>
    <TabItem value="local_file" label="Local">

        [`file`テーブルエンジン](/sql-reference/table-functions/file)を使用してローカルファイルを読み取ります。簡単にするために、ファイルを`user_files`ディレクトリにコピーします（このディレクトリはClickHouseバイナリをダウンロードしたディレクトリにあります）。

```sql
        DESCRIBE TABLE file('comments.tsv')

        Query id: 8ca9b2f9-65a2-4982-954a-890de710a336

        ┌─name──────┬─type────────────────────┐
        │ id        │ Nullable(Int64)         │
        │ type      │ Nullable(String)        │
        │ author    │ Nullable(String)        │
        │ timestamp │ Nullable(DateTime64(9)) │
        │ comment   │ Nullable(String)        │
        │ children  │ Array(Nullable(Int64))  │
        └───────────┴─────────────────────────┘
```

        ClickHouseは、大きなバッチの行を分析することによって、カラムの名前とデータ型を推測することに注意してください。ファイル名からファイルフォーマットを特定できない場合は、第2引数として指定できます：

```sql
        SELECT count()
        FROM file(
        'comments.tsv',
        'TabSeparatedWithNames'
        )
```

        詳細については、[`file`テーブル関数](/sql-reference/table-functions/file)のドキュメントページをご覧ください。
        <br/>
    </TabItem>
    <TabItem value="PostgreSQL" label="PostgreSQL">

        [`postgresql`テーブル関数](/sql-reference/table-functions/postgresql)を使用して、PostgreSQLのテーブルからデータを読み取ります：

```sql
        SELECT *
        FROM
        postgresql(
        'localhost:5432',
        'my_database',
        'my_table',
        'postgresql_user',
        'password')
        ;
```

        詳細については、[`postgresql`テーブル関数](/sql-reference/table-functions/postgresql)のドキュメントページをご覧ください。
        <br/>
    </TabItem>
    <TabItem value="MySQL" label="MySQL">

        [`mysql`テーブル関数](/sql-reference/table-functions/mysql)を使用して、MySQLのテーブルからデータを読み取ります：

```sql
        SELECT *
        FROM
        mysql(
        'localhost:3306',
        'my_database',
        'my_table',
        'mysql_user',
        'password')
        ;
```

        詳細については、[`mysql`テーブル関数](/sql-reference/table-functions/mysql)のドキュメントページをご覧ください。
        <br/>
    </TabItem>
    <TabItem value="Other DBMS" label="ODBC/JDBC">

        ClickHouseは、任意のODBCまたはJDBCデータソースからデータを読み取ることができます：

```sql
        SELECT *
        FROM
        odbc(
        'DSN=mysqlconn',
        'my_database',
        'my_table'
        );
```

        詳細については、[`odbc`テーブル関数](/sql-reference/table-functions/odbc)と[`jdbc`テーブル関数](/sql-reference/table-functions/jdbc)のドキュメントページをご覧ください。
        <br/>
    </TabItem>
    <TabItem value="messagequeue" label="Message Queues">

        メッセージキューは、対応するテーブルエンジンを使用してClickHouseにデータをストリーミングできます。これには、次のものが含まれます：

        - **Kafka**：[`Kafka`テーブルエンジン](/engines/table-engines/integrations/kafka)を使用してKafkaと統合
        - **Amazon MSK**：[Amazon Managed Streaming for Apache Kafka (MSK)](/integrations/kafka/cloud/amazon-msk/)と統合
        - **RabbitMQ**：[`RabbitMQ`テーブルエンジン](/engines/table-engines/integrations/rabbitmq)を使用してRabbitMQと統合
        <br/>
    </TabItem>
    <TabItem value="datalake" label="Data Lakes">

        ClickHouseは、次のソースからデータを読み取るためのテーブル関数を提供しています：

        - **Hadoop**：[`hdfs`テーブル関数](/sql-reference/table-functions/hdfs)を使用してApache Hadoopと統合
        - **Hudi**：[`hudi`テーブル関数](/sql-reference/table-functions/hudi)を使用してS3内の既存のApache Hudiテーブルから読み取る
        - **Iceberg**：[`iceberg`テーブル関数](/sql-reference/table-functions/iceberg)を使用してS3内の既存のApache Icebergテーブルから読み取る
        - **DeltaLake**：[`deltaLake`テーブル関数](/sql-reference/table-functions/deltalake)を使用してS3内の既存のDelta Lakeテーブルから読み取る
        <br/>
    </TabItem>
    <TabItem value="Other" label="Other">

        既存のフレームワークやデータソースをClickHouseに接続する方法を見つけるために、[ClickHouse統合の長いリスト](/integrations)をご覧ください。
        <br/>
    </TabItem>
</Tabs>

## 探索する

- ClickHouseの仕組みの基礎を学ぶには、[コアコンセプト](/managing-data/core-concepts)セクションをご覧ください。
- ClickHouseの主要な概念や機能について深く掘り下げた[高度なチュートリアル](tutorial.md)をご覧ください。
- [ClickHouse Academy](https://learn.clickhouse.com/visitor_class_catalog)で、無料のオンデマンドトレーニングコースを受講し、学習を続けてください。
- 挿入方法に関する指示を含む[例のデータセット](/getting-started/example-datasets/)のリストがあります。
- 外部ソースからデータが来ている場合は、メッセージキュー、データベース、パイプラインなどへの接続に関する[統合ガイドのコレクション](/integrations/)をご覧ください。
- UI/BI可視化ツールを使用している場合は、ClickHouseにUIを接続するための[ユーザーガイド](/integrations/data-visualization/)を確認してください。
- [主キー](/guides/best-practices/sparse-primary-indexes.md)に関するユーザーガイドは、主キーの定義方法と必要なすべての情報を提供しています。

</VerticalStepper>
