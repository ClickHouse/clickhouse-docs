---
title: 'Управление данными'
description: 'Управление данными для обеспечения наблюдаемости'
slug: /observability/managing-data
keywords: ['observability', 'logs', 'traces', 'metrics', 'OpenTelemetry', 'Grafana', 'OTel']
show_related_blogs: true
doc_type: 'guide'
---

import observability_14 from '@site/static/images/use-cases/observability/observability-14.png';
import Image from '@theme/IdealImage';


# Управление данными

Развертывания ClickHouse для задач наблюдаемости, как правило, работают с большими объемами данных, которыми необходимо управлять. ClickHouse предоставляет ряд возможностей, упрощающих управление данными.



## Разделы

Разбиение на разделы (partitioning) в ClickHouse позволяет логически разделять данные на диске в соответствии со столбцом или SQL-выражением. При таком разделении над каждым разделом можно выполнять операции независимо, например удалять его. Это позволяет пользователям своевременно перемещать разделы, а значит и подмножества данных, между уровнями хранения, а также [удалять устаревшие данные/эффективно удалять данные из кластера](/sql-reference/statements/alter/partition).

Разделение задаётся для таблицы при её первоначальном определении с помощью секции `PARTITION BY`. Эта секция может содержать SQL-выражение над любыми столбцами, результаты которого определяют, в какой раздел будет отправлена строка.

<Image img={observability_14} alt="Разделы" size="md" />

Части данных логически ассоциируются (через общий префикс имени папки) с каждым разделом на диске и могут запрашиваться изолированно. В приведённом ниже примере схема `otel_logs` по умолчанию разбивает данные по дням, используя выражение `toDate(Timestamp)`. По мере вставки строк в ClickHouse это выражение вычисляется для каждой строки, и строка направляется в соответствующий раздел, если он уже существует (если строка первая для дня, раздел будет создан).

```sql
CREATE TABLE default.otel_logs
(
...
)
ENGINE = MergeTree
PARTITION BY toDate(Timestamp)
ORDER BY (ServiceName, SeverityText, toUnixTimestamp(Timestamp), TraceId)
```

С разделами можно выполнять [ряд операций](/sql-reference/statements/alter/partition), включая [создание резервных копий](/sql-reference/statements/alter/partition#freeze-partition), [манипуляции с колонками](/sql-reference/statements/alter/partition#clear-column-in-partition), мутации, [изменяющие](/sql-reference/statements/alter/partition#update-in-partition)/[удаляющие](/sql-reference/statements/alter/partition#delete-in-partition) данные по строкам, и [очистку индексов (например, вторичных индексов)](/sql-reference/statements/alter/partition#clear-index-in-partition).

В качестве примера предположим, что наша таблица `otel_logs` партиционирована по дню. Если заполнить её структурированным набором логов, она будет содержать данные за несколько дней:

```sql
SELECT Timestamp::Date AS day,
         count() AS c
FROM otel_logs
GROUP BY day
ORDER BY c DESC

┌────────day─┬───────c─┐
│ 2019-01-22 │ 2333977 │
│ 2019-01-23 │ 2326694 │
│ 2019-01-26 │ 1986456 │
│ 2019-01-24 │ 1896255 │
│ 2019-01-25 │ 1821770 │
└────────────┴─────────┘

Получено 5 строк. Время выполнения: 0.058 сек. Обработано 10.37 млн строк, 82.92 МБ (177.96 млн строк/с., 1.42 ГБ/с.)
Пиковое использование памяти: 4.41 МиБ.
```

Текущие партиции можно получить с помощью простого запроса к системной таблице:

```sql
SELECT DISTINCT partition
FROM system.parts
WHERE `table` = 'otel_logs'

┌─partition──┐
│ 2019-01-22 │
│ 2019-01-23 │
│ 2019-01-24 │
│ 2019-01-25 │
│ 2019-01-26 │
└────────────┘

5 строк в наборе. Затрачено: 0.005 сек.
```

У нас может быть ещё одна таблица `otel_logs_archive`, которая используется для хранения более старых данных. Данные можно эффективно перемещать в эту таблицу по партициям (это всего лишь изменение метаданных).

```sql
CREATE TABLE otel_logs_archive AS otel_logs
--перенос данных в архивную таблицу
ALTER TABLE otel_logs
        (MOVE PARTITION tuple('2019-01-26') TO TABLE otel_logs_archive
--проверка переноса данных
SELECT
        Timestamp::Date AS day,
        count() AS c
FROM otel_logs
GROUP BY day
ORDER BY c DESC

┌────────day─┬───────c─┐
│ 2019-01-22 │ 2333977 │
│ 2019-01-23 │ 2326694 │
│ 2019-01-24 │ 1896255 │
│ 2019-01-25 │ 1821770 │
└────────────┴─────────┘

Получено 4 строки. Затрачено: 0.051 сек. Обработано 8.38 млн строк, 67.03 МБ (163.52 млн строк/с., 1.31 ГБ/с.)
Пиковое использование памяти: 4.40 МиБ.
```


SELECT Timestamp::Date AS day,
count() AS c
FROM otel&#95;logs&#95;archive
GROUP BY day
ORDER BY c DESC

┌────────day─┬───────c─┐
│ 2019-01-26 │ 1986456 │
└────────────┴─────────┘

1 строка в наборе. Прошло: 0.024 сек. Обработано 1.99 млн строк, 15.89 MB (83.86 млн строк/с, 670.87 MB/с)
Пиковое использование памяти: 4.99 MiB.

````

В отличие от других методов, которые требуют использования `INSERT INTO SELECT` и перезаписи данных в новую целевую таблицу.

:::note Перемещение партиций
[Перемещение партиций между таблицами](/sql-reference/statements/alter/partition#move-partition-to-table) требует выполнения нескольких условий: таблицы должны иметь одинаковую структуру, ключ партиционирования, первичный ключ и индексы/проекции. Подробные указания по заданию партиций в DDL-командах `ALTER` можно найти [здесь](/sql-reference/statements/alter/partition#how-to-set-partition-expression).
:::

Кроме того, данные можно эффективно удалять по партициям. Это гораздо более ресурсоэффективно, чем альтернативные методы (мутации или легковесные удаления), и является предпочтительным способом.

```sql
ALTER TABLE otel_logs
        (DROP PARTITION tuple('2019-01-25'))

SELECT
        Timestamp::Date AS day,
        count() AS c
FROM otel_logs
GROUP BY day
ORDER BY c DESC
┌────────day─┬───────c─┐
│ 2019-01-22 │ 4667954 │
│ 2019-01-23 │ 4653388 │
│ 2019-01-24 │ 3792510 │
└────────────┴─────────┘
````

:::note
Эта возможность используется функциональностью TTL при настройке [`ttl_only_drop_parts=1`](/operations/settings/merge-tree-settings#ttl_only_drop_parts). Подробности см. в разделе [Управление данными с помощью TTL](#data-management-with-ttl-time-to-live).
:::

### Применение

Приведённый выше пример демонстрирует, как данные могут эффективно переноситься и обрабатываться по партициям. На практике пользователи чаще всего будут использовать операции с партициями в сценариях наблюдаемости для двух случаев:

* **Многоуровневые архитектуры** — перенос данных между уровнями хранилища (см. [Уровни хранилища](#storage-tiers)), что позволяет строить архитектуры типа hot-cold.
* **Эффективное удаление** — когда данные достигают заданного TTL (см. [Управление данными с помощью TTL](#data-management-with-ttl-time-to-live))

Ниже мы подробно рассмотрим оба этих случая.

### Производительность запросов

Хотя партиции могут помочь с производительностью запросов, это сильно зависит от характера доступа к данным. Если запросы нацелены только на несколько партиций (в идеале одну), производительность потенциально может улучшиться. Это обычно полезно только в том случае, если ключ партиционирования не входит в первичный ключ и вы фильтруете по нему. Однако запросы, которым необходимо охватить множество партиций, могут работать медленнее, чем при отсутствии партиционирования (так как потенциально может быть больше кусков данных — parts). Преимущество нацеливания запросов на одну партицию будет менее заметным или вовсе отсутствовать, если ключ партиционирования уже является ранним столбцом в первичном ключе. Партиционирование также может использоваться для [оптимизации запросов с GROUP BY](/engines/table-engines/mergetree-family/custom-partitioning-key#group-by-optimisation-using-partition-key), если значения в каждой партиции уникальны. Однако в общем случае пользователям следует в первую очередь оптимизировать первичный ключ и рассматривать партиционирование как технику оптимизации запросов только в исключительных случаях, когда характер доступа предполагает обращение к конкретному предсказуемому подмножеству данных, например, партиционирование по дням при большинстве запросов к данным за последний день. Пример такого поведения приведён [здесь](https://medium.com/datadenys/using-partitions-in-clickhouse-3ea0decb89c4).


## Управление данными с помощью TTL (Time-to-live)

Time-to-Live (TTL) — ключевая функция в решениях для наблюдаемости на базе ClickHouse, обеспечивающая эффективное хранение и управление данными, особенно с учётом того, что огромные объёмы данных непрерывно генерируются. Реализация TTL в ClickHouse обеспечивает автоматическое истечение срока хранения и удаление устаревших данных, гарантируя оптимальное использование хранилища и поддержание производительности без ручного вмешательства. Эта возможность критична для поддержания компактности базы данных, снижения затрат на хранение и того, чтобы запросы оставались быстрыми и эффективными, фокусируясь на наиболее релевантных и свежих данных. Кроме того, она помогает соблюдать политики хранения данных за счёт систематического управления жизненным циклом данных, повышая общую устойчивость и масштабируемость решения для наблюдаемости.

TTL в ClickHouse может задаваться как на уровне таблицы, так и на уровне отдельных столбцов.

### TTL на уровне таблицы

Схема по умолчанию как для логов, так и для трейсов включает TTL для удаления данных по истечении заданного периода. Он задаётся в ClickHouse exporter под ключом `ttl`, например:

```yaml
exporters:
 clickhouse:
   endpoint: tcp://localhost:9000?dial_timeout=10s&compress=lz4&async_insert=1
   ttl: 72h
```

Этот синтаксис в настоящее время поддерживает [синтаксис продолжительностей Golang](https://pkg.go.dev/time#ParseDuration). **Мы рекомендуем использовать суффикс `h` и следить за тем, чтобы он соответствовал периоду партиционирования. Например, если вы партиционируете по дням, убедитесь, что значение кратно суткам, например 24h, 48h, 72h.** Это автоматически гарантирует, что к таблице будет добавлено условие TTL, например, если `ttl: 96h`.

```sql
PARTITION BY toDate(Timestamp)
ORDER BY (ServiceName, SpanName, toUnixTimestamp(Timestamp), TraceId)
TTL toDateTime(Timestamp) + toIntervalDay(4)
SETTINGS ttl_only_drop_parts = 1
```

По умолчанию данные с истекшим TTL удаляются, когда ClickHouse [объединяет части данных](/engines/table-engines/mergetree-family/mergetree#mergetree-data-storage). Когда ClickHouse обнаруживает, что срок действия данных истек, он выполняет внеплановое слияние.

:::note Scheduled TTLs
TTL не применяется немедленно, а запускается по расписанию, как указано выше. Настройка таблицы MergeTree `merge_with_ttl_timeout` задает минимальную задержку в секундах перед повторным выполнением слияния с TTL на удаление. Значение по умолчанию — 14400 секунд (4 часа). Но это только минимальная задержка — может пройти больше времени, прежде чем будет запущено слияние по TTL. Если значение слишком маленькое, будет выполняться много внеплановых слияний, которые могут потреблять большое количество ресурсов. Принудительно запустить применение TTL можно командой `ALTER TABLE my_table MATERIALIZE TTL`.
:::

**Важно: мы рекомендуем использовать настройку [`ttl_only_drop_parts=1`](/operations/settings/merge-tree-settings#ttl_only_drop_parts)** (применяется схемой по умолчанию). Когда эта настройка включена, ClickHouse удаляет целую часть, если все строки в ней истекли. Удаление целых частей вместо частичной очистки строк с истекшим TTL (достигаемой за счет ресурсоемких мутаций при `ttl_only_drop_parts=0`) позволяет использовать более короткие значения `merge_with_ttl_timeout` и снижает влияние на производительность системы. Если данные разбиты на партиции по той же единице, по которой вы выполняете истечение TTL, например по дню, части будут естественным образом содержать данные только из заданного интервала. Это обеспечит эффективное применение `ttl_only_drop_parts=1`.

### TTL на уровне столбца

В приведенном выше примере срок действия данных задается на уровне таблицы. Пользователи также могут задавать истечение данных на уровне столбца. По мере устаревания данных это можно использовать для удаления столбцов, ценность которых для расследований не оправдывает затраты ресурсов на их хранение. Например, мы рекомендуем сохранять столбец `Body` на случай, если будут добавлены новые динамические метаданные, которые не были извлечены во время вставки, например новая метка Kubernetes. По прошествии некоторого времени, например 1 месяца, может стать очевидно, что эта дополнительная метаинформация не полезна — следовательно, ценность хранения столбца `Body` ограничена.

Ниже показано, как столбец `Body` может быть удален через 30 дней.

```sql
CREATE TABLE otel_logs_v2
(
        `Body` String TTL Timestamp + INTERVAL 30 DAY,
        `Timestamp` DateTime,
        ...
)
ENGINE = MergeTree
ORDER BY (ServiceName, Timestamp)
```

:::note
Чтобы задать TTL на уровне отдельного столбца, пользователи должны определить собственную схему. Это нельзя настроить в OTel collector.
:::


## Повторное сжатие данных

Хотя мы обычно рекомендуем использовать `ZSTD(1)` для наборов данных наблюдаемости, пользователи могут поэкспериментировать с другими алгоритмами сжатия или более высокими уровнями, например `ZSTD(3)`. Помимо задания этого параметра при создании схемы, сжатие можно настроить так, чтобы оно изменялось по истечении заданного периода. Это может быть уместно, если кодек или алгоритм сжатия обеспечивает лучшее сжатие, но приводит к снижению производительности запросов. Такой компромисс может быть приемлем для старых данных, к которым обращаются реже, но не для свежих данных, которые чаще используются при расследованиях.

Пример этого показан ниже: мы сжимаем данные с помощью `ZSTD(3)` через 4 дня вместо того, чтобы удалять их.

```sql
CREATE TABLE default.otel_logs_v2
(
        `Body` String,
        `Timestamp` DateTime,
        `ServiceName` LowCardinality(String),
        `Status` UInt16,
        `RequestProtocol` LowCardinality(String),
        `RunTime` UInt32,
        `Size` UInt32,
        `UserAgent` String,
        `Referer` String,
        `RemoteUser` String,
        `RequestType` LowCardinality(String),
        `RequestPath` String,
        `RemoteAddress` IPv4,
        `RefererDomain` String,
        `RequestPage` String,
        `SeverityText` LowCardinality(String),
        `SeverityNumber` UInt8,
)
ENGINE = MergeTree
ORDER BY (ServiceName, Timestamp)
TTL Timestamp + INTERVAL 4 DAY RECOMPRESS CODEC(ZSTD(3))
```

:::note Оценка производительности
Мы рекомендуем всегда оценивать влияние различных уровней и алгоритмов сжатия как на производительность вставки, так и на производительность выполнения запросов. Например, дельта‑кодеки могут быть полезны для сжатия временных меток. Однако если они являются частью первичного ключа, производительность фильтрации может ухудшиться.
:::

Дополнительные сведения и примеры по настройке TTL можно найти [здесь](/engines/table-engines/mergetree-family/mergetree#table_engine-mergetree-multiple-volumes). Примеры того, как можно добавлять и изменять TTL для таблиц и столбцов, можно найти [здесь](/engines/table-engines/mergetree-family/mergetree#table_engine-mergetree-ttl). О том, как TTL позволяет реализовывать иерархии хранения, такие как архитектуры с горячим и тёплым уровнями, см. раздел [Storage tiers](#storage-tiers).


## Уровни хранилища {#storage-tiers}

В ClickHouse пользователи могут создавать уровни хранилища на разных дисках, например, горячие/актуальные данные на SSD и более старые данные в S3. Такая архитектура позволяет использовать более дешёвое хранилище для старых данных, для которых допустимы более высокие значения SLA по времени выполнения запросов из-за их редкого использования при расследованиях.

:::note Не относится к ClickHouse Cloud
ClickHouse Cloud использует единственную копию данных в S3 с кэшами узлов на SSD. Поэтому уровни хранилища в ClickHouse Cloud не требуются.
:::

Создание уровней хранилища предполагает предварительное создание дисков, которые затем используются для формирования политик хранения с томами, указываемыми при создании таблицы. Данные могут автоматически перемещаться между дисками на основе уровня заполнения, размеров частей и приоритетов томов. Дополнительные сведения можно найти [здесь](/engines/table-engines/mergetree-family/mergetree#table_engine-mergetree-multiple-volumes).

Хотя данные можно вручную перемещать между дисками с помощью команды `ALTER TABLE MOVE PARTITION`, перемещение данных между томами также может контролироваться с помощью TTL. Полный пример приведён [здесь](/guides/developer/ttl#implementing-a-hotwarmcold-architecture).



## Управление изменениями схемы

Схемы логов и трейсов неизбежно будут меняться в течение жизненного цикла системы, например, когда пользователи начинают мониторить новые системы с иными метаданными или метками подов. При генерации данных в соответствии со схемой OTel и сохранении исходных событий в структурированном формате схемы ClickHouse будут устойчивы к этим изменениям. Однако по мере появления новых метаданных и изменения шаблонов выполнения запросов пользователям потребуется обновлять схемы, чтобы отразить эти изменения.

Чтобы избежать простоя во время изменений схемы, у пользователей есть несколько вариантов, которые мы приводим ниже.

### Использовать значения по умолчанию

Столбцы могут быть добавлены в схему с использованием значений [`DEFAULT`](/sql-reference/statements/create/table#default). Указанное значение по умолчанию будет использоваться, если оно не задано при выполнении INSERT.

Изменения схемы могут быть внесены до изменения логики преобразования материализованного представления или конфигурации OTel collector, которые приводят к отправке этих новых столбцов.

После изменения схемы пользователи могут перенастроить OTel collectors. Предполагая, что пользователи используют рекомендуемый процесс, описанный в разделе [&quot;Извлечение структуры с помощью SQL&quot;](/docs/use-cases/observability/schema-design#extracting-structure-with-sql), когда OTel collectors отправляют свои данные в движок таблицы Null, а материализованное представление отвечает за извлечение целевой схемы и отправку результатов в целевую таблицу для хранения, представление можно изменить с помощью [синтаксиса `ALTER TABLE ... MODIFY QUERY`](/sql-reference/statements/alter/view). Предположим, что у нас есть целевая таблица ниже с соответствующим материализованным представлением (аналогичным используемому в &quot;Извлечении структуры с помощью SQL&quot;) для извлечения целевой схемы из структурированных логов OTel:

```sql
CREATE TABLE default.otel_logs_v2
(
        `Body` String,
        `Timestamp` DateTime,
        `ServiceName` LowCardinality(String),
        `Status` UInt16,
        `RequestProtocol` LowCardinality(String),
        `RunTime` UInt32,
        `UserAgent` String,
        `Referer` String,
        `RemoteUser` String,
        `RequestType` LowCardinality(String),
        `RequestPath` String,
        `RemoteAddress` IPv4,
        `RefererDomain` String,
        `RequestPage` String,
        `SeverityText` LowCardinality(String),
        `SeverityNumber` UInt8
)
ENGINE = MergeTree
ORDER BY (ServiceName, Timestamp)

CREATE MATERIALIZED VIEW otel_logs_mv TO otel_logs_v2 AS
SELECT
        Body,
        Timestamp::DateTime AS Timestamp,
        ServiceName,
        LogAttributes['status']::UInt16 AS Status,
        LogAttributes['request_protocol'] AS RequestProtocol,
        LogAttributes['run_time'] AS RunTime,
        LogAttributes['user_agent'] AS UserAgent,
        LogAttributes['referer'] AS Referer,
        LogAttributes['remote_user'] AS RemoteUser,
        LogAttributes['request_type'] AS RequestType,
        LogAttributes['request_path'] AS RequestPath,
        LogAttributes['remote_addr'] AS RemoteAddress,
        domain(LogAttributes['referer']) AS RefererDomain,
        path(LogAttributes['request_path']) AS RequestPage,
        multiIf(Status::UInt64 > 500, 'CRITICAL', Status::UInt64 > 400, 'ERROR', Status::UInt64 > 300, 'WARNING', 'INFO') AS SeverityText,
        multiIf(Status::UInt64 > 500, 20, Status::UInt64 > 400, 17, Status::UInt64 > 300, 13, 9) AS SeverityNumber
FROM otel_logs
```

Предположим, что мы хотим добавить новый столбец `Size`, получаемый из `LogAttributes`. Мы можем добавить его в схему таблицы с помощью `ALTER TABLE`, указав значение по умолчанию:

```sql
ALTER TABLE otel_logs_v2
        (ADD COLUMN `Size` UInt64 DEFAULT JSONExtractUInt(Body, 'size'))
```

В приведённом выше примере мы указываем значение по умолчанию, используя ключ `size` в `LogAttributes` (оно будет равно 0, если ключ не существует). Это означает, что запросы, обращающиеся к этому столбцу для строк, в которых значение не было вставлено, должны обращаться к Map и, следовательно, будут выполняться медленнее. Мы также могли бы без труда указать это значение как константу, например 0, снижая затраты на выполнение последующих запросов к строкам, в которых значение отсутствует. Запрос к этой таблице показывает, что значение заполняется из Map в точном соответствии с ожиданиями:

```sql
SELECT Size
FROM otel_logs_v2
LIMIT 5
┌──Size─┐
│ 30577 │
│  5667 │
│  5379 │
│  1696 │
│ 41483 │
└───────┘

5 строк в наборе. Затрачено: 0.012 сек.
```


Чтобы гарантировать, что это значение будет вставляться во все последующие данные, мы можем изменить наше материализованное представление с помощью оператора `ALTER TABLE`, как показано ниже:

```sql
ALTER TABLE otel_logs_mv
        MODIFY QUERY
SELECT
        Body,
        Timestamp::DateTime AS Timestamp,
        ServiceName,
        LogAttributes['status']::UInt16 AS Status,
        LogAttributes['request_protocol'] AS RequestProtocol,
        LogAttributes['run_time'] AS RunTime,
        LogAttributes['size'] AS Size,
        LogAttributes['user_agent'] AS UserAgent,
        LogAttributes['referer'] AS Referer,
        LogAttributes['remote_user'] AS RemoteUser,
        LogAttributes['request_type'] AS RequestType,
        LogAttributes['request_path'] AS RequestPath,
        LogAttributes['remote_addr'] AS RemoteAddress,
        domain(LogAttributes['referer']) AS RefererDomain,
        path(LogAttributes['request_path']) AS RequestPage,
        multiIf(Status::UInt64 > 500, 'CRITICAL', Status::UInt64 > 400, 'ERROR', Status::UInt64 > 300,                 'WARNING', 'INFO') AS SeverityText,
        multiIf(Status::UInt64 > 500, 20, Status::UInt64 > 400, 17, Status::UInt64 > 300, 13, 9) AS SeverityNumber
FROM otel_logs
```

Последующие строки будут иметь заполненный столбец `Size` при вставке.

### Создание новых таблиц

В качестве альтернативы описанному выше процессу пользователи могут просто создать новую целевую таблицу с новой схемой. Любые материализованные представления затем можно изменить так, чтобы они использовали новую таблицу, с помощью вышеупомянутой команды `ALTER TABLE MODIFY QUERY.` При таком подходе пользователи могут версионировать свои таблицы, например `otel_logs_v3`.

В результате у пользователей остается несколько таблиц для выполнения запросов. Чтобы выполнять запросы по нескольким таблицам, пользователи могут использовать [функцию `merge`](/sql-reference/table-functions/merge), которая принимает шаблоны с подстановочными символами в имени таблицы. Ниже мы демонстрируем это, выполняя запрос к версиям v2 и v3 таблицы `otel_logs`:

```sql
SELECT Status, count() AS c
FROM merge('otel_logs_v[2|3]')
GROUP BY Status
ORDER BY c DESC
LIMIT 5

┌─Status─┬────────c─┐
│   200  │ 38319300 │
│   304  │  1360912 │
│   302  │   799340 │
│   404  │   420044 │
│   301  │   270212 │
└────────┴──────────┘

5 строк в наборе. Затрачено: 0.137 сек. Обработано 41.46 миллионов строк, 82.92 МБ (302.43 миллионов строк/сек., 604.85 МБ/сек.)
```

Если нужно обойтись без использования функции `merge` и при этом предоставить конечным пользователям единую таблицу, объединяющую несколько таблиц, можно использовать [движок таблиц Merge](/engines/table-engines/special/merge). Ниже показано, как это сделать:

```sql
CREATE TABLE otel_logs_merged
ENGINE = Merge('default', 'otel_logs_v[2|3]')

SELECT Status, count() AS c
FROM otel_logs_merged
GROUP BY Status
ORDER BY c DESC
LIMIT 5

┌─Status─┬────────c─┐
│   200  │ 38319300 │
│   304  │  1360912 │
│   302  │   799340 │
│   404  │   420044 │
│   301  │   270212 │
└────────┴──────────┘

5 rows in set. Elapsed: 0.073 sec. Processed 41.46 million rows, 82.92 MB (565.43 million rows/s., 1.13 GB/s.)
```

Это можно обновлять при добавлении новой таблицы, используя синтаксис `EXCHANGE` для таблиц. Например, чтобы добавить таблицу версии v4, мы можем создать новую таблицу и атомарно подменить предыдущую версию новой.

```sql
CREATE TABLE otel_logs_merged_temp
ENGINE = Merge('default', 'otel_logs_v[2|3|4]')

EXCHANGE TABLE otel_logs_merged_temp AND otel_logs_merged

SELECT Status, count() AS c
FROM otel_logs_merged
GROUP BY Status
ORDER BY c DESC
LIMIT 5
```


┌─Status─┬────────c─┐
│   200  │ 39259996 │
│   304  │  1378564 │
│   302  │   820118 │
│   404  │   429220 │
│   301  │   276960 │
└────────┴──────────┘

5 строк в наборе. Прошло: 0.068 сек. Обработано 42,46 миллиона строк, 84,92 МБ (620,45 миллиона строк/с., 1,24 ГБ/с.)

```
```
