---
slug: /use-cases/observability/clickstack/performance_tuning
title: 'ClickStack - Настройка производительности'
sidebar_label: 'Настройка производительности'
description: 'Настройка производительности для ClickStack — стек обсервабилити ClickHouse'
doc_type: 'guide'
keywords: ['clickstack', 'обсервабилити', 'logs', 'performance', 'optimization']
---

import BetaBadge from '@theme/badges/BetaBadge';
import materializedViewDiagram from '@site/static/images/materialized-view/materialized-view-diagram.png';
import trace_filtering from '@site/static/images/clickstack/performance_guide/trace_filtering.png';
import trace_filtering_v2 from '@site/static/images/clickstack/performance_guide/trace_filtering_v2.png';
import select_merge_table from '@site/static/images/clickstack/performance_guide/select_merge_table.png';

import Image from '@theme/IdealImage';


## Введение \{#introduction\}

В данном руководстве рассматриваются наиболее распространённые и эффективные оптимизации производительности ClickStack, достаточные для оптимизации большинства реальных обсервабилити-нагрузок, обычно до десятков терабайт данных в день.

Оптимизации представлены в продуманном порядке: начиная с самых простых и дающих наибольший эффект приёмов и переходя к более продвинутой и специализированной настройке. Начальные оптимизации следует применять в первую очередь — зачастую они сами по себе дают существенный прирост производительности. По мере роста объёмов данных и усложнения нагрузок последующие приёмы становятся всё более целесообразными для применения.

## Концепции ClickHouse \{#clickhouse-concepts\}

Прежде чем применять какие‑либо оптимизации, описанные в этом руководстве, важно познакомиться с несколькими базовыми концепциями ClickHouse.

В ClickStack каждый **источник данных напрямую сопоставляется с одной или несколькими таблицами ClickHouse**. При использовании OpenTelemetry ClickStack создаёт и управляет набором таблиц по умолчанию, которые хранят логи, трейсы и метрики. Если вы используете пользовательские схемы или управляете собственными таблицами, вы, вероятно, уже знакомы с этими концепциями. Однако если вы просто отправляете данные через коллектор OpenTelemetry, эти таблицы создаются автоматически, и именно к ним будут применяться все описанные ниже оптимизации.

| Тип данных                              | Таблица                                                                                                                |
|-----------------------------------------|------------------------------------------------------------------------------------------------------------------------|
| Логи                                    | [otel_logs](/use-cases/observability/clickstack/ingesting-data/schemas#logs)                                          |
| Трейсы                                  | [otel_traces](/use-cases/observability/clickstack/ingesting-data/schemas#traces)                                      |
| Метрики (gauge)                         | [otel_metrics_gauge](/use-cases/observability/clickstack/ingesting-data/schemas#gauge)                                |
| Метрики (суммы)                         | [otel_metrics_sum](/use-cases/observability/clickstack/ingesting-data/schemas#sum)                                    |
| Метрики (гистограмма)                   | [otel_metrics_histogram](/use-cases/observability/clickstack/ingesting-data/schemas#histogram)                        |
| Метрики (экспоненциальные гистограммы) | [otel_metrics_exponentialhistogram](/use-cases/observability/clickstack/ingesting-data/schemas#exponential-histograms) |
| Метрики (summary)                       | [otel_metrics_summary](/use-cases/observability/clickstack/ingesting-data/schemas#summary-table)                      |
| Сессии                                  | [hyperdx_sessions](/use-cases/observability/clickstack/ingesting-data/schemas#sessions)                               |

Таблицы привязываются к [базам данных](/sql-reference/statements/create/database) в ClickHouse. По умолчанию используется база данных `default` — это можно [изменить в коллекторе OpenTelemetry](/use-cases/observability/clickstack/config#otel-collector).

:::important Фокус на логах и трейcах
В большинстве случаев настройка производительности фокусируется на таблицах логов и трейсов. Хотя таблицы метрик можно оптимизировать для фильтрации, их схемы намеренно ориентированы на нагрузки в стиле Prometheus и обычно не требуют изменений для стандартной визуализации. Логи и трейсы, напротив, поддерживают более широкий спектр шаблонов доступа и поэтому сильнее всего выигрывают от оптимизации. Данные сессий имеют фиксированный пользовательский опыт, и их схема редко нуждается в изменениях.
:::

Как минимум, вам следует понимать следующие базовые принципы ClickHouse:

| Концепция | Описание |
|----------|----------|
| **Таблицы** | Как источники данных в ClickStack соответствуют базовым таблицам ClickHouse. Таблицы в ClickHouse в основном используют движок [MergeTree](/engines/table-engines/mergetree-family/mergetree). |
| **Части** | Как данные записываются в неизменяемые части и со временем сливаются. |
| **Партиции** | Партиции группируют части данных таблицы в организованные логические единицы. Эти единицы проще администрировать, запрашивать и оптимизировать. |
| **Слияния (merges)** | Внутренний процесс, который объединяет части, чтобы уменьшить их количество, по которым нужно выполнять запрос. Критически важен для поддержания производительности запросов. |
| **Гранулы** | Наименьшая единица данных, которую ClickHouse читает и отбрасывает (prune) во время выполнения запроса. |
| **Первичные (упорядочивающие) ключи** | Как ключ `ORDER BY` определяет расположение данных на диске, степень сжатия и отбрасывание данных при выполнении запросов. |

Эти концепции лежат в основе производительности ClickHouse. Они определяют, как данные записываются, как они структурированы на диске и насколько эффективно ClickHouse может пропускать чтение данных во время выполнения запроса. Каждая оптимизация в этом руководстве — будь то материализованные столбцы, индексы пропуска данных, первичные ключи, проекции или materialized view — опирается на эти ключевые механизмы.

Рекомендуется ознакомиться со следующей документацией ClickHouse перед началом тюнинга:

- [Создание таблиц в ClickHouse](/guides/creating-tables) — простое введение в таблицы.
- [Части](/parts)
- [Партиции](/partitions)
- [Слияния](/merges)
- [Первичные ключи/индексы](/primary-indexes)
- [Как ClickHouse хранит данные: части и гранулы](/guides/best-practices/sparse-primary-indexes) — более продвинутое руководство по тому, как данные структурируются и запрашиваются в ClickHouse, с детальным разбором гранул и первичных ключей.
- [MergeTree](/engines/table-engines/mergetree-family/mergetree) — продвинутое справочное руководство по MergeTree, полезное для команд и понимания внутренних деталей.

Все описанные ниже оптимизации можно применять непосредственно к базовым таблицам, используя стандартный SQL ClickHouse — либо через [консоль SQL в ClickHouse Cloud](/integrations/sql-clients/sql-console), либо через [клиент ClickHouse](/interfaces/cli).

## Оптимизация 1. Материализация часто запрашиваемых атрибутов \{#materialize-frequently-queried-attributes\}

Первая и самая простая оптимизация для пользователей ClickStack — определить часто запрашиваемые атрибуты в `LogAttributes`, `ScopeAttributes` и `ResourceAttributes` и вынести их в отдельные столбцы верхнего уровня с помощью материализованных столбцов.

Одна только эта оптимизация часто бывает достаточной, чтобы масштабировать развертывания ClickStack до десятков терабайт в день, и её следует применять прежде, чем переходить к более продвинутым методам настройки.

### Зачем материализовать атрибуты \{#why-materialize-attributes\}

ClickStack хранит метаданные, такие как Kubernetes-метки, метаданные сервисов и пользовательские атрибуты, в столбцах типа `Map(String, String)`. Хотя это обеспечивает гибкость, выполнение запросов к отдельным ключам внутри Map-столбца имеет важные последствия для производительности.

При запросе одного ключа из Map-столбца ClickHouse должен прочитать весь этот столбец с диска. Если карта содержит много ключей, это приводит к лишним операциям ввода-вывода и более медленным запросам по сравнению с чтением выделенного столбца.

Материализация часто запрашиваемых атрибутов устраняет эти издержки, извлекая значение во время вставки и сохраняя его как отдельный столбец.

Материализованные столбцы:

- Вычисляются автоматически во время вставок
- Не могут быть явно заданы в командах INSERT
- Поддерживают любые выражения ClickHouse
- Позволяют конвертировать тип из String в более эффективные числовые или типы дат
- Позволяют использовать пропускающие индексы и первичный ключ
- Сокращают чтение с диска за счёт избегания полного доступа к карте

:::note
ClickStack автоматически обнаруживает материализованные столбцы, извлечённые из карт, и прозрачно использует их при выполнении запросов, даже когда пользователи продолжают запрашивать исходный путь к атрибуту.
:::

### Пример \{#materialize-column-example\}

Рассмотрим стандартную схему ClickStack для трейсов, в которой метаданные Kubernetes сохраняются в `ResourceAttributes`:

```sql
CREATE TABLE IF NOT EXISTS otel_traces
(
    `Timestamp` DateTime64(9) CODEC(Delta(8), ZSTD(1)),
    `TraceId` String CODEC(ZSTD(1)),
    `SpanId` String CODEC(ZSTD(1)),
    `ParentSpanId` String CODEC(ZSTD(1)),
    `TraceState` String CODEC(ZSTD(1)),
    `SpanName` LowCardinality(String) CODEC(ZSTD(1)),
    `SpanKind` LowCardinality(String) CODEC(ZSTD(1)),
    `ServiceName` LowCardinality(String) CODEC(ZSTD(1)),
    `ResourceAttributes` Map(LowCardinality(String), String) CODEC(ZSTD(1)),
    `ScopeName` String CODEC(ZSTD(1)),
    `ScopeVersion` String CODEC(ZSTD(1)),
    `SpanAttributes` Map(LowCardinality(String), String) CODEC(ZSTD(1)),
    `Duration` UInt64 CODEC(ZSTD(1)),
    `StatusCode` LowCardinality(String) CODEC(ZSTD(1)),
    `StatusMessage` String CODEC(ZSTD(1)),
    `Events.Timestamp` Array(DateTime64(9)) CODEC(ZSTD(1)),
    `Events.Name` Array(LowCardinality(String)) CODEC(ZSTD(1)),
    `Events.Attributes` Array(Map(LowCardinality(String), String)) CODEC(ZSTD(1)),
    `Links.TraceId` Array(String) CODEC(ZSTD(1)),
    `Links.SpanId` Array(String) CODEC(ZSTD(1)),
    `Links.TraceState` Array(String) CODEC(ZSTD(1)),
    `Links.Attributes` Array(Map(LowCardinality(String), String)) CODEC(ZSTD(1)),
    `__hdx_materialized_rum.sessionId` String MATERIALIZED ResourceAttributes['rum.sessionId'] CODEC(ZSTD(1)),
    INDEX idx_trace_id TraceId TYPE bloom_filter(0.001) GRANULARITY 1,
    INDEX idx_rum_session_id __hdx_materialized_rum.sessionId TYPE bloom_filter(0.001) GRANULARITY 1,
    INDEX idx_res_attr_key mapKeys(ResourceAttributes) TYPE bloom_filter(0.01) GRANULARITY 1,
    INDEX idx_res_attr_value mapValues(ResourceAttributes) TYPE bloom_filter(0.01) GRANULARITY 1,
    INDEX idx_span_attr_key mapKeys(SpanAttributes) TYPE bloom_filter(0.01) GRANULARITY 1,
    INDEX idx_span_attr_value mapValues(SpanAttributes) TYPE bloom_filter(0.01) GRANULARITY 1,
    INDEX idx_duration Duration TYPE minmax GRANULARITY 1,
    INDEX idx_lower_span_name lower(SpanName) TYPE tokenbf_v1(32768, 3, 0) GRANULARITY 8
)
ENGINE = MergeTree
PARTITION BY toDate(Timestamp)
ORDER BY (ServiceName, SpanName, toDateTime(Timestamp))
TTL toDate(Timestamp) + toIntervalDay(30)
SETTINGS index_granularity = 8192, ttl_only_drop_parts = 1;
```

Пользователь может фильтровать трейсы, используя синтаксис Lucene, например `ResourceAttributes.k8s.pod.name:"checkout-675775c4cc-f2p9c"`:

<Image img={trace_filtering} size="lg" alt="Фильтрация трейсов" />

В результате получается SQL-предикат, похожий на следующий:

```sql
ResourceAttributes['k8s.pod.name'] = 'checkout-675775c4cc-f2p9c'
```

Поскольку при этом происходит обращение к ключу `Map`, ClickHouse должен читать весь столбец `ResourceAttributes` для каждой подходящей строки — он может быть очень большим, если `Map` содержит много ключей.

Если к этому атрибуту часто выполняются запросы, его следует материализовать как столбец верхнего уровня.

Чтобы извлечь имя пода при вставке данных, добавьте материализованный столбец:

```sql
ALTER TABLE otel_v2.otel_traces
ADD COLUMN PodName String
MATERIALIZED ResourceAttributes['k8s.pod.name']
```

Начиная с этого момента, **новые** данные будут сохранять имя пода в отдельном столбце `PodName`.

Теперь пользователи могут эффективно выполнять запросы по именам подов, используя синтаксис Lucene, например `PodName:"checkout-675775c4cc-f2p9c"`.

<Image img={trace_filtering_v2} size="lg" alt="Фильтрация трасс v2" />

Для вновь вставляемых данных это полностью исключает доступ к структуре map и значительно сокращает объем операций ввода-вывода.


Однако даже если пользователи продолжают выполнять запросы по исходному пути атрибута, например `ResourceAttributes.k8s.pod.name:"checkout-675775c4cc-f2p9c"`, **ClickStack автоматически перепишет запрос** внутренне, чтобы использовать материализованный столбец `PodName`, то есть с использованием предиката:

```sql
PodName = 'checkout-675775c4cc-f2p9c'
```

Это гарантирует, что пользователи получают преимущества от оптимизации без изменения дашбордов, оповещений или сохранённых запросов.

:::note
По умолчанию материализованные столбцы исключаются из запросов `SELECT *`. Это сохраняет инвариант: результаты запроса всегда можно повторно вставить в таблицу.
:::


### Материализация исторических данных \{#materializing-historical-data\}

Материализованные столбцы автоматически применяются только к данным, вставленным после создания столбца. Для уже существующих данных запросы к материализованному столбцу будут прозрачно возвращаться к чтению из исходного map-столбца.

Если производительность при работе с историческими данными критична, столбец можно ретроспективно заполнить с помощью мутации, например:

```sql
ALTER TABLE otel_v2.otel_traces
MATERIALIZE COLUMN PodName
```

Это перезаписывает существующие [части](/parts) для заполнения столбца. Мутации выполняются в одном потоке для каждой части и могут занимать много времени на больших наборах данных. Чтобы ограничить влияние, область действия мутаций можно сузить до конкретной партиции:

```sql
ALTER TABLE otel_v2.otel_traces
MATERIALIZE COLUMN PodName
IN PARTITION '2026-01-02'
```

Ход выполнения мутаций можно отслеживать в таблице `system.mutations`, например:

```sql
SELECT *
FROM system.mutations
WHERE database = 'otel'
  AND table = 'otel_traces'
ORDER BY create_time DESC;
```

Дождитесь, пока для соответствующей мутации значение `is_done` не станет равным 1.

:::important
Мутации создают дополнительную нагрузку на ввод-вывод (I/O) и CPU, поэтому их следует использовать как можно реже. Во многих случаях достаточно позволить старым данным естественным образом устареть и полагаться на улучшение производительности при обработке недавно принятых данных.
:::


## Оптимизация 2. Добавление индексов пропуска данных \{#adding-skip-indices\}

После материализации часто запрашиваемых атрибутов следующая оптимизация — добавить индексы пропуска данных, чтобы еще больше сократить объем данных, которые ClickHouse нужно прочитать при выполнении запроса.

Индексы пропуска данных позволяют ClickHouse не сканировать целые блоки данных, когда можно определить, что в них нет подходящих значений. В отличие от традиционных вторичных индексов, индексы пропуска данных работают на уровне гранул и наиболее эффективны, когда фильтры в запросах исключают значительную часть набора данных. При корректном использовании они могут значительно ускорить фильтрацию по высококардинальным атрибутам без изменения семантики запроса.

Рассмотрим схему трассировок по умолчанию для ClickStack, которая включает индексы пропуска данных:

```sql
CREATE TABLE IF NOT EXISTS otel_traces
(
    `Timestamp` DateTime64(9) CODEC(Delta(8), ZSTD(1)),
    `TraceId` String CODEC(ZSTD(1)),
    `SpanId` String CODEC(ZSTD(1)),
    `ParentSpanId` String CODEC(ZSTD(1)),
    `TraceState` String CODEC(ZSTD(1)),
    `SpanName` LowCardinality(String) CODEC(ZSTD(1)),
    `SpanKind` LowCardinality(String) CODEC(ZSTD(1)),
    `ServiceName` LowCardinality(String) CODEC(ZSTD(1)),
    `ResourceAttributes` Map(LowCardinality(String), String) CODEC(ZSTD(1)),
    `ScopeName` String CODEC(ZSTD(1)),
    `ScopeVersion` String CODEC(ZSTD(1)),
    `SpanAttributes` Map(LowCardinality(String), String) CODEC(ZSTD(1)),
    `Duration` UInt64 CODEC(ZSTD(1)),
    `StatusCode` LowCardinality(String) CODEC(ZSTD(1)),
    `StatusMessage` String CODEC(ZSTD(1)),
    `Events.Timestamp` Array(DateTime64(9)) CODEC(ZSTD(1)),
    `Events.Name` Array(LowCardinality(String)) CODEC(ZSTD(1)),
    `Events.Attributes` Array(Map(LowCardinality(String), String)) CODEC(ZSTD(1)),
    `Links.TraceId` Array(String) CODEC(ZSTD(1)),
    `Links.SpanId` Array(String) CODEC(ZSTD(1)),
    `Links.TraceState` Array(String) CODEC(ZSTD(1)),
    `Links.Attributes` Array(Map(LowCardinality(String), String)) CODEC(ZSTD(1)),
    `__hdx_materialized_rum.sessionId` String MATERIALIZED ResourceAttributes['rum.sessionId'] CODEC(ZSTD(1)),
    INDEX idx_trace_id TraceId TYPE bloom_filter(0.001) GRANULARITY 1,
    INDEX idx_rum_session_id __hdx_materialized_rum.sessionId TYPE bloom_filter(0.001) GRANULARITY 1,
    INDEX idx_res_attr_key mapKeys(ResourceAttributes) TYPE bloom_filter(0.01) GRANULARITY 1,
    INDEX idx_res_attr_value mapValues(ResourceAttributes) TYPE bloom_filter(0.01) GRANULARITY 1,
    INDEX idx_span_attr_key mapKeys(SpanAttributes) TYPE bloom_filter(0.01) GRANULARITY 1,
    INDEX idx_span_attr_value mapValues(SpanAttributes) TYPE bloom_filter(0.01) GRANULARITY 1,
    INDEX idx_duration Duration TYPE minmax GRANULARITY 1,
    INDEX idx_lower_span_name lower(SpanName) TYPE tokenbf_v1(32768, 3, 0) GRANULARITY 8
)
ENGINE = MergeTree
PARTITION BY toDate(Timestamp)
ORDER BY (ServiceName, SpanName, toDateTime(Timestamp))
TTL toDate(Timestamp) + toIntervalDay(30)
SETTINGS index_granularity = 8192, ttl_only_drop_parts = 1;
```

Эти индексы ориентированы на два распространённых варианта:

* Фильтрация строк с высокой кардинальностью, например TraceId, идентификаторы сессий, ключи или значения атрибутов
* Фильтрация по числовым диапазонам, например по длительности спанов


### Фильтры Блума \{#bloom-filters\}

Индексы на основе фильтров Блума — наиболее часто используемый тип skip-индексов в ClickStack. Они хорошо подходят для строковых столбцов с высокой кардинальностью, как правило, не менее десятков тысяч различных значений. Вероятность ложного срабатывания 0.01 при гранулярности 1 — хорошее значение по умолчанию, которое балансирует накладные расходы на хранение и эффективность отсечения данных.

Продолжая пример из «Оптимизации 1», предположим, что имя пода Kubernetes было материализовано из ResourceAttributes:

```sql
ALTER TABLE otel_traces
ADD COLUMN PodName String
MATERIALIZED ResourceAttributes['k8s.pod.name']
```

Затем можно добавить skip-индекс на основе фильтра Блума, чтобы ускорить фильтрацию по этому столбцу:

```sql
ALTER TABLE otel_traces
ADD INDEX idx_pod_name PodName
TYPE bloom_filter(0.01)
GRANULARITY 1
```

После добавления skip-индекс необходимо материализовать — см. [&quot;Materialize skip index.&quot;](#materialize-skip-index)

После создания и материализации ClickHouse может пропускать целые гранулы, которые гарантированно не содержат запрашиваемое имя пода, что потенциально уменьшает объём данных, считываемых при выполнении запросов, таких как `PodName:"checkout-675775c4cc-f2p9c"`.

Фильтры Блума наиболее эффективны, когда распределение значений таково, что конкретное значение встречается в относительно небольшом числе частей. Это часто происходит естественным образом в обсервабилити-нагрузках, где метаданные, такие как имена подов, идентификаторы трассировок (trace IDs) или идентификаторы сессий, коррелированы со временем и, следовательно, кластеризованы ключом сортировки таблицы.

Как и все skip-индексы, фильтры Блума следует добавлять избирательно и проверять по реальным паттернам запросов, чтобы убедиться, что они дают измеримую пользу — см. [&quot;Evaluating skip index effectiveness.&quot;](#evaluating-skip-index-effectiveness)


### Индексы min-max \{#min-max-indices\}

Индексы minmax хранят минимальное и максимальное значение для каждой гранулы и являются чрезвычайно лёгкими. Они особенно эффективны для числовых столбцов и диапазонных запросов. Хотя они могут не ускорять каждый запрос, их ресурсоёмкость низкая, и их почти всегда имеет смысл добавлять для числовых полей.

Индексы minmax лучше всего работают, когда числовые значения либо естественным образом упорядочены, либо ограничены узкими диапазонами в пределах каждой партиции.

Предположим, что Kafka offset часто запрашивается из `SpanAttributes`:

```sql
SpanAttributes['messaging.kafka.offset']
```

Это значение можно материализовать и преобразовать в числовой тип:

```sql
ALTER TABLE otel_traces
ADD COLUMN KafkaOffset UInt64
MATERIALIZED toUInt64(SpanAttributes['messaging.kafka.offset'])
```

Затем можно добавить индекс minmax:

```sql
ALTER TABLE otel_traces
ADD INDEX idx_kafka_offset KafkaOffset TYPE minmax GRANULARITY 1
```

Это позволяет ClickHouse эффективно пропускать части при фильтрации по диапазонам смещений Kafka, например при отладке лага потребителя или поведения при повторном воспроизведении.

Кроме того, индекс должен быть [материализован](#materialize-skip-index) прежде, чем он станет доступен.


### Материализация пропускающего индекса \{#materialize-skip-index\}

После того как пропускающий индекс был добавлен, он применяется только к новым данным, поступающим при приёме. Исторические данные не смогут воспользоваться преимуществами индекса, пока вы явно не материализуете его.

Если вы уже добавили пропускающий индекс, например:

```sql
ALTER TABLE otel_traces ADD INDEX idx_kafka_offset KafkaOffset TYPE minmax GRANULARITY 1;
```

Необходимо явно создать индекс для уже существующих данных:

```sql
ALTER TABLE otel_traces MATERIALIZE INDEX idx_kafka_offset;
```

:::note[Материализация skip-индексов]
Материализация skip-индекса, как правило, малозатратна и безопасна для выполнения, особенно для minmax-индексов. Для индексов Bloom filter на больших наборах данных пользователи могут предпочесть материализовывать их по партициям, чтобы лучше контролировать использование ресурсов, например:

```sql
ALTER TABLE otel_v2.otel_traces
MATERIALIZE INDEX idx_kafka_offset
IN PARTITION '2026-01-02';
```

:::

Материализация пропускающего индекса выполняется как операция мутации. Ход её выполнения можно отслеживать по системным таблицам.

```sql

SELECT *
FROM system.mutations
WHERE database = 'otel'
  AND table = 'otel_traces'
ORDER BY create_time DESC;
```

Дождитесь, пока для соответствующей мутации значение `is_done` не станет равным 1.

После этого убедитесь, что данные индекса были созданы:

```sql
SELECT database, table, name,
       data_compressed_bytes,
       data_uncompressed_bytes,
       marks_bytes
FROM system.data_skipping_indices
WHERE database = 'otel'
  AND table = 'otel_traces'
  AND name = 'idx_kafka_offset';
```

Ненулевые значения указывают, что индекс был успешно материализован.

Важно учитывать, что размер индекса пропуска данных напрямую влияет на производительность запроса. Очень большие индексы пропуска данных, порядка десятков или сотен гигабайт, могут заметно дольше вычисляться во время выполнения запроса, что может снизить или даже свести к нулю их пользу.

На практике индексы `minmax` обычно очень маленькие и недорогие в вычислении, что делает их почти всегда безопасными для материализации. Индексы Bloom filter, напротив, могут значительно увеличиваться в зависимости от кардинальности, гранулярности и вероятности ложных срабатываний.

Размер Bloom filter можно уменьшить, увеличивая допустимую вероятность ложных срабатываний. Например, увеличение параметра `probability` с `0.01` до `0.05` приводит к созданию меньшего индекса, который вычисляется быстрее, ценой менее агрессивного отсечения данных. Хотя может пропускаться меньше гранул, общая задержка выполнения запроса может уменьшиться за счёт более быстрого вычисления индекса.

Настройка параметров Bloom filter, таким образом, является оптимизацией, зависящей от нагрузки, и должна проверяться с использованием реальных шаблонов запросов и объёмов данных, близких к боевым.

Для получения дополнительной информации об индексах пропуска данных см. руководство [&quot;Понимание индексов пропуска данных в ClickHouse&quot;](/optimize/skipping-indexes/examples)


### Оценка эффективности пропускающих индексов \{#evaluating-skip-index-effectiveness\}

Самый достоверный способ оценить отсечение с помощью пропускающих индексов — использовать `EXPLAIN indexes = 1`, который показывает, сколько [частей](/parts) и [гранул](/guides/best-practices/sparse-primary-indexes#data-is-organized-into-granules-for-parallel-data-processing) исключается на каждом этапе планирования запроса. В большинстве случаев желательно увидеть значительное сокращение количества гранул на этапе Skip, лучше всего после того, как первичный ключ уже сузил пространство поиска. Пропускающие индексы оцениваются после отсечения по партициям и первичному ключу, поэтому их влияние лучше всего измерять относительно оставшихся частей и гранул.

`EXPLAIN` подтверждает, что отсечение происходит, но не гарантирует итогового ускорения. Пропускающие индексы требуют вычислительных ресурсов, особенно если INDEX большой. Всегда измеряйте производительность запросов до и после добавления и материализации INDEX, чтобы подтвердить реальное улучшение производительности.

Например, рассмотрим пропускающий индекс Bloom filter по умолчанию для TraceId, включенный в стандартную схему Traces:

```sql
INDEX idx_trace_id TraceId TYPE bloom_filter(0.001) GRANULARITY 1
```

Вы можете использовать `EXPLAIN indexes = 1`, чтобы увидеть, насколько это эффективно для селективного запроса:

```sql
EXPLAIN indexes = 1
SELECT *
FROM otel_v2.otel_traces
WHERE (ServiceName = 'accounting')
  AND (TraceId = 'aeea7f401feb75fc5af8eb25ebc8e974');

ReadFromMergeTree (otel_v2.otel_traces)
Indexes:
  PrimaryKey
    Keys:
      ServiceName
    Parts: 6/18
    Granules: 255/35898
  Skip
    Name: idx_trace_id
    Description: bloom_filter GRANULARITY 1
    Parts: 1/6
    Granules: 1/255
```

В этом случае фильтр по первичному ключу сначала существенно уменьшает набор данных (с 35898 гранул до 255), а затем фильтр Блума сокращает его дальше до одной гранулы (1/255). Это идеальный сценарий для skip-индексов: отсечение по первичному ключу сужает область поиска, а затем skip-индекс отбрасывает большую часть оставшихся данных.

Чтобы оценить реальный эффект, измерьте производительность запроса при стабильных настройках и сравните время выполнения. Используйте `FORMAT Null`, чтобы избежать накладных расходов на сериализацию результата, и отключите кэш условий запроса, чтобы запуски были воспроизводимыми:

```sql
SELECT *
FROM otel_traces
WHERE (ServiceName = 'accountingservice') AND (TraceId = '4512e822ca3c0c68bbf5d4a263f9943d')
SETTINGS use_query_condition_cache = 0

2 rows in set. Elapsed: 0.025 sec. Processed 8.52 thousand rows, 299.78 KB (341.22 thousand rows/s., 12.00 MB/s.)
Peak memory usage: 41.97 MiB.
```

Теперь выполните тот же запрос с отключенными пропускающими индексами:

```sql
SELECT *
FROM otel_traces
WHERE (ServiceName = 'accountingservice') AND (TraceId = '4512e822ca3c0c68bbf5d4a263f9943d')
FORMAT Null
SETTINGS use_query_condition_cache = 0, use_skip_indexes = 0;

0 rows in set. Elapsed: 0.702 sec. Processed 1.62 million rows, 56.62 MB (2.31 million rows/s., 80.71 MB/s.)
Peak memory usage: 198.39 MiB.
```

Отключение `use_query_condition_cache` гарантирует, что результаты не зависят от кэшированных решений по фильтрации, а установка `use_skip_indexes = 0` обеспечивает чистый базовый уровень для сравнения. Если отсечение эффективно и стоимость вычисления индекса мала, запрос с индексом должен работать существенно быстрее, как в примере выше.

:::tip
Если `EXPLAIN` показывает минимальное отсечение гранул или skip-индекс очень большой, стоимость его вычисления может свести на нет любую пользу. Используйте `EXPLAIN indexes = 1`, чтобы подтвердить отсечение, а затем выполните бенчмарк, чтобы подтвердить сквозные улучшения производительности.
:::


### Когда добавлять skip-индексы \{#when-to-add-skip-indexes\}

Skip-индексы следует добавлять избирательно, исходя из типов фильтров, которые пользователи запускают чаще всего, и распределения данных в частях и гранулах. Цель состоит в том, чтобы отфильтровать достаточно гранул, чтобы компенсировать стоимость вычисления самого индекса, поэтому бенчмаркинг на данных, максимально приближённых к продакшену, критически важен.

**Для числовых столбцов, которые используются в фильтрах, minmax skip-индекс почти всегда является хорошим выбором.** Он легковесный, дешёвый в вычислении и может быть эффективен для диапазонных предикатов — особенно когда значения слабо упорядочены или ограничены узкими диапазонами внутри частей. Даже когда minmax не помогает для конкретного типа запросов, его накладные расходы обычно достаточно низки, чтобы всё равно было разумно его оставить.

**Строковые столбцы. Используйте Bloom-фильтры, когда кардинальность высока, а значения разреженные.**

Bloom-фильтры наиболее эффективны для строковых столбцов с высокой кардинальностью, где каждое значение встречается относительно редко, то есть большинство частей и гранул не содержат искомого значения. Как правило, Bloom-фильтры наиболее перспективны, когда столбец имеет как минимум 10 000 различных значений, и часто работают лучше всего при 100 000+ различных значениях. Они также более эффективны, когда совпадающие значения сгруппированы в небольшом количестве последовательных частей, что обычно происходит, когда столбец коррелирует с ключом сортировки. Опять же, результаты могут различаться — ничто не заменит тестирование на реальных данных.

## Optimization 3. Modifying the primary key \{#modifying-the-primary-key\}

Первичный ключ — один из важнейших компонентов настройки производительности ClickHouse для большинства типов нагрузок. Чтобы эффективно его настраивать, необходимо понимать, как он работает и как взаимодействует с вашими шаблонами запросов. В конечном итоге первичный ключ должен соответствовать тому, как пользователи обращаются к данным, в частности, по каким столбцам они чаще всего фильтруют.

Хотя первичный ключ также влияет на сжатие и физическую организацию хранения, его основная задача — производительность запросов. В ClickStack первичные ключи «из коробки» уже оптимизированы под наиболее распространённые паттерны доступа для обсервабилити и обеспечивают высокую степень сжатия. Ключи по умолчанию для таблиц логов, трейсов и метрик спроектированы так, чтобы хорошо работать для типичных сценариев.

Фильтрация по столбцам, которые идут раньше в первичном ключе, более эффективна, чем фильтрация по столбцам, которые идут позже. Хотя конфигурации по умолчанию достаточно для большинства пользователей, есть случаи, когда изменение первичного ключа может улучшить производительность для конкретных типов нагрузок.

:::note[Замечание о терминологии]
Во всём этом документе термин «ordering key» используется как синоним «primary key». Строго говоря, в ClickHouse это разные понятия, но для ClickStack они обычно соответствуют одним и тем же столбцам, указанным в `ORDER BY` для таблицы. Подробнее см. [документацию ClickHouse](/engines/table-engines/mergetree-family/mergetree#choosing-a-primary-key-that-differs-from-the-sorting-key) о выборе первичного ключа, отличающегося от ключа сортировки.
:::

Перед изменением какого‑либо первичного ключа настоятельно рекомендуется ознакомиться с нашим [руководством по тому, как работают первичные индексы](/primary-indexes) в ClickHouse:

Настройка первичного ключа специфична для таблицы и типа данных. Изменение, которое полезно для одной таблицы и типа данных, может не подходить для других. Цель всегда — оптимизировать под конкретный тип данных, например логи.

**Обычно вы будете оптимизировать таблицы для логов и трейсов. Изменять первичный ключ для других типов данных требуется редко.**

Ниже приведены первичные ключи по умолчанию для таблиц ClickStack для логов и метрик.

- Логи ([`otel_logs`](/use-cases/observability/clickstack/ingesting-data/schemas#logs)) — `(ServiceName, TimestampTime, Timestamp)`
- Трейсы (['otel_traces](/use-cases/observability/clickstack/ingesting-data/schemas#traces)) — `(ServiceName, SpanName, toDateTime(Timestamp))`

См. раздел [«Таблицы и схемы, используемые ClickStack»](/use-cases/observability/clickstack/ingesting-data/schemas) для первичных ключей, используемых в таблицах для других типов данных. Например, таблицы трейсов оптимизированы под фильтрацию по имени сервиса и имени спана, затем по метке времени и идентификатору трейса. Таблицы логов, напротив, оптимизированы под фильтрацию по имени сервиса, затем по дате и затем по метке времени. Хотя оптимально, если пользователь применяет фильтры в порядке следования столбцов в первичном ключе, запросы всё равно будут значительно выигрывать при фильтрации по любому из этих столбцов в любом порядке, поскольку ClickHouse будет [отсекать данные до чтения](/optimize/skipping-indexes).

При выборе первичного ключа есть и другие соображения, влияющие на оптимальный порядок столбцов. См. раздел [«Выбор первичного ключа.»](#choosing-a-primary-key)

**Первичные ключи следует изменять изолированно для каждой таблицы. То, что имеет смысл для логов, может не иметь смысла для трейсов или метрик.**

### Выбор первичного ключа \{#choosing-a-primary-key\}

Сначала определите, отличаются ли ваши шаблоны доступа к данным от настроек по умолчанию для конкретной таблицы. Например, если вы чаще всего фильтруете логи по Kubernetes-ноде, а уже затем по имени сервиса, и это является доминирующим рабочим процессом, это может оправдывать изменение первичного ключа.

:::note[Изменение первичного ключа по умолчанию]
Первичные ключи по умолчанию достаточно хороши в большинстве случаев. Изменения следует вносить с осторожностью и только при чётком понимании паттернов запросов. Модификация первичного ключа может ухудшить производительность для других рабочих процессов, поэтому тестирование обязательно.
:::

После того как вы выделили нужные столбцы, вы можете начать оптимизацию ключа сортировки/первичного ключа.

Можно применить несколько простых правил, чтобы помочь выбрать ключ сортировки. Следующие пункты иногда могут конфликтовать между собой, поэтому учитывайте их по порядку. Стремитесь выбрать максимум 4–5 ключей по этому процессу:

1. Выберите столбцы, которые соответствуют вашим типовым фильтрам и шаблонам доступа. Если вы обычно начинаете расследования по обсервабилити с фильтрации по конкретному столбцу, например имени пода, этот столбец будет часто использоваться в `WHERE`. Отдавайте приоритет включению таких столбцов в ключ по сравнению с теми, которые используются реже.
2. Предпочитайте столбцы, которые при фильтрации помогают исключить большой процент от общего числа строк, тем самым уменьшая объём данных, которые нужно прочитать. Часто хорошими кандидатами являются имена сервисов и коды статусов — во втором случае только если вы фильтруете по значениям, которые исключают большинство строк, например, фильтрация по коду 200 в большинстве систем будет соответствовать большей части строк, тогда как ошибки 500 будут соответствовать небольшой подвыборке.
3. Предпочитайте столбцы, которые, вероятно, будут сильно коррелировать с другими столбцами в таблице. Это поможет обеспечить, что соответствующие значения также будут храниться подряд, улучшая сжатие.
4. Операции `GROUP BY` (агрегации для графиков) и `ORDER BY` (сортировка) по столбцам в ключе сортировки могут выполняться более эффективно с точки зрения потребления памяти.

После определения подмножества столбцов для ключа сортировки их необходимо задать в определённом порядке. Этот порядок может существенно влиять как на эффективность фильтрации по вторичным столбцам ключа в запросах, так и на коэффициент сжатия файлов данных таблицы. В общем случае лучше упорядочить ключи в порядке возрастания их кардинальности. Это нужно сбалансировать с тем фактом, что фильтрация по столбцам, которые находятся дальше в ключе сортировки, будет менее эффективной, чем по тем, что идут раньше в кортеже. Сбалансируйте эти свойства и учитывайте свои шаблоны доступа. И, что наиболее важно, тестируйте варианты. Для более глубокого понимания ключей сортировки и способов их оптимизации рекомендуется прочитать ["Choosing a Primary Key."](/best-practices/choosing-a-primary-key); для ещё более детального погружения в тюнинг первичных ключей и внутренние структуры данных см. ["A practical introduction to primary indexes in ClickHouse."](/guides/best-practices/sparse-primary-indexes)

### Изменение первичного ключа \{#changing-the-primary-key\}

Если вы уверены в своих паттернах доступа до начала ингестии данных, просто удалите и заново создайте таблицу для соответствующего типа данных.

Ниже приведён пример простого способа создания новой таблицы логов с существующей схемой, но с новым первичным ключом, который включает столбец `SeverityText` перед `ServiceName`.

<VerticalStepper headerLevel="h4">

#### Создать новую таблицу \{#create-new-table-with-key\}

```sql
CREATE TABLE otel_logs_temp AS otel_logs
PRIMARY KEY (SeverityText, ServiceName, TimestampTime)
ORDER BY (SeverityText, ServiceName, TimestampTime)
```

:::note Ordering key vs primary key
Обратите внимание, что в приведённом выше примере требуется указать `PRIMARY KEY` и `ORDER BY`.
В ClickStack они почти всегда совпадают.
`ORDER BY` контролирует физическую организацию данных, а `PRIMARY KEY` определяет разреженный индекс.
В редких случаях с очень большими нагрузками они могут различаться, но большинству пользователей следует держать их согласованными.
:::

#### Обмен и удаление таблицы \{#exhange-and-drop-table\}

Оператор `EXCHANGE` используется для атомарной [смены имён](/concepts/glossary#atomicity) таблиц. Временную таблицу (теперь это старая таблица по умолчанию) можно удалить.

```sql
EXCHANGE TABLES otel_logs_temp AND otel_logs
DROP TABLE otel_logs_temp
```

</VerticalStepper>

Однако **первичный ключ нельзя изменить у уже существующей таблицы**. Для его изменения требуется создать новую таблицу.

Следующий процесс можно использовать, чтобы гарантировать сохранность старых данных и возможность их прозрачного чтения (с использованием существующего ключа в HyperDX, при необходимости), в то время как новые данные будут доступны через новую таблицу, оптимизированную под паттерны доступа пользователей. Такой подход гарантирует, что конвейеры приёма не нужно изменять: данные по‑прежнему отправляются в таблицы по умолчанию, а все изменения остаются прозрачными для пользователей.

:::note
Backfill существующих данных в новую таблицу редко оправдан в крупном масштабе. Затраты на вычисления и ввод‑вывод (I/O) обычно высоки и не окупаются выигрышем в производительности. Вместо этого позвольте старым данным устаревать [через TTL](/use-cases/observability/clickstack/ttl), в то время как новые данные получают выгоду от улучшенного ключа.
:::

<VerticalStepper headerLevel="h4">

Ниже используется тот же пример введения `SeverityText` в качестве первого столбца в первичном ключе. В этом случае создаётся таблица для новых данных, при этом старая таблица сохраняется для исторического анализа.

#### Создать новую таблицу \{#create-new-table-with-key-2\}

Создайте новую таблицу с нужным первичным ключом. Обратите внимание на суффикс `_23_01_2025` — адаптируйте его к текущей дате, например:

```sql
CREATE TABLE otel_logs_23_01_2025 AS otel_logs
PRIMARY KEY (SeverityText, ServiceName, TimestampTime)
ORDER BY (SeverityText, ServiceName, TimestampTime)
```

#### Создать таблицу Merge \{#create-merge-table\}

[Движок Merge](/engines/table-engines/special/merge) (не путать с MergeTree) сам по себе не хранит данные, но позволяет читать данные одновременно из любого количества других таблиц.

```sql
CREATE TABLE otel_logs_merge
AS otel_logs
ENGINE = Merge(currentDatabase(), 'otel_logs*')
```

:::note
`currentDatabase()` предполагает, что команда выполняется в нужной базе данных. В противном случае укажите имя базы данных явно.
:::

Теперь вы можете выполнять запросы к этой таблице, чтобы убедиться, что она возвращает данные из `otel_logs`.

#### Обновить HyperDX для чтения из таблицы Merge \{#update-hyperdx-to-read-from-merge-tree\}

Настройте HyperDX на использование `otel_logs_merge` в качестве таблицы для источника данных логов.

<Image img={select_merge_table} size="lg" alt="Выбор таблицы Merge"/>

На этом этапе записи продолжают идти в `otel_logs` с исходным первичным ключом, а чтение выполняется через таблицу Merge. Для пользователей нет видимых изменений и нет влияния на ингестию.

#### Обменять таблицы \{#exchange-the-tables\}

Теперь оператор `EXCHANGE` используется для атомарной смены имён таблиц `otel_logs` и `otel_logs_23_01_2025`.

```sql
EXCHANGE TABLES otel_logs AND otel_logs_23_01_2025
```

Записи теперь идут в новую таблицу `otel_logs` с обновлённым первичным ключом. Существующие данные остаются в `otel_logs_23_01_2025` и по‑прежнему доступны через таблицу Merge. Суффикс указывает дату, когда было выполнено изменение, и соответствует максимальной метке времени, содержащейся в этой таблице.

Этот процесс позволяет изменять первичный ключ без прерывания ингестии и без видимого эффекта для пользователей.

</VerticalStepper>

Этот процесс можно адаптировать, если потребуются дальнейшие изменения первичных ключей. Например, если вы спустя неделю решите, что на самом деле в первичный ключ должен входить `SeverityNumber`, а не `SeverityText`. Следующую процедуру можно применять столько раз, сколько потребуется изменений первичного ключа.

<VerticalStepper headerLevel="h4">

#### Создайте новую таблицу \{#create-new-table-with-key-3\}

Создайте новую таблицу с нужным первичным ключом.
В примере ниже `30_01_2025` используется как суффикс для обозначения даты таблицы, например:

```sql
CREATE TABLE otel_logs_30_01_2025 AS otel_logs
PRIMARY KEY (SeverityNumber, ServiceName, TimestampTime)
ORDER BY (SeverityNumber, ServiceName, TimestampTime)
```

#### Поменяйте таблицы местами \{#exchange-the-tables-v2\}

Теперь оператор `EXCHANGE` используется для атомарной смены имён таблиц `otel_logs` и `otel_logs_30_01_2025`.

```sql
EXCHANGE TABLES otel_logs AND otel_logs_30_01_2025
```

Записи теперь поступают в новую таблицу `otel_logs` с обновлённым первичным ключом. Старые данные остаются в `otel_logs_30_01_2025` и доступны через merge-таблицу.

</VerticalStepper>

:::note Избыточные таблицы
Если настроены политики TTL (что рекомендуется), таблицы со старыми первичными ключами, которые больше не принимают записи, будут постепенно опустошаться по мере истечения срока хранения данных. За ними следует наблюдать и периодически очищать их после того, как они перестанут содержать данные. В настоящее время этот процесс очистки выполняется вручную.
:::

## Оптимизация 4. Использование Materialized Views \{#exploting-materialied-views\}

<BetaBadge/>

ClickStack может использовать [Incremental Materialized Views](/materialized-view/incremental-materialized-view) для ускорения визуализаций, которые зависят от ресурсоёмких агрегирующих запросов, например при вычислении средней продолжительности запроса в минуту на протяжении времени. Эта функция может значительно улучшить производительность запросов и, как правило, наиболее полезна для крупных развертываний — порядка 10 TB в день и выше, — обеспечивая масштабирование до уровней PB в день. Incremental Materialized Views находятся в статусе бета и должны использоваться с осторожностью.

Подробные сведения об использовании этой функции в ClickStack см. в нашем отдельном руководстве ["ClickStack - Materialized Views."](/use-cases/observability/clickstack/materialized_views)

## Optimization 5. Exploiting Projections \{#exploting-projections\}

Проекции представляют собой заключительную, продвинутую оптимизацию, которую имеет смысл рассматривать после того, как вы оценили материализованные столбцы, пропускающие индексы, первичные ключи и materialized views. Хотя проекции и materialized views могут выглядеть похожими, в ClickStack они служат разным целям и лучше всего подходят для разных сценариев.

<iframe width="560" height="315" src="https://www.youtube.com/embed/6CdnUdZSEG0?si=1zUyrP-tCvn9tXse" title="Видеопроигрыватель YouTube" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

На практике **проекцию можно рассматривать как дополнительную, скрытую копию таблицы**, которая хранит те же строки в **другом физическом порядке**. Это даёт проекции собственный первичный индекс, отличный от ключа `ORDER BY` базовой таблицы, что позволяет ClickHouse эффективнее отбрасывать данные для шаблонов доступа, не совпадающих с исходным порядком.

Materialized views могут добиться аналогичного эффекта, явно записывая строки в отдельную целевую таблицу с иным ключом сортировки. Ключевое отличие в том, что **проекции поддерживаются и обслуживаются автоматически и прозрачно** для ClickHouse, в то время как materialized views — это явные таблицы, которые должны быть зарегистрированы и намеренно выбраны ClickStack.

Когда запрос направлен к базовой таблице, ClickHouse оценивает базовую структуру хранения и все доступные проекции, берёт выборки по их первичным индексам и выбирает такую структуру, которая сможет выдать корректный результат, считывая наименьшее количество гранул. Это решение принимается автоматически анализатором запросов.

В ClickStack проекции, таким образом, лучше всего подходят для **чистого переупорядочивания данных**, когда:

- Шаблоны доступа принципиально отличаются от ключа первичного индекса по умолчанию
- Нереалистично покрыть все рабочие нагрузки одним ключом сортировки
- Вы хотите, чтобы ClickHouse прозрачно выбирал оптимальное физическое размещение данных

Для предагрегации и ускорения метрик ClickStack настоятельно предпочитает использовать **явные materialized views**, которые дают прикладному уровню полный контроль над выбором представлений и их использованием.

Для дополнительной справочной информации см.:

- [Руководство по проекциям](/data-modeling/projections)
- [Когда использовать проекции](/data-modeling/projections#when-to-use-projections)
- [Materialized views и проекции: сравнение](/managing-data/materialized-views-versus-projections)

### Примеры проекций \{#example-projections\}

Предположим, ваша таблица трассировок оптимизирована под стандартный паттерн доступа ClickStack:

```sql
ORDER BY (ServiceName, SpanName, toDateTime(Timestamp))
```

Если ваш основной рабочий сценарий также связан с фильтрацией по TraceId (или вы часто группируете и фильтруете данные по нему), вы можете добавить проекцию, в которой строки хранятся, отсортированные по TraceId и времени:

```sql
ALTER TABLE otel_v2.otel_traces
ADD PROJECTION prj_traceid_time
(
    SELECT *
    ORDER BY (TraceId, toDateTime(Timestamp))
);
```

:::note Используйте подстановку
В приведённом выше примере проекции используется подстановка (`SELECT *`). Хотя выбор подмножества столбцов может снизить накладные расходы на запись, он также ограничивает случаи, когда проекция может быть использована, поскольку только запросы, которые могут быть полностью удовлетворены этими столбцами, смогут воспользоваться проекцией. В ClickStack это часто сводит использование проекций к очень узким случаям. По этой причине в общем случае рекомендуется использовать подстановку, чтобы максимально расширить область применения.
:::

Как и другие изменения в организации данных, проекция влияет только на вновь записываемые части. Чтобы построить её для существующих данных, материализуйте её:

```sql
ALTER TABLE otel_v2.otel_traces
MATERIALIZE PROJECTION prj_traceid_time;
```

:::note
Материализация проекции может занять много времени и потребовать значительных ресурсов. Поскольку срок жизни данных обсервабилити обычно ограничен TTL, это следует делать только при крайней необходимости. В большинстве случаев достаточно, чтобы проекция применялась только к недавно принятым данным, оптимизируя таким образом наиболее часто запрашиваемые диапазоны времени, например последние 24 часа.
:::

ClickHouse может автоматически выбрать проекцию, если оценивает, что она просканирует меньше гранул, чем базовое размещение данных. Проекции наиболее надёжны, когда они представляют собой простое переупорядочивание полного набора строк (`SELECT *`), а фильтры запроса хорошо согласованы с `ORDER BY` проекции.

Запросы, которые фильтруют по TraceId (особенно по равенству) и включают диапазон времени, будут особенно эффективны с приведённой выше проекцией. Например:

```sql
-- Fetch a specific trace quickly
SELECT *
FROM otel_traces
WHERE TraceId = 'aeea7f401feb75fc5af8eb25ebc8e974'
  AND Timestamp >= now() - INTERVAL 1 DAY
ORDER BY Timestamp;

-- Trace-scoped aggregation
SELECT
  toStartOfMinute(Timestamp) AS t,
  count() AS spans
FROM otel_traces
WHERE TraceId = 'aeea7f401feb75fc5af8eb25ebc8e974'
  AND Timestamp >= now() - INTERVAL 1 DAY
GROUP BY t
ORDER BY t;
```

Запросы, которые не накладывают ограничение на `TraceId` или в основном фильтруют по другим измерениям, не являющимся ведущими в ключе сортировки проекции, обычно не дают выигрыша по производительности (и вместо этого могут выполняться по базовой схеме хранения).

:::note
Проекции также могут хранить агрегации (аналогично materialized views). В ClickStack агрегации на основе проекций в целом не рекомендуются, поскольку их выбор зависит от анализатора ClickHouse, а использование сложнее контролировать и интерпретировать. Вместо этого предпочтительнее явные materialized views, которые ClickStack может регистрировать и выбирать целенаправленно на уровне приложения.
:::

На практике проекции лучше всего подходят для сценариев, когда вы часто переходите от более широкого поиска к детализированному анализу, ориентированному на конкретный трейс (например, выбор всех спанов для конкретного TraceId).


### Затраты и рекомендации \{#projection-costs-and-guidance\}

- **Накладные расходы на вставку**: `SELECT *` projection с другим ключом сортировки по сути приводит к двойной записи данных, что увеличивает write I/O и может потребовать дополнительную пропускную способность CPU и диска для поддержания ингестии.
- **Используйте умеренно**: Projections лучше всего применять для действительно различных паттернов доступа, когда вторичный физический порядок даёт значимое сокращение объёма обрабатываемых данных для значительной доли запросов, например, когда две команды выполняют запросы к одному и тому же датасету принципиально разными способами.
- **Проверяйте с помощью бенчмарков**: Как и для любой настройки, сравните фактическую задержку выполнения запросов и использование ресурсов до и после добавления и материализации projection.

Для более подробного ознакомления см.:

- [Руководство по projections в ClickHouse](/data-modeling/projections#when-to-use-projections)
- [Materialized views vs projections](/managing-data/materialized-views-versus-projections)

### Легковесные проекции с `_part_offset` \{#lightweight-projections\}

<BetaBadge/>

:::note[Легковесные проекции находятся в статусе Beta для ClickStack]
Легковесные проекции на основе `_part_offset` не рекомендуются для рабочих нагрузок ClickStack. Хотя они уменьшают объем хранилища и write I/O, они могут приводить к большему количеству случайных обращений во время выполнения запроса, а их поведение в продакшене в масштабах обсервабилити все еще оценивается. Эта рекомендация может измениться по мере развития функциональности и накопления эксплуатационных данных.
:::

Более новые версии ClickHouse также поддерживают более легковесные проекции, которые хранят только ключ сортировки проекции плюс указатель `_part_offset` на базовую таблицу, вместо дублирования полноценных строк. Это может существенно снизить накладные расходы на хранение, а недавние улучшения позволяют выполнять отсечение на уровне гранул, что делает их более похожими на настоящие вторичные индексы. См.:

- [Более умное хранение с _part_offset](/data-modeling/projections#smarter_storage_with_part_offset)
- [Объяснение и примеры в блоге](https://clickhouse.com/blog/projections-secondary-indices#example-combining-multiple-projection-indexes)

### Альтернативы \{#projection-alternatives\}

Если вам нужны несколько ключей сортировки, PROJECTION — не единственный вариант. В зависимости от эксплуатационных ограничений и того, как вы хотите, чтобы ClickStack маршрутизировал запросы, рассмотрите:

- Настройку коллектора OpenTelemetry так, чтобы он записывал данные в две таблицы с разными ключами `ORDER BY`, и создание отдельных источников ClickStack для каждой таблицы.
- Создание materialized view в виде конвейера копирования, то есть подключение materialized view к основной таблице, которая выбирает сырые строки во вторичную таблицу с другим ключом сортировки (шаблон денормализации или маршрутизации). Создайте источник для этой целевой таблицы. Примеры можно найти [здесь](/materialized-view/incremental-materialized-view#filtering-and-transformation).