---
slug: /use-cases/observability/clickstack/migration/elastic/concepts
title: 'Эквивалентные понятия в ClickStack и Elastic'
pagination_prev: null
pagination_next: null
sidebar_label: 'Эквивалентные понятия'
sidebar_position: 1
description: 'Эквивалентные понятия в ClickStack и Elastic'
show_related_blogs: true
keywords: ['Elasticsearch']
doc_type: 'reference'
---

import Image from '@theme/IdealImage';
import elasticsearch from '@site/static/images/use-cases/observability/elasticsearch.png';
import clickhouse from '@site/static/images/use-cases/observability/clickhouse.png';
import clickhouse_execution from '@site/static/images/use-cases/observability/clickhouse-execution.png';
import elasticsearch_execution from '@site/static/images/use-cases/observability/elasticsearch-execution.png';
import elasticsearch_transforms from '@site/static/images/use-cases/observability/es-transforms.png';
import clickhouse_mvs from '@site/static/images/use-cases/observability/ch-mvs.png';


## Elastic Stack и ClickStack {#elastic-vs-clickstack}

И Elastic Stack, и ClickStack охватывают базовые роли платформы наблюдаемости, но подходят к этим ролям с разными принципами проектирования. Эти роли включают:

- **UI и оповещения**: инструменты для запросов к данным, построения дашбордов и управления оповещениями.
- **Хранилище и движок запросов**: backend‑системы, отвечающие за хранение данных наблюдаемости и выполнение аналитических запросов.
- **Сбор данных и ETL**: агенты и конвейеры, которые собирают телеметрию и обрабатывают её перед этапом ингестии.

В таблице ниже показано, как каждый стек сопоставляет свои компоненты с этими ролями:

| **Роль** | **Elastic Stack** | **ClickStack** | **Комментарии** |
|--------------------------|--------------------------------------------------|--------------------------------------------------|--------------|
| **UI и оповещения** | **Kibana** — дашборды, поиск и оповещения      | **HyperDX** — UI в реальном времени, поиск и оповещения   | Оба инструмента служат основным интерфейсом для пользователей, включая визуализации и управление оповещениями. HyperDX специально создан для задач наблюдаемости и тесно связан с семантикой OpenTelemetry. |
| **Хранилище и движок запросов** | **Elasticsearch** — хранилище JSON‑документов с инвертированным индексом | **ClickHouse** — колоночная база данных с векторизованным движком | Elasticsearch использует инвертированный индекс, оптимизированный для поиска; ClickHouse использует колоночное хранение и SQL для высокоскоростной аналитики по структурированным и полуструктурированным данным. |
| **Сбор данных** | **Elastic Agent**, **Beats** (например, Filebeat, Metricbeat) | **OpenTelemetry Collector** (edge + gateway)     | Elastic поддерживает кастомные shippers и унифицированный агент, управляемый через Fleet. ClickStack полагается на OpenTelemetry, что обеспечивает вендор‑независимый сбор и обработку данных. |
| **SDK для инструментирования** | **Elastic APM agents** (проприетарные)             | **OpenTelemetry SDKs** (распространяются в составе ClickStack) | SDK Elastic привязаны к стеку Elastic. ClickStack опирается на OpenTelemetry SDKs для логов, метрик и трейсов на основных языках программирования. |
| **ETL / обработка данных** | **Logstash**, конвейеры приёма данных (ingest pipelines) | **OpenTelemetry Collector** + материализованные представления ClickHouse | Elastic использует конвейеры приёма данных и Logstash для трансформации. ClickStack переносит вычисления на момент вставки данных за счёт материализованных представлений и процессоров OTel collector, которые эффективно и инкрементально преобразуют данные. |
| **Архитектурная философия** | Вертикально интегрированные проприетарные агенты и форматы | Основанные на открытых стандартах, слабо связанные компоненты   | Elastic строит плотно интегрированную экосистему. ClickStack делает акцент на модульности и стандартах (OpenTelemetry, SQL, объектное хранилище) для гибкости и экономической эффективности. |

ClickStack делает упор на открытые стандарты и совместимость, будучи полностью OpenTelemetry‑native от уровня сбора до UI. Напротив, Elastic предлагает плотно связанный и более вертикально интегрированный стек с проприетарными агентами и форматами.

Поскольку **Elasticsearch** и **ClickHouse** являются основными движками, отвечающими за хранение, обработку и запрос данных в своих стеках, важно понимать, чем они отличаются. Эти системы определяют производительность, масштабируемость и гибкость всей архитектуры наблюдаемости. В следующем разделе рассматриваются ключевые различия между Elasticsearch и ClickHouse — включая то, как они моделируют данные, обрабатывают приём данных (ингестию), выполняют запросы и управляют хранилищем.



## Elasticsearch vs ClickHouse {#elasticsearch-vs-clickhouse}

ClickHouse и Elasticsearch организуют и обрабатывают данные, используя разные базовые модели, но многие ключевые концепции служат схожим целям. В этом разделе приведены основные соответствия для пользователей, знакомых с Elastic, с отображением на их аналоги в ClickHouse. Хотя терминология отличается, большинство сценариев наблюдаемости можно воспроизвести — часто более эффективно — в ClickStack.

### Базовые структурные концепции {#core-structural-concepts}

| **Elasticsearch** | **ClickHouse / SQL** | **Описание** |
|-------------------|----------------------|------------------|
| **Field** | **Column** | Базовая единица данных, содержащая одно или несколько значений определённого типа. Поля в Elasticsearch могут хранить примитивы, а также массивы и объекты. Поле может иметь только один тип. ClickHouse также поддерживает массивы и объекты (`Tuples`, `Maps`, `Nested`), а также динамические типы, такие как [`Variant`](/sql-reference/data-types/variant) и [`Dynamic`](/sql-reference/data-types/dynamic), которые позволяют одному столбцу иметь несколько типов. |
| **Document** | **Row** | Набор полей (столбцов). Документы в Elasticsearch по умолчанию более гибкие: новые поля добавляются динамически на основе данных (тип выводится из самих данных). Строки в ClickHouse по умолчанию привязаны к схеме, и пользователи должны вставлять все столбцы для строки либо их подмножество. Тип [`JSON`](/integrations/data-formats/json/overview) в ClickHouse поддерживает эквивалентное создание полуструктурированных динамических столбцов на основе вставляемых данных. |
| **Index** | **Table** | Единица выполнения запросов и хранения. В обеих системах запросы выполняются к индексам или таблицам, которые хранят строки/документы. |
| *Implicit* | Schema (SQL)         | Схемы SQL группируют таблицы в пространства имён, часто используемые для управления доступом. В Elasticsearch и ClickHouse нет схем в терминах SQL, но обе системы поддерживают защиту на уровне строк и таблиц через роли и RBAC. |
| **Cluster** | **Cluster / Database** | Кластеры Elasticsearch — это экземпляры среды выполнения, которые управляют одним или несколькими индексами. В ClickHouse базы данных организуют таблицы в логическом пространстве имён, обеспечивая ту же логическую группировку, что и кластер в Elasticsearch. Кластер ClickHouse — это распределённый набор узлов, аналогичный Elasticsearch, но он отделён от самих данных и не зависит от них. |

### Моделирование данных и гибкость {#data-modeling-and-flexibility}

Elasticsearch известен своей гибкостью схемы за счёт [dynamic mappings](https://www.elastic.co/docs/manage-data/data-store/mapping/dynamic-mapping). Поля создаются по мере приёма документов, а типы выводятся автоматически — пока схема не задана явно. ClickHouse по умолчанию строже — таблицы определяются с явными схемами — но обеспечивает гибкость за счёт типов [`Dynamic`](/sql-reference/data-types/dynamic), [`Variant`](/sql-reference/data-types/variant) и [`JSON`](/integrations/data-formats/json/overview). Это позволяет реализовать ингестию полуструктурированных данных с динамическим созданием столбцов и выводом типов, аналогично Elasticsearch. Аналогично, тип [`Map`](/sql-reference/data-types/map) позволяет хранить произвольные пары ключ–значение — хотя для ключа и значения принудительно используется один и тот же тип.

Подход ClickHouse к гибкой типизации более прозрачен и управляем. В отличие от Elasticsearch, где конфликты типов могут вызывать ошибки при ингестии, ClickHouse допускает данные смешанных типов в столбцах [`Variant`](/sql-reference/data-types/variant) и поддерживает эволюцию схемы за счёт использования типа [`JSON`](/integrations/data-formats/json/overview).

Если тип [`JSON`](/integrations/data-formats/json/overview) не используется, схема определяется статически. Если значения для строки не указаны, соответствующие столбцы либо объявляются как [`Nullable`](/sql-reference/data-types/nullable) (в ClickStack не используется), либо получают значение по умолчанию для своего типа, например пустое значение для `String`.

### Ингестия и трансформация {#ingestion-and-transformation}

Elasticsearch использует конвейеры приёма (ingest pipelines) с процессорами (например, `enrich`, `rename`, `grok`) для трансформации документов перед индексированием. В ClickHouse аналогичная функциональность реализуется с помощью [**инкрементных материализованных представлений**](/materialized-view/incremental-materialized-view), которые могут [фильтровать и трансформировать](/materialized-view/incremental-materialized-view#filtering-and-transformation) или [обогащать](/materialized-view/incremental-materialized-view#lookup-table) входящие данные и вставлять результаты в целевые таблицы. Вы также можете вставлять данные в движок таблицы `Null`, если нужно сохранять только результат материализованного представления. Это означает, что сохраняются только результаты любых материализованных представлений, а исходные данные отбрасываются — что позволяет экономить место в хранилище.



Для обогащения данных в Elasticsearch предусмотрены специализированные [enrich processors](https://www.elastic.co/docs/reference/enrich-processor/enrich-processor), которые добавляют контекст к документам. В ClickHouse [**словарями**](/dictionary) можно пользоваться как на [этапе выполнения запроса](/dictionary#query-time-enrichment), так и на [этапе приёма данных](/dictionary#index-time-enrichment) для обогащения строк — например, чтобы [сопоставлять IP-адреса с местоположениями](/use-cases/observability/schema-design#using-ip-dictionaries) или выполнять [поиск по user agent](/use-cases/observability/schema-design#using-regex-dictionaries-user-agent-parsing) при вставке.

### Query languages {#query-languages}

Elasticsearch поддерживает [ряд языков запросов](https://www.elastic.co/docs/explore-analyze/query-filter/languages), включая запросы [DSL](https://www.elastic.co/docs/explore-analyze/query-filter/languages/querydsl), [ES|QL](https://www.elastic.co/docs/explore-analyze/query-filter/languages/esql), [EQL](https://www.elastic.co/docs/explore-analyze/query-filter/languages/eql) и [KQL](https://www.elastic.co/docs/explore-analyze/query-filter/languages/kql) (в стиле Lucene), но имеет ограниченную поддержку `JOIN` — доступны только **left outer join** через [`ES|QL`](https://www.elastic.co/guide/en/elasticsearch/reference/8.x/esql-commands.html#esql-lookup-join). ClickHouse поддерживает **полный синтаксис SQL**, включая [все типы join](/sql-reference/statements/select/join#supported-types-of-join), [оконные функции](/sql-reference/window-functions), подзапросы (включая коррелированные) и CTE. Это серьёзное преимущество для пользователей, которым необходимо коррелировать сигналы наблюдаемости (observability) с бизнес-данными или данными инфраструктуры.

В ClickStack [HyperDX предоставляет совместимый с Lucene интерфейс поиска](/use-cases/observability/clickstack/search) для упрощения миграции, а также полную поддержку SQL через бэкенд ClickHouse. Этот синтаксис сопоставим с синтаксисом [Elastic query string](https://www.elastic.co/docs/reference/query-languages/query-dsl/query-dsl-query-string-query#query-string-syntax). Для точного сравнения этого синтаксиса см. ["Searching in ClickStack and Elastic"](/use-cases/observability/clickstack/migration/elastic/search).

### File formats and interfaces {#file-formats-and-interfaces}

Elasticsearch поддерживает ингестию JSON (и [ограниченно CSV](https://www.elastic.co/docs/reference/enrich-processor/csv-processor)). ClickHouse поддерживает более **70 форматов файлов**, включая Parquet, Protobuf, Arrow, CSV и другие — как для ингестии, так и для экспорта. Это упрощает интеграцию с внешними конвейерами и инструментами.

Обе системы предлагают REST API, но ClickHouse также предоставляет **родной протокол** для низкой задержки и высокой пропускной способности. Родной интерфейс более эффективно, чем HTTP, поддерживает прогресс выполнения запроса, сжатие и потоковую передачу и используется по умолчанию для большинства процессов продакшн-ингестии.

### Indexing and storage {#indexing-and-storage}

<Image img={elasticsearch} alt="Elasticsearch" size="lg"/>

Концепция шардирования является фундаментальной для модели масштабируемости Elasticsearch. Каждый ① [**index**](https://www.elastic.co/blog/what-is-an-elasticsearch-index) разбивается на **shards**, каждый из которых представляет собой физический индекс Lucene, хранящийся на диске в виде сегментов. Шард может иметь одну или несколько физических копий, называемых репликами, для повышения отказоустойчивости. Для масштабирования шарды и реплики могут быть распределены по нескольким узлам. Один шард ② состоит из одного или нескольких неизменяемых сегментов. Сегмент — это базовая структура индексации в Lucene, библиотеке на Java, обеспечивающей функции индексации и поиска, на которой основан Elasticsearch.

:::note Insert processing in Elasticsearch
Ⓐ Новые документы Ⓑ сначала попадают в буфер индексации в памяти, который по умолчанию сбрасывается раз в секунду. Для сброшенных документов используется формула маршрутизации, чтобы определить целевой шард, и на диск для этого шарда записывается новый сегмент. Для повышения эффективности запросов и обеспечения физического удаления удалённых или обновлённых документов сегменты в фоне непрерывно сливаются в более крупные, пока не достигнут максимального размера 5 ГБ. Однако возможно принудительно выполнить слияние в более крупные сегменты.
:::



Elasticsearch рекомендует размер шардов порядка [50 ГБ или 200 миллионов документов](https://www.elastic.co/docs/deploy-manage/production-guidance/optimize-performance/size-shards) из‑за [накладных расходов на кучу JVM и метаданные](https://www.elastic.co/docs/deploy-manage/production-guidance/optimize-performance/size-shards#each-shard-has-overhead). Существует также жесткое ограничение в [2 миллиарда документов на шард](https://www.elastic.co/docs/deploy-manage/production-guidance/optimize-performance/size-shards#troubleshooting-max-docs-limit). Elasticsearch параллелизирует запросы по шардам, но каждый шард обрабатывается с помощью **одного потока**, что делает чрезмерный шардинг и дорогим, и контрпродуктивным. Это по своей сути тесно связывает шардинг с масштабированием: для масштабирования производительности требуются больше шардов (и узлов).

Elasticsearch индексирует все поля в [**обратные индексы**](https://www.elastic.co/docs/manage-data/data-store/index-basics) для быстрого поиска, при необходимости используя [**doc values**](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/doc-values) для агрегаций, сортировки и доступа к вычисляемым полям. Числовые и гео‑поля используют [Block K-D trees](https://users.cs.duke.edu/~pankaj/publications/papers/bkd-sstd.pdf) для поиска по геопространственным данным, а также по числовым диапазонам и диапазонам дат. 

Важно, что Elasticsearch хранит полный оригинальный документ в [`_source`](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/mapping-source-field) (сжатый с помощью `LZ4`, `Deflate` или `ZSTD`), тогда как ClickHouse не хранит отдельное представление документа. Данные реконструируются из колонок во время выполнения запроса, что экономит место на диске. Та же возможность доступна в Elasticsearch с помощью [Synthetic `_source`](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/mapping-source-field#synthetic-source), хотя и с рядом [ограничений](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/mapping-source-field#synthetic-source-restrictions). Отключение `_source` также имеет [последствия](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/mapping-source-field#include-exclude), которые не относятся к ClickHouse.

В Elasticsearch [index mappings](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html) (аналог схем таблиц в ClickHouse) определяют типы полей и структуры данных, используемые для хранения и обработки запросов.

ClickHouse, напротив, является **колоночной** системой — каждая колонка хранится независимо, но всегда отсортирована по первичному/упорядочивающему ключу таблицы. Такое упорядочивание позволяет использовать [разреженные первичные индексы](/primary-indexes), которые дают ClickHouse возможность эффективно пропускать данные во время выполнения запроса. Когда запросы фильтруют по полям первичного ключа, ClickHouse считывает только релевантные части каждой колонки, существенно снижая количество операций дискового ввода‑вывода и повышая производительность — даже без полноценного индекса по каждой колонке. 

<Image img={clickhouse} alt="ClickHouse" size="lg"/>

ClickHouse также поддерживает [**skip indexes**](/optimize/skipping-indexes), которые ускоряют фильтрацию за счет предварительного вычисления индексных данных для выбранных колонок. Их необходимо явно определять, но они могут существенно повысить производительность. Дополнительно ClickHouse позволяет пользователям указывать [кодеки сжатия](/use-cases/observability/schema-design#using-codecs) и алгоритмы сжатия для каждой колонки — то, чего не поддерживает Elasticsearch (его [сжатие](https://www.elastic.co/docs/reference/elasticsearch/index-settings/index-modules) применяется только к хранению JSON в `_source`).

ClickHouse также поддерживает шардинг, но его модель спроектирована с приоритетом **вертикального масштабирования**. Один шард может хранить **триллионы строк** и продолжает эффективно работать до тех пор, пока позволяют память, CPU и диск. В отличие от Elasticsearch, **нет жесткого ограничения по числу строк** в шарде. Шарды в ClickHouse логические — по сути, это отдельные таблицы — и не требуют разбиения, если только набор данных не превышает емкость одного узла. Обычно это происходит из‑за ограничений по размеру диска; шардинг ① вводится только тогда, когда необходим горизонтальный масштаб, что снижает сложность и накладные расходы. В этом случае, аналогично Elasticsearch, шард будет содержать подмножество данных. Данные внутри одного шарда организованы как набор ② неизменяемых частей данных, содержащих ③ несколько структур данных.

Обработка внутри шарда ClickHouse **полностью параллелизована**, и пользователям рекомендуется масштабироваться вертикально, чтобы избежать сетевых затрат, связанных с перемещением данных между узлами. 



:::note Вставка данных в ClickHouse
Вставки в ClickHouse по умолчанию **синхронные** — запись подтверждается только после фиксации транзакции (commit), — но могут быть настроены на **асинхронные вставки**, чтобы реализовать подобное Elasticsearch буферизование и пакетную обработку. Если используются [асинхронные вставки данных](https://clickhouse.com/blog/asynchronous-data-inserts-in-clickhouse), то Ⓐ вновь вставленные строки сначала попадают в Ⓑ буфер вставки в памяти, который по умолчанию сбрасывается каждые 200 миллисекунд. Если используется несколько шардов, для маршрутизации вновь вставленных строк на целевой шард используется [распределённая таблица](/engines/table-engines/special/distributed). На диске для шарда записывается новая часть.
:::

### Распределение и репликация {#distribution-and-replication}

Хотя и Elasticsearch, и ClickHouse используют кластеры, шарды и реплики для обеспечения масштабируемости и отказоустойчивости, их модели существенно различаются по реализации и характеристикам производительности.

Elasticsearch использует модель репликации **primary-secondary**. Когда данные записываются в основной (primary) шард, они синхронно копируются в одну или несколько реплик. Эти реплики сами по себе являются полными шардами, распределёнными по узлам для обеспечения избыточности. Elasticsearch подтверждает запись только после того, как все требуемые реплики подтвердят операцию — это модель, обеспечивающая почти **последовательную согласованность** (sequential consistency), хотя **грязные чтения** с реплик возможны до полной синхронизации. **Master-узел** координирует кластер, управляя размещением шардов, состоянием и выборами лидера.

Напротив, ClickHouse по умолчанию использует **конечную согласованность** (eventual consistency), координируемую с помощью **Keeper** — лёгкой альтернативы ZooKeeper. Записи могут отправляться на любую реплику напрямую или через [**распределённую таблицу**](/engines/table-engines/special/distributed), которая автоматически выбирает реплику. Репликация асинхронная — изменения распространяются на другие реплики после подтверждения записи. Для более строгих гарантий ClickHouse [поддерживает **последовательную согласованность**](/migrations/postgresql/appendix#sequential-consistency), при которой запись подтверждается только после фиксации на всех репликах, хотя этот режим редко используется из-за его влияния на производительность. Распределённые таблицы унифицируют доступ к нескольким шардам, перенаправляя запросы `SELECT` на все шарды и объединяя результаты. Для операций `INSERT` они балансируют нагрузку, равномерно распределяя данные по шардам. Репликация в ClickHouse очень гибкая: любая реплика (копия шарда) может принимать записи, и все изменения асинхронно синхронизируются с остальными. Такая архитектура позволяет обслуживать запросы без перерывов при сбоях или обслуживании, при этом повторная синхронизация выполняется автоматически, устраняя необходимость в жёстком primary-secondary на уровне данных.

:::note ClickHouse Cloud
В **ClickHouse Cloud** архитектура использует модель вычислений типа shared-nothing, при которой один **шард опирается на объектное хранилище**. Это заменяет традиционную отказоустойчивость на основе реплик и позволяет **одновременно читать и записывать шард с нескольких узлов**. Разделение хранилища и вычислений обеспечивает эластичное масштабирование без явного управления репликами.
:::

Вкратце:

- **Elastic**: шарды — это физические структуры Lucene, привязанные к памяти JVM. Чрезмерное шардирование приводит к потерям производительности. Репликация синхронная и координируется master-узлом.
- **ClickHouse**: шарды логические и вертикально масштабируемые, с очень эффективным локальным выполнением. Репликация асинхронная (но может быть последовательной), координация лёгкая.

В конечном счёте, ClickHouse делает ставку на простоту и производительность при масштабировании, минимизируя необходимость тонкой настройки шардов, при этом при необходимости предоставляя строгие гарантии согласованности.

### Дедупликация и маршрутизация {#deduplication-and-routing}

Elasticsearch выполняет дедупликацию документов на основе их `_id`, маршрутизируя их по шардам соответствующим образом. ClickHouse не хранит идентификатор строки по умолчанию, но поддерживает **дедупликацию во время вставки**, позволяя пользователям безопасно повторять неудачные вставки. Для более тонкого контроля `ReplacingMergeTree` и другие движки таблиц позволяют выполнять дедупликацию по конкретным столбцам.

Маршрутизация индекса в Elasticsearch гарантирует, что определённые документы всегда направляются в определённые шарды. В ClickHouse пользователи могут определять **ключи шардирования** или использовать таблицы `Distributed`, чтобы добиться похожей локальности данных.

### Агрегации и модель выполнения {#aggregations-execution-model}

Обе системы поддерживают агрегацию данных, но ClickHouse предлагает значительно [больше функций](/sql-reference/aggregate-functions/reference), включая статистические, аппроксимирующие и специализированные аналитические функции.

В задачах наблюдаемости один из наиболее распространённых вариантов использования агрегаций — подсчёт того, как часто возникают конкретные сообщения журнала или события (и оповещение в случае необычной частоты).

Эквивалентом SQL-запроса ClickHouse `SELECT count(*) FROM ... GROUP BY ...` в Elasticsearch является [terms aggregation](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html), которая относится к [bucket aggregation](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket.html) в Elasticsearch.

`GROUP BY` с `count(*)` в ClickHouse и terms aggregation в Elasticsearch в целом эквивалентны по функциональности, но сильно различаются по реализации, производительности и качеству результатов.



Эта агрегация в Elasticsearch [оценивает результаты в запросах типа "top-N"](https://www.elastic.co/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation#terms-agg-doc-count-error) (например, топ‑10 хостов по количеству), когда запрашиваемые данные распределены по нескольким шардам. Такой подход повышает скорость, но может снижать точность. Пользователи могут уменьшить эту погрешность, [анализируя `doc_count_error_upper_bound`](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html#terms-agg-doc-count-error) и увеличивая параметр `shard_size` — ценой большего расхода памяти и более медленного выполнения запросов.

Elasticsearch также требует указания [параметра `size`](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation-size) для всех агрегатов с разбиением по бакетам — нет способа вернуть все уникальные группы без явного задания лимита. Агрегации с высокой кардинальностью рискуют упереться в [ограничение `max_buckets`](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-settings.html#search-settings-max-buckets) или вынуждают выполнять пагинацию с помощью [составной (composite) агрегации](https://www.elastic.co/docs/reference/aggregations/bucket/composite-aggregation), что часто бывает сложно и неэффективно.

ClickHouse, напротив, изначально выполняет точные агрегации. Такие функции, как `count(*)`, возвращают корректные результаты без необходимости подстройки конфигурации, что делает поведение запросов более простым и предсказуемым.

ClickHouse не накладывает ограничений на размер. Вы можете выполнять неограниченные `GROUP BY`‑запросы по большим наборам данных. Если пороги по памяти превышены, ClickHouse [может сбрасывать данные на диск](https://clickhouse.com/docs/en/sql-reference/statements/select/group-by#group-by-in-external-memory). Агрегации, группирующие по префиксу первичного ключа, особенно эффективны, зачастую выполняясь с минимальным потреблением памяти.

#### Execution model {#execution-model}

Вышеописанные различия объясняются моделями выполнения запросов в Elasticsearch и ClickHouse, которые принципиально по‑разному подходят к исполнению запросов и использованию параллелизма.

ClickHouse был спроектирован для максимальной эффективности на современном оборудовании. По умолчанию ClickHouse выполняет SQL‑запрос с N параллельными линиями исполнения на машине с N ядрами CPU: 

<Image img={clickhouse_execution} alt="ClickHouse execution" size="lg"/>

На одном узле линии выполнения делят данные на независимые диапазоны, что позволяет обрабатывать их параллельно в потоках CPU. Это включает фильтрацию, агрегацию и сортировку. Локальные результаты с каждой линии в итоге объединяются, и применяется оператор `LIMIT`, если запрос содержит соответствующее предложение.

Выполнение запросов дополнительно распараллеливается за счёт:
1. **SIMD‑векторизации**: операции над колоночными данными используют [SIMD‑инструкции CPU](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data) (например, [AVX512](https://en.wikipedia.org/wiki/AVX-512)), что позволяет пакетно обрабатывать значения.
2. **Параллелизма на уровне кластера**: в распределённых конфигурациях каждый узел выполняет обработку запросов локально. [Частичные состояния агрегации](https://clickhouse.com/blog/aggregate-functions-combinators-in-clickhouse-for-arrays-maps-and-states#working-with-aggregation-states) потоково передаются на инициирующий узел и там объединяются. Если ключи `GROUP BY` в запросе согласованы с ключами шардинга, объём слияния может быть [минимизирован или полностью устранён](/operations/settings/settings#distributed_group_by_no_merge).
<br/>
Эта модель обеспечивает эффективное масштабирование по ядрам и узлам, делая ClickHouse хорошо подходящим для масштабной аналитики. Использование *частичных состояний агрегации* позволяет объединять промежуточные результаты с разных потоков и узлов без потери точности.

Elasticsearch, напротив, для большинства агрегаций назначает по одному потоку на шард, независимо от числа доступных ядер CPU. Эти потоки возвращают локальные для шарда top‑N результаты, которые затем объединяются на координирующем узле. Такой подход может приводить к недоиспользованию ресурсов системы и к потенциальной неточности глобальных агрегаций, особенно когда частые термины распределены по нескольким шардам. Точность можно повысить, увеличив параметр `shard_size`, но это происходит за счёт большего использования памяти и увеличения задержек выполнения запросов.

<Image img={elasticsearch_execution} alt="Elasticsearch execution" size="lg"/>

В итоге ClickHouse выполняет агрегации и запросы с более тонким уровнем параллелизма и лучшим контролем над аппаратными ресурсами, тогда как Elasticsearch опирается на выполнение по шардам с более жёсткими ограничениями.

Для более детального рассмотрения механики агрегаций в соответствующих технологиях рекомендуем публикацию в блоге ["ClickHouse vs. Elasticsearch: The Mechanics of Count Aggregations"](https://clickhouse.com/blog/clickhouse_vs_elasticsearch_mechanics_of_count_aggregations#elasticsearch).

### Data management {#data-management}

Elasticsearch и ClickHouse принципиально по‑разному подходят к управлению данными наблюдаемости во временных рядах — в частности, в аспектах хранения (retention), ротации (rollover) и многоуровневого хранения (tiered storage).



#### Управление жизненным циклом индексов vs нативный TTL {#lifecycle-vs-ttl}

В Elasticsearch долгосрочное управление данными осуществляется с помощью **Index Lifecycle Management (ILM)** и **Data Streams**. Эти механизмы позволяют задавать политики, которые определяют, когда индексы должны переключаться (rollover; например, по достижении определённого размера или возраста), когда старые индексы следует переносить на более дешёвое хранилище (например, уровни warm или cold) и когда их нужно окончательно удалять. Это необходимо, поскольку Elasticsearch **не поддерживает повторное шардирование**, и шарды не могут расти бесконечно без деградации производительности. Чтобы управлять размерами шардов и обеспечивать эффективное удаление, необходимо периодически создавать новые индексы и удалять старые — фактически выполняя ротацию данных на уровне индексов.

ClickHouse использует иной подход. Данные, как правило, хранятся в **одной таблице** и управляются с помощью **TTL-выражений (time-to-live)** на уровне столбцов или партиций. Данные могут быть **разбиты на партиции по дате**, что позволяет эффективно их удалять без необходимости создавать новые таблицы или выполнять ротацию индексов. По мере старения данных и выполнения TTL-условия ClickHouse автоматически удаляет их — не требуется какая-либо дополнительная инфраструктура для управления ротацией.

#### Уровни хранилища и hot-warm архитектуры {#storage-tiers}

Elasticsearch поддерживает архитектуры хранения **hot-warm-cold-frozen**, где данные перемещаются между уровнями хранилища с разными характеристиками производительности. Обычно это настраивается через ILM и привязано к ролям нод в кластере.

ClickHouse поддерживает **многоуровневое хранилище** с помощью нативных движков таблиц, таких как `MergeTree`, которые могут автоматически перемещать старые данные между различными **томами (volumes)** (например, с SSD на HDD и далее в объектное хранилище) по пользовательским правилам. Это позволяет имитировать hot-warm-cold подход Elastic — но без сложности управления несколькими ролями нод или кластерами.

:::note ClickHouse Cloud
В **ClickHouse Cloud** это становится ещё более прозрачным: все данные хранятся в **объектном хранилище (например, S3)**, а вычислительные ресурсы отделены. Данные могут оставаться в объектном хранилище до момента запроса, после чего они подгружаются и кэшируются локально (или в распределённом кэше), обеспечивая такой же профиль затрат, как frozen-уровень в Elastic, но с лучшими характеристиками производительности. Такой подход означает, что данные не нужно перемещать между уровнями хранилища, делая hot-warm архитектуры избыточными.
:::

### Rollups vs инкрементальные агрегаты {#rollups-vs-incremental-aggregates}

В Elasticsearch **rollups** или **aggregates** реализуются с помощью механизма под названием [**transforms**](https://www.elastic.co/guide/en/elasticsearch/reference/current/transforms.html). Они используются для агрегирования временных рядов с фиксированными интервалами (например, каждый час или каждый день) по модели **скользящего окна**. Такие операции настраиваются как периодические фоновые задачи, агрегирующие данные из одного индекса и записывающие результаты в отдельный **rollup-индекс**. Это позволяет снизить стоимость запросов на большие интервалы времени, избегая повторных сканов сырых высококардинальных данных.

Следующая диаграмма в общих чертах иллюстрирует, как работают transforms (обратите внимание, что синим цветом показаны все документы, принадлежащие одному и тому же бакету, для которого мы хотим заранее вычислить агрегированные значения):

<Image img={elasticsearch_transforms} alt="Трансформации в Elasticsearch" size="lg"/>

Непрерывные transforms используют [checkpoints](https://www.elastic.co/guide/en/elasticsearch/reference/current/transform-checkpoints.html), основанные на настраиваемом интервале проверки (параметр transform [frequency](https://www.elastic.co/guide/en/elasticsearch/reference/current/put-transform.html) со значением по умолчанию 1 минута). На диаграмме выше мы предполагаем, что ① новая контрольная точка (checkpoint) создаётся после истечения интервала проверки. Затем Elasticsearch проверяет изменения в исходном индексе transforms и обнаруживает три новых `blue` документа (11, 12 и 13), появившихся после предыдущей контрольной точки. Поэтому исходный индекс фильтруется по всем существующим `blue` документам и с помощью [composite aggregation](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-composite-aggregation.html) (для использования [pagination](https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html) результатов) агрегированные значения пересчитываются (и целевой индекс обновляется документом, который заменяет документ с предыдущими агрегированными значениями). Аналогично, в точках ② и ③ новые контрольные точки обрабатываются путём проверки изменений и пересчёта агрегированных значений по всем существующим документам, принадлежащим тому же `blue`-бакету.

ClickHouse использует принципиально иной подход. Вместо периодического переагрегирования данных ClickHouse поддерживает **инкрементальные материализованные представления**, которые трансформируют и агрегируют данные **в момент вставки**. Когда новые данные записываются в исходную таблицу, материализованное представление выполняет предопределённый SQL-запрос агрегации только над новыми **вставленными блоками** и записывает агрегированные результаты в целевую таблицу.



Эта модель стала возможной благодаря поддержке в ClickHouse [**частичных агрегатных состояний**](https://clickhouse.com/docs/en/sql-reference/data-types/aggregatefunction) — промежуточных представлений агрегатных функций, которые могут быть сохранены и затем объединены. Это позволяет пользователям хранить частично агрегированные результаты, которые быстро запрашиваются и при этом недороги в обновлении. Поскольку агрегация выполняется по мере поступления данных, нет необходимости запускать дорогостоящие периодические задания или заново агрегировать старые данные.

Ниже мы схематично показываем механику инкрементных материализованных представлений в абстрактном виде (обратите внимание, что мы используем синий цвет для всех строк, принадлежащих одной и той же группе, для которой мы хотим заранее вычислить агрегатные значения): 

<Image img={clickhouse_mvs} alt="Материализованные представления ClickHouse" size="lg"/>

На схеме выше исходная таблица материализованного представления уже содержит часть данных, в которой хранятся некоторые `blue` строки (с 1 по 10), принадлежащие одной и той же группе. Для этой группы уже существует часть данных в целевой таблице представления, хранящая [частичное агрегатное состояние](https://www.youtube.com/watch?v=QDAJTKZT8y4) для `blue`-группы. Когда выполняются вставки ① ② ③ новых строк в исходную таблицу, для каждой вставки создаётся соответствующая часть данных исходной таблицы и, параллельно, для каждого блока вновь вставленных строк вычисляется частичное агрегатное состояние и вставляется в виде части данных в целевую таблицу материализованного представления. ④ Во время фоновых слияний частей частичные агрегатные состояния объединяются, что приводит к инкрементной агрегации данных. 

Обратите внимание, что все [агрегатные функции](https://clickhouse.com/docs/en/sql-reference/aggregate-functions/reference) (их более 90), включая их комбинации с [комбинаторами агрегатных функций](https://www.youtube.com/watch?v=7ApwD0cfAFI), поддерживают [частичные агрегатные состояния](https://clickhouse.com/docs/en/sql-reference/data-types/aggregatefunction). 

Более конкретное сравнение Elasticsearch и ClickHouse для инкрементных агрегатов приведено в этом [примере](https://github.com/ClickHouse/examples/tree/main/blog-examples/clickhouse-vs-elasticsearch/continuous-data-transformation#continuous-data-transformation-example). 

Преимущества подхода ClickHouse заключаются в следующем:

- **Всегда актуальные агрегаты**: материализованные представления всегда синхронизированы с исходной таблицей.
- **Отсутствие фоновых заданий**: агрегации переносятся на время вставки, а не на время запроса.
- **Лучшая производительность в реальном времени**: идеально для нагрузок наблюдаемости и аналитики в реальном времени, когда свежие агрегаты требуются немедленно.
- **Композиционность**: материализованные представления можно накладывать слоями или соединять с другими представлениями и таблицами для более сложных стратегий ускорения запросов.
- **Разные TTL**: к исходной и целевой таблицам материализованного представления можно применять разные настройки TTL.

Эта модель особенно эффективна для сценариев наблюдаемости, где пользователям необходимо вычислять метрики, такие как поминутные уровни ошибок, задержки или top-N-разбиения без сканирования миллиардов сырых записей для каждого запроса.

### Поддержка lakehouse {#lakehouse-support}

ClickHouse и Elasticsearch используют принципиально разные подходы к интеграции с lakehouse-архитектурами. ClickHouse — это полнофункциональный движок выполнения запросов, способный выполнять запросы по lakehouse-форматам, таким как [Iceberg](/sql-reference/table-functions/iceberg) и [Delta Lake](/sql-reference/table-functions/deltalake), а также интегрироваться с каталогами data lake, такими как [AWS Glue](/use-cases/data-lake/glue-catalog) и [Unity catalog](/use-cases/data-lake/unity-catalog). Эти форматы опираются на эффективное выполнение запросов к файлам [Parquet](/interfaces/formats/Parquet), которые полностью поддерживаются ClickHouse. ClickHouse может напрямую читать таблицы Iceberg и Delta Lake, обеспечивая бесшовную интеграцию с современными архитектурами data lake.

В отличие от этого, Elasticsearch жёстко связан со своим внутренним форматом данных и хранилищем на базе Lucene. Он не может напрямую выполнять запросы к lakehouse-форматам или файлам Parquet, что ограничивает его способность участвовать в современных архитектурах data lake. Elasticsearch требует предварительного преобразования данных и загрузки их в собственный проприетарный формат перед выполнением запросов.

Lakehouse-возможности ClickHouse выходят далеко за рамки простого чтения данных:



- **Интеграция с каталогами данных**: ClickHouse поддерживает интеграцию с каталогами данных, такими как [AWS Glue](/use-cases/data-lake/glue-catalog), что обеспечивает автоматическое обнаружение и доступ к таблицам в объектном хранилище.
- **Поддержка объектного хранилища**: нативная поддержка выполнения запросов к данным, размещённым в [S3](/engines/table-engines/integrations/s3), [GCS](/sql-reference/table-functions/gcs) и [Azure Blob Storage](/engines/table-engines/integrations/azureBlobStorage), без необходимости перемещения данных.
- **Федерация запросов**: возможность коррелировать данные из нескольких источников, включая lakehouse‑таблицы, традиционные базы данных и таблицы ClickHouse с использованием [внешних словарей](/dictionary) и [табличных функций](/sql-reference/table-functions).
- **Инкрементальная загрузка**: поддержка непрерывной загрузки из lakehouse‑таблиц в локальные таблицы [MergeTree](/engines/table-engines/mergetree-family/mergetree) с использованием таких возможностей, как [S3Queue](/engines/table-engines/integrations/s3queue) и [ClickPipes](/integrations/clickpipes).
- **Оптимизация производительности**: распределённое выполнение запросов по данным lakehouse с использованием [функций cluster](/sql-reference/table-functions/cluster) для повышения производительности.

Эти возможности делают ClickHouse естественным выбором для организаций, внедряющих lakehouse‑архитектуры, позволяя им использовать как гибкость озёр данных, так и производительность колоночной базы данных. 
