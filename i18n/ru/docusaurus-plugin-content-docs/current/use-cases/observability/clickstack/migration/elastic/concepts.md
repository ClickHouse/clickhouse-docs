---
slug: /use-cases/observability/clickstack/migration/elastic/concepts
title: 'Эквивалентные понятия в ClickStack и Elastic'
pagination_prev: null
pagination_next: null
sidebar_label: 'Эквивалентные понятия'
sidebar_position: 1
description: 'Эквивалентные понятия — ClickStack и Elastic'
show_related_blogs: true
keywords: ['Elasticsearch']
doc_type: 'reference'
---

import Image from '@theme/IdealImage';
import elasticsearch from '@site/static/images/use-cases/observability/elasticsearch.png';
import clickhouse from '@site/static/images/use-cases/observability/clickhouse.png';
import clickhouse_execution from '@site/static/images/use-cases/observability/clickhouse-execution.png';
import elasticsearch_execution from '@site/static/images/use-cases/observability/elasticsearch-execution.png';
import elasticsearch_transforms from '@site/static/images/use-cases/observability/es-transforms.png';
import clickhouse_mvs from '@site/static/images/use-cases/observability/ch-mvs.png';


## Elastic Stack против ClickStack {#elastic-vs-clickstack}

И Elastic Stack, и ClickStack охватывают основные функции платформы наблюдаемости, но реализуют их с различными подходами к проектированию. Эти функции включают:

- **UI и оповещения**: инструменты для запроса данных, создания дашбордов и управления оповещениями.
- **Хранилище и движок запросов**: серверные системы, отвечающие за хранение данных наблюдаемости и выполнение аналитических запросов.
- **Сбор данных и ETL**: агенты и конвейеры, которые собирают телеметрические данные и обрабатывают их перед загрузкой.

В таблице ниже показано, как каждый стек сопоставляет свои компоненты с этими функциями:

| **Функция**                    | **Elastic Stack**                                           | **ClickStack**                                                   | **Комментарии**                                                                                                                                                                                                      |
| --------------------------- | ----------------------------------------------------------- | ---------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **UI и оповещения**           | **Kibana** — дашборды, поиск и оповещения                 | **HyperDX** — UI в реальном времени, поиск и оповещения                   | Оба служат основным интерфейсом для пользователей, включая визуализацию и управление оповещениями. HyperDX специально разработан для наблюдаемости и тесно интегрирован с семантикой OpenTelemetry.                          |
| **Хранилище и движок запросов**  | **Elasticsearch** — хранилище JSON-документов с инвертированным индексом | **ClickHouse** — колоночная база данных с векторизованным движком | Elasticsearch использует инвертированный индекс, оптимизированный для поиска; ClickHouse использует колоночное хранилище и SQL для высокоскоростной аналитики структурированных и полуструктурированных данных.                                            |
| **Сбор данных**         | **Elastic Agent**, **Beats** (например, Filebeat, Metricbeat)    | **OpenTelemetry Collector** (граничный + шлюз)                     | Elastic поддерживает пользовательские агенты доставки и унифицированный агент, управляемый Fleet. ClickStack использует OpenTelemetry, обеспечивая независимый от поставщика сбор и обработку данных.                                                |
| **SDK инструментирования**    | **Elastic APM agents** (проприетарные)                        | **OpenTelemetry SDKs** (распространяемые ClickStack)               | SDK Elastic привязаны к стеку Elastic. ClickStack построен на SDK OpenTelemetry для логов, метрик и трассировок в основных языках программирования.                                                                             |
| **ETL / Обработка данных**   | **Logstash**, конвейеры загрузки                              | **OpenTelemetry Collector** + материализованные представления ClickHouse      | Elastic использует конвейеры загрузки и Logstash для преобразования данных. ClickStack переносит вычисления на момент вставки через материализованные представления и процессоры OTel collector, которые эффективно и инкрементально преобразуют данные. |
| **Философия архитектуры** | Вертикально интегрированные проприетарные агенты и форматы       | Слабосвязанные компоненты на основе открытых стандартов                  | Elastic создает тесно интегрированную экосистему. ClickStack делает акцент на модульности и стандартах (OpenTelemetry, SQL, объектное хранилище) для обеспечения гибкости и экономической эффективности.                                           |

ClickStack делает акцент на открытых стандартах и совместимости, являясь полностью нативным для OpenTelemetry от сбора до UI. В отличие от этого, Elastic предоставляет тесно связанную, но более вертикально интегрированную экосистему с проприетарными агентами и форматами.

Учитывая, что **Elasticsearch** и **ClickHouse** являются основными движками, отвечающими за хранение, обработку и запросы данных в соответствующих стеках, понимание их различий имеет важное значение. Эти системы определяют производительность, масштабируемость и гибкость всей архитектуры наблюдаемости. В следующем разделе рассматриваются ключевые различия между Elasticsearch и ClickHouse, включая то, как они моделируют данные, обрабатывают загрузку, выполняют запросы и управляют хранилищем.


## Elasticsearch и ClickHouse {#elasticsearch-vs-clickhouse}

ClickHouse и Elasticsearch организуют данные и выполняют запросы на основе различных базовых моделей, однако многие ключевые концепции служат схожим целям. В этом разделе описываются основные соответствия для пользователей, знакомых с Elastic, и их аналоги в ClickHouse. Хотя терминология различается, большинство рабочих процессов наблюдаемости можно воспроизвести — часто более эффективно — в ClickStack.

### Основные структурные концепции {#core-structural-concepts}

| **Elasticsearch** | **ClickHouse / SQL**   | **Описание**                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ----------------- | ---------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Field**         | **Column**             | Базовая единица данных, содержащая одно или несколько значений определенного типа. Поля Elasticsearch могут хранить примитивы, а также массивы и объекты. Поля могут иметь только один тип. ClickHouse также поддерживает массивы и объекты (`Tuples`, `Maps`, `Nested`), а также динамические типы, такие как [`Variant`](/sql-reference/data-types/variant) и [`Dynamic`](/sql-reference/data-types/dynamic), которые позволяют столбцу иметь несколько типов.              |
| **Document**      | **Row**                | Набор полей (столбцов). Документы Elasticsearch по умолчанию более гибкие: новые поля добавляются динамически на основе данных (тип выводится автоматически). Строки ClickHouse по умолчанию привязаны к схеме, и пользователям необходимо вставлять все столбцы для строки или их подмножество. Тип [`JSON`](/integrations/data-formats/json/overview) в ClickHouse поддерживает эквивалентное динамическое создание полуструктурированных столбцов на основе вставляемых данных. |
| **Index**         | **Table**              | Единица выполнения запросов и хранения данных. В обеих системах запросы выполняются к индексам или таблицам, которые хранят строки/документы.                                                                                                                                                                                                                                                                                                                       |
| _Implicit_        | Schema (SQL)           | SQL-схемы группируют таблицы в пространства имен, часто используемые для управления доступом. Elasticsearch и ClickHouse не имеют схем, но обе системы поддерживают безопасность на уровне строк и таблиц через роли и RBAC.                                                                                                                                                                                                                                        |
| **Cluster**       | **Cluster / Database** | Кластеры Elasticsearch — это экземпляры времени выполнения, которые управляют одним или несколькими индексами. В ClickHouse базы данных организуют таблицы в логическом пространстве имен, обеспечивая ту же логическую группировку, что и кластер в Elasticsearch. Кластер ClickHouse представляет собой распределенный набор узлов, аналогичный Elasticsearch, но отделен и независим от самих данных.                                                                                           |

### Моделирование данных и гибкость {#data-modeling-and-flexibility}

Elasticsearch известен своей гибкостью схемы благодаря [динамическим отображениям](https://www.elastic.co/docs/manage-data/data-store/mapping/dynamic-mapping). Поля создаются по мере приема документов, а типы выводятся автоматически — если схема не указана явно. ClickHouse по умолчанию более строгий — таблицы определяются с явными схемами — но предлагает гибкость через типы [`Dynamic`](/sql-reference/data-types/dynamic), [`Variant`](/sql-reference/data-types/variant) и [`JSON`](/integrations/data-formats/json/overview). Они обеспечивают прием полуструктурированных данных с динамическим созданием столбцов и выводом типов, аналогично Elasticsearch. Аналогичным образом, тип [`Map`](/sql-reference/data-types/map) позволяет хранить произвольные пары ключ-значение — хотя для ключа и значения применяется единый тип.

Подход ClickHouse к гибкости типов более прозрачен и контролируем. В отличие от Elasticsearch, где конфликты типов могут вызывать ошибки приема данных, ClickHouse допускает данные смешанных типов в столбцах [`Variant`](/sql-reference/data-types/variant) и поддерживает эволюцию схемы через использование типа [`JSON`](/integrations/data-formats/json/overview).

Если не используется [`JSON`](/integrations/data-formats/json/overview), схема определяется статически. Если значения для строки не предоставлены, они будут либо определены как [`Nullable`](/sql-reference/data-types/nullable) (не используется в ClickStack), либо получат значение по умолчанию для типа, например, пустое значение для `String`.

### Прием и преобразование данных {#ingestion-and-transformation}

Elasticsearch использует конвейеры приема данных с процессорами (например, `enrich`, `rename`, `grok`) для преобразования документов перед индексацией. В ClickHouse аналогичная функциональность достигается с помощью [**инкрементных материализованных представлений**](/materialized-view/incremental-materialized-view), которые могут [фильтровать, преобразовывать](/materialized-view/incremental-materialized-view#filtering-and-transformation) или [обогащать](/materialized-view/incremental-materialized-view#lookup-table) входящие данные и вставлять результаты в целевые таблицы. Вы также можете вставлять данные в движок таблиц `Null`, если вам нужно сохранить только результат материализованного представления. Это означает, что сохраняются только результаты материализованных представлений, а исходные данные отбрасываются — что экономит место для хранения.


Для обогащения данных Elasticsearch поддерживает специализированные [процессоры обогащения](https://www.elastic.co/docs/reference/enrich-processor/enrich-processor), добавляющие контекст к документам. В ClickHouse [**словари**](/dictionary) могут использоваться как [во время выполнения запросов](/dictionary#query-time-enrichment), так и [во время загрузки данных](/dictionary#index-time-enrichment) для обогащения строк — например, для [сопоставления IP-адресов с местоположениями](/use-cases/observability/schema-design#using-ip-dictionaries) или применения [поиска по user agent](/use-cases/observability/schema-design#using-regex-dictionaries-user-agent-parsing) при вставке.

### Языки запросов {#query-languages}

Elasticsearch поддерживает [несколько языков запросов](https://www.elastic.co/docs/explore-analyze/query-filter/languages), включая запросы [DSL](https://www.elastic.co/docs/explore-analyze/query-filter/languages/querydsl), [ES|QL](https://www.elastic.co/docs/explore-analyze/query-filter/languages/esql), [EQL](https://www.elastic.co/docs/explore-analyze/query-filter/languages/eql) и [KQL](https://www.elastic.co/docs/explore-analyze/query-filter/languages/kql) (в стиле Lucene), но имеет ограниченную поддержку соединений — доступны только **левые внешние соединения** через [`ES|QL`](https://www.elastic.co/guide/en/elasticsearch/reference/8.x/esql-commands.html#esql-lookup-join). ClickHouse поддерживает **полный синтаксис SQL**, включая [все типы соединений](/sql-reference/statements/select/join#supported-types-of-join), [оконные функции](/sql-reference/window-functions), подзапросы (в том числе коррелированные) и CTE. Это существенное преимущество для пользователей, которым необходимо коррелировать сигналы наблюдаемости с бизнес-данными или данными инфраструктуры.

В ClickStack [HyperDX предоставляет интерфейс поиска, совместимый с Lucene](/use-cases/observability/clickstack/search), для упрощения перехода, наряду с полной поддержкой SQL через бэкенд ClickHouse. Этот синтаксис сопоставим с синтаксисом [строки запроса Elastic](https://www.elastic.co/docs/reference/query-languages/query-dsl/query-dsl-query-string-query#query-string-syntax). Для точного сравнения синтаксиса см. [«Поиск в ClickStack и Elastic»](/use-cases/observability/clickstack/migration/elastic/search).

### Форматы файлов и интерфейсы {#file-formats-and-interfaces}

Elasticsearch поддерживает загрузку JSON (и [ограниченную поддержку CSV](https://www.elastic.co/docs/reference/enrich-processor/csv-processor)). ClickHouse поддерживает более **70 форматов файлов**, включая Parquet, Protobuf, Arrow, CSV и другие — как для загрузки, так и для экспорта. Это упрощает интеграцию с внешними конвейерами и инструментами.

Обе системы предоставляют REST API, но ClickHouse также предоставляет **нативный протокол** для взаимодействия с низкой задержкой и высокой пропускной способностью. Нативный интерфейс поддерживает отслеживание прогресса запросов, сжатие и потоковую передачу более эффективно, чем HTTP, и является стандартным для большинства производственных сценариев загрузки данных.

### Индексирование и хранение {#indexing-and-storage}

<Image img={elasticsearch} alt='Elasticsearch' size='lg' />

Концепция шардирования является основополагающей для модели масштабируемости Elasticsearch. Каждый ① [**индекс**](https://www.elastic.co/blog/what-is-an-elasticsearch-index) разбивается на **шарды**, каждый из которых представляет собой физический индекс Lucene, хранящийся в виде сегментов на диске. Шард может иметь одну или несколько физических копий, называемых репликами шардов, для обеспечения отказоустойчивости. Для масштабируемости шарды и реплики могут распределяться по нескольким узлам. Один шард ② состоит из одного или нескольких неизменяемых сегментов. Сегмент — это базовая структура индексирования Lucene, библиотеки Java, предоставляющей функции индексирования и поиска, на которых основан Elasticsearch.

:::note Обработка вставки в Elasticsearch
Ⓐ Вновь вставленные документы Ⓑ сначала попадают в буфер индексирования в памяти, который по умолчанию сбрасывается раз в секунду. Для определения целевого шарда для сброшенных документов используется формула маршрутизации, и для шарда на диске записывается новый сегмент. Для повышения эффективности запросов и обеспечения физического удаления удалённых или обновлённых документов сегменты непрерывно объединяются в фоновом режиме в более крупные сегменты, пока не достигнут максимального размера 5 ГБ. Однако возможно принудительное объединение в более крупные сегменты.
:::


Elasticsearch рекомендует подбирать размер шардов порядка [50 ГБ или 200 миллионов документов](https://www.elastic.co/docs/deploy-manage/production-guidance/optimize-performance/size-shards) из‑за [накладных расходов на кучу JVM и метаданные](https://www.elastic.co/docs/deploy-manage/production-guidance/optimize-performance/size-shards#each-shard-has-overhead). Также существует жесткий предел в [2 миллиарда документов на шард](https://www.elastic.co/docs/deploy-manage/production-guidance/optimize-performance/size-shards#troubleshooting-max-docs-limit). Elasticsearch распараллеливает выполнение запросов по шардам, но каждый шард обрабатывается **одним потоком**, что делает чрезмерное шардирование одновременно дорогостоящим и контрпродуктивным. В результате шардирование оказывается жестко связано с масштабированием: для увеличения производительности требуется больше шардов (и узлов).

Elasticsearch индексирует все поля в [**обратные индексы**](https://www.elastic.co/docs/manage-data/data-store/index-basics) для быстрого поиска, при необходимости используя [**doc values**](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/doc-values) для агрегаций, сортировки и доступа к вычисляемым полям. Числовые и гео‑поля используют [Block K-D trees](https://users.cs.duke.edu/~pankaj/publications/papers/bkd-sstd.pdf) для поиска по геопространственным данным, а также по числовым и временным диапазонам. 

Важно, что Elasticsearch хранит полный исходный документ в [`_source`](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/mapping-source-field) (сжатый с помощью `LZ4`, `Deflate` или `ZSTD`), в то время как ClickHouse не хранит отдельное представление документа. Данные реконструируются из столбцов во время выполнения запроса, что экономит место на диске. Аналогичная возможность существует в Elasticsearch с использованием [Synthetic `_source`](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/mapping-source-field#synthetic-source), хотя и с рядом [ограничений](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/mapping-source-field#synthetic-source-restrictions). Отключение `_source` также имеет [последствия](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/mapping-source-field#include-exclude), которые не относятся к ClickHouse.

В Elasticsearch [index mappings](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html) (эквивалент схем таблиц в ClickHouse) определяют типы полей и структуры данных, используемые для хранения и выполнения запросов.

ClickHouse, напротив, является **колоночной** системой — каждый столбец хранится независимо, но всегда отсортирован по первичному/упорядочивающему ключу таблицы. Эта упорядоченность позволяет использовать [разреженные первичные индексы](/primary-indexes), благодаря которым ClickHouse эффективно пропускает данные во время выполнения запроса. Когда запросы фильтруют по полям первичного ключа, ClickHouse считывает только релевантные части каждого столбца, значительно снижая количество операций ввода‑вывода с диска и повышая производительность — даже без полного индекса по каждому столбцу. 

<Image img={clickhouse} alt="ClickHouse" size="lg"/>

ClickHouse также поддерживает [**skip indexes**](/optimize/skipping-indexes), которые ускоряют фильтрацию за счет предварительного вычисления индексных данных для выбранных столбцов. Они должны быть явно определены, но могут существенно улучшать производительность. Дополнительно ClickHouse позволяет пользователям задавать [кодеки сжатия](/use-cases/observability/schema-design#using-codecs) и алгоритмы сжатия для каждого столбца — того, чего Elasticsearch не поддерживает (его [compression](https://www.elastic.co/docs/reference/elasticsearch/index-settings/index-modules) применяется только к хранению JSON в `_source`).

ClickHouse также поддерживает шардирование, но его модель ориентирована на **вертикальное масштабирование**. Один шард может хранить **триллионы строк** и продолжать работать эффективно, пока это позволяют память, CPU и диск. В отличие от Elasticsearch, в ClickHouse **нет жесткого предела числа строк** на шард. Шарды в ClickHouse логические — по сути, это отдельные таблицы — и не требуют партиционирования до тех пор, пока набор данных не превысит возможности одного узла. Обычно это происходит из‑за ограничений по размеру диска, и шардирование ① вводится только тогда, когда требуется горизонтальное масштабирование, — что снижает сложность и накладные расходы. В этом случае, аналогично Elasticsearch, шард будет содержать подмножество данных. Данные внутри одного шарда организованы как набор ② неизменяемых частей данных, содержащих ③ несколько структур данных.

Обработка внутри шарда ClickHouse **полностью распараллелена**, и пользователям рекомендуется масштабироваться по вертикали, чтобы избегать сетевых издержек, связанных с перемещением данных между узлами. 



:::note Обработка вставок в ClickHouse
Вставки в ClickHouse **по умолчанию синхронные** — запись подтверждается только после фиксации — но могут быть настроены для **асинхронных вставок**, чтобы обеспечить буферизацию и пакетирование, как в Elastic. При использовании [асинхронных вставок данных](https://clickhouse.com/blog/asynchronous-data-inserts-in-clickhouse) Ⓐ вновь вставляемые строки сначала попадают в Ⓑ буфер вставок в памяти, который по умолчанию сбрасывается каждые 200 миллисекунд. При использовании нескольких шардов для маршрутизации вновь вставляемых строк к целевому шарду используется [распределённая таблица](/engines/table-engines/special/distributed). Для шарда на диске записывается новая часть.
:::

### Распределение и репликация {#distribution-and-replication}

Хотя и Elasticsearch, и ClickHouse используют кластеры, шарды и реплики для обеспечения масштабируемости и отказоустойчивости, их модели существенно различаются по реализации и характеристикам производительности.

Elasticsearch использует модель репликации **первичный-вторичный**. При записи данных в первичный шард они синхронно копируются в одну или несколько реплик. Эти реплики сами являются полноценными шардами, распределёнными по узлам для обеспечения избыточности. Elasticsearch подтверждает записи только после того, как все необходимые реплики подтвердят операцию — модель, которая обеспечивает близкую к **последовательной согласованности**, хотя **грязные чтения** из реплик возможны до полной синхронизации. **Главный узел** координирует кластер, управляя распределением шардов, состоянием работоспособности и выбором лидера.

Напротив, ClickHouse по умолчанию использует **конечную согласованность**, координируемую **Keeper** — лёгкой альтернативой ZooKeeper. Записи могут отправляться напрямую в любую реплику или через [**распределённую таблицу**](/engines/table-engines/special/distributed), которая автоматически выбирает реплику. Репликация асинхронная — изменения распространяются на другие реплики после подтверждения записи. Для более строгих гарантий ClickHouse [поддерживает **последовательную согласованность**](/migrations/postgresql/appendix#sequential-consistency), при которой записи подтверждаются только после фиксации на всех репликах, хотя этот режим редко используется из-за влияния на производительность. Распределённые таблицы объединяют доступ к нескольким шардам, перенаправляя запросы `SELECT` ко всем шардам и объединяя результаты. Для операций `INSERT` они балансируют нагрузку, равномерно распределяя данные по шардам. Репликация ClickHouse очень гибкая: любая реплика (копия шарда) может принимать записи, и все изменения асинхронно синхронизируются с остальными. Эта архитектура позволяет непрерывно обслуживать запросы во время сбоев или обслуживания, при этом ресинхронизация выполняется автоматически — устраняя необходимость в принудительном применении модели первичный-вторичный на уровне данных.

:::note ClickHouse Cloud
В **ClickHouse Cloud** архитектура представляет модель вычислений без общих ресурсов, где один **шард поддерживается объектным хранилищем**. Это заменяет традиционную высокую доступность на основе реплик, позволяя **одновременно читать и записывать шард несколькими узлами**. Разделение хранилища и вычислений обеспечивает эластичное масштабирование без явного управления репликами.
:::

Резюмируя:

- **Elastic**: Шарды являются физическими структурами Lucene, привязанными к памяти JVM. Избыточное шардирование приводит к снижению производительности. Репликация синхронная и координируется главным узлом.
- **ClickHouse**: Шарды логические и вертикально масштабируемые, с высокоэффективным локальным выполнением. Репликация асинхронная (но может быть последовательной), а координация лёгкая.

В конечном счёте ClickHouse отдаёт предпочтение простоте и производительности в масштабе, минимизируя необходимость настройки шардов, при этом предлагая строгие гарантии согласованности при необходимости.

### Дедупликация и маршрутизация {#deduplication-and-routing}

Elasticsearch дедуплицирует документы на основе их `_id`, соответственно маршрутизируя их к шардам. ClickHouse не хранит идентификатор строки по умолчанию, но поддерживает **дедупликацию во время вставки**, позволяя пользователям безопасно повторять неудавшиеся вставки. Для большего контроля `ReplacingMergeTree` и другие движки таблиц обеспечивают дедупликацию по определённым столбцам.

Маршрутизация индексов в Elasticsearch гарантирует, что определённые документы всегда направляются к определённым шардам. В ClickHouse пользователи могут определять **ключи шардирования** или использовать таблицы `Distributed` для достижения аналогичной локальности данных.

### Агрегации и модель выполнения {#aggregations-execution-model}

Хотя обе системы поддерживают агрегацию данных, ClickHouse предлагает значительно [больше функций](/sql-reference/aggregate-functions/reference), включая статистические, приближённые и специализированные аналитические функции.

В сценариях наблюдаемости одним из наиболее распространённых применений агрегаций является подсчёт частоты возникновения определённых сообщений журнала или событий (и оповещение в случае необычной частоты).

Эквивалентом SQL-запроса ClickHouse `SELECT count(*) FROM ... GROUP BY ...` в Elasticsearch является [агрегация terms](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html), которая представляет собой [агрегацию bucket](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket.html) в Elasticsearch.

`GROUP BY` с `count(*)` в ClickHouse и агрегация terms в Elasticsearch в целом эквивалентны с точки зрения функциональности, но они существенно различаются по реализации, производительности и качеству результатов.


Эта агрегация в Elasticsearch [оценивает результаты в запросах "top-N"](https://www.elastic.co/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation#terms-agg-doc-count-error) (например, топ-10 хостов по количеству), когда запрашиваемые данные распределены по нескольким шардам. Такая оценка повышает скорость, но может снижать точность. Пользователи могут уменьшить эту погрешность, [проверяя `doc_count_error_upper_bound`](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html#terms-agg-doc-count-error) и увеличивая параметр `shard_size` — ценой повышенного потребления памяти и снижения производительности запросов.

Elasticsearch также требует указания параметра [`size`](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation-size) для всех агрегаций с группировкой — невозможно вернуть все уникальные группы без явного указания лимита. Агрегации с высокой кардинальностью рискуют достичь [ограничений `max_buckets`](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-settings.html#search-settings-max-buckets) или требуют пагинации с помощью [составной агрегации](https://www.elastic.co/docs/reference/aggregations/bucket/composite-aggregation), что часто оказывается сложным и неэффективным.

ClickHouse, напротив, выполняет точные агрегации из коробки. Функции вроде `count(*)` возвращают точные результаты без необходимости настройки, что делает поведение запросов проще и более предсказуемым.

ClickHouse не накладывает ограничений на размер. Вы можете выполнять неограниченные запросы с группировкой на больших наборах данных. Если превышены пороговые значения памяти, ClickHouse [может использовать диск](https://clickhouse.com/docs/en/sql-reference/statements/select/group-by#group-by-in-external-memory). Агрегации, которые группируют по префиксу первичного ключа, особенно эффективны и часто выполняются с минимальным потреблением памяти.

#### Модель выполнения {#execution-model}

Вышеуказанные различия можно объяснить моделями выполнения Elasticsearch и ClickHouse, которые используют принципиально разные подходы к выполнению запросов и параллелизму.

ClickHouse был разработан для максимальной эффективности на современном оборудовании. По умолчанию ClickHouse выполняет SQL-запрос с N параллельными потоками выполнения на машине с N ядрами процессора:

<Image img={clickhouse_execution} alt='Выполнение ClickHouse' size='lg' />

На одном узле потоки выполнения разделяют данные на независимые диапазоны, позволяя параллельную обработку по потокам процессора. Это включает фильтрацию, агрегацию и сортировку. Локальные результаты из каждого потока в конечном итоге объединяются, и применяется оператор ограничения, если запрос содержит предложение limit.

Выполнение запросов дополнительно распараллеливается за счет:

1. **SIMD-векторизации**: операции над колоночными данными используют [инструкции SIMD процессора](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data) (например, [AVX512](https://en.wikipedia.org/wiki/AVX-512)), позволяя пакетную обработку значений.
2. **Параллелизма на уровне кластера**: в распределенных конфигурациях каждый узел выполняет обработку запросов локально. [Частичные состояния агрегации](https://clickhouse.com/blog/aggregate-functions-combinators-in-clickhouse-for-arrays-maps-and-states#working-with-aggregation-states) передаются на инициирующий узел и объединяются. Если ключи `GROUP BY` запроса совпадают с ключами шардирования, объединение может быть [минимизировано или полностью исключено](/operations/settings/settings#distributed_group_by_no_merge).
   <br />
   Эта модель обеспечивает эффективное масштабирование по ядрам и узлам, делая
   ClickHouse хорошо подходящим для крупномасштабной аналитики. Использование *частичных
   состояний агрегации* позволяет объединять промежуточные результаты из разных потоков и
   узлов без потери точности.

Elasticsearch, напротив, назначает один поток на шард для большинства агрегаций, независимо от количества доступных ядер процессора. Эти потоки возвращают локальные для шарда результаты top-N, которые объединяются на координирующем узле. Такой подход может приводить к недоиспользованию системных ресурсов и вносить потенциальные неточности в глобальные агрегации, особенно когда частые термины распределены по нескольким шардам. Точность можно улучшить, увеличив параметр `shard_size`, но это происходит ценой повышенного потребления памяти и увеличения задержки запросов.

<Image img={elasticsearch_execution} alt='Выполнение Elasticsearch' size='lg' />

Таким образом, ClickHouse выполняет агрегации и запросы с более детальным параллелизмом и большим контролем над аппаратными ресурсами, в то время как Elasticsearch полагается на выполнение на основе шардов с более жесткими ограничениями.

Для получения дополнительных сведений о механизмах агрегаций в соответствующих технологиях мы рекомендуем статью в блоге ["ClickHouse vs. Elasticsearch: The Mechanics of Count Aggregations"](https://clickhouse.com/blog/clickhouse_vs_elasticsearch_mechanics_of_count_aggregations#elasticsearch).

### Управление данными {#data-management}

Elasticsearch и ClickHouse используют принципиально разные подходы к управлению данными наблюдаемости временных рядов — особенно в отношении хранения данных, ротации и многоуровневого хранения.


#### Управление жизненным циклом индексов vs встроенный TTL {#lifecycle-vs-ttl}

В Elasticsearch долгосрочное управление данными осуществляется через **Index Lifecycle Management (ILM)** и **Data Streams**. Эти функции позволяют пользователям определять политики, которые управляют тем, когда происходит ротация индексов (например, после достижения определенного размера или возраста), когда старые индексы перемещаются в более дешевое хранилище (например, на уровни warm или cold), и когда они окончательно удаляются. Это необходимо, потому что Elasticsearch **не поддерживает повторное шардирование**, а шарды не могут расти бесконечно без снижения производительности. Для управления размерами шардов и обеспечения эффективного удаления необходимо периодически создавать новые индексы и удалять старые — фактически выполняя ротацию данных на уровне индексов.

ClickHouse использует другой подход. Данные обычно хранятся в **одной таблице** и управляются с помощью **TTL-выражений (time-to-live)** на уровне столбцов или партиций. Данные могут быть **партиционированы по дате**, что позволяет эффективно удалять их без необходимости создавать новые таблицы или выполнять ротацию индексов. По мере старения данных и выполнения условия TTL ClickHouse автоматически удаляет их — никакой дополнительной инфраструктуры для управления ротацией не требуется.

#### Уровни хранения и hot-warm архитектуры {#storage-tiers}

Elasticsearch поддерживает архитектуры хранения **hot-warm-cold-frozen**, где данные перемещаются между уровнями хранения с различными характеристиками производительности. Обычно это настраивается через ILM и привязывается к ролям узлов в кластере.

ClickHouse поддерживает **многоуровневое хранение** через встроенные движки таблиц, такие как `MergeTree`, которые могут автоматически перемещать старые данные между различными **томами** (например, с SSD на HDD или в объектное хранилище) на основе пользовательских правил. Это позволяет воспроизвести подход hot-warm-cold из Elastic — но без сложности управления несколькими ролями узлов или кластерами.

:::note ClickHouse Cloud
В **ClickHouse Cloud** это становится еще более простым: все данные хранятся в **объектном хранилище (например, S3)**, а вычисления отделены. Данные могут оставаться в объектном хранилище до момента запроса, после чего они извлекаются и кэшируются локально (или в распределенном кэше) — обеспечивая такой же профиль стоимости, как уровень frozen в Elastic, но с лучшими характеристиками производительности. Этот подход означает, что данные не нужно перемещать между уровнями хранения, что делает hot-warm архитектуры избыточными.
:::

### Свертки vs инкрементальные агрегаты {#rollups-vs-incremental-aggregates}

В Elasticsearch **свертки** или **агрегаты** реализуются с помощью механизма, называемого [**transforms**](https://www.elastic.co/guide/en/elasticsearch/reference/current/transforms.html). Они используются для суммирования данных временных рядов с фиксированными интервалами (например, почасово или ежедневно) с использованием модели **скользящего окна**. Они настраиваются как повторяющиеся фоновые задачи, которые агрегируют данные из одного индекса и записывают результаты в отдельный **индекс сверток**. Это помогает снизить стоимость долгосрочных запросов, избегая повторного сканирования исходных данных с высокой кардинальностью.

Следующая диаграмма абстрактно показывает, как работают transforms (обратите внимание, что мы используем синий цвет для всех документов, принадлежащих одному bucket, для которого мы хотим предварительно вычислить агрегированные значения):

<Image
  img={elasticsearch_transforms}
  alt='Elasticsearch transforms'
  size='lg'
/>

Непрерывные transforms используют [контрольные точки](https://www.elastic.co/guide/en/elasticsearch/reference/current/transform-checkpoints.html) transform на основе настраиваемого интервала проверки (transform [frequency](https://www.elastic.co/guide/en/elasticsearch/reference/current/put-transform.html) со значением по умолчанию 1 минута). На диаграмме выше мы предполагаем, что ① новая контрольная точка создается после истечения интервала проверки. Теперь Elasticsearch проверяет изменения в исходном индексе transforms и обнаруживает три новых `синих` документа (11, 12 и 13), которые появились с момента предыдущей контрольной точки. Поэтому исходный индекс фильтруется по всем существующим `синим` документам, и с помощью [композитной агрегации](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-composite-aggregation.html) (для использования [пагинации](https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html) результатов) агрегированные значения пересчитываются (и целевой индекс обновляется документом, заменяющим документ, содержащий предыдущие агрегированные значения). Аналогично, в ② и ③ новые контрольные точки обрабатываются путем проверки изменений и пересчета агрегированных значений из всех существующих документов, принадлежащих одному «синему» bucket.

ClickHouse использует принципиально другой подход. Вместо периодической повторной агрегации данных ClickHouse поддерживает **инкрементальные материализованные представления**, которые преобразуют и агрегируют данные **во время вставки**. Когда новые данные записываются в исходную таблицу, материализованное представление выполняет предопределенный SQL-запрос агрегации только для новых **вставленных блоков** и записывает агрегированные результаты в целевую таблицу.


Эта модель стала возможной благодаря поддержке в ClickHouse [**частичных агрегатных состояний**](https://clickhouse.com/docs/en/sql-reference/data-types/aggregatefunction) — промежуточных представлений агрегатных функций, которые можно сохранять и впоследствии объединять. Это позволяет пользователям поддерживать частично агрегированные результаты, которые быстро запрашиваются и недорого обновляются. Поскольку агрегация происходит по мере поступления данных, нет необходимости запускать дорогостоящие повторяющиеся задачи или повторно суммировать старые данные.

Мы схематично изображаем механику инкрементных материализованных представлений в абстрактном виде (обратите внимание, что мы используем синий цвет для всех строк, принадлежащих одной группе, для которой мы хотим предварительно вычислить агрегатные значения):

<Image img={clickhouse_mvs} alt='Материализованные представления ClickHouse' size='lg' />

На диаграмме выше исходная таблица материализованного представления уже содержит часть данных, хранящую некоторые `синие` строки (от 1 до 10), принадлежащие одной группе. Для этой группы также уже существует часть данных в целевой таблице представления, хранящая [частичное агрегатное состояние](https://www.youtube.com/watch?v=QDAJTKZT8y4) для `синей` группы. Когда происходят вставки ① ② ③ новых строк в исходную таблицу, для каждой вставки создается соответствующая часть данных исходной таблицы, и параллельно (только) для каждого блока вновь вставленных строк вычисляется частичное агрегатное состояние и вставляется в виде части данных в целевую таблицу материализованного представления. ④ Во время фонового слияния частей частичные агрегатные состояния объединяются, что приводит к инкрементной агрегации данных.

Обратите внимание, что все [агрегатные функции](https://clickhouse.com/docs/en/sql-reference/aggregate-functions/reference) (более 90), включая их комбинации с [комбинаторами](https://www.youtube.com/watch?v=7ApwD0cfAFI) агрегатных функций, поддерживают [частичные агрегатные состояния](https://clickhouse.com/docs/en/sql-reference/data-types/aggregatefunction).

Более конкретный пример сравнения Elasticsearch и ClickHouse для инкрементных агрегатов см. в этом [примере](https://github.com/ClickHouse/examples/tree/main/blog-examples/clickhouse-vs-elasticsearch/continuous-data-transformation#continuous-data-transformation-example).

Преимущества подхода ClickHouse включают:

- **Всегда актуальные агрегаты**: материализованные представления всегда синхронизированы с исходной таблицей.
- **Отсутствие фоновых задач**: агрегации выполняются во время вставки, а не во время запроса.
- **Улучшенная производительность в реальном времени**: идеально подходит для задач наблюдаемости и аналитики в реальном времени, где требуются мгновенно актуальные агрегаты.
- **Компонуемость**: материализованные представления могут быть многоуровневыми или объединяться с другими представлениями и таблицами для более сложных стратегий ускорения запросов.
- **Различные TTL**: к исходной таблице и целевой таблице материализованного представления могут применяться различные настройки TTL.

Эта модель особенно эффективна для сценариев наблюдаемости, где пользователям необходимо вычислять метрики, такие как частота ошибок в минуту, задержки или разбивки top-N, без сканирования миллиардов исходных записей на запрос.

### Поддержка Lakehouse {#lakehouse-support}

ClickHouse и Elasticsearch используют принципиально разные подходы к интеграции с lakehouse. ClickHouse — это полнофункциональный движок выполнения запросов, способный выполнять запросы к форматам lakehouse, таким как [Iceberg](/sql-reference/table-functions/iceberg) и [Delta Lake](/sql-reference/table-functions/deltalake), а также интегрироваться с каталогами озер данных, такими как [AWS Glue](/use-cases/data-lake/glue-catalog) и [Unity catalog](/use-cases/data-lake/unity-catalog). Эти форматы основаны на эффективном запросе файлов [Parquet](/interfaces/formats/Parquet), которые ClickHouse полностью поддерживает. ClickHouse может напрямую читать таблицы как Iceberg, так и Delta Lake, обеспечивая бесшовную интеграцию с современными архитектурами озер данных.

В отличие от этого, Elasticsearch тесно связан со своим внутренним форматом данных и движком хранения на основе Lucene. Он не может напрямую запрашивать форматы lakehouse или файлы Parquet, что ограничивает его возможности участия в современных архитектурах озер данных. Elasticsearch требует преобразования и загрузки данных в свой проприетарный формат перед тем, как их можно будет запросить.

Возможности ClickHouse для работы с lakehouse выходят за рамки простого чтения данных:


- **Интеграция с каталогами данных**: ClickHouse поддерживает интеграцию с каталогами данных, такими как [AWS Glue](/use-cases/data-lake/glue-catalog), что позволяет автоматически находить и получать доступ к таблицам в объектном хранилище.
- **Поддержка объектного хранилища**: встроенная поддержка выполнения запросов к данным, находящимся в [S3](/engines/table-engines/integrations/s3), [GCS](/sql-reference/table-functions/gcs) и [Azure Blob Storage](/engines/table-engines/integrations/azureBlobStorage), без необходимости перемещения данных.
- **Федерация запросов**: возможность сопоставлять данные из нескольких источников, включая lakehouse-таблицы, традиционные базы данных и таблицы ClickHouse, с использованием [внешних словарей](/dictionary) и [табличных функций](/sql-reference/table-functions).
- **Инкрементальная загрузка**: поддержка непрерывной загрузки из lakehouse-таблиц в локальные таблицы [MergeTree](/engines/table-engines/mergetree-family/mergetree) с использованием таких возможностей, как [S3Queue](/engines/table-engines/integrations/s3queue) и [ClickPipes](/integrations/clickpipes).
- **Оптимизация производительности**: распределённое выполнение запросов по данным lakehouse с использованием [cluster-функций](/sql-reference/table-functions/cluster) для повышения производительности.

Эти возможности делают ClickHouse естественным выбором для организаций, внедряющих lakehouse-архитектуры, позволяя им использовать как гибкость data lake, так и производительность колонночной базы данных. 
