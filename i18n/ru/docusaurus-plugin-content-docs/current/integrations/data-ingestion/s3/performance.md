---
slug: /integrations/s3/performance
sidebar_position: 2
sidebar_label: 'Оптимизация производительности'
title: 'Оптимизация производительности вставки и чтения из S3'
description: 'Оптимизация производительности чтения и вставки из S3'
doc_type: 'guide'
keywords: ['s3', 'performance', 'optimization', 'object storage', 'data loading']
---

import Image from '@theme/IdealImage';
import InsertMechanics from '@site/static/images/integrations/data-ingestion/s3/insert_mechanics.png';
import Pull from '@site/static/images/integrations/data-ingestion/s3/pull.png';
import Merges from '@site/static/images/integrations/data-ingestion/s3/merges.png';
import ResourceUsage from '@site/static/images/integrations/data-ingestion/s3/resource_usage.png';
import InsertThreads from '@site/static/images/integrations/data-ingestion/s3/insert_threads.png';
import S3Cluster from '@site/static/images/integrations/data-ingestion/s3/s3Cluster.png';
import HardwareSize from '@site/static/images/integrations/data-ingestion/s3/hardware_size.png';

В этом разделе основное внимание уделяется оптимизации производительности при чтении и вставке данных из S3 с использованием [табличных функций s3](/sql-reference/table-functions/s3).

:::info
**Описанный в этом руководстве подход можно применять и к другим реализациям объектного хранилища с собственными табличными функциями, таким как [GCS](/sql-reference/table-functions/gcs) и [Azure Blob storage](/sql-reference/table-functions/azureBlobStorage).**
:::

Прежде чем настраивать потоки и размеры блоков для повышения производительности вставки, мы рекомендуем сначала разобраться в механизме вставок в S3. Если вы уже знакомы с этим механизмом или просто хотите получить несколько быстрых рекомендаций, переходите сразу к нашему примеру [ниже](/integrations/s3/performance#example-dataset).


## Механизмы вставки данных (одиночный узел) {#insert-mechanics-single-node}

Два основных фактора, помимо размера оборудования, влияют на производительность и использование ресурсов при вставке данных в ClickHouse (для одиночного узла): **размер блока вставки** и **параллелизм вставки**.

### Размер блока вставки {#insert-block-size}

<Image
  img={InsertMechanics}
  size='lg'
  border
  alt='Механизмы размера блока вставки в ClickHouse'
/>

При выполнении `INSERT INTO SELECT` ClickHouse получает порцию данных и ① формирует (как минимум) один блок вставки в памяти (для каждого [ключа партиционирования](/engines/table-engines/mergetree-family/custom-partitioning-key)) из полученных данных. Данные блока сортируются, и применяются оптимизации, специфичные для движка таблицы. Затем данные сжимаются и ② записываются в хранилище базы данных в виде нового куска данных.

Размер блока вставки влияет как на [использование дискового ввода-вывода](https://en.wikipedia.org/wiki/Category:Disk_file_systems), так и на использование памяти сервера ClickHouse. Большие блоки вставки используют больше памяти, но генерируют более крупные и менее многочисленные начальные куски. Чем меньше кусков ClickHouse необходимо создать для загрузки большого объема данных, тем меньше требуется дискового ввода-вывода и автоматических [фоновых слияний](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#more-parts--more-background-part-merges).

При использовании запроса `INSERT INTO SELECT` в сочетании с движком интеграционной таблицы или табличной функцией данные извлекаются сервером ClickHouse:

<Image
  img={Pull}
  size='lg'
  border
  alt='Извлечение данных из внешних источников в ClickHouse'
/>

До полной загрузки данных сервер выполняет цикл:

```bash
① Извлечь и разобрать следующую порцию данных и сформировать из неё блок данных в памяти (один на ключ партиционирования).

② Записать блок в новый кусок в хранилище.

Перейти к ①
```

В ①, размер зависит от размера блока вставки, который можно контролировать двумя настройками:

- [`min_insert_block_size_rows`](/operations/settings/settings#min_insert_block_size_rows) (по умолчанию: `1048545` миллион строк)
- [`min_insert_block_size_bytes`](/operations/settings/settings#min_insert_block_size_bytes) (по умолчанию: `256 МиБ`)

Когда в блоке вставки накапливается указанное количество строк или достигается настроенный объем данных (в зависимости от того, что произойдет первым), это инициирует запись блока в новый кусок. Цикл вставки продолжается с шага ①.

Обратите внимание, что значение `min_insert_block_size_bytes` обозначает несжатый размер блока в памяти (а не сжатый размер куска на диске). Также обратите внимание, что созданные блоки и куски редко содержат точно настроенное количество строк или байтов, поскольку ClickHouse обрабатывает данные потоково и построчно-[блочно](/operations/settings/settings#max_block_size). Поэтому эти настройки определяют минимальные пороговые значения.

#### Учитывайте слияния {#be-aware-of-merges}

Чем меньше настроенный размер блока вставки, тем больше начальных кусков создается при загрузке большого объема данных, и тем больше фоновых слияний кусков выполняется одновременно с приемом данных. Это может вызвать конкуренцию за ресурсы (процессор и память) и потребовать дополнительного времени (для достижения [здорового](/operations/settings/merge-tree-settings#parts_to_throw_insert) (3000) количества кусков) после завершения приема данных.

:::important
Производительность запросов ClickHouse будет негативно затронута, если количество кусков превысит [рекомендуемые лимиты](/operations/settings/merge-tree-settings#parts_to_throw_insert).
:::

ClickHouse будет непрерывно [объединять куски](https://clickhouse.com/blog/asynchronous-data-inserts-in-clickhouse#data-needs-to-be-batched-for-optimal-performance) в более крупные куски, пока они не [достигнут](/operations/settings/merge-tree-settings#max_bytes_to_merge_at_max_space_in_pool) сжатого размера ~150 ГиБ. Эта диаграмма показывает, как сервер ClickHouse объединяет куски:

<Image img={Merges} size='lg' border alt='Фоновые слияния в ClickHouse' />

Один сервер ClickHouse использует несколько [потоков фонового слияния](/operations/server-configuration-parameters/settings#background_pool_size) для выполнения параллельных [слияний кусков](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#more-parts--more-background-part-merges:~:text=to%20execute%20concurrent-,part%20merges,-.%20Each%20thread%20executes). Каждый поток выполняет цикл:

```bash
① Определить, какие куски объединять следующими, и загрузить эти куски в виде блоков в память.

② Объединить загруженные блоки в памяти в более крупный блок.

```


③ Записать объединённый блок в новую часть на диске.

Перейти к ①

````

Обратите внимание, что [увеличение](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#hardware-size) количества ядер процессора и объёма оперативной памяти повышает пропускную способность фоновых слияний.

Куски, объединённые в более крупные куски, помечаются как [неактивные](/operations/system-tables/parts) и окончательно удаляются через [настраиваемое](/operations/settings/merge-tree-settings#old_parts_lifetime) количество минут. Со временем это формирует дерево объединённых кусков (отсюда и название семейства таблиц [`MergeTree`](/engines/table-engines/mergetree-family)).

### Параллелизм вставки {#insert-parallelism}

<Image img={ResourceUsage} size="lg" border alt="Использование ресурсов при параллельной вставке" />

Сервер ClickHouse может обрабатывать и вставлять данные параллельно. Уровень параллелизма вставки влияет на пропускную способность загрузки данных и потребление памяти сервером ClickHouse. Параллельная загрузка и обработка данных требует больше оперативной памяти, но увеличивает пропускную способность загрузки за счёт более быстрой обработки данных.

Табличные функции, такие как s3, позволяют указывать наборы имён загружаемых файлов с помощью glob-шаблонов. Когда glob-шаблон соответствует нескольким существующим файлам, ClickHouse может распараллелить чтение между этими файлами и внутри них, а также параллельно вставлять данные в таблицу, используя параллельно работающие потоки вставки (на сервер): 

<Image img={InsertThreads} size="lg" border alt="Параллельные потоки вставки в ClickHouse" />

Пока все данные из всех файлов не будут обработаны, каждый поток вставки выполняет цикл: 

```bash
① Получить следующую порцию необработанных данных из файла (размер порции определяется настроенным размером блока) и создать из неё блок данных в памяти.

② Записать блок в новый кусок на диске.

Перейти к ①. 
````

Количество таких параллельных потоков вставки можно настроить с помощью настройки [`max_insert_threads`](/operations/settings/settings#max_insert_threads). Значение по умолчанию — `1` для открытой версии ClickHouse и `4` для [ClickHouse Cloud](https://clickhouse.com/cloud).

При большом количестве файлов параллельная обработка несколькими потоками вставки работает эффективно. Она позволяет полностью задействовать как доступные ядра CPU, так и пропускную способность сети (для параллельной загрузки файлов). В сценариях, когда в таблицу загружается всего несколько крупных файлов, ClickHouse автоматически устанавливает высокий уровень параллелизма обработки данных и оптимизирует использование сетевой пропускной способности, создавая дополнительные потоки чтения на каждый поток вставки для параллельного чтения (загрузки) большего числа отдельных диапазонов внутри крупных файлов.

Для функции и таблицы s3 параллельная загрузка отдельного файла определяется значениями [max&#95;download&#95;threads](https://clickhouse.com/codebrowser/ClickHouse/src/Core/Settings.h.html#DB::SettingsTraits::Data::max_download_threads) и [max&#95;download&#95;buffer&#95;size](https://clickhouse.com/codebrowser/ClickHouse/src/Core/Settings.h.html#DB::SettingsTraits::Data::max_download_buffer_size). Файлы будут загружаться параллельно только в том случае, если их размер больше `2 * max_download_buffer_size`. По умолчанию значение `max_download_buffer_size` установлено в 10 MiB. В некоторых случаях вы можете безопасно увеличить размер этого буфера до 50 MB (`max_download_buffer_size=52428800`), чтобы обеспечить загрузку каждого файла одним потоком. Это может сократить время, которое каждый поток тратит на обращения к S3, а значит, и суммарное время ожидания S3. Кроме того, для файлов, которые слишком малы для параллельного чтения, ClickHouse автоматически выполняет предварительное чтение данных, асинхронно предварительно считывая такие файлы для увеличения общей пропускной способности.


## Измерение производительности {#measuring-performance}

Оптимизация производительности запросов с использованием табличных функций S3 требуется как при выполнении запросов непосредственно к данным в хранилище (т.е. при ad-hoc запросах, где используются только вычислительные ресурсы ClickHouse, а данные остаются в S3 в исходном формате), так и при загрузке данных из S3 в табличный движок ClickHouse MergeTree. Если не указано иное, приведенные ниже рекомендации применимы к обоим сценариям.


## Влияние размера аппаратного обеспечения {#impact-of-hardware-size}

<Image
  img={HardwareSize}
  size='lg'
  border
  alt='Влияние размера аппаратного обеспечения на производительность ClickHouse'
/>

Количество доступных ядер процессора и объем оперативной памяти влияют на:

- поддерживаемый [начальный размер частей](#insert-block-size)
- возможный уровень [параллелизма вставки](#insert-parallelism)
- пропускную способность [фоновых слияний частей](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#more-parts--more-background-part-merges)

и, следовательно, на общую пропускную способность загрузки данных.


## Локальность региона {#region-locality}

Убедитесь, что ваши бакеты находятся в том же регионе, что и экземпляры ClickHouse. Эта простая оптимизация может существенно повысить производительность пропускной способности, особенно при развертывании экземпляров ClickHouse на инфраструктуре AWS.


## Форматы {#formats}

ClickHouse может читать файлы, хранящиеся в S3-бакетах, в [поддерживаемых форматах](/interfaces/formats#formats-overview) с помощью функции `s3` и движка `S3`. При чтении исходных файлов некоторые из этих форматов имеют явные преимущества:

- Форматы с закодированными именами столбцов, такие как Native, Parquet, CSVWithNames и TabSeparatedWithNames, требуют менее подробного описания в запросах, поскольку пользователю не нужно указывать имена столбцов в функции `s3`. Имена столбцов позволяют автоматически определить эту информацию.
- Форматы различаются по производительности чтения и записи. Native и Parquet являются наиболее оптимальными форматами для производительности чтения, поскольку они уже ориентированы на столбцы и более компактны. Формат Native дополнительно выигрывает от соответствия способу хранения данных ClickHouse в памяти, что снижает накладные расходы на обработку при потоковой передаче данных в ClickHouse.
- Размер блока часто влияет на задержку чтения больших файлов. Это особенно заметно при выборке данных, например, при возврате первых N строк. В случае форматов, таких как CSV и TSV, файлы должны быть полностью разобраны для возврата набора строк. Форматы, такие как Native и Parquet, позволяют выполнять выборку значительно быстрее.
- Каждый формат сжатия имеет свои преимущества и недостатки, часто балансируя между уровнем сжатия и скоростью, смещая акцент в сторону производительности сжатия или распаковки. При сжатии исходных файлов, таких как CSV или TSV, lz4 обеспечивает самую быструю производительность распаковки, жертвуя уровнем сжатия. Gzip обычно сжимает лучше за счёт немного более медленной скорости чтения. Xz идёт ещё дальше, обычно обеспечивая наилучшее сжатие при самой медленной производительности сжатия и распаковки. При экспорте Gz и lz4 предлагают сопоставимую скорость сжатия. Учитывайте скорость вашего соединения. Любые преимущества от более быстрой распаковки или сжатия легко нивелируются медленным соединением с вашими S3-бакетами.
- Форматы, такие как Native или Parquet, обычно не оправдывают накладные расходы на сжатие. Любая экономия размера данных, вероятно, будет минимальной, поскольку эти форматы изначально компактны. Время, затраченное на сжатие и распаковку, редко компенсирует время передачи по сети, особенно учитывая, что S3 доступен глобально с высокой пропускной способностью сети.


## Пример набора данных {#example-dataset}

Для демонстрации дальнейших возможных оптимизаций мы будем использовать [посты из набора данных Stack Overflow](/data-modeling/schema-design#stack-overflow-dataset), оптимизируя как производительность запросов, так и производительность вставки этих данных.

Этот набор данных состоит из 189 файлов Parquet, по одному на каждый месяц с июля 2008 года по март 2024 года.

Обратите внимание, что мы используем Parquet для повышения производительности согласно нашим [рекомендациям выше](#formats), выполняя все запросы на кластере ClickHouse, расположенном в том же регионе, что и бакет. Этот кластер имеет 3 узла, каждый с 32 ГиБ оперативной памяти и 8 виртуальными процессорами.

Без какой-либо настройки мы демонстрируем производительность вставки этого набора данных в табличный движок MergeTree, а также выполнение запроса для определения пользователей, задающих наибольшее количество вопросов. Оба этих запроса намеренно требуют полного сканирования данных.

```sql
-- Топ пользователей
SELECT
    OwnerDisplayName,
    count() AS num_posts
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
WHERE OwnerDisplayName NOT IN ('', 'anon')
GROUP BY OwnerDisplayName
ORDER BY num_posts DESC
LIMIT 5

┌─OwnerDisplayName─┬─num_posts─┐
│ user330315       │     10344 │
│ user4039065      │      5316 │
│ user149341       │      4102 │
│ user529758       │      3700 │
│ user3559349      │      3068 │
└──────────────────┴───────────┘

5 rows in set. Elapsed: 3.013 sec. Processed 59.82 million rows, 24.03 GB (19.86 million rows/s., 7.98 GB/s.)
Peak memory usage: 603.64 MiB.

-- Загрузка в таблицу posts
INSERT INTO posts SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')

0 rows in set. Elapsed: 191.692 sec. Processed 59.82 million rows, 24.03 GB (312.06 thousand rows/s., 125.37 MB/s.)
```

В нашем примере мы возвращаем только несколько строк. При измерении производительности запросов `SELECT`, где клиенту возвращаются большие объемы данных, используйте либо [формат null](/interfaces/formats/Null) для запросов, либо направляйте результаты в [движок `Null`](/engines/table-engines/special/null.md). Это позволит избежать перегрузки клиента данными и насыщения сети.

:::info
При чтении данных запросами начальный запрос часто может выполняться медленнее, чем при повторении того же запроса. Это можно объяснить как собственным кэшированием S3, так и [кэшем вывода схемы ClickHouse](/operations/system-tables/schema_inference_cache). Он сохраняет выведенную схему для файлов, что позволяет пропустить этап вывода схемы при последующих обращениях, тем самым сокращая время выполнения запроса.
:::


## Использование потоков для чтения {#using-threads-for-reads}

Производительность чтения из S3 масштабируется линейно с количеством ядер при условии, что вы не ограничены пропускной способностью сети или локальным вводом-выводом. Увеличение количества потоков также приводит к дополнительным затратам памяти, о которых следует помнить. Для потенциального улучшения производительности чтения можно изменить следующие параметры:

- Обычно значения `max_threads` по умолчанию достаточно, то есть равного количеству ядер. Если объем памяти, используемой для запроса, велик и его необходимо уменьшить, или значение `LIMIT` для результатов низкое, это значение можно установить ниже. Пользователи с большим объемом памяти могут поэкспериментировать с увеличением этого значения для возможного повышения пропускной способности чтения из S3. Обычно это полезно только на машинах с небольшим количеством ядер, то есть &lt; 10. Преимущество от дальнейшей параллелизации обычно уменьшается, поскольку другие ресурсы становятся узким местом, например сеть и конкуренция за процессор.
- Версии ClickHouse до 22.3.1 распараллеливали чтение только между несколькими файлами при использовании функции `s3` или движка таблиц `S3`. Это требовало от пользователя обеспечить разделение файлов на фрагменты в S3 и чтение с использованием шаблона glob для достижения оптимальной производительности чтения. Более поздние версии теперь распараллеливают загрузку внутри одного файла.
- В сценариях с малым количеством потоков пользователи могут получить выгоду от установки `remote_filesystem_read_method` в значение "read" для синхронного чтения файлов из S3.
- Для функции и таблицы s3 параллельная загрузка отдельного файла определяется значениями [`max_download_threads`](/operations/settings/settings#max_download_threads) и [`max_download_buffer_size`](/operations/settings/settings#max_download_buffer_size). Хотя [`max_download_threads`](/operations/settings/settings#max_download_threads) управляет количеством используемых потоков, файлы будут загружаться параллельно только в том случае, если их размер превышает 2 \* `max_download_buffer_size`. По умолчанию значение `max_download_buffer_size` установлено на 10 МиБ. В некоторых случаях можно безопасно увеличить размер этого буфера до 50 МБ (`max_download_buffer_size=52428800`), чтобы обеспечить загрузку меньших файлов только одним потоком. Это может сократить время, которое каждый поток тратит на выполнение вызовов S3, и, таким образом, также уменьшить время ожидания S3. См. [эту статью в блоге](https://clickhouse.com/blog/clickhouse-1-trillion-row-challenge) для примера.

Перед внесением каких-либо изменений для улучшения производительности убедитесь, что вы проводите соответствующие измерения. Поскольку вызовы API S3 чувствительны к задержкам и могут влиять на время выполнения на клиенте, используйте журнал запросов для метрик производительности, то есть `system.query_log`.

Рассмотрим наш предыдущий запрос: удвоение `max_threads` до `16` (значение `max_threads` по умолчанию равно количеству ядер на узле) улучшает производительность запроса на чтение в 2 раза за счет увеличения потребления памяти. Дальнейшее увеличение `max_threads` дает убывающую отдачу, как показано ниже.

```sql
SELECT
    OwnerDisplayName,
    count() AS num_posts
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
WHERE OwnerDisplayName NOT IN ('', 'anon')
GROUP BY OwnerDisplayName
ORDER BY num_posts DESC
LIMIT 5
SETTINGS max_threads = 16

┌─OwnerDisplayName─┬─num_posts─┐
│ user330315       │     10344 │
│ user4039065      │      5316 │
│ user149341       │      4102 │
│ user529758       │      3700 │
│ user3559349      │      3068 │
└──────────────────┴───────────┘

Получено 5 строк. Затрачено: 1.505 сек. Обработано 59.82 млн строк, 24.03 ГБ (39.76 млн строк/с., 15.97 ГБ/с.)
Пиковое использование памяти: 178.58 МиБ.

SETTINGS max_threads = 32

Получено 5 строк. Затрачено: 0.779 сек. Обработано 59.82 млн строк, 24.03 ГБ (76.81 млн строк/с., 30.86 ГБ/с.)
Пиковое использование памяти: 369.20 МиБ.

SETTINGS max_threads = 64

Получено 5 строк. Затрачено: 0.674 сек. Обработано 59.82 млн строк, 24.03 ГБ (88.81 млн строк/с., 35.68 ГБ/с.)
Пиковое использование памяти: 639.99 МиБ.
```


## Настройка потоков и размера блока для вставок {#tuning-threads-and-block-size-for-inserts}

Для достижения максимальной производительности загрузки данных необходимо выбрать (1) размер блока вставки и (2) соответствующий уровень параллелизма вставки на основе (3) количества доступных ядер процессора и оперативной памяти. Вкратце:

- Чем больше мы [задаём размер блока вставки](#insert-block-size), тем меньше частей должен создавать ClickHouse и тем меньше требуется операций [дискового ввода-вывода](https://en.wikipedia.org/wiki/Category:Disk_file_systems) и [фоновых слияний](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#more-parts--more-background-part-merges).
- Чем больше мы задаём [количество параллельных потоков вставки](#insert-parallelism), тем быстрее будут обрабатываться данные.

Между этими двумя факторами производительности существует противоречие (плюс компромисс с фоновым слиянием частей). Объём доступной оперативной памяти серверов ClickHouse ограничен. Большие блоки используют больше оперативной памяти, что ограничивает количество параллельных потоков вставки, которые мы можем использовать. И наоборот, большее количество параллельных потоков вставки требует больше оперативной памяти, поскольку количество потоков вставки определяет количество блоков вставки, создаваемых в памяти одновременно. Это ограничивает возможный размер блоков вставки. Кроме того, может возникнуть конкуренция за ресурсы между потоками вставки и потоками фонового слияния. Большое количество настроенных потоков вставки (1) создаёт больше частей, которые необходимо объединить, и (2) отнимает ядра процессора и память у потоков фонового слияния.

Для подробного описания того, как поведение этих параметров влияет на производительность и ресурсы, рекомендуем [прочитать эту статью в блоге](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part2). Как описано в этой статье, настройка может включать тщательный баланс двух параметров. Такое исчерпывающее тестирование часто непрактично, поэтому в итоге мы рекомендуем:

```bash
• max_insert_threads: выберите примерно половину доступных ядер процессора для потоков вставки (чтобы оставить достаточно выделенных ядер для фоновых слияний)

• peak_memory_usage_in_bytes: выберите предполагаемое пиковое использование памяти; либо всю доступную оперативную память (если это изолированная загрузка), либо половину или меньше (чтобы оставить место для других параллельных задач)

Затем:
min_insert_block_size_bytes = peak_memory_usage_in_bytes / (~3 * max_insert_threads)
```

С помощью этой формулы вы можете установить `min_insert_block_size_rows` в 0 (чтобы отключить пороговое значение на основе строк), одновременно устанавливая `max_insert_threads` в выбранное значение, а `min_insert_block_size_bytes` — в результат, рассчитанный по приведённой выше формуле.

Применим эту формулу к нашему предыдущему примеру Stack Overflow.

- `max_insert_threads=4` (8 ядер на узел)
- `peak_memory_usage_in_bytes` — 32 ГиБ (100% ресурсов узла) или `34359738368` байт.
- `min_insert_block_size_bytes` = `34359738368/(3*4) = 2863311530`

```sql
INSERT INTO posts SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet') SETTINGS min_insert_block_size_rows=0, max_insert_threads=4, min_insert_block_size_bytes=2863311530

0 строк в наборе. Затрачено: 128.566 сек. Обработано 59.82 миллиона строк, 24.03 ГБ (465.28 тысяч строк/с., 186.92 МБ/с.)
```

Как показано, настройка этих параметров улучшила производительность вставки более чем на `33%`. Мы оставляем читателю возможность проверить, можно ли дополнительно улучшить производительность одного узла.


## Масштабирование с помощью ресурсов и узлов {#scaling-with-resources-and-nodes}

Масштабирование с помощью ресурсов и узлов применимо как к запросам на чтение, так и к запросам на вставку.

### Вертикальное масштабирование {#vertical-scaling}

Все предыдущие настройки и запросы использовали только один узел в нашем кластере ClickHouse Cloud. Часто у пользователей доступно более одного узла ClickHouse. Мы рекомендуем пользователям начинать с вертикального масштабирования, улучшая пропускную способность S3 линейно с увеличением количества ядер. Если мы повторим наши предыдущие запросы на вставку и чтение на более крупном узле ClickHouse Cloud с удвоенными ресурсами (64 ГиБ, 16 виртуальных ЦП) с соответствующими настройками, оба запроса выполнятся примерно в два раза быстрее.

```sql
INSERT INTO posts SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet') SETTINGS min_insert_block_size_rows=0, max_insert_threads=8, min_insert_block_size_bytes=2863311530

0 rows in set. Elapsed: 67.294 sec. Processed 59.82 million rows, 24.03 GB (888.93 thousand rows/s., 357.12 MB/s.)

SELECT
    OwnerDisplayName,
    count() AS num_posts
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
WHERE OwnerDisplayName NOT IN ('', 'anon')
GROUP BY OwnerDisplayName
ORDER BY num_posts DESC
LIMIT 5
SETTINGS max_threads = 92

5 rows in set. Elapsed: 0.421 sec. Processed 59.82 million rows, 24.03 GB (142.08 million rows/s., 57.08 GB/s.)
```

:::note
Отдельные узлы также могут быть ограничены пропускной способностью сети и запросами S3 GET, что препятствует линейному масштабированию производительности по вертикали.
:::

### Горизонтальное масштабирование {#horizontal-scaling}

В конечном итоге горизонтальное масштабирование часто становится необходимым из-за доступности оборудования и экономической эффективности. В ClickHouse Cloud производственные кластеры имеют как минимум 3 узла. Поэтому пользователи могут захотеть использовать все узлы для вставки данных.

Использование кластера для чтения из S3 требует применения функции `s3Cluster`, как описано в разделе [Использование кластеров](/integrations/s3#utilizing-clusters). Это позволяет распределять операции чтения по узлам.

Сервер, который первоначально получает запрос на вставку, сначала разрешает шаблон glob, а затем динамически распределяет обработку каждого соответствующего файла между собой и другими серверами.

<Image
  img={S3Cluster}
  size='lg'
  border
  alt='Функция s3Cluster в ClickHouse'
/>

Мы повторяем наш предыдущий запрос на чтение, распределяя рабочую нагрузку по 3 узлам, изменив запрос для использования `s3Cluster`. В ClickHouse Cloud это выполняется автоматически путем обращения к кластеру `default`.

Как отмечено в разделе [Использование кластеров](/integrations/s3#utilizing-clusters), эта работа распределяется на уровне файлов. Чтобы воспользоваться этой функцией, пользователям потребуется достаточное количество файлов, т. е. как минимум больше, чем количество узлов.

```sql
SELECT
    OwnerDisplayName,
    count() AS num_posts
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
WHERE OwnerDisplayName NOT IN ('', 'anon')
GROUP BY OwnerDisplayName
ORDER BY num_posts DESC
LIMIT 5
SETTINGS max_threads = 16

┌─OwnerDisplayName─┬─num_posts─┐
│ user330315       │     10344 │
│ user4039065      │      5316 │
│ user149341       │      4102 │
│ user529758       │      3700 │
│ user3559349      │      3068 │
└──────────────────┴───────────┘

5 rows in set. Elapsed: 0.622 sec. Processed 59.82 million rows, 24.03 GB (96.13 million rows/s., 38.62 GB/s.)
Peak memory usage: 176.74 MiB.
```

Аналогично, наш запрос на вставку может быть распределен с использованием улучшенных настроек, определенных ранее для одного узла:

```sql
INSERT INTO posts SELECT *
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet') SETTINGS min_insert_block_size_rows=0, max_insert_threads=4, min_insert_block_size_bytes=2863311530

0 rows in set. Elapsed: 171.202 sec. Processed 59.82 million rows, 24.03 GB (349.41 thousand rows/s., 140.37 MB/s.)
```


Читатели заметят, что чтение файлов улучшило производительность операций чтения, но не вставки. По умолчанию, хотя операции чтения распределяются с использованием `s3Cluster`, вставки выполняются на узле-инициаторе. Это означает, что, несмотря на выполнение чтения на каждом узле, результирующие строки будут направляться на инициатор для последующего распределения. В сценариях с высокой пропускной способностью это может стать узким местом. Чтобы устранить это, установите параметр `parallel_distributed_insert_select` для функции `s3cluster`.

Установка значения `parallel_distributed_insert_select=2` гарантирует, что `SELECT` и `INSERT` будут выполняться на каждом шарде из/в базовую таблицу распределённого движка на каждом узле.

```sql
INSERT INTO posts
SELECT *
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
SETTINGS parallel_distributed_insert_select = 2, min_insert_block_size_rows=0, max_insert_threads=4, min_insert_block_size_bytes=2863311530

0 rows in set. Elapsed: 54.571 sec. Processed 59.82 million rows, 24.03 GB (1.10 million rows/s., 440.38 MB/s.)
Peak memory usage: 11.75 GiB.
```

Как и ожидалось, это снижает скорость вставки данных в три раза.


## Дополнительная настройка {#further-tuning}

### Отключение дедупликации {#disable-de-duplication}

Операции вставки иногда могут завершаться с ошибками, такими как таймауты. При сбое вставки данные могут быть успешно вставлены, а могут и не быть. Чтобы клиент мог безопасно повторить попытку вставки, по умолчанию в распределённых развёртываниях, таких как ClickHouse Cloud, ClickHouse пытается определить, были ли данные уже успешно вставлены. Если вставляемые данные помечены как дубликат, ClickHouse не вставляет их в целевую таблицу. Однако пользователь всё равно получит статус успешной операции, как если бы данные были вставлены в обычном режиме.

Хотя такое поведение, которое создаёт дополнительную нагрузку при вставке, имеет смысл при загрузке данных от клиента или пакетами, оно может быть излишним при выполнении `INSERT INTO SELECT` из объектного хранилища. Отключив эту функциональность во время вставки, можно улучшить производительность, как показано ниже:

```sql
INSERT INTO posts
SETTINGS parallel_distributed_insert_select = 2, min_insert_block_size_rows = 0, max_insert_threads = 4, min_insert_block_size_bytes = 2863311530, insert_deduplicate = 0
SELECT *
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
SETTINGS parallel_distributed_insert_select = 2, min_insert_block_size_rows = 0, max_insert_threads = 4, min_insert_block_size_bytes = 2863311530, insert_deduplicate = 0

0 rows in set. Elapsed: 52.992 sec. Processed 59.82 million rows, 24.03 GB (1.13 million rows/s., 453.50 MB/s.)
Peak memory usage: 26.57 GiB.
```

### Оптимизация при вставке {#optimize-on-insert}

В ClickHouse настройка `optimize_on_insert` управляет тем, объединяются ли части данных в процессе вставки. Когда она включена (`optimize_on_insert = 1` по умолчанию), небольшие части объединяются в более крупные по мере их вставки, что улучшает производительность запросов за счёт уменьшения количества частей, которые необходимо прочитать. Однако это объединение добавляет накладные расходы к процессу вставки, потенциально замедляя вставки с высокой пропускной способностью.

Отключение этой настройки (`optimize_on_insert = 0`) пропускает объединение во время вставок, позволяя записывать данные быстрее, особенно при обработке частых небольших вставок. Процесс объединения откладывается на фоновое выполнение, что обеспечивает лучшую производительность вставки, но временно увеличивает количество небольших частей, что может замедлить запросы до завершения фонового объединения. Эта настройка идеальна, когда производительность вставки является приоритетом, а процесс фонового объединения может эффективно выполнить оптимизацию позже. Как показано ниже, отключение этой настройки может улучшить пропускную способность вставки:

```sql
SELECT *
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
SETTINGS parallel_distributed_insert_select = 2, min_insert_block_size_rows = 0, max_insert_threads = 4, min_insert_block_size_bytes = 2863311530, insert_deduplicate = 0, optimize_on_insert = 0

0 rows in set. Elapsed: 49.688 sec. Processed 59.82 million rows, 24.03 GB (1.20 million rows/s., 483.66 MB/s.)
```


## Прочие замечания {#misc-notes}

- При ограниченном объёме памяти рекомендуется уменьшить значение параметра `max_insert_delayed_streams_for_parallel_write` при вставке данных в S3.
