---
slug: /integrations/s3/performance
sidebar_position: 2
sidebar_label: 'Оптимизация производительности'
title: 'Оптимизация производительности вставки и чтения из S3'
description: 'Оптимизация производительности чтения и вставки в S3'
doc_type: 'guide'
keywords: ['s3', 'производительность', 'оптимизация', 'объектное хранилище', 'загрузка данных']
---

import Image from '@theme/IdealImage';
import InsertMechanics from '@site/static/images/integrations/data-ingestion/s3/insert_mechanics.png';
import Pull from '@site/static/images/integrations/data-ingestion/s3/pull.png';
import Merges from '@site/static/images/integrations/data-ingestion/s3/merges.png';
import ResourceUsage from '@site/static/images/integrations/data-ingestion/s3/resource_usage.png';
import InsertThreads from '@site/static/images/integrations/data-ingestion/s3/insert_threads.png';
import S3Cluster from '@site/static/images/integrations/data-ingestion/s3/s3Cluster.png';
import HardwareSize from '@site/static/images/integrations/data-ingestion/s3/hardware_size.png';

Этот раздел посвящен оптимизации производительности при чтении и записи данных из S3 с использованием [табличных функций s3](/sql-reference/table-functions/s3).

:::info
**Рекомендации, описанные в этом руководстве, применимы и к другим реализациям объектного хранилища с их собственными табличными функциями, такими как [GCS](/sql-reference/table-functions/gcs) и [Azure Blob storage](/sql-reference/table-functions/azureBlobStorage).**
:::

Перед настройкой потоков и размеров блоков для повышения производительности записи рекомендуется разобраться в механизме записи данных в S3. Если вы уже знакомы с этим механизмом или хотите сразу перейти к практическим советам, см. пример [ниже](/integrations/s3/performance#example-dataset).


## Механизм вставки данных (одиночный узел) {#insert-mechanics-single-node}

Два основных фактора, помимо характеристик оборудования, влияют на производительность и использование ресурсов при вставке данных в ClickHouse (для одиночного узла): **размер блока вставки** и **параллелизм вставки**.

### Размер блока вставки {#insert-block-size}

<Image
  img={InsertMechanics}
  size='lg'
  border
  alt='Механизм размера блока вставки в ClickHouse'
/>

При выполнении `INSERT INTO SELECT` ClickHouse получает порцию данных и ① формирует (как минимум) один блок вставки в памяти (для каждого [ключа партиционирования](/engines/table-engines/mergetree-family/custom-partitioning-key)) из полученных данных. Данные блока сортируются, и применяются оптимизации, специфичные для движка таблицы. Затем данные сжимаются и ② записываются в хранилище базы данных в виде нового куска данных.

Размер блока вставки влияет как на [использование дискового ввода-вывода](https://en.wikipedia.org/wiki/Category:Disk_file_systems), так и на использование памяти сервера ClickHouse. Большие блоки вставки используют больше памяти, но генерируют более крупные и менее многочисленные начальные куски. Чем меньше кусков ClickHouse необходимо создать для загрузки большого объема данных, тем меньше требуется дискового ввода-вывода и автоматических [фоновых слияний](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#more-parts--more-background-part-merges).

При использовании запроса `INSERT INTO SELECT` в сочетании с движком интеграционной таблицы или табличной функцией данные извлекаются сервером ClickHouse:

<Image
  img={Pull}
  size='lg'
  border
  alt='Извлечение данных из внешних источников в ClickHouse'
/>

До полной загрузки данных сервер выполняет цикл:

```bash
① Извлечь и разобрать следующую порцию данных и сформировать из неё блок данных в памяти (один на ключ партиционирования).

② Записать блок в новый кусок в хранилище.

Перейти к ①
```

В ①, размер зависит от размера блока вставки, который можно контролировать двумя настройками:

- [`min_insert_block_size_rows`](/operations/settings/settings#min_insert_block_size_rows) (по умолчанию: `1048545` миллион строк)
- [`min_insert_block_size_bytes`](/operations/settings/settings#min_insert_block_size_bytes) (по умолчанию: `256 MiB`)

Когда в блоке вставки накапливается указанное количество строк или достигается настроенный объем данных (в зависимости от того, что произойдет первым), это инициирует запись блока в новый кусок. Цикл вставки продолжается с шага ①.

Обратите внимание, что значение `min_insert_block_size_bytes` обозначает несжатый размер блока в памяти (а не сжатый размер куска на диске). Также обратите внимание, что созданные блоки и куски редко содержат точно настроенное количество строк или байтов, поскольку ClickHouse обрабатывает данные потоково и построчно-[блочно](/operations/settings/settings#max_block_size). Поэтому эти настройки определяют минимальные пороговые значения.

#### Учитывайте слияния {#be-aware-of-merges}

Чем меньше настроенный размер блока вставки, тем больше начальных кусков создается при загрузке большого объема данных, и тем больше фоновых слияний кусков выполняется одновременно с приемом данных. Это может вызвать конкуренцию за ресурсы (CPU и память) и потребовать дополнительного времени (для достижения [здорового](/operations/settings/merge-tree-settings#parts_to_throw_insert) (3000) количества кусков) после завершения приема данных.

:::important
Производительность запросов ClickHouse будет негативно затронута, если количество кусков превысит [рекомендуемые лимиты](/operations/settings/merge-tree-settings#parts_to_throw_insert).
:::

ClickHouse будет непрерывно [объединять куски](https://clickhouse.com/blog/asynchronous-data-inserts-in-clickhouse#data-needs-to-be-batched-for-optimal-performance) в более крупные куски, пока они не [достигнут](/operations/settings/merge-tree-settings#max_bytes_to_merge_at_max_space_in_pool) сжатого размера ~150 GiB. Эта диаграмма показывает, как сервер ClickHouse объединяет куски:

<Image img={Merges} size='lg' border alt='Фоновые слияния в ClickHouse' />

Один сервер ClickHouse использует несколько [фоновых потоков слияния](/operations/server-configuration-parameters/settings#background_pool_size) для выполнения параллельных [слияний кусков](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#more-parts--more-background-part-merges:~:text=to%20execute%20concurrent-,part%20merges,-.%20Each%20thread%20executes). Каждый поток выполняет цикл:

```bash
① Определить, какие куски объединять следующими, и загрузить эти куски в виде блоков в память.

② Объединить загруженные блоки в памяти в более крупный блок.

```


③ Записать объединённый блок в новую часть на диске.

Вернуться к ①

````

Обратите внимание, что [увеличение](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#hardware-size) количества ядер процессора и объёма оперативной памяти повышает пропускную способность фонового слияния.

Куски, объединённые в более крупные куски, помечаются как [неактивные](/operations/system-tables/parts) и окончательно удаляются через [настраиваемое](/operations/settings/merge-tree-settings#old_parts_lifetime) количество минут. Со временем это формирует дерево объединённых кусков (отсюда название таблиц семейства [`MergeTree`](/engines/table-engines/mergetree-family)).

### Параллелизм вставки {#insert-parallelism}

<Image img={ResourceUsage} size="lg" border alt="Использование ресурсов при параллельной вставке" />

Сервер ClickHouse может обрабатывать и вставлять данные параллельно. Уровень параллелизма вставки влияет на пропускную способность загрузки данных и использование памяти сервера ClickHouse. Параллельная загрузка и обработка данных требует больше оперативной памяти, но увеличивает пропускную способность загрузки за счёт более быстрой обработки данных.

Табличные функции, такие как s3, позволяют указывать наборы имён загружаемых файлов с помощью glob-шаблонов. Когда glob-шаблон соответствует нескольким существующим файлам, ClickHouse может распараллелить чтение между этими файлами и внутри них, а также вставлять данные параллельно в таблицу, используя параллельно работающие потоки вставки (на сервер): 

<Image img={InsertThreads} size="lg" border alt="Параллельные потоки вставки в ClickHouse" />

Пока не будут обработаны все данные из всех файлов, каждый поток вставки выполняет цикл: 

```bash
① Получить следующую порцию необработанных данных файла (размер порции определяется настроенным размером блока) и создать из неё блок данных в памяти.

② Записать блок в новый кусок на хранилище.

Перейти к ①. 
````

Количество таких параллельных потоков вставки можно настроить с помощью параметра [`max_insert_threads`](/operations/settings/settings#max_insert_threads). Значение по умолчанию — `1` для ClickHouse с открытым исходным кодом и 4 для [ClickHouse Cloud](https://clickhouse.com/cloud).

При большом количестве файлов параллельная обработка несколькими потоками вставки работает эффективно. Это позволяет полностью задействовать как доступные ядра процессора, так и пропускную способность сети (для параллельной загрузки файлов). В сценариях, когда в таблицу загружается всего несколько больших файлов, ClickHouse автоматически обеспечивает высокий уровень параллелизма обработки данных и оптимизирует использование пропускной способности сети, создавая дополнительные потоки чтения на каждый поток вставки для параллельного чтения (скачивания) различных диапазонов внутри больших файлов.

Для функции и таблицы s3 параллельная загрузка отдельного файла определяется значениями [max&#95;download&#95;threads](https://clickhouse.com/codebrowser/ClickHouse/src/Core/Settings.h.html#DB::SettingsTraits::Data::max_download_threads) и [max&#95;download&#95;buffer&#95;size](https://clickhouse.com/codebrowser/ClickHouse/src/Core/Settings.h.html#DB::SettingsTraits::Data::max_download_buffer_size). Файлы будут загружаться параллельно только в том случае, если их размер превышает `2 * max_download_buffer_size`. По умолчанию значение `max_download_buffer_size` составляет 10 МиБ. В некоторых случаях можно безопасно увеличить размер этого буфера до 50 МБ (`max_download_buffer_size=52428800`), чтобы каждый файл загружался одним потоком. Это может сократить время, которое каждый поток тратит на выполнение вызовов к S3, и, следовательно, также уменьшить время ожидания S3. Кроме того, для файлов, которые слишком малы для параллельного чтения, ClickHouse автоматически выполняет предварительную загрузку данных, асинхронно считывая такие файлы заранее для увеличения пропускной способности.


## Измерение производительности {#measuring-performance}

Оптимизация производительности запросов с использованием табличных функций S3 требуется как при выполнении запросов непосредственно к данным в хранилище (т.е. при ad-hoc запросах, где используются только вычислительные ресурсы ClickHouse, а данные остаются в S3 в исходном формате), так и при загрузке данных из S3 в табличный движок ClickHouse MergeTree. Если не указано иное, приведенные ниже рекомендации применимы к обоим сценариям.


## Влияние конфигурации оборудования {#impact-of-hardware-size}

<Image
  img={HardwareSize}
  size='lg'
  border
  alt='Влияние конфигурации оборудования на производительность ClickHouse'
/>

Количество доступных ядер процессора и объем оперативной памяти влияют на:

- поддерживаемый [начальный размер кусков](#insert-block-size)
- возможный уровень [параллелизма вставки](#insert-parallelism)
- пропускную способность [фоновых слияний кусков](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#more-parts--more-background-part-merges)

и, следовательно, на общую пропускную способность загрузки данных.


## Локальность региона {#region-locality}

Убедитесь, что ваши бакеты находятся в том же регионе, что и экземпляры ClickHouse. Эта простая оптимизация может существенно повысить производительность, особенно если вы развертываете экземпляры ClickHouse на инфраструктуре AWS.


## Форматы {#formats}

ClickHouse может читать файлы, хранящиеся в S3-бакетах, в [поддерживаемых форматах](/interfaces/formats#formats-overview) с помощью функции `s3` и движка `S3`. При чтении сырых файлов некоторые из этих форматов имеют явные преимущества:

- Форматы с закодированными именами столбцов, такие как Native, Parquet, CSVWithNames и TabSeparatedWithNames, требуют менее подробных запросов, поскольку пользователю не нужно указывать имена столбцов в функции `s3`. Имена столбцов позволяют автоматически определить эту информацию.
- Форматы различаются по производительности чтения и записи. Native и Parquet являются наиболее оптимальными форматами для производительности чтения, поскольку они уже ориентированы на столбцы и более компактны. Формат Native дополнительно выигрывает от соответствия способу хранения данных ClickHouse в памяти, что снижает накладные расходы на обработку при потоковой передаче данных в ClickHouse.
- Размер блока часто влияет на задержку чтения больших файлов. Это особенно заметно при выборке данных, например, при возврате первых N строк. В случае форматов, таких как CSV и TSV, файлы должны быть полностью разобраны для возврата набора строк. Форматы, такие как Native и Parquet, позволяют выполнять выборку быстрее.
- Каждый формат сжатия имеет свои преимущества и недостатки, часто балансируя между уровнем сжатия и скоростью, смещая акцент в сторону производительности сжатия или распаковки. При сжатии сырых файлов, таких как CSV или TSV, lz4 обеспечивает самую быструю производительность распаковки, жертвуя уровнем сжатия. Gzip обычно сжимает лучше за счёт немного более медленной скорости чтения. Xz идёт ещё дальше, обычно обеспечивая лучшее сжатие при самой медленной производительности сжатия и распаковки. При экспорте Gz и lz4 предлагают сопоставимую скорость сжатия. Учитывайте скорость вашего соединения. Любые преимущества от более быстрой распаковки или сжатия легко нивелируются медленным соединением с вашими S3-бакетами.
- Форматы, такие как Native или Parquet, обычно не оправдывают накладные расходы на сжатие. Любая экономия размера данных, вероятно, будет минимальной, поскольку эти форматы изначально компактны. Время, затраченное на сжатие и распаковку, редко компенсирует время передачи по сети, особенно учитывая, что S3 доступен глобально с высокой пропускной способностью сети.


## Пример набора данных {#example-dataset}

Для иллюстрации дальнейших возможных оптимизаций мы будем использовать [публикации из набора данных Stack Overflow](/data-modeling/schema-design#stack-overflow-dataset), оптимизируя как производительность запросов, так и производительность вставки этих данных.

Этот набор данных состоит из 189 файлов Parquet, по одному на каждый месяц с июля 2008 года по март 2024 года.

Обратите внимание, что мы используем Parquet для достижения высокой производительности, согласно нашим [рекомендациям выше](#formats), выполняя все запросы на кластере ClickHouse, расположенном в том же регионе, что и бакет. Этот кластер состоит из 3 узлов, каждый с 32 ГиБ оперативной памяти и 8 виртуальными процессорами.

Без какой-либо настройки мы демонстрируем производительность вставки этого набора данных в движок таблиц MergeTree, а также выполнение запроса для определения пользователей, задающих больше всего вопросов. Оба этих запроса намеренно требуют полного сканирования данных.

```sql
-- Топ имен пользователей
SELECT
    OwnerDisplayName,
    count() AS num_posts
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
WHERE OwnerDisplayName NOT IN ('', 'anon')
GROUP BY OwnerDisplayName
ORDER BY num_posts DESC
LIMIT 5

┌─OwnerDisplayName─┬─num_posts─┐
│ user330315       │     10344 │
│ user4039065      │      5316 │
│ user149341       │      4102 │
│ user529758       │      3700 │
│ user3559349      │      3068 │
└──────────────────┴───────────┘

5 rows in set. Elapsed: 3.013 sec. Processed 59.82 million rows, 24.03 GB (19.86 million rows/s., 7.98 GB/s.)
Peak memory usage: 603.64 MiB.

-- Загрузка в таблицу posts
INSERT INTO posts SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')

0 rows in set. Elapsed: 191.692 sec. Processed 59.82 million rows, 24.03 GB (312.06 thousand rows/s., 125.37 MB/s.)
```

В нашем примере мы возвращаем только несколько строк. При измерении производительности запросов `SELECT`, где клиенту возвращаются большие объемы данных, используйте либо [формат null](/interfaces/formats/Null) для запросов, либо направляйте результаты в [движок `Null`](/engines/table-engines/special/null.md). Это позволит избежать перегрузки клиента данными и насыщения сети.

:::info
При чтении данных с помощью запросов начальный запрос часто может выполняться медленнее, чем при повторении того же запроса. Это можно объяснить как собственным кешированием S3, так и [кешем вывода схемы ClickHouse](/operations/system-tables/schema_inference_cache). Он сохраняет выведенную схему для файлов, что позволяет пропустить этап вывода схемы при последующих обращениях, тем самым сокращая время выполнения запроса.
:::


## Использование потоков для чтения {#using-threads-for-reads}

Производительность чтения из S3 масштабируется линейно с количеством ядер при условии, что вы не ограничены пропускной способностью сети или локальным вводом-выводом. Увеличение количества потоков также приводит к дополнительным затратам памяти, о которых следует помнить. Для потенциального улучшения производительности чтения можно изменить следующие параметры:

- Обычно значения `max_threads` по умолчанию достаточно, то есть равного количеству ядер. Если объем памяти, используемой для запроса, велик и его необходимо уменьшить, или если `LIMIT` результатов низкий, это значение можно уменьшить. Пользователи с большим объемом памяти могут поэкспериментировать с увеличением этого значения для возможного повышения пропускной способности чтения из S3. Обычно это имеет смысл только на машинах с небольшим количеством ядер, то есть &lt; 10. Выигрыш от дальнейшей параллелизации обычно уменьшается, поскольку другие ресурсы становятся узким местом, например сеть и конкуренция за процессор.
- Версии ClickHouse до 22.3.1 распараллеливали чтение только между несколькими файлами при использовании функции `s3` или движка таблиц `S3`. Это требовало от пользователя разделения файлов на фрагменты в S3 и чтения с использованием шаблона glob для достижения оптимальной производительности чтения. В более поздних версиях загрузка распараллеливается внутри файла.
- В сценариях с малым количеством потоков может быть полезно установить `remote_filesystem_read_method` в значение "read" для синхронного чтения файлов из S3.
- Для функции и таблицы s3 параллельная загрузка отдельного файла определяется значениями [`max_download_threads`](/operations/settings/settings#max_download_threads) и [`max_download_buffer_size`](/operations/settings/settings#max_download_buffer_size). Хотя [`max_download_threads`](/operations/settings/settings#max_download_threads) управляет количеством используемых потоков, файлы будут загружаться параллельно только в том случае, если их размер превышает 2 \* `max_download_buffer_size`. По умолчанию `max_download_buffer_size` установлен в 10 МиБ. В некоторых случаях можно безопасно увеличить размер этого буфера до 50 МБ (`max_download_buffer_size=52428800`), чтобы меньшие файлы загружались только одним потоком. Это может сократить время, которое каждый поток тратит на выполнение вызовов S3, и, таким образом, также уменьшить время ожидания S3. См. [эту статью в блоге](https://clickhouse.com/blog/clickhouse-1-trillion-row-challenge) для примера.

Перед внесением каких-либо изменений для улучшения производительности убедитесь, что вы проводите соответствующие измерения. Поскольку вызовы S3 API чувствительны к задержкам и могут влиять на время выполнения на клиенте, используйте журнал запросов для метрик производительности, то есть `system.query_log`.

Рассмотрим наш предыдущий запрос: удвоение `max_threads` до `16` (по умолчанию `max_threads` равен количеству ядер на узле) улучшает производительность запроса чтения в 2 раза за счет увеличения потребления памяти. Дальнейшее увеличение `max_threads` дает убывающую отдачу, как показано ниже.

```sql
SELECT
    OwnerDisplayName,
    count() AS num_posts
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
WHERE OwnerDisplayName NOT IN ('', 'anon')
GROUP BY OwnerDisplayName
ORDER BY num_posts DESC
LIMIT 5
SETTINGS max_threads = 16

┌─OwnerDisplayName─┬─num_posts─┐
│ user330315       │     10344 │
│ user4039065      │      5316 │
│ user149341       │      4102 │
│ user529758       │      3700 │
│ user3559349      │      3068 │
└──────────────────┴───────────┘

Получено 5 строк. Затрачено: 1.505 sec. Обработано 59.82 million rows, 24.03 GB (39.76 million rows/s., 15.97 GB/s.)
Пиковое использование памяти: 178.58 MiB.

SETTINGS max_threads = 32

Получено 5 строк. Затрачено: 0.779 sec. Обработано 59.82 million rows, 24.03 GB (76.81 million rows/s., 30.86 GB/s.)
Пиковое использование памяти: 369.20 MiB.

SETTINGS max_threads = 64

Получено 5 строк. Затрачено: 0.674 sec. Обработано 59.82 million rows, 24.03 GB (88.81 million rows/s., 35.68 GB/s.)
Пиковое использование памяти: 639.99 MiB.
```


## Настройка потоков и размера блока для вставок {#tuning-threads-and-block-size-for-inserts}

Для достижения максимальной производительности загрузки данных необходимо выбрать (1) размер блока вставки и (2) соответствующий уровень параллелизма вставки на основе (3) количества доступных ядер процессора и оперативной памяти. Вкратце:

- Чем больше мы [настроим размер блока вставки](#insert-block-size), тем меньше частей должен создавать ClickHouse и тем меньше требуется операций [дискового ввода-вывода](https://en.wikipedia.org/wiki/Category:Disk_file_systems) и [фоновых слияний](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#more-parts--more-background-part-merges).
- Чем больше мы настроим [количество параллельных потоков вставки](#insert-parallelism), тем быстрее будут обрабатываться данные.

Между этими двумя факторами производительности существует противоречие (плюс компромисс с фоновым слиянием частей). Объем доступной оперативной памяти серверов ClickHouse ограничен. Большие блоки используют больше оперативной памяти, что ограничивает количество параллельных потоков вставки, которые мы можем использовать. И наоборот, большее количество параллельных потоков вставки требует больше оперативной памяти, поскольку количество потоков вставки определяет количество блоков вставки, создаваемых в памяти одновременно. Это ограничивает возможный размер блоков вставки. Кроме того, может возникать конкуренция за ресурсы между потоками вставки и потоками фонового слияния. Большое количество настроенных потоков вставки (1) создает больше частей, которые необходимо объединить, и (2) отнимает ядра процессора и память у потоков фонового слияния.

Для подробного описания того, как поведение этих параметров влияет на производительность и ресурсы, рекомендуем [прочитать эту статью в блоге](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part2). Как описано в этой статье, настройка может включать тщательный баланс двух параметров. Такое исчерпывающее тестирование часто непрактично, поэтому в итоге мы рекомендуем:

```bash
• max_insert_threads: выберите примерно половину доступных ядер процессора для потоков вставки (чтобы оставить достаточно выделенных ядер для фоновых слияний)

• peak_memory_usage_in_bytes: выберите предполагаемое пиковое использование памяти; либо всю доступную оперативную память (если это изолированная загрузка), либо половину или меньше (чтобы оставить место для других параллельных задач)

Затем:
min_insert_block_size_bytes = peak_memory_usage_in_bytes / (~3 * max_insert_threads)
```

С помощью этой формулы вы можете установить `min_insert_block_size_rows` в 0 (чтобы отключить пороговое значение на основе строк), одновременно установив `max_insert_threads` в выбранное значение, а `min_insert_block_size_bytes` — в вычисленный результат из приведенной выше формулы.

Применим эту формулу к нашему предыдущему примеру со Stack Overflow.

- `max_insert_threads=4` (8 ядер на узел)
- `peak_memory_usage_in_bytes` — 32 ГиБ (100% ресурсов узла) или `34359738368` байт.
- `min_insert_block_size_bytes` = `34359738368/(3*4) = 2863311530`

```sql
INSERT INTO posts SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet') SETTINGS min_insert_block_size_rows=0, max_insert_threads=4, min_insert_block_size_bytes=2863311530

0 строк в наборе. Затрачено: 128.566 сек. Обработано 59.82 млн строк, 24.03 ГБ (465.28 тыс. строк/с., 186.92 МБ/с.)
```

Как показано, настройка этих параметров улучшила производительность вставки более чем на `33%`. Мы оставляем читателю возможность проверить, можно ли дополнительно улучшить производительность одного узла.


## Масштабирование с помощью ресурсов и узлов {#scaling-with-resources-and-nodes}

Масштабирование с помощью ресурсов и узлов применимо как к запросам на чтение, так и к запросам на вставку.

### Вертикальное масштабирование {#vertical-scaling}

Все предыдущие настройки и запросы использовали только один узел в нашем кластере ClickHouse Cloud. У пользователей также часто имеется более одного узла ClickHouse. Мы рекомендуем пользователям сначала масштабироваться вертикально, увеличивая пропускную способность S3 линейно с количеством ядер. Если мы повторим наши предыдущие запросы на вставку и чтение на более крупном узле ClickHouse Cloud с удвоенными ресурсами (64 ГиБ, 16 vCPU) с соответствующими настройками, оба выполнятся примерно в два раза быстрее.

```sql
INSERT INTO posts SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet') SETTINGS min_insert_block_size_rows=0, max_insert_threads=8, min_insert_block_size_bytes=2863311530

0 rows in set. Elapsed: 67.294 sec. Processed 59.82 million rows, 24.03 GB (888.93 thousand rows/s., 357.12 MB/s.)

SELECT
    OwnerDisplayName,
    count() AS num_posts
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
WHERE OwnerDisplayName NOT IN ('', 'anon')
GROUP BY OwnerDisplayName
ORDER BY num_posts DESC
LIMIT 5
SETTINGS max_threads = 92

5 rows in set. Elapsed: 0.421 sec. Processed 59.82 million rows, 24.03 GB (142.08 million rows/s., 57.08 GB/s.)
```

:::note
Отдельные узлы также могут быть ограничены сетью и запросами S3 GET, что препятствует линейному масштабированию производительности по вертикали.
:::

### Горизонтальное масштабирование {#horizontal-scaling}

В конечном итоге горизонтальное масштабирование часто становится необходимым из-за доступности оборудования и экономической эффективности. В ClickHouse Cloud производственные кластеры имеют как минимум 3 узла. Поэтому пользователи могут захотеть использовать все узлы для вставки данных.

Использование кластера для чтения из S3 требует применения функции `s3Cluster`, как описано в разделе [Использование кластеров](/integrations/s3#utilizing-clusters). Это позволяет распределять операции чтения между узлами.

Сервер, который первоначально получает запрос на вставку, сначала разрешает шаблон glob, а затем динамически распределяет обработку каждого соответствующего файла между собой и другими серверами.

<Image
  img={S3Cluster}
  size='lg'
  border
  alt='Функция s3Cluster в ClickHouse'
/>

Мы повторяем наш предыдущий запрос на чтение, распределяя рабочую нагрузку между 3 узлами, изменив запрос для использования `s3Cluster`. В ClickHouse Cloud это выполняется автоматически путем обращения к кластеру `default`.

Как отмечено в разделе [Использование кластеров](/integrations/s3#utilizing-clusters), эта работа распределяется на уровне файлов. Чтобы воспользоваться этой функцией, пользователям потребуется достаточное количество файлов, т. е. как минимум больше, чем количество узлов.

```sql
SELECT
    OwnerDisplayName,
    count() AS num_posts
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
WHERE OwnerDisplayName NOT IN ('', 'anon')
GROUP BY OwnerDisplayName
ORDER BY num_posts DESC
LIMIT 5
SETTINGS max_threads = 16

┌─OwnerDisplayName─┬─num_posts─┐
│ user330315       │     10344 │
│ user4039065      │      5316 │
│ user149341       │      4102 │
│ user529758       │      3700 │
│ user3559349      │      3068 │
└──────────────────┴───────────┘

5 rows in set. Elapsed: 0.622 sec. Processed 59.82 million rows, 24.03 GB (96.13 million rows/s., 38.62 GB/s.)
Peak memory usage: 176.74 MiB.
```

Аналогично, наш запрос на вставку может быть распределен с использованием улучшенных настроек, определенных ранее для одного узла:

```sql
INSERT INTO posts SELECT *
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet') SETTINGS min_insert_block_size_rows=0, max_insert_threads=4, min_insert_block_size_bytes=2863311530

0 rows in set. Elapsed: 171.202 sec. Processed 59.82 million rows, 24.03 GB (349.41 thousand rows/s., 140.37 MB/s.)
```


Читатели заметят, что чтение файлов улучшило производительность запросов, но не операций вставки. По умолчанию, хотя операции чтения распределяются с помощью `s3Cluster`, вставки выполняются на узле-инициаторе. Это означает, что хотя чтение происходит на каждом узле, полученные строки направляются инициатору для последующего распределения. В сценариях с высокой пропускной способностью это может стать узким местом. Чтобы решить эту проблему, установите параметр `parallel_distributed_insert_select` для функции `s3cluster`.

Установка значения `parallel_distributed_insert_select=2` обеспечивает выполнение `SELECT` и `INSERT` на каждом шарде из/в базовую таблицу распределённого движка на каждом узле.

```sql
INSERT INTO posts
SELECT *
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
SETTINGS parallel_distributed_insert_select = 2, min_insert_block_size_rows=0, max_insert_threads=4, min_insert_block_size_bytes=2863311530

0 rows in set. Elapsed: 54.571 sec. Processed 59.82 million rows, 24.03 GB (1.10 million rows/s., 440.38 MB/s.)
Peak memory usage: 11.75 GiB.
```

Как и ожидалось, это снижает производительность вставки в 3 раза.


## Дополнительная настройка {#further-tuning}

### Отключение дедупликации {#disable-de-duplication}

Операции вставки иногда могут завершаться с ошибками, такими как таймауты. При неудачной вставке данные могут быть успешно вставлены, а могут и не быть. Чтобы клиент мог безопасно повторять попытки вставки, по умолчанию в распределённых развёртываниях, таких как ClickHouse Cloud, ClickHouse пытается определить, были ли данные уже успешно вставлены. Если вставляемые данные помечены как дубликат, ClickHouse не вставляет их в целевую таблицу. Однако пользователь всё равно получит статус успешной операции, как если бы данные были вставлены в обычном режиме.

Хотя такое поведение, создающее дополнительную нагрузку при вставке, имеет смысл при загрузке данных от клиента или пакетами, оно может быть излишним при выполнении `INSERT INTO SELECT` из объектного хранилища. Отключив эту функциональность во время вставки, можно улучшить производительность, как показано ниже:

```sql
INSERT INTO posts
SETTINGS parallel_distributed_insert_select = 2, min_insert_block_size_rows = 0, max_insert_threads = 4, min_insert_block_size_bytes = 2863311530, insert_deduplicate = 0
SELECT *
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
SETTINGS parallel_distributed_insert_select = 2, min_insert_block_size_rows = 0, max_insert_threads = 4, min_insert_block_size_bytes = 2863311530, insert_deduplicate = 0

0 rows in set. Elapsed: 52.992 sec. Processed 59.82 million rows, 24.03 GB (1.13 million rows/s., 453.50 MB/s.)
Peak memory usage: 26.57 GiB.
```

### Оптимизация при вставке {#optimize-on-insert}

В ClickHouse настройка `optimize_on_insert` управляет тем, объединяются ли куски данных в процессе вставки. Когда она включена (`optimize_on_insert = 1` по умолчанию), небольшие куски объединяются в более крупные по мере их вставки, что улучшает производительность запросов за счёт уменьшения количества кусков, которые необходимо прочитать. Однако это объединение добавляет дополнительную нагрузку к процессу вставки, потенциально замедляя высокопроизводительные вставки.

Отключение этой настройки (`optimize_on_insert = 0`) пропускает объединение во время вставок, позволяя записывать данные быстрее, особенно при обработке частых небольших вставок. Процесс объединения откладывается на фоновое выполнение, что обеспечивает лучшую производительность вставки, но временно увеличивает количество небольших кусков, что может замедлить запросы до завершения фонового объединения. Эта настройка идеальна, когда производительность вставки является приоритетом, а процесс фонового объединения может эффективно выполнить оптимизацию позже. Как показано ниже, отключение этой настройки может улучшить пропускную способность вставки:

```sql
SELECT *
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
SETTINGS parallel_distributed_insert_select = 2, min_insert_block_size_rows = 0, max_insert_threads = 4, min_insert_block_size_bytes = 2863311530, insert_deduplicate = 0, optimize_on_insert = 0

0 rows in set. Elapsed: 49.688 sec. Processed 59.82 million rows, 24.03 GB (1.20 million rows/s., 483.66 MB/s.)
```


## Прочие замечания {#misc-notes}

- Для сценариев с ограниченной памятью рекомендуется уменьшить значение `max_insert_delayed_streams_for_parallel_write` при вставке данных в S3.
