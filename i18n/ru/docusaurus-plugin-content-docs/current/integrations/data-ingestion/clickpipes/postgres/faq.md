---
sidebar_label: 'FAQ'
description: 'Часто задаваемые вопросы о ClickPipes для Postgres.'
slug: /integrations/clickpipes/postgres/faq
sidebar_position: 2
title: 'FAQ по ClickPipes для Postgres'
keywords: ['postgres faq', 'clickpipes', 'toast columns', 'replication slot', 'publications']
doc_type: 'reference'
---

import failover_slot from '@site/static/images/integrations/data-ingestion/clickpipes/postgres/failover_slot.png'
import Image from '@theme/IdealImage';


# Часто задаваемые вопросы по ClickPipes для Postgres

### Как режим простоя влияет на мой Postgres CDC ClickPipe? {#how-does-idling-affect-my-postgres-cdc-clickpipe}

Если ваш сервис ClickHouse Cloud находится в режиме простоя, ваш Postgres CDC ClickPipe продолжит синхронизацию данных — сервис будет активироваться при наступлении следующего интервала синхронизации для обработки входящих данных. После завершения синхронизации и наступления периода простоя сервис снова перейдет в режим ожидания.

Например, если интервал синхронизации установлен на 30 минут, а время простоя сервиса — на 10 минут, ваш сервис будет активироваться каждые 30 минут, работать в течение 10 минут, а затем снова переходить в режим простоя.

### Как обрабатываются столбцы TOAST в ClickPipes для Postgres? {#how-are-toast-columns-handled-in-clickpipes-for-postgres}

Дополнительную информацию см. на странице [Обработка столбцов TOAST](./toast).

### Как обрабатываются генерируемые столбцы в ClickPipes для Postgres? {#how-are-generated-columns-handled-in-clickpipes-for-postgres}

Дополнительную информацию см. на странице [Генерируемые столбцы Postgres: подводные камни и рекомендации](./generated_columns).

### Должны ли таблицы иметь первичные ключи для участия в Postgres CDC? {#do-tables-need-to-have-primary-keys-to-be-part-of-postgres-cdc}

Для репликации таблицы с помощью ClickPipes для Postgres она должна иметь либо первичный ключ, либо определенный параметр [REPLICA IDENTITY](https://www.postgresql.org/docs/current/sql-altertable.html#SQL-ALTERTABLE-REPLICA-IDENTITY).

- **Первичный ключ**: наиболее простой подход — определить первичный ключ для таблицы. Это обеспечивает уникальный идентификатор для каждой строки, что критически важно для отслеживания обновлений и удалений. В этом случае можно оставить для REPLICA IDENTITY значение `DEFAULT` (поведение по умолчанию).
- **Replica Identity**: если таблица не имеет первичного ключа, можно задать replica identity. Параметр replica identity может быть установлен в значение `FULL`, что означает использование всей строки для идентификации изменений. Альтернативно можно настроить использование уникального индекса, если он существует для таблицы, установив REPLICA IDENTITY в значение `USING INDEX index_name`.
  Чтобы установить replica identity в значение FULL, используйте следующую SQL-команду:

```sql
ALTER TABLE your_table_name REPLICA IDENTITY FULL;
```

REPLICA IDENTITY FULL также включает репликацию неизмененных столбцов TOAST. Подробнее об этом [здесь](./toast).

Обратите внимание, что использование `REPLICA IDENTITY FULL` может негативно влиять на производительность, а также приводить к более быстрому росту WAL, особенно для таблиц без первичного ключа с частыми обновлениями или удалениями, поскольку требуется регистрировать больше данных для каждого изменения. Если у вас есть вопросы или вам требуется помощь в настройке первичных ключей или replica identity для ваших таблиц, обратитесь в нашу службу поддержки.

Важно отметить, что если не определен ни первичный ключ, ни replica identity, ClickPipes не сможет реплицировать изменения для этой таблицы, и в процессе репликации могут возникнуть ошибки. Поэтому рекомендуется проверить схемы ваших таблиц и убедиться, что они соответствуют этим требованиям, прежде чем настраивать ваш ClickPipe.

### Поддерживаются ли секционированные таблицы в рамках Postgres CDC? {#do-you-support-partitioned-tables-as-part-of-postgres-cdc}

Да, секционированные таблицы поддерживаются «из коробки» при условии, что для них определен PRIMARY KEY или REPLICA IDENTITY. PRIMARY KEY и REPLICA IDENTITY должны присутствовать как в родительской таблице, так и в её секциях. Подробнее об этом можно прочитать [здесь](https://blog.peerdb.io/real-time-change-data-capture-for-postgres-partitioned-tables).

### Можно ли подключать базы данных Postgres, которые не имеют публичного IP-адреса или находятся в частных сетях? {#can-i-connect-postgres-databases-that-dont-have-a-public-ip-or-are-in-private-networks}

Да! ClickPipes для Postgres предлагает два способа подключения к базам данных в частных сетях:

1. **SSH-туннелирование**
   - Подходит для большинства сценариев использования
   - Инструкции по настройке см. [здесь](/integrations/clickpipes/postgres#adding-your-source-postgres-database-connection)
   - Работает во всех регионах

2. **AWS PrivateLink**
   - Доступен в трех регионах AWS:
     - us-east-1
     - us-east-2
     - eu-central-1
   - Подробные инструкции по настройке см. в нашей [документации по PrivateLink](/knowledgebase/aws-privatelink-setup-for-clickpipes)
   - Для регионов, где PrivateLink недоступен, используйте SSH-туннелирование


### Как обрабатываются операции UPDATE и DELETE? {#how-do-you-handle-updates-and-deletes}

ClickPipes для Postgres фиксирует как операции INSERT, так и UPDATE из Postgres в виде новых строк с различными версиями (используя столбец версии `_peerdb_`) в ClickHouse. Движок таблиц ReplacingMergeTree периодически выполняет дедупликацию в фоновом режиме на основе ключа сортировки (столбцы ORDER BY), сохраняя только строку с последней версией `_peerdb_`.

Операции DELETE из Postgres передаются в виде новых строк, помеченных как удалённые (с использованием столбца `_peerdb_is_deleted`). Поскольку процесс дедупликации является асинхронным, вы можете временно видеть дубликаты. Для решения этой проблемы необходимо обрабатывать дедупликацию на уровне запросов.

Также обратите внимание, что по умолчанию Postgres не отправляет значения столбцов, которые не являются частью первичного ключа или идентификатора реплики, во время операций DELETE. Если вы хотите фиксировать полные данные строки при выполнении DELETE, можно установить [REPLICA IDENTITY](https://www.postgresql.org/docs/current/sql-altertable.html#SQL-ALTERTABLE-REPLICA-IDENTITY) в значение FULL.

Для получения дополнительной информации обратитесь к:

- [Рекомендации по использованию движка таблиц ReplacingMergeTree](https://docs.peerdb.io/bestpractices/clickhouse_datamodeling#replacingmergetree-table-engine)
- [Блог о внутреннем устройстве CDC из Postgres в ClickHouse](https://clickhouse.com/blog/postgres-to-clickhouse-data-modeling-tips)

### Можно ли обновлять столбцы первичного ключа в PostgreSQL? {#can-i-update-primary-key-columns-in-postgresql}

:::warning
Обновления первичного ключа в PostgreSQL не могут быть корректно воспроизведены в ClickHouse по умолчанию.

Это ограничение существует потому, что дедупликация `ReplacingMergeTree` работает на основе столбцов `ORDER BY` (которые обычно соответствуют первичному ключу). Когда первичный ключ обновляется в PostgreSQL, он отображается как новая строка с другим ключом в ClickHouse, а не как обновление существующей строки. Это может привести к тому, что в вашей таблице ClickHouse будут существовать как старое, так и новое значения первичного ключа.
:::

Обратите внимание, что обновление столбцов первичного ключа не является распространённой практикой при проектировании баз данных PostgreSQL, поскольку первичные ключи предназначены для использования в качестве неизменяемых идентификаторов. Большинство приложений по своей архитектуре избегают обновления первичных ключей, что делает это ограничение редко встречающимся в типичных сценариях использования.

Доступна экспериментальная настройка, которая может включить обработку обновлений первичного ключа, но она имеет существенные последствия для производительности и не рекомендуется для использования в продакшене без тщательного анализа.

Если ваш сценарий использования требует обновления столбцов первичного ключа в PostgreSQL с корректным отражением этих изменений в ClickHouse, пожалуйста, свяжитесь с нашей службой поддержки по адресу [db-integrations-support@clickhouse.com](mailto:db-integrations-support@clickhouse.com), чтобы обсудить ваши конкретные требования и возможные решения.

### Поддерживаются ли изменения схемы? {#do-you-support-schema-changes}

Для получения дополнительной информации обратитесь к странице [ClickPipes для Postgres: Поддержка распространения изменений схемы](./schema-changes).

### Какова стоимость ClickPipes для Postgres CDC? {#what-are-the-costs-for-clickpipes-for-postgres-cdc}

Для получения подробной информации о ценах обратитесь к [разделу о ценах на ClickPipes для Postgres CDC на нашей главной странице обзора тарификации](/cloud/reference/billing/clickpipes).

### Размер слота репликации растёт или не уменьшается; в чём может быть проблема? {#my-replication-slot-size-is-growing-or-not-decreasing-what-might-be-the-issue}

Если вы замечаете, что размер вашего слота репликации Postgres продолжает увеличиваться или не уменьшается, это обычно означает, что **записи WAL (журнала упреждающей записи) не потребляются (или не «воспроизводятся») достаточно быстро** вашим конвейером CDC или процессом репликации. Ниже приведены наиболее распространённые причины и способы их устранения.

1. **Внезапные всплески активности базы данных**
   - Крупные пакетные обновления, массовые вставки или значительные изменения схемы могут быстро генерировать большое количество данных WAL.
   - Слот репликации будет удерживать эти записи WAL до тех пор, пока они не будут потреблены, что вызывает временный скачок размера.

2. **Долго выполняющиеся транзакции**
   - Открытая транзакция заставляет Postgres сохранять все сегменты WAL, созданные с момента начала транзакции, что может значительно увеличить размер слота.
   - Установите `statement_timeout` и `idle_in_transaction_session_timeout` в разумные значения, чтобы предотвратить бесконечное удержание транзакций в открытом состоянии:
     ```sql
     SELECT
         pid,
         state,
         age(now(), xact_start) AS transaction_duration,
         query AS current_query
     FROM
         pg_stat_activity
     WHERE
         xact_start IS NOT NULL
     ORDER BY
         age(now(), xact_start) DESC;
     ```
     Используйте этот запрос для выявления необычно долго выполняющихся транзакций.


3. **Операции обслуживания или служебные операции (например, `pg_repack`)**
   - Инструменты типа `pg_repack` могут переписывать целые таблицы, генерируя большие объемы данных WAL за короткое время.
   - Планируйте выполнение этих операций в периоды низкой нагрузки или тщательно отслеживайте использование WAL во время их работы.

4. **VACUUM и VACUUM ANALYZE**
   - Хотя эти операции необходимы для поддержания работоспособности базы данных, они могут создавать дополнительный трафик WAL — особенно при сканировании больших таблиц.
   - Рассмотрите возможность использования параметров настройки autovacuum или планирования ручных операций VACUUM в часы низкой нагрузки.

5. **Потребитель репликации не читает слот активно**
   - Если ваш конвейер CDC (например, ClickPipes) или другой потребитель репликации останавливается, приостанавливается или аварийно завершает работу, данные WAL будут накапливаться в слоте.
   - Убедитесь, что ваш конвейер работает непрерывно, и проверяйте журналы на наличие ошибок подключения или аутентификации.

Для подробного изучения этой темы ознакомьтесь с нашей статьей в блоге: [Преодоление подводных камней логического декодирования Postgres](https://blog.peerdb.io/overcoming-pitfalls-of-postgres-logical-decoding#heading-beware-of-replication-slot-growth-how-to-monitor-it).

### Как типы данных Postgres сопоставляются с ClickHouse? {#how-are-postgres-data-types-mapped-to-clickhouse}

ClickPipes для Postgres стремится сопоставлять типы данных Postgres максимально нативно на стороне ClickHouse. Этот документ содержит полный список каждого типа данных и его сопоставления: [Матрица типов данных](https://docs.peerdb.io/datatypes/datatype-matrix).

### Могу ли я определить собственное сопоставление типов данных при репликации данных из Postgres в ClickHouse? {#can-i-define-my-own-data-type-mapping-while-replicating-data-from-postgres-to-clickhouse}

В настоящее время мы не поддерживаем определение пользовательских сопоставлений типов данных в рамках конвейера. Однако обратите внимание, что сопоставление типов данных по умолчанию, используемое ClickPipes, является высоконативным. Большинство типов столбцов в Postgres реплицируются максимально близко к их нативным эквивалентам в ClickHouse. Например, типы массивов целых чисел в Postgres реплицируются как типы массивов целых чисел в ClickHouse.

### Как реплицируются столбцы JSON и JSONB из Postgres? {#how-are-json-and-jsonb-columns-replicated-from-postgres}

Столбцы JSON и JSONB реплицируются как тип String в ClickHouse. Поскольку ClickHouse поддерживает нативный [тип JSON](/sql-reference/data-types/newjson), вы можете создать материализованное представление над таблицами ClickPipes для выполнения преобразования при необходимости. Альтернативно, вы можете использовать [функции JSON](/sql-reference/functions/json-functions) непосредственно на столбцах типа String. Мы активно работаем над функцией, которая реплицирует столбцы JSON и JSONB напрямую в тип JSON в ClickHouse. Ожидается, что эта функция станет доступна через несколько месяцев.

### Что происходит с операциями вставки, когда зеркало приостановлено? {#what-happens-to-inserts-when-a-mirror-is-paused}

Когда вы приостанавливаете зеркало, сообщения помещаются в очередь в слоте репликации на исходном Postgres, что гарантирует их буферизацию и предотвращает потерю. Однако приостановка и возобновление зеркала приведут к повторному установлению соединения, что может занять некоторое время в зависимости от источника.

В ходе этого процесса прерываются как операция синхронизации (извлечение данных из Postgres и их потоковая передача в необработанную таблицу ClickHouse), так и операция нормализации (из необработанной таблицы в целевую таблицу). Однако они сохраняют состояние, необходимое для надежного возобновления.

- Для синхронизации, если она отменяется на полпути, confirmed_flush_lsn в Postgres не продвигается, поэтому следующая синхронизация начнется с той же позиции, что и прерванная, обеспечивая согласованность данных.
- Для нормализации порядок вставки ReplacingMergeTree обрабатывает дедупликацию.

Таким образом, хотя процессы синхронизации и нормализации прерываются во время паузы, это безопасно, поскольку они могут возобновиться без потери данных или нарушения согласованности.

### Можно ли автоматизировать создание ClickPipe или выполнить его через API или CLI? {#can-clickpipe-creation-be-automated-or-done-via-api-or-cli}

Postgres ClickPipe также можно создавать и управлять через конечные точки [OpenAPI](https://clickhouse.com/docs/cloud/manage/openapi). Эта функция находится в бета-версии, а справочник API можно найти [здесь](https://clickhouse.com/docs/cloud/manage/api/swagger#tag/beta). Мы также активно работаем над поддержкой Terraform для создания Postgres ClickPipes.

### Как ускорить начальную загрузку? {#how-do-i-speed-up-my-initial-load}


Вы не можете ускорить уже выполняющуюся начальную загрузку. Однако вы можете оптимизировать будущие начальные загрузки, настроив определенные параметры. По умолчанию настройки сконфигурированы с 4 параллельными потоками и количеством строк снимка на раздел, равным 100 000. Это расширенные настройки, которые обычно достаточны для большинства сценариев использования.

Для версий Postgres 13 и ниже сканирование диапазонов CTID выполняется медленнее, и эти настройки становятся более критичными. В таких случаях рассмотрите следующий процесс для улучшения производительности:

1. **Удалите существующий канал (pipe)**: Это необходимо для применения новых настроек.
2. **Удалите целевые таблицы в ClickHouse**: Убедитесь, что таблицы, созданные предыдущим каналом, удалены.
3. **Создайте новый канал с оптимизированными настройками**: Обычно увеличьте количество строк снимка на раздел до значения от 1 миллиона до 10 миллионов, в зависимости от ваших конкретных требований и нагрузки, которую может выдержать ваш экземпляр Postgres.

Эти корректировки должны значительно улучшить производительность начальной загрузки, особенно для более старых версий Postgres. Если вы используете Postgres 14 или более поздней версии, эти настройки менее значимы благодаря улучшенной поддержке сканирования диапазонов CTID.

### Как следует определять область публикаций при настройке репликации? {#how-should-i-scope-my-publications-when-setting-up-replication}

Вы можете позволить ClickPipes управлять вашими публикациями (требуются дополнительные разрешения) или создать их самостоятельно. При публикациях, управляемых ClickPipes, мы автоматически обрабатываем добавление и удаление таблиц при редактировании канала. При самостоятельном управлении тщательно определяйте область ваших публикаций, включая только те таблицы, которые необходимо реплицировать — включение ненужных таблиц замедлит декодирование WAL в Postgres.

Если вы включаете какую-либо таблицу в вашу публикацию, убедитесь, что она имеет либо первичный ключ, либо `REPLICA IDENTITY FULL`. Если у вас есть таблицы без первичного ключа, создание публикации для всех таблиц приведет к сбою операций DELETE и UPDATE для этих таблиц.

Чтобы определить таблицы без первичных ключей в вашей базе данных, вы можете использовать этот запрос:

```sql
SELECT table_schema, table_name
FROM information_schema.tables
WHERE
    (table_catalog, table_schema, table_name) NOT IN (
        SELECT table_catalog, table_schema, table_name
        FROM information_schema.table_constraints
        WHERE constraint_type = 'PRIMARY KEY') AND
    table_schema NOT IN ('information_schema', 'pg_catalog', 'pgq', 'londiste');
```

У вас есть два варианта при работе с таблицами без первичных ключей:

1. **Исключите таблицы без первичных ключей из ClickPipes**:
   Создайте публикацию только с таблицами, имеющими первичный ключ:

   ```sql
   CREATE PUBLICATION clickpipes_publication FOR TABLE table_with_primary_key1, table_with_primary_key2, ...;
   ```

2. **Включите таблицы без первичных ключей в ClickPipes**:
   Если вы хотите включить таблицы без первичного ключа, необходимо изменить их идентификатор реплики на `FULL`. Это обеспечивает корректную работу операций UPDATE и DELETE:
   ```sql
   ALTER TABLE table_without_primary_key1 REPLICA IDENTITY FULL;
   ALTER TABLE table_without_primary_key2 REPLICA IDENTITY FULL;
   CREATE PUBLICATION clickpipes_publication FOR TABLE <...>, <...>;
   ```

:::tip
Если вы создаете публикацию вручную вместо того, чтобы позволить ClickPipes управлять ею, мы не рекомендуем создавать публикацию `FOR ALL TABLES`, это приводит к увеличению трафика от Postgres к ClickPipes (к отправке изменений для других таблиц, не входящих в канал) и снижает общую эффективность.

Для публикаций, созданных вручную, добавьте все необходимые таблицы в публикацию перед добавлением их в канал.
:::

:::warning
Если вы реплицируете из реплики для чтения Postgres/горячего резерва, вам необходимо создать собственную публикацию на основном экземпляре, которая автоматически распространится на резервный. ClickPipe не сможет управлять публикацией в этом случае, так как вы не можете создавать публикации на резервном экземпляре.
:::

### Рекомендуемые настройки `max_slot_wal_keep_size` {#recommended-max_slot_wal_keep_size-settings}

- **Минимум:** Установите [`max_slot_wal_keep_size`](https://www.postgresql.org/docs/devel/runtime-config-replication.html#GUC-MAX-SLOT-WAL-KEEP-SIZE) для сохранения как минимум **двухдневного объема** данных WAL.
- **Для больших баз данных (высокий объем транзакций):** Сохраняйте как минимум **в 2-3 раза больше** пикового объема генерации WAL в день.
- **Для сред с ограниченным хранилищем:** Настраивайте это консервативно, чтобы **избежать исчерпания дискового пространства**, обеспечивая при этом стабильность репликации.

#### Как рассчитать правильное значение {#how-to-calculate-the-right-value}

Чтобы определить правильную настройку, измерьте скорость генерации WAL:

##### Для PostgreSQL 10+ {#for-postgresql-10}


```sql
SELECT pg_wal_lsn_diff(pg_current_wal_insert_lsn(), '0/0') / 1024 / 1024 AS wal_generated_mb;
```

##### Для PostgreSQL 9.6 и ниже: {#for-postgresql-96-and-below}

```sql
SELECT pg_xlog_location_diff(pg_current_xlog_insert_location(), '0/0') / 1024 / 1024 AS wal_generated_mb;
```

- Выполните указанный выше запрос в разное время суток, особенно в периоды высокой транзакционной активности.
- Рассчитайте, сколько WAL генерируется за 24-часовой период.
- Умножьте это число на 2 или 3, чтобы обеспечить достаточное время хранения.
- Установите для `max_slot_wal_keep_size` полученное значение в МБ или ГБ.

##### Пример {#example}

Если ваша база данных генерирует 100 ГБ WAL в день, установите:

```sql
max_slot_wal_keep_size = 200GB
```

### Я вижу ошибку ReceiveMessage EOF в логах. Что это означает? {#im-seeing-a-receivemessage-eof-error-in-the-logs-what-does-it-mean}

`ReceiveMessage` — это функция в протоколе логического декодирования Postgres, которая читает сообщения из потока репликации. Ошибка EOF (End of File) указывает на то, что соединение с сервером Postgres было неожиданно закрыто при попытке чтения из потока репликации.

Это восстанавливаемая, полностью некритичная ошибка. ClickPipes автоматически попытается переподключиться и возобновить процесс репликации.

Это может произойти по нескольким причинам:

- **Низкое значение wal_sender_timeout:** Убедитесь, что `wal_sender_timeout` составляет 5 минут или больше. Этот параметр контролирует, как долго сервер ожидает ответа от клиента перед закрытием соединения. Если таймаут слишком мал, это может привести к преждевременным разрывам соединения.
- **Проблемы с сетью:** Временные сбои в сети могут привести к разрыву соединения.
- **Перезапуск сервера Postgres:** Если сервер Postgres перезапускается или аварийно завершает работу, соединение будет потеряно.

### Мой слот репликации аннулирован. Что делать? {#my-replication-slot-is-invalidated-what-should-i-do}

Единственный способ восстановить ClickPipe — запустить повторную синхронизацию, что можно сделать на странице настроек.

Наиболее распространенной причиной аннулирования слота репликации является низкое значение параметра `max_slot_wal_keep_size` в вашей базе данных PostgreSQL (например, несколько гигабайт). Мы рекомендуем увеличить это значение. [Обратитесь к этому разделу](/integrations/clickpipes/postgres/faq#recommended-max_slot_wal_keep_size-settings) по настройке `max_slot_wal_keep_size`. В идеале это значение должно быть установлено не менее 200 ГБ, чтобы предотвратить аннулирование слота репликации.

В редких случаях мы наблюдали возникновение этой проблемы даже при неустановленном `max_slot_wal_keep_size`. Это может быть связано со сложной и редкой ошибкой в PostgreSQL, хотя причина остается неясной.

### Я вижу ошибки нехватки памяти (OOM) в ClickHouse во время приема данных через ClickPipe. Можете помочь? {#i-am-seeing-out-of-memory-ooms-on-clickhouse-while-my-clickpipe-is-ingesting-data-can-you-help}

Одной из распространенных причин ошибок OOM в ClickHouse является недостаточный размер вашего сервиса. Это означает, что текущая конфигурация сервиса не имеет достаточных ресурсов (например, памяти или процессора) для эффективной обработки нагрузки приема данных. Мы настоятельно рекомендуем масштабировать сервис для удовлетворения требований приема данных через ClickPipe.

Другая причина, которую мы наблюдали, — это наличие материализованных представлений с потенциально неоптимизированными соединениями:

- Распространенная техника оптимизации для JOIN заключается в следующем: если у вас есть `LEFT JOIN`, где правая таблица очень большая, перепишите запрос с использованием `RIGHT JOIN` и переместите большую таблицу на левую сторону. Это позволяет планировщику запросов более эффективно использовать память.

- Другая оптимизация для JOIN — явная фильтрация таблиц через `подзапросы` или `CTE`, а затем выполнение `JOIN` по этим подзапросам. Это предоставляет планировщику подсказки о том, как эффективно фильтровать строки и выполнять `JOIN`.

### Я вижу ошибку `invalid snapshot identifier` во время начальной загрузки. Что делать? {#i-am-seeing-an-invalid-snapshot-identifier-during-the-initial-load-what-should-i-do}

Ошибка `invalid snapshot identifier` возникает при разрыве соединения между ClickPipes и вашей базой данных Postgres. Это может произойти из-за таймаутов шлюза, перезапусков базы данных или других временных проблем.

Рекомендуется не выполнять никаких разрушительных операций, таких как обновления или перезапуски, в вашей базе данных Postgres во время выполнения начальной загрузки, и убедиться, что сетевое соединение с вашей базой данных стабильно.


Чтобы решить эту проблему, запустите повторную синхронизацию из интерфейса ClickPipes. Это перезапустит процесс начальной загрузки с самого начала.

### Что произойдет при удалении публикации в Postgres? {#what-happens-if-i-drop-a-publication-in-postgres}

Удаление публикации в Postgres приведет к разрыву соединения ClickPipe, поскольку публикация необходима для получения изменений из источника. В этом случае вы получите уведомление об ошибке, указывающее на отсутствие публикации.

Чтобы восстановить работу ClickPipe после удаления публикации:

1. Создайте новую публикацию с тем же именем и необходимыми таблицами в Postgres
2. Нажмите кнопку «Resync tables» на вкладке Settings вашего ClickPipe

Повторная синхронизация необходима, поскольку пересозданная публикация будет иметь другой идентификатор объекта (OID) в Postgres, даже при совпадении имени. Процесс повторной синхронизации обновляет целевые таблицы и восстанавливает соединение.

Также вы можете создать полностью новый канал, если это предпочтительнее.

Обратите внимание: при работе с партиционированными таблицами создавайте публикацию с соответствующими настройками:

```sql
CREATE PUBLICATION clickpipes_publication
FOR TABLE <...>, <...>
WITH (publish_via_partition_root = true);
```

### Что делать при ошибках `Unexpected Datatype` или `Cannot parse type XX ...`? {#what-if-i-am-seeing-unexpected-datatype-errors}

Эта ошибка обычно возникает, когда исходная база данных Postgres содержит тип данных, который невозможно сопоставить при приеме данных.
Для более конкретных случаев см. варианты ниже.

### Возникают ошибки вида `invalid memory alloc request size <XXX>` при репликации/создании слота {#postgres-invalid-memalloc-bug}

В патч-версиях Postgres 17.5/16.9/15.13/14.18/13.21 была обнаружена ошибка, из-за которой определенные рабочие нагрузки могут вызывать экспоненциальный рост использования памяти, что приводит к запросу выделения памяти >1 ГБ, который Postgres считает недопустимым. Эта ошибка [была исправлена](https://github.com/postgres/postgres/commit/d87d07b7ad3b782cb74566cd771ecdb2823adf6a) и будет включена в следующую серию патчей Postgres (17.6...). Уточните у вашего провайдера Postgres, когда эта патч-версия будет доступна для обновления. Если обновление невозможно выполнить немедленно, при возникновении ошибки потребуется повторная синхронизация канала.

### Необходимо сохранять полную историческую запись в ClickHouse, даже при удалении данных из исходной базы данных Postgres. Можно ли полностью игнорировать операции DELETE и TRUNCATE из Postgres в ClickPipes? {#ignore-delete-truncate}

Да! Перед созданием Postgres ClickPipe создайте публикацию без операций DELETE. Например:

```sql
CREATE PUBLICATION <pub_name> FOR TABLES IN SCHEMA <schema_name> WITH (publish = 'insert,update');
```

Затем при [настройке](https://clickhouse.com/docs/integrations/clickpipes/postgres#configuring-the-replication-settings) Postgres ClickPipe убедитесь, что выбрано это имя публикации.

Обратите внимание, что операции TRUNCATE игнорируются ClickPipes и не реплицируются в ClickHouse.

### Почему невозможно реплицировать таблицу, в имени которой есть точка? {#replicate-table-dot}

В настоящее время PeerDB имеет ограничение: точки в идентификаторах исходных таблиц (в имени схемы или имени таблицы) не поддерживаются для репликации, поскольку PeerDB не может определить, что является схемой, а что таблицей, так как разделение происходит по точке.
Ведется работа по поддержке раздельного ввода схемы и таблицы для обхода этого ограничения.

### Начальная загрузка завершена, но в ClickHouse отсутствуют данные. В чем может быть проблема? {#initial-load-issue}

Если начальная загрузка завершилась без ошибок, но в целевой таблице ClickHouse отсутствуют данные, возможно, на исходных таблицах Postgres включены политики RLS (Row Level Security).
Также стоит проверить:

- Имеет ли пользователь достаточные права для чтения исходных таблиц.
- Есть ли на стороне ClickHouse политики строк, которые могут фильтровать строки.

### Можно ли создать слот репликации с включенным переключением при отказе через ClickPipe? {#failover-slot}

Да, для Postgres ClickPipe с режимом репликации CDC или Snapshot + CDC можно создать слот репликации с включенным переключением при отказе, активировав соответствующий переключатель в разделе `Advanced Settings` при создании ClickPipe. Обратите внимание, что для использования этой функции требуется Postgres версии 17 или выше.

<Image img={failover_slot} border size='md' />


При соответствующей настройке источника слот сохраняется после переключения на реплику для чтения Postgres, обеспечивая непрерывную репликацию данных. Подробнее [здесь](https://www.postgresql.org/docs/current/logical-replication-failover.html).

### Возникают ошибки вида `Internal error encountered during logical decoding of aborted sub-transaction` {#transient-logical-decoding-errors}

Эта ошибка указывает на временную проблему с логическим декодированием прерванной подтранзакции и характерна для пользовательских реализаций Aurora Postgres. Поскольку ошибка возникает в процедуре `ReorderBufferPreserveLastSpilledSnapshot`, это означает, что логическое декодирование не может прочитать снимок, выгруженный на диск. Рекомендуется попробовать увеличить значение параметра [`logical_decoding_work_mem`](https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-LOGICAL-DECODING-WORK-MEM).

### Возникают ошибки вида `error converting new tuple to map` или `error parsing logical message` во время CDC-репликации {#logical-message-processing-errors}

Postgres отправляет информацию об изменениях в виде сообщений с фиксированным протоколом. Эти ошибки возникают, когда ClickPipe получает сообщение, которое не может разобрать — либо из-за повреждения при передаче, либо из-за отправки некорректных сообщений. Хотя конкретная причина может различаться, мы наблюдали несколько таких случаев при использовании источников Neon Postgres. Если вы также сталкиваетесь с этой проблемой при работе с Neon, создайте запрос в их службу поддержки. В остальных случаях обратитесь в нашу службу поддержки за консультацией.
