---
sidebar_label: Часто задаваемые вопросы о ClickPipes для Postgres
description: Часто задаваемые вопросы о ClickPipes для Postgres.
slug: /integrations/clickpipes/postgres/faq
sidebar_position: 2
---


# Часто задаваемые вопросы о ClickPipes для Postgres

### Как простаивание влияет на мой Postgres CDC ClickPipe? {#how-does-idling-affect-my-postgres-cdc-clickpipe}

Если ваш сервис ClickHouse Cloud находится в режиме простоя, ваш Postgres CDC ClickPipe будет продолжать синхронизировать данные, ваш сервис проснется на следующем интервале синхронизации, чтобы обработать входящие данные. Как только синхронизация завершится и будет достигнут период простоя, ваш сервис вернется в режим простоя.

Например, если интервал синхронизации установлен на 30 минут, а время простоя вашего сервиса установлено на 10 минут, ваш сервис будет просыпаться каждые 30 минут и быть активным в течение 10 минут, а затем снова вернется в режим простоя.

### Как обрабатываются TOAST колонки в ClickPipes для Postgres? {#how-are-toast-columns-handled-in-clickpipes-for-postgres}

Пожалуйста, обратитесь к странице [Обработка TOAST колонок](./toast) для получения дополнительной информации.

### Как обрабатываются сгенерированные колонки в ClickPipes для Postgres? {#how-are-generated-columns-handled-in-clickpipes-for-postgres}

Пожалуйста, обратитесь к странице [Сгенерированные колонки Postgres: Подводные камни и лучшие практики](./generated_columns) для получения дополнительной информации.

### Нужны ли таблицам первичные ключи, чтобы быть частью Postgres CDC? {#do-tables-need-to-have-primary-keys-to-be-part-of-postgres-cdc}

Да, для CDC таблицы должны иметь либо первичный ключ, либо [REPLICA IDENTITY](https://www.postgresql.org/docs/current/sql-altertable.html#SQL-ALTERTABLE-REPLICA-IDENTITY). REPLICA IDENTITY можно установить как FULL или настроить на использование уникального индекса.

### Поддерживаете ли вы партиционированные таблицы как часть Postgres CDC? {#do-you-support-partitioned-tables-as-part-of-postgres-cdc}

Да, партиционированные таблицы поддерживаются из коробки, если у них определены PRIMARY KEY или REPLICA IDENTITY. PRIMARY KEY и REPLICA IDENTITY должны присутствовать как в родительской таблице, так и в ее партициях. Вы можете прочитать об этом [здесь](https://blog.peerdb.io/real-time-change-data-capture-for-postgres-partitioned-tables).

### Могу ли я подключить базы данных Postgres, не имеющие публичного IP или находящиеся в частных сетях? {#can-i-connect-postgres-databases-that-dont-have-a-public-ip-or-are-in-private-networks}

Да! ClickPipes для Postgres предлагает два способа подключения к базам данных в частных сетях:

1. **SSH Tunneling**
   - Хорошо работает для большинства сценариев.
   - Смотрите инструкции по настройке [здесь](/integrations/clickpipes/postgres#adding-your-source-postgres-database-connection).
   - Работает во всех регионах.

2. **AWS PrivateLink**
   - Доступен в трех регионах AWS:
     - us-east-1
     - us-east-2 
     - eu-central-1
   - Для подробных инструкций по настройке смотрите нашу [документацию по PrivateLink](/knowledgebase/aws-privatelink-setup-for-clickpipes#requirements).
   - Для регионов, где PrivateLink недоступен, используйте SSH-туннелирование.

### Как вы обрабатываете UPDATE и DELETE? {#how-do-you-handle-updates-and-deletes}

ClickPipes для Postgres захватывает как INSERT, так и UPDATE из Postgres как новые строки с разными версиями (с использованием колонки `_peerdb_` версии) в ClickHouse. Табличный движок ReplacingMergeTree периодически выполняет дедупликацию в фоновом режиме на основе ключа упорядочивания (ORDER BY колонки), сохраняя только строку с самой последней версией `_peerdb_`.

DELETE из Postgres передаются как новые строки, помеченные как удаленные (с использованием колонки `_peerdb_is_deleted`). Поскольку процесс дедупликации асинхронный, вы можете временно видеть дубликаты. Для решения этой проблемы вам нужно обрабатывать дедупликацию на уровне запроса.

Для получения дополнительной информации смотрите:

* [Лучшие практики для табличного движка ReplacingMergeTree](https://docs.peerdb.io/bestpractices/clickhouse_datamodeling#replacingmergetree-table-engine)
* [Блог о внутренних механизмах постгреса в ClickHouse CDC](https://clickhouse.com/blog/postgres-to-clickhouse-data-modeling-tips)

### Поддерживаете ли вы изменения схемы? {#do-you-support-schema-changes}

Пожалуйста, обратитесь к странице [ClickPipes для Postgres: Поддержка распространения изменений схемы](./schema-changes) для получения дополнительной информации.

### Каковы затраты на ClickPipes для Postgres CDC? {#what-are-the-costs-for-clickpipes-for-postgres-cdc}

На этапе предварительного просмотра ClickPipes бесплатен. Цены после GA еще нужно определить. Цель состоит в том, чтобы сделать цены разумными и высококонкурентными по сравнению с внешними инструментами ETL.

### Мой размер слота репликации растет или не уменьшается; в чем может быть проблема? {#my-replication-slot-size-is-growing-or-not-decreasing-what-might-be-the-issue}

Если вы заметили, что размер вашего слота репликации Postgres продолжает увеличиваться или не уменьшается, это обычно означает, что **записи WAL (Write-Ahead Log) не потребляются (или "воспроизводятся") достаточно быстро** вашим CDC-каналом или процессом репликации. Ниже приведены наиболее распространенные причины и способы их устранения.

1. **Внезапные всплески активности базы данных**  
   - Большие пакетные обновления, массовые вставки или значительные изменения схемы могут быстро сгенерировать много данных WAL.  
   - Слот репликации будет удерживать эти записи WAL, пока они не будут потреблены, что вызывает временный всплеск в размере.

2. **Долгосрочные транзакции**  
   - Открытая транзакция заставляет Postgres удерживать все сегменты WAL, генерируемые с момента начала транзакции, что может значительно увеличить размер слота.  
   - Установите `statement_timeout` и `idle_in_transaction_session_timeout` на разумные значения, чтобы предотвратить бесконечное открытие транзакций:
     ```sql
     SELECT 
         pid,
         state,
         age(now(), xact_start) AS transaction_duration,
         query AS current_query
     FROM 
         pg_stat_activity
     WHERE 
         xact_start IS NOT NULL
     ORDER BY 
         age(now(), xact_start) DESC;
     ```
     Используйте этот запрос, чтобы выявить необычно долго работающие транзакции.

3. **Операции обслуживания или утилит (например, `pg_repack`)**  
   - Инструменты, такие как `pg_repack`, могут переписывать целые таблицы, генерируя большие объемы данных WAL за короткое время.  
   - Запланируйте эти операции в периоды меньшей нагрузки или внимательно следите за использованием WAL во время их выполнения.

4. **VACUUM и VACUUM ANALYZE**  
   - Хотя они необходимы для здоровья базы данных, эти операции могут создать дополнительный трафик WAL — особенно если они сканируют большие таблицы.  
   - Рассмотрите возможность настройки параметров автозапуска или планирования ручных операций VACUUM в часы низкой нагрузки.

5. **Потребитель репликации не активно читает слот**  
   - Если ваш CDC-канал (например, ClickPipes) или другой потребитель репликации остановится, приостановится или выйдет из строя, данные WAL будут накапливаться в слоте.  
   - Убедитесь, что ваш канал постоянно работает, и проверьте журналы на наличие ошибок подключения или аутентификации.

Для глубокого изучения этой темы, пожалуйста, ознакомьтесь с нашей публикацией в блоге: [Преодоление ловушек логического декодирования Postgres](https://blog.peerdb.io/overcoming-pitfalls-of-postgres-logical-decoding#heading-beware-of-replication-slot-growth-how-to-monitor-it).

### Как типы данных Postgres соответствуют ClickHouse? {#how-are-postgres-data-types-mapped-to-clickhouse}

ClickPipes для Postgres стремится сопоставить типы данных Postgres как можно более нативно со стороны ClickHouse. Этот документ предоставляет исчерпывающий список каждого типа данных и его сопоставления: [Матрица типов данных](https://docs.peerdb.io/datatypes/datatype-matrix).

### Могу ли я определить собственное сопоставление типов данных при репликации данных из Postgres в ClickHouse? {#can-i-define-my-own-data-type-mapping-while-replicating-data-from-postgres-to-clickhouse}

На данный момент мы не поддерживаем определение пользовательских сопоставлений типов данных как часть канала. Однако обратите внимание, что стандартное сопоставление типов данных, используемое ClickPipes, является высоко нативным. Большинство типов колонок в Postgres реплицируются настолько близко, насколько это возможно, к их нативным аналогам в ClickHouse. Например, массивы целых чисел в Postgres реплицируются как массивы целых чисел в ClickHouse.

### Как реплицируются колонки JSON и JSONB из Postgres? {#how-are-json-and-jsonb-columns-replicated-from-postgres}

Колонки JSON и JSONB реплицируются как тип String в ClickHouse. Поскольку ClickHouse поддерживает нативный [JSON тип](/sql-reference/data-types/newjson), вы можете создать материализованное представление для таблиц ClickPipes, чтобы выполнить преобразование, если это необходимо. В качестве альтернативы вы можете использовать [JSON функции](/sql-reference/functions/json-functions) непосредственно на колонках String. Мы активно работаем над функцией, которая позволяет реплицировать колонки JSON и JSONB непосредственно в тип JSON в ClickHouse. Ожидается, что эта функция будет доступна через несколько месяцев.

### Что происходит с вставками, когда зеркало приостановлено? {#what-happens-to-inserts-when-a-mirror-is-paused}

Когда вы приостанавливаете зеркало, сообщения ставятся в очередь в слоте репликации на исходном Postgres, что обеспечивает их буферизацию и защиту от потери. Однако приостановка и возобновление зеркала вновь устанавливает соединение, что может занять некоторое время в зависимости от источника.

В процессе как синхронизация (извлечение данных из Postgres и потоковая передача их в сырую таблицу ClickHouse), так и нормализация (с сырой таблицы в целевую таблицу) прерываются. Тем не менее, они сохраняют состояние, необходимое для устойчивого возобновления.

- Для синхронизации, если она завершится неожиданно, `confirmed_flush_lsn` в Postgres не продвигается, так что следующая синхронизация начнется с той же позиции, что и прерванная, обеспечивая консистентность данных.
- Для нормализации порядок вставки ReplacingMergeTree обрабатывает дедупликацию.

Вкратце, хотя процессы синхронизации и нормализации прерываются на время паузы, это безопасно, поскольку они могут возобновиться без потери или несоответствия данных.

### Можно ли автоматизировать создание ClickPipe или выполнить его через API или CLI? {#can-clickpipe-creation-be-automated-or-done-via-api-or-cli}

На данный момент вы можете создать ClickPipe только через интерфейс. Однако мы активно работаем над открытием конечных точек OpenAPI и Terraform. Ожидаем, что это будет выпущено в ближайшем будущем (в течение месяца). Если вас интересует возможность стать партнером по дизайну для этой функции, пожалуйста, свяжитесь с db-integrations-support@clickhouse.com.

### Как мне ускорить первоначальную загрузку? {#how-do-i-speed-up-my-initial-load}

Вы не можете ускорить уже выполняемую первоначальную загрузку. Однако вы можете оптимизировать будущие первоначальные загрузки, изменив некоторые настройки. По умолчанию настройки сконфигурированы с 4 параллельными потоками и числом строк по снимку на партицию, установленным на 100,000. Эти настройки являются продвинутыми и обычно подходят для большинства случаев использования.

Для версий Postgres 13 или ниже сканирование диапазонов CTID медленнее, и эти настройки становятся более критичными. В таких случаях рассмотрите следующий процесс для повышения производительности:

1. **Удалите существующий канал**: Это необходимо для применения новых настроек.
2. **Удалите целевые таблицы в ClickHouse**: Убедитесь, что таблицы, созданные предыдущим каналом, удалены.
3. **Создайте новый канал с оптимизированными настройками**: Обычно увеличьте число строк в снимке на партицию до 1-10 миллионов, в зависимости от ваших конкретных требований и нагрузки, с которой может справиться ваш экземпляр Postgres.

Эти настройки должны значительно повысить производительность первоначальной загрузки, особенно для более старых версий Postgres. Если вы используете Postgres 14 или более поздние версии, влияние этих настроек менее критично из-за улучшенной поддержки сканирования диапазонов CTID.

### Как мне определить области действия своих публикаций при настройке репликации? {#how-should-i-scope-my-publications-when-setting-up-replication}

Вы можете позволить ClickPipes управлять вашими публикациями (требуется доступ на запись) или создать их самостоятельно. С управляемыми ClickPipes публикациями мы автоматически обрабатываем добавления и удаления таблиц, когда вы редактируете канал. Если вы управляете самостоятельно, внимательно определяйте область действия своих публикаций, чтобы включать только таблицы, которые необходимо реплицировать — включение ненужных таблиц замедлит декодирование WAL в Postgres.

Если вы включаете любую таблицу в свою публикацию, убедитесь, что у нее есть либо первичный ключ, либо `REPLICA IDENTITY FULL`. Если у вас есть таблицы без первичного ключа, создание публикации для всех таблиц приведет к сбою операций DELETE и UPDATE для этих таблиц.

Чтобы выявить таблицы без первичных ключей в вашей базе данных, вы можете использовать этот запрос:
```sql
SELECT table_schema, table_name
FROM information_schema.tables
WHERE
    (table_catalog, table_schema, table_name) NOT IN (
        SELECT table_catalog, table_schema, table_name
        FROM information_schema.table_constraints
        WHERE constraint_type = 'PRIMARY KEY') AND
    table_schema NOT IN ('information_schema', 'pg_catalog', 'pgq', 'londiste');
```

У вас есть два варианта при работе с таблицами без первичных ключей:

1. **Исключите таблицы без первичных ключей из ClickPipes**:
   Создайте публикацию только с таблицами, которые имеют первичный ключ:
   ```sql
   CREATE PUBLICATION my_publication FOR TABLE table_with_primary_key1, table_with_primary_key2, ...;
   ```

2. **Включите таблицы без первичных ключей в ClickPipes**:
   Если вы хотите включить таблицы без первичного ключа, вам нужно изменить их идентичность реплики на `FULL`. Это обеспечит корректную работу операций UPDATE и DELETE:
   ```sql
   ALTER TABLE table_without_primary_key1 REPLICA IDENTITY FULL;
   ALTER TABLE table_without_primary_key2 REPLICA IDENTITY FULL;
   CREATE PUBLICATION clickpipes_publication FOR ALL TABLES;
   ```

## Рекомендуемые настройки `max_slot_wal_keep_size` {#recommended-max_slot_wal_keep_size-settings}

- **Минимально:** Установите [`max_slot_wal_keep_size`](https://www.postgresql.org/docs/devel/runtime-config-replication.html#GUC-MAX-SLOT-WAL-KEEP-SIZE) для удержания как минимум **двух дней** WAL данных.
- **Для больших баз данных (высокий объем транзакций):** Удерживайте как минимум **2-3 раза** пиковое генерирование WAL за день.
- **Для сред с ограниченным хранилищем:** Настройте это консервативно, чтобы **избежать исчерпания дискового пространства**, одновременно обеспечивая стабильность репликации.

### Как рассчитать правильное значение {#how-to-calculate-the-right-value}

Чтобы определить правильную настройку, измерьте скорость генерации WAL:

#### Для PostgreSQL 10+: {#for-postgresql-10}

```sql
SELECT pg_wal_lsn_diff(pg_current_wal_insert_lsn(), '0/0') / 1024 / 1024 AS wal_generated_mb;
```

#### Для PostgreSQL 9.6 и ниже: {#for-postgresql-96-and-below}

```sql
SELECT pg_xlog_location_diff(pg_current_xlog_insert_location(), '0/0') / 1024 / 1024 AS wal_generated_mb;
```

* Запустите вышеуказанный запрос в разное время суток, особенно в периоды высокой транзакционной активности.
* Рассчитайте, сколько WAL генерируется за 24-часовой период.
* Умножьте это число на 2 или 3, чтобы обеспечить достаточное удержание.
* Установите `max_slot_wal_keep_size` на полученное значение в МБ или ГБ.

#### Пример: {#example}

Если ваша база данных генерирует 100 ГБ WAL в день, установите:

```sql
max_slot_wal_keep_size = 200GB
```

### Мой слот репликации недействителен. Что мне делать? {#my-replication-slot-is-invalidated-what-should-i-do}

Единственный способ восстановить ClickPipe — это инициировать повторную синхронизацию, которую вы можете сделать на странице настроек.

Наиболее распространенной причиной недействительности слота репликации является низкое значение настройки `max_slot_wal_keep_size` в вашей базе данных PostgreSQL (например, несколько гигабайт). Мы рекомендуем увеличить это значение. [Смотрите этот раздел](/integrations/clickpipes/postgres/faq#recommended-max_slot_wal_keep_size-settings) о настройке `max_slot_wal_keep_size`. В идеале это значение должно составлять как минимум 200 ГБ, чтобы предотвратить недействительность слота репликации.

В редких случаях мы наблюдали эту проблему даже при том, что `max_slot_wal_keep_size` не настроен. Это могло быть вызвано сложным и редким сбоем в PostgreSQL, хотя причина остается неясной.

### Я наблюдаю Out Of Memory (OOMs) в ClickHouse, когда мой ClickPipe загружает данные. Можете помочь? {#i-am-seeing-out-of-memory-ooms-on-clickhouse-while-my-clickpipe-is-ingesting-data-can-you-help}

Одной из распространенных причин OOM в ClickHouse является недостаточный размер вашего сервиса. Это означает, что текущая конфигурация вашего сервиса не имеет достаточных ресурсов (например, памяти или ЦП), чтобы эффективно справляться с нагрузкой по загрузке данных. Мы настоятельно рекомендуем увеличить мощность сервиса, чтобы соответствовать требованиям вашей загрузки данных ClickPipe.

Еще одной причиной, которую мы наблюдали, являются существующие потоковые материализованные представления с потенциально неоптимизированными соединениями:

- Распространенная техника оптимизации для JOIN'ов заключается в том, что если у вас есть `LEFT JOIN`, где правая таблица очень большая. В этом случае перепишите запрос, используя `RIGHT JOIN`, и перенесите большую таблицу на левую сторону. Это позволяет планировщику запросов более эффективно использовать память.

- Еще одной оптимизацией для JOIN'ов является явная фильтрация таблиц через `subqueries` или `CTEs`, а затем выполнение `JOIN` по этим подзапросам. Это дает планировщику подсказки о том, как эффективно фильтровать строки и выполнять `JOIN`.

### Я вижу ошибку `invalid snapshot identifier` во время первоначальной загрузки. Что мне делать? {#i-am-seeing-an-invalid-snapshot-identifier-during-the-initial-load-what-should-i-do}

Ошибка `invalid snapshot identifier` возникает, когда происходит обрыв соединения между ClickPipes и вашей базой данных Postgres. Это может произойти из-за тайм-аутов шлюза, перезапуска базы данных или других временных проблем.

Рекомендуется не выполнять никаких разрушительных операций, таких как обновления или перезапуски, на вашей базе данных Postgres во время выполнения первоначальной загрузки и убедиться, что сетевое соединение с вашей базой данных стабильно.

Чтобы решить эту проблему, вы можете инициировать повторную синхронизацию через интерфейс ClickPipes. Это перезапустит процесс первоначальной загрузки с самого начала.
