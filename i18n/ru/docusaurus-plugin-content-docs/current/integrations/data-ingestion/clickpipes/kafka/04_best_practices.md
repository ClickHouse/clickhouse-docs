---
sidebar_label: 'Лучшие практики'
description: 'Подробные рекомендации по лучшим практикам при работе с Kafka ClickPipes'
slug: /integrations/clickpipes/kafka/best-practices
sidebar_position: 1
title: 'Лучшие практики'
doc_type: 'guide'
keywords: ['лучшие практики kafka', 'clickpipes', 'сжатие', 'аутентификация', 'масштабирование']
---



# Рекомендации по лучшим практикам {#best-practices}



## Сжатие сообщений {#compression}

Мы настоятельно рекомендуем использовать сжатие для ваших тем Kafka. Сжатие позволяет существенно сократить затраты на передачу данных практически без влияния на производительность.
Чтобы узнать больше о сжатии сообщений в Kafka, рекомендуем начать с этого [руководства](https://www.confluent.io/blog/apache-kafka-message-compression/).



## Ограничения {#limitations}

- [`DEFAULT`](/sql-reference/statements/create/table#default) не поддерживается.



## Семантика доставки {#delivery-semantics}
ClickPipes for Kafka обеспечивает семантику доставки `at-least-once` (одна из наиболее распространённых моделей). Нам будет полезно получить вашу обратную связь по семантике доставки через [форму обратной связи](https://clickhouse.com/company/contact?loc=clickpipes). Если вам нужна семантика `exactly-once`, мы рекомендуем использовать наш официальный sink-коннектор [`clickhouse-kafka-connect`](https://clickhouse.com/blog/real-time-event-streaming-with-kafka-connect-confluent-cloud-clickhouse).



## Аутентификация

Для источников данных, использующих протокол Apache Kafka, ClickPipes поддерживает аутентификацию [SASL/PLAIN](https://docs.confluent.io/platform/current/kafka/authentication_sasl/authentication_sasl_plain.html) с шифрованием TLS, а также `SASL/SCRAM-SHA-256` и `SASL/SCRAM-SHA-512`. В зависимости от источника потоковых данных (Redpanda, MSK и т. д.) будут доступны все или часть этих механизмов аутентификации в соответствии с требованиями совместимости. Если ваши требования к аутентификации отличаются, пожалуйста, [сообщите нам об этом](https://clickhouse.com/company/contact?loc=clickpipes).

### IAM

:::info
Аутентификация IAM для MSK ClickPipe — функция на стадии бета-тестирования.
:::

ClickPipes поддерживает следующие методы аутентификации AWS MSK:

* Аутентификацию [SASL/SCRAM-SHA-512](https://docs.aws.amazon.com/msk/latest/developerguide/msk-password.html)
* Аутентификацию на основе [учётных данных IAM или ролевого доступа](https://docs.aws.amazon.com/msk/latest/developerguide/how-to-use-iam-access-control.html)

При использовании аутентификации IAM для подключения к брокеру MSK роль IAM должна иметь необходимые права.
Ниже приведён пример требуемой политики IAM для API Apache Kafka для MSK:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:Connect"
            ],
            "Resource": [
                "arn:aws:kafka:us-west-2:12345678912:cluster/clickpipes-testing-brokers/b194d5ae-5013-4b5b-ad27-3ca9f56299c9-10"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:DescribeTopic",
                "kafka-cluster:ReadData"
            ],
            "Resource": [
                "arn:aws:kafka:us-west-2:12345678912:topic/clickpipes-testing-brokers/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:AlterGroup",
                "kafka-cluster:DescribeGroup"
            ],
            "Resource": [
                "arn:aws:kafka:us-east-1:12345678912:group/clickpipes-testing-brokers/*"
            ]
        }
    ]
}
```

#### Настройка отношений доверия

Если вы аутентифицируетесь в MSK с помощью ARN роли IAM, необходимо настроить отношения доверия между вашим экземпляром ClickHouse Cloud и этой ролью, чтобы роль могла быть использована.

:::note
Доступ на основе ролей работает только для экземпляров ClickHouse Cloud, развернутых в AWS.
:::

```json
{
    "Version": "2012-10-17",
    "Statement": [
        ...
        {
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::12345678912:role/CH-S3-your-clickhouse-cloud-role"
            },
            "Action": "sts:AssumeRole"
        },
    ]
}
```

### Пользовательские сертификаты

ClickPipes для Kafka поддерживает загрузку пользовательских сертификатов для брокеров Kafka, использующих непубличные серверные сертификаты.
Также поддерживается загрузка клиентских сертификатов и ключей для аутентификации на основе взаимного TLS (mTLS).


## Производительность {#performance}

### Пакетная обработка {#batching}
ClickPipes вставляет данные в ClickHouse пакетами. Это позволяет избежать создания слишком большого количества частей в базе данных, что может привести к проблемам с производительностью кластера.

Пакеты вставляются, когда выполняется одно из следующих условий:
- Размер пакета достиг максимального значения (100 000 строк или 32 МБ на каждый 1 ГБ памяти пода)
- Пакет остается открытым максимальное допустимое время (5 секунд)

### Задержка {#latency}

Задержка (определяемая как время между моментом формирования сообщения в Kafka и моментом, когда сообщение становится доступным в ClickHouse) зависит от ряда факторов (например, задержка брокера, сетевая задержка, размер/формат сообщения). Описанная в разделе выше [пакетная обработка](#batching) также влияет на задержку. Мы рекомендуем тестировать ваш конкретный сценарий с типичными нагрузками, чтобы определить ожидаемую задержку.

ClickPipes не предоставляет никаких гарантий относительно задержки. Если у вас есть жесткие требования к низкой задержке, пожалуйста, [свяжитесь с нами](https://clickhouse.com/company/contact?loc=clickpipes).

### Масштабирование {#scaling}

ClickPipes for Kafka спроектирован для горизонтального и вертикального масштабирования. По умолчанию мы создаем группу потребителей с одним потребителем. Это можно настроить при создании ClickPipe или в любое другое время в разделе **Settings** -> **Advanced Settings** -> **Scaling**.

ClickPipes обеспечивает высокую доступность за счет архитектуры с распределением по зонам доступности.
Для этого требуется масштабирование как минимум до двух потребителей.

Независимо от количества запущенных потребителей, отказоустойчивость заложена по умолчанию.
Если потребитель или его базовая инфраструктура выходит из строя,
ClickPipe автоматически перезапустит потребителя и продолжит обработку сообщений.

### Бенчмарки {#benchmarks}

Ниже приведены некоторые неформальные бенчмарки для ClickPipes for Kafka, которые можно использовать, чтобы получить общее представление о базовой производительности. Важно понимать, что на производительность могут влиять многие факторы, включая размер сообщения, типы данных и формат данных. Ваши результаты могут отличаться, и приведенные показатели не являются гарантией фактической производительности.

Подробности бенчмарка:

- Мы использовали продуктовые сервисы ClickHouse Cloud с достаточным количеством ресурсов, чтобы пропускная способность не ограничивалась обработкой вставок на стороне ClickHouse.
- Сервис ClickHouse Cloud, кластер Kafka (Confluent Cloud) и ClickPipe работали в одном регионе (`us-east-2`).
- ClickPipe был сконфигурирован с одной репликой размера L (4 ГиБ оперативной памяти и 1 vCPU).
- Пример данных включал вложенные данные с комбинацией типов `UUID`, `String` и `Int`. Другие типы данных, такие как `Float`, `Decimal` и `DateTime`, могут быть менее производительными.
- Не было заметной разницы в производительности при использовании сжатых и несжатых данных.

| Размер реплики | Размер сообщения | Формат данных | Пропускная способность |
|----------------|------------------|---------------|------------------------|
| Large (L)      | 1.6 КБ           | JSON          | 63 МБ/с                |
| Large (L)      | 1.6 КБ           | Avro          | 99 МБ/с                |
