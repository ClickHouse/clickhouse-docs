---
'sidebar_label': 'Лучшие практики'
'description': 'Детали лучших практик, которым следует следовать при работе с Kafka
  ClickPipes'
'slug': '/integrations/clickpipes/kafka/best-practices'
'sidebar_position': 1
'title': 'Лучшие практики'
'doc_type': 'guide'
---
# Лучшие практики {#best-practices}

## Сжатие сообщений {#compression}

Мы настоятельно рекомендуем использовать сжатие для ваших тем Kafka. Сжатие может привести к значительной экономии на затратах на передачу данных практически без уменьшения производительности.  
Чтобы узнать больше о сжатии сообщений в Kafka, мы рекомендуем начать с этого [руководства](https://www.confluent.io/blog/apache-kafka-message-compression/).

## Ограничения {#limitations}

- [`DEFAULT`](/sql-reference/statements/create/table#default) не поддерживается.

## Семантика доставки {#delivery-semantics}  
ClickPipes для Kafka предоставляет семантику доставки `at-least-once` (один из самых распространенных подходов). Нам будет приятно услышать ваш отзыв о семантике доставки [форма обратной связи](https://clickhouse.com/company/contact?loc=clickpipes). Если вам нужна семантика exactly-once, мы рекомендуем использовать наш официальный [`clickhouse-kafka-connect`](https://clickhouse.com/blog/real-time-event-streaming-with-kafka-connect-confluent-cloud-clickhouse) приемник.

## Аутентификация {#authentication}  
Для источников данных с протоколом Apache Kafka ClickPipes поддерживает [SASL/PLAIN](https://docs.confluent.io/platform/current/kafka/authentication_sasl/authentication_sasl_plain.html) аутентификацию с TLS шифрованием, а также `SASL/SCRAM-SHA-256` и `SASL/SCRAM-SHA-512`. В зависимости от источника потоков (Redpanda, MSK и т. д.) будут включены все или подсет этих механизмов аутентификации в зависимости от совместимости. Если ваши потребности в аутентификации отличаются, пожалуйста, [сообщите нам об этом](https://clickhouse.com/company/contact?loc=clickpipes).

### IAM {#iam}

:::info  
Аутентификация IAM для ClickPipe MSK является функцией бета-версии.  
:::

ClickPipes поддерживает следующую аутентификацию AWS MSK:

- [Аутентификация SASL/SCRAM-SHA-512](https://docs.aws.amazon.com/msk/latest/developerguide/msk-password.html)
- [Аутентификация с использованием IAM Учетных данных или Ролевого доступа](https://docs.aws.amazon.com/msk/latest/developerguide/how-to-use-iam-access-control.html)

При использовании аутентификации IAM для подключения к брокеру MSK IAM роль должна иметь необходимые разрешения.  
Ниже приведен пример необходимой IAM политики для API Apache Kafka для MSK:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:Connect"
            ],
            "Resource": [
                "arn:aws:kafka:us-west-2:12345678912:cluster/clickpipes-testing-brokers/b194d5ae-5013-4b5b-ad27-3ca9f56299c9-10"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:DescribeTopic",
                "kafka-cluster:ReadData"
            ],
            "Resource": [
                "arn:aws:kafka:us-west-2:12345678912:topic/clickpipes-testing-brokers/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:AlterGroup",
                "kafka-cluster:DescribeGroup"
            ],
            "Resource": [
                "arn:aws:kafka:us-east-1:12345678912:group/clickpipes-testing-brokers/*"
            ]
        }
    ]
}
```

#### Настройка доверительных отношений {#configuring-a-trusted-relationship}

Если вы аутентифицируетесь в MSK с помощью ARN роли IAM, вам потребуется добавить доверительные отношения между вашим экземпляром ClickHouse Cloud, чтобы роль могла быть назначена.

:::note  
Доступ на основе ролей работает только для экземпляров ClickHouse Cloud, развернутых в AWS.  
:::

```json
{
    "Version": "2012-10-17",
    "Statement": [
        ...
        {
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::12345678912:role/CH-S3-your-clickhouse-cloud-role"
            },
            "Action": "sts:AssumeRole"
        },
    ]
}
```

### Пользовательские сертификаты {#custom-certificates}  
ClickPipes для Kafka поддерживает загрузку пользовательских сертификатов для брокеров Kafka, которые используют непубличные серверные сертификаты.  
Также поддерживается загрузка клиентских сертификатов и ключей для аутентификации на основе взаимного TLS (mTLS).

## Производительность {#performance}

### Пакетная обработка {#batching}  
ClickPipes вставляет данные в ClickHouse пакетами. Это необходимо, чтобы избежать создания слишком большого количества частей в базе данных, что может привести к проблемам с производительностью в кластере.

Пакеты вставляются, когда выполнено одно из следующих условий:
- Размер пакета достиг максимального значения (100 000 строк или 32 МБ на 1 ГБ памяти пода)
- Пакет открыт на максимальное время (5 секунд)

### Задержка {#latency}

Задержка (определяемая как время между производством сообщения Kafka и его доступностью в ClickHouse) будет зависеть от ряда факторов (например, задержка брокера, задержка сети, размер/формат сообщения). Пакетная обработка, описанная в разделе выше, также повлияет на задержку. Мы всегда рекомендуем протестировать ваш конкретный случай с типичными нагрузками, чтобы определить ожидаемую задержку.

ClickPipes не предоставляет никаких гарантий относительно задержки. Если у вас есть конкретные требования к низкой задержке, пожалуйста, [свяжитесь с нами](https://clickhouse.com/company/contact?loc=clickpipes).

### Масштабирование {#scaling}

ClickPipes для Kafka разработан для горизонтального и вертикального масштабирования. По умолчанию мы создаем группу потребителей с одним потребителем. Это можно настроить во время создания ClickPipe или в любое другое время в разделе **Настройки** -> **Расширенные настройки** -> **Масштабирование**.

ClickPipes обеспечивает высокую доступность с архитектурой, распределенной по зонам доступности.  
Для этого требуется масштабирование как минимум до двух потребителей.

Независимо от количества работающих потребителей, отказоустойчивость доступна по дизайну.  
Если потребитель или его инфраструктура выходят из строя, ClickPipe автоматически перезапустит потребителя и продолжит обработку сообщений.

### Бенчмарки {#benchmarks}

Ниже приведены несколько неофициальных бенчмарков для ClickPipes для Kafka, которые можно использовать для получения общего представления о базовой производительности. Важно знать, что на производительность могут влиять многие факторы, включая размер сообщения, типы данных и формат данных. Ваши результаты могут отличаться, и то, что мы показываем здесь, не является гарантией фактической производительности.

Детали бенчмарков:

- Мы использовали производственные службы ClickHouse Cloud с достаточными ресурсами, чтобы обеспечить, чтобы пропускная способность не была узким местом из-за обработки вставок на стороне ClickHouse.
- Сервис ClickHouse Cloud, кластер Kafka (Confluent Cloud) и ClickPipe работали в одном регионе (`us-east-2`).
- ClickPipe был настроен с одной репликой размера L (4 GiB RAM и 1 vCPU).
- Пример данных включал вложенные данные с комбинацией типов данных `UUID`, `String` и `Int`. Другие типы данных, такие как `Float`, `Decimal` и `DateTime`, могут работать менее эффективно.
- Не было заметной разницы в производительности при использовании сжатых и несжатых данных.

| Размер реплики | Размер сообщения | Формат данных | Пропускная способность |
|----------------|------------------|---------------|-----------------------|
| Большой (L)    | 1.6kb            |   JSON        | 63mb/s               |
| Большой (L)    | 1.6kb            |   Avro        | 99mb/s               |