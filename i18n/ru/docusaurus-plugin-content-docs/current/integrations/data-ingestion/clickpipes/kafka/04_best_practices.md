---
sidebar_label: 'Рекомендации по работе'
description: 'Лучшие практики при работе с Kafka ClickPipes'
slug: /integrations/clickpipes/kafka/best-practices
sidebar_position: 1
title: 'Лучшие практики'
doc_type: 'guide'
keywords: ['kafka best practices', 'clickpipes', 'compression', 'authentication', 'scaling']
---



# Рекомендации {#best-practices}


## Сжатие сообщений {#compression}

Мы настоятельно рекомендуем использовать сжатие для топиков Kafka. Сжатие позволяет значительно снизить затраты на передачу данных практически без потери производительности.
Чтобы узнать больше о сжатии сообщений в Kafka, рекомендуем начать с этого [руководства](https://www.confluent.io/blog/apache-kafka-message-compression/).


## Ограничения {#limitations}

- [`DEFAULT`](/sql-reference/statements/create/table#default) не поддерживается.


## Семантика доставки {#delivery-semantics}

ClickPipes для Kafka обеспечивает семантику доставки `at-least-once` (один из наиболее распространённых подходов). Мы будем рады получить ваши отзывы о семантике доставки через [форму обратной связи](https://clickhouse.com/company/contact?loc=clickpipes). Если вам необходима семантика exactly-once, рекомендуем использовать наш официальный sink [`clickhouse-kafka-connect`](https://clickhouse.com/blog/real-time-event-streaming-with-kafka-connect-confluent-cloud-clickhouse).


## Аутентификация {#authentication}

Для источников данных по протоколу Apache Kafka ClickPipes поддерживает аутентификацию [SASL/PLAIN](https://docs.confluent.io/platform/current/kafka/authentication_sasl/authentication_sasl_plain.html) с шифрованием TLS, а также `SASL/SCRAM-SHA-256` и `SASL/SCRAM-SHA-512`. В зависимости от источника потоковых данных (Redpanda, MSK и т. д.) будут доступны все или некоторые из этих механизмов аутентификации в зависимости от совместимости. Если ваши требования к аутентификации отличаются, пожалуйста, [оставьте нам отзыв](https://clickhouse.com/company/contact?loc=clickpipes).

### IAM {#iam}

:::info
Аутентификация IAM для MSK ClickPipe является бета-функцией.
:::

ClickPipes поддерживает следующие методы аутентификации AWS MSK:

- Аутентификация [SASL/SCRAM-SHA-512](https://docs.aws.amazon.com/msk/latest/developerguide/msk-password.html)
- Аутентификация на основе [учетных данных IAM или ролевого доступа](https://docs.aws.amazon.com/msk/latest/developerguide/how-to-use-iam-access-control.html)

При использовании аутентификации IAM для подключения к брокеру MSK роль IAM должна иметь необходимые разрешения.
Ниже приведен пример требуемой политики IAM для API Apache Kafka в MSK:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["kafka-cluster:Connect"],
      "Resource": [
        "arn:aws:kafka:us-west-2:12345678912:cluster/clickpipes-testing-brokers/b194d5ae-5013-4b5b-ad27-3ca9f56299c9-10"
      ]
    },
    {
      "Effect": "Allow",
      "Action": ["kafka-cluster:DescribeTopic", "kafka-cluster:ReadData"],
      "Resource": [
        "arn:aws:kafka:us-west-2:12345678912:topic/clickpipes-testing-brokers/*"
      ]
    },
    {
      "Effect": "Allow",
      "Action": ["kafka-cluster:AlterGroup", "kafka-cluster:DescribeGroup"],
      "Resource": [
        "arn:aws:kafka:us-east-1:12345678912:group/clickpipes-testing-brokers/*"
      ]
    }
  ]
}
```

#### Настройка доверительных отношений {#configuring-a-trusted-relationship}

Если вы выполняете аутентификацию в MSK с помощью ARN роли IAM, необходимо добавить доверительные отношения между вашим экземпляром ClickHouse Cloud, чтобы роль могла быть принята.

:::note
Ролевой доступ работает только для экземпляров ClickHouse Cloud, развернутых в AWS.
:::

```json
{
    "Version": "2012-10-17",
    "Statement": [
        ...
        {
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::12345678912:role/CH-S3-your-clickhouse-cloud-role"
            },
            "Action": "sts:AssumeRole"
        },
    ]
}
```

### Пользовательские сертификаты {#custom-certificates}

ClickPipes для Kafka поддерживает загрузку пользовательских сертификатов для брокеров Kafka, использующих непубличные серверные сертификаты.
Также поддерживается загрузка клиентских сертификатов и ключей для аутентификации на основе взаимного TLS (mTLS).


## Производительность {#performance}

### Пакетная обработка {#batching}

ClickPipes вставляет данные в ClickHouse пакетами. Это позволяет избежать создания слишком большого количества частей в базе данных, что может привести к проблемам с производительностью в кластере.

Пакеты вставляются при выполнении одного из следующих критериев:

- Размер пакета достиг максимального значения (100 000 строк или 32 МБ на 1 ГБ памяти pod)
- Пакет был открыт в течение максимального времени (5 секунд)

### Задержка {#latency}

Задержка (определяемая как время между созданием сообщения Kafka и его доступностью в ClickHouse) зависит от ряда факторов (например, задержка брокера, сетевая задержка, размер/формат сообщения). [Пакетная обработка](#batching), описанная в разделе выше, также влияет на задержку. Мы всегда рекомендуем тестировать ваш конкретный сценарий использования с типичными нагрузками для определения ожидаемой задержки.

ClickPipes не предоставляет никаких гарантий относительно задержки. Если у вас есть особые требования к низкой задержке, пожалуйста, [свяжитесь с нами](https://clickhouse.com/company/contact?loc=clickpipes).

### Масштабирование {#scaling}

ClickPipes для Kafka спроектирован для горизонтального и вертикального масштабирования. По умолчанию мы создаем группу потребителей с одним потребителем. Это можно настроить при создании ClickPipe или в любой другой момент в разделе **Settings** -> **Advanced Settings** -> **Scaling**.

ClickPipes обеспечивает высокую доступность благодаря архитектуре, распределенной по зонам доступности.
Для этого требуется масштабирование как минимум до двух потребителей.

Независимо от количества работающих потребителей, отказоустойчивость обеспечивается по умолчанию.
Если потребитель или его базовая инфраструктура выходит из строя,
ClickPipe автоматически перезапустит потребителя и продолжит обработку сообщений.

### Тесты производительности {#benchmarks}

Ниже приведены некоторые неформальные тесты производительности для ClickPipes для Kafka, которые можно использовать для получения общего представления о базовой производительности. Важно понимать, что многие факторы могут влиять на производительность, включая размер сообщения, типы данных и формат данных. Ваши результаты могут отличаться, и то, что мы показываем здесь, не является гарантией фактической производительности.

Детали тестирования:

- Мы использовали производственные сервисы ClickHouse Cloud с достаточными ресурсами, чтобы гарантировать, что пропускная способность не ограничивалась обработкой вставок на стороне ClickHouse.
- Сервис ClickHouse Cloud, кластер Kafka (Confluent Cloud) и ClickPipe работали в одном регионе (`us-east-2`).
- ClickPipe был настроен с одной репликой размера L (4 ГиБ оперативной памяти и 1 vCPU).
- Тестовые данные включали вложенные данные со смешанными типами данных `UUID`, `String` и `Int`. Другие типы данных, такие как `Float`, `Decimal` и `DateTime`, могут показывать меньшую производительность.
- Не было заметной разницы в производительности при использовании сжатых и несжатых данных.

| Размер реплики | Размер сообщения | Формат данных | Пропускная способность |
| -------------- | ---------------- | ------------- | ---------------------- |
| Large (L)      | 1.6kb            | JSON          | 63mb/s                 |
| Large (L)      | 1.6kb            | Avro          | 99mb/s                 |
