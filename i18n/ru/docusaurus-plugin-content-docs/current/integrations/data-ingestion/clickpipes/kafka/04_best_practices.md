---
sidebar_label: 'Лучшие практики'
description: 'Описание лучших практик работы с Kafka ClickPipes'
slug: /integrations/clickpipes/kafka/best-practices
sidebar_position: 1
title: 'Лучшие практики'
doc_type: 'guide'
keywords: ['kafka лучшие практики', 'clickpipes', 'сжатие', 'аутентификация', 'масштабирование']
integration:
  - support_level: 'core'
  - category: 'clickpipes'
---

# Лучшие практики \{#best-practices\}

## Сжатие сообщений \{#compression\}

Мы настоятельно рекомендуем использовать сжатие для ваших топиков в Kafka. Сжатие позволяет значительно сократить затраты на передачу данных практически без ущерба для производительности.
Чтобы узнать больше о сжатии сообщений в Kafka, мы рекомендуем начать с этого [руководства](https://www.confluent.io/blog/apache-kafka-message-compression/).

## Ограничения \{#limitations\}

- [`DEFAULT`](/sql-reference/statements/create/table#default) не поддерживается.
- Размер отдельных сообщений по умолчанию ограничен 8 МБ (в несжатом виде) при использовании минимального размера реплики (XS) и 16 МБ (в несжатом виде) для более крупных реплик. Сообщения, превышающие этот предел, будут отклонены с ошибкой. Если вам нужны сообщения большего размера, свяжитесь со службой поддержки.

## Семантика доставки \{#delivery-semantics\}

ClickPipes для Kafka обеспечивает семантику доставки `at-least-once` (одна из наиболее распространённых моделей). Нам будет важно получить от вас обратную связь по семантике доставки через [форму обратной связи](https://clickhouse.com/company/contact?loc=clickpipes). Если вам требуется семантика exactly-once, мы рекомендуем использовать наш официальный sink [`clickhouse-kafka-connect`](https://clickhouse.com/blog/real-time-event-streaming-with-kafka-connect-confluent-cloud-clickhouse).

## Аутентификация \{#authentication\}

Для источников данных, использующих протокол Apache Kafka, ClickPipes поддерживает аутентификацию [SASL/PLAIN](https://docs.confluent.io/platform/current/kafka/authentication_sasl/authentication_sasl_plain.html) с шифрованием TLS, а также `SASL/SCRAM-SHA-256` и `SASL/SCRAM-SHA-512`. В зависимости от конкретного потокового источника (Redpanda, MSK и т. д.) могут поддерживаться все или лишь часть этих механизмов аутентификации — в зависимости от совместимости. Если ваши требования к аутентификации отличаются, пожалуйста, [сообщите нам об этом](https://clickhouse.com/company/contact?loc=clickpipes).

## Размер выборки Warpstream \{#warpstream-settings\}

ClickPipes полагаются на параметр Kafka `max.fetch_bytes` для ограничения объёма данных, обрабатываемых на одном узле ClickPipes в любой момент времени. В некоторых случаях
Warpstream не учитывает этот параметр, что может привести к неожиданным сбоям конвейеров. Мы настоятельно рекомендуем установить специальный параметр Warpstream `kafkaMaxFetchPartitionBytesUncompressedOverride`
на 8 MB (или меньше) при конфигурировании вашего агента Warpstream, чтобы предотвратить сбои ClickPipes.

### IAM \{#iam\}

:::info
Аутентификация IAM для MSK ClickPipe находится в бета-версии.
:::

ClickPipes поддерживает следующие способы аутентификации AWS MSK:

* аутентификация [SASL/SCRAM-SHA-512](https://docs.aws.amazon.com/msk/latest/developerguide/msk-password.html)
* аутентификация с использованием [учетных данных IAM или доступа на основе ролей](https://docs.aws.amazon.com/msk/latest/developerguide/how-to-use-iam-access-control.html)

При использовании аутентификации IAM для подключения к брокеру MSK роль IAM должна иметь необходимые разрешения.
Ниже приведён пример необходимой политики IAM для API Apache Kafka в MSK:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:Connect"
            ],
            "Resource": [
                "arn:aws:kafka:us-west-2:12345678912:cluster/clickpipes-testing-brokers/b194d5ae-5013-4b5b-ad27-3ca9f56299c9-10"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:DescribeTopic",
                "kafka-cluster:ReadData"
            ],
            "Resource": [
                "arn:aws:kafka:us-west-2:12345678912:topic/clickpipes-testing-brokers/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:AlterGroup",
                "kafka-cluster:DescribeGroup"
            ],
            "Resource": [
                "arn:aws:kafka:us-east-1:12345678912:group/clickpipes-testing-brokers/*"
            ]
        }
    ]
}
```


#### Настройка доверительных отношений \{#configuring-a-trusted-relationship\}

Если вы аутентифицируетесь в MSK с помощью ARN роли IAM, необходимо добавить доверительные отношения между вашим экземпляром ClickHouse Cloud и этой ролью, чтобы эту роль можно было назначать.

:::note
Доступ на основе ролей работает только для экземпляров ClickHouse Cloud, развернутых в AWS.
:::

```json
{
    "Version": "2012-10-17",
    "Statement": [
        ...
        {
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::12345678912:role/CH-S3-your-clickhouse-cloud-role"
            },
            "Action": "sts:AssumeRole"
        },
    ]
}
```


### Пользовательские сертификаты \{#custom-certificates\}

ClickPipes для Kafka поддерживает загрузку пользовательских сертификатов для брокеров Kafka, которые используют непубличные серверные сертификаты.
Также поддерживается загрузка клиентских сертификатов и ключей для аутентификации на основе взаимного TLS (mTLS).

## Производительность \{#performance\}

### Пакетирование \{#batching\}

ClickPipes вставляет данные в ClickHouse пакетами. Это делается, чтобы избежать создания слишком большого количества частей в базе данных, что может привести к проблемам с производительностью кластера.

Пакеты вставляются при выполнении одного из следующих условий:

- Размер пакета достиг максимального значения (100 000 строк или 32 МБ на 1 ГБ памяти пода)
- Пакет остается открытым максимально допустимое время (5 секунд)

### Задержка \{#latency\}

Задержка (определяется как время между публикацией сообщения в Kafka и моментом, когда сообщение становится доступным в ClickHouse) зависит от ряда факторов (например, задержка брокера, сетевая задержка, размер/формат сообщения). [Пакетирование](#batching), описанное в разделе выше, также влияет на задержку. Мы всегда рекомендуем тестировать ваш конкретный сценарий использования при типичных нагрузках, чтобы определить ожидаемую задержку.

ClickPipes не предоставляет никаких гарантий в отношении задержки. Если у вас есть специфические требования к низкой задержке, пожалуйста, [свяжитесь с нами](https://clickhouse.com/company/contact?loc=clickpipes).

### Масштабирование \{#scaling\}

ClickPipes for Kafka спроектирован для горизонтального и вертикального масштабирования. По умолчанию создаётся группа потребителей с одним потребителем. Это можно настроить во время создания ClickPipe или в любой момент позже в **Settings** -> **Advanced Settings** -> **Scaling**.

ClickPipes обеспечивает высокую доступность благодаря архитектуре, распределённой по зонам доступности.
Для этого требуется масштабирование как минимум до двух потребителей.

Независимо от количества работающих потребителей, отказоустойчивость обеспечивается архитектурно.
Если потребитель или его базовая инфраструктура выходит из строя,
ClickPipe автоматически перезапускает потребителя и продолжает обработку сообщений.

### Бенчмарки \{#benchmarks\}

Ниже приведены некоторые неформальные бенчмарки для ClickPipes for Kafka, которые можно использовать, чтобы получить общее представление о базовой производительности. Важно понимать, что на производительность могут влиять многие факторы, включая размер сообщения, типы данных и формат данных. Ваши результаты могут отличаться, и приведённые здесь данные не являются гарантией фактической производительности.

Подробности тестирования:

- Мы использовали продуктивные сервисы ClickHouse Cloud с достаточным количеством ресурсов, чтобы обеспечить отсутствие узких мест по пропускной способности на стороне ClickHouse при обработке операций вставки.
- Сервис ClickHouse Cloud, кластер Kafka (Confluent Cloud) и ClickPipe работали в одном регионе (`us-east-2`).
- ClickPipe был сконфигурирован с одной репликой размера L (4 GiB оперативной памяти и 1 vCPU).
- В примере данных были вложенные структуры с сочетанием типов данных `UUID`, `String` и `Int`. Другие типы данных, такие как `Float`, `Decimal` и `DateTime`, могут быть менее производительными.
- Не наблюдалось заметной разницы в производительности между сжатыми и несжатыми данными.

| Размер реплики | Размер сообщения | Формат данных | Пропускная способность |
|----------------|------------------|---------------|------------------------|
| Large (L)      | 1.6kb            |   JSON        | 63mb/s                 |
| Large (L)      | 1.6kb            |   Avro        | 99mb/s                 |