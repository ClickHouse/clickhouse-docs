---
sidebar_label: 'Возможности и настройки'
slug: /integrations/dbt/features-and-configurations
sidebar_position: 2
description: 'Возможности использования dbt с ClickHouse'
keywords: ['clickhouse', 'dbt', 'features']
title: 'Возможности и настройки'
doc_type: 'guide'
---

import TOCInline from '@theme/TOCInline';
import ClickHouseSupportedBadge from '@theme/badges/ClickHouseSupported';


# Возможности и конфигурации

<ClickHouseSupportedBadge/>

В этом разделе представлена документация по некоторым функциям dbt для ClickHouse.

<TOCInline toc={toc}  maxHeadingLevel={3} />



## Конфигурации Profile.yml {#profile-yml-configurations}

Для подключения к ClickHouse из dbt необходимо добавить [профиль](https://docs.getdbt.com/docs/core/connect-data-platform/connection-profiles) в файл `profiles.yml`. Профиль ClickHouse имеет следующий синтаксис:

```yaml
your_profile_name:
  target: dev
  outputs:
    dev:
      type: clickhouse

      # Необязательные параметры
      schema: [default] # База данных ClickHouse для моделей dbt
      driver: [http] # http или native. Если не указано, определяется автоматически на основе настройки порта
      host: [localhost]
      port: [8123] # Если не указано, по умолчанию используется 8123, 8443, 9000, 9440 в зависимости от настроек secure и driver
      user: [default] # Пользователь для всех операций с базой данных
      password: [<empty string>] # Пароль пользователя
      cluster: [<empty string>] # Если указано, определенные DDL/табличные операции будут выполняться с предложением `ON CLUSTER` для этого кластера. Распределенные материализации требуют этой настройки. Подробнее см. в разделе о кластере ClickHouse ниже.
      verify: [True] # Проверять TLS-сертификат при использовании TLS/SSL
      secure: [False] # Использовать TLS (нативный протокол) или HTTPS (протокол http)
      client_cert: [null] # Путь к клиентскому TLS-сертификату в формате .pem
      client_cert_key: [null] # Путь к закрытому ключу для клиентского TLS-сертификата
      retries: [1] # Количество попыток повтора при возникновении повторяемого исключения базы данных (например, ошибки 503 'Service Unavailable')
      compression: [<empty string>] # Использовать сжатие gzip, если указано (http), или тип сжатия для нативного соединения
      connect_timeout: [10] # Таймаут в секундах для установления соединения с ClickHouse
      send_receive_timeout: [300] # Таймаут в секундах для получения данных от сервера ClickHouse
      cluster_mode: [False] # Использовать специальные настройки для улучшения работы с реплицируемыми базами данных (рекомендуется для ClickHouse Cloud)
      use_lw_deletes: [False] # Использовать стратегию `delete+insert` в качестве инкрементной стратегии по умолчанию.
      check_exchange: [True] # Проверять, что ClickHouse поддерживает атомарную команду EXCHANGE TABLES. (Не требуется для большинства версий ClickHouse)
      local_suffix: [_local] # Суффикс таблицы для локальных таблиц на шардах при распределенных материализациях.
      local_db_prefix: [<empty string>] # Префикс базы данных для локальных таблиц на шардах при распределенных материализациях. Если не указано, используется та же база данных, что и для распределенной таблицы.
      allow_automatic_deduplication: [False] # Включить автоматическую дедупликацию ClickHouse для реплицируемых таблиц
      tcp_keepalive: [False] # Только для нативного клиента, задает конфигурацию TCP keepalive. Укажите пользовательские настройки keepalive в формате [idle_time_sec, interval_sec, probes].
      custom_settings: [{}] # Словарь пользовательских настроек ClickHouse для соединения - по умолчанию пустой.
      database_engine: "" # Движок базы данных для использования при создании новых схем ClickHouse (баз данных). Если не указано (по умолчанию), новые базы данных будут использовать движок базы данных ClickHouse по умолчанию (обычно Atomic).
      threads: [1] # Количество потоков для использования при выполнении запросов. Перед установкой значения больше 1 обязательно прочитайте раздел [согласованность чтения после записи](#read-after-write-consistency).

      # Настройки нативного соединения (clickhouse-driver)
      sync_request_timeout: [5] # Таймаут для ping-запроса к серверу
      compress_block_size: [1048576] # Размер блока сжатия, если сжатие включено
```

### Schema и Database {#schema-vs-database}

Идентификатор отношения модели dbt `database.schema.table` несовместим с ClickHouse, поскольку ClickHouse не
поддерживает `schema`.
Поэтому используется упрощенный подход `schema.table`, где `schema` — это база данных ClickHouse. Использование базы данных `default`
не рекомендуется.

### Предупреждение об операторе SET {#set-statement-warning}

Во многих средах использование оператора SET для сохранения настройки ClickHouse для всех запросов DBT ненадежно
и может вызвать неожиданные сбои. Это особенно актуально при использовании HTTP-соединений через балансировщик нагрузки,
распределяющий запросы между несколькими узлами (например, ClickHouse Cloud), хотя в некоторых случаях это может также
происходить с нативными соединениями ClickHouse. В связи с этим рекомендуется настраивать все необходимые параметры ClickHouse в
свойстве "custom_settings" профиля DBT в качестве лучшей практики, вместо того чтобы полагаться на оператор "SET" в pre-hook, как
иногда предлагалось.

### Настройка `quote_columns` {#setting-quote_columns}


Чтобы предотвратить предупреждение, убедитесь, что явно задано значение для `quote_columns` в вашем `dbt_project.yml`. Дополнительную информацию см. в [документации по quote_columns](https://docs.getdbt.com/reference/resource-configs/quote_columns).

```yaml
seeds:
  +quote_columns: false #или `true`, если заголовки столбцов CSV содержат пробелы
```

### О кластере ClickHouse {#about-the-clickhouse-cluster}

При использовании кластера ClickHouse необходимо учитывать два аспекта:

- Настройка параметра `cluster`.
- Обеспечение согласованности чтения после записи, особенно при использовании более одного потока (`threads`).

#### Настройка кластера {#cluster-setting}

Параметр `cluster` в профиле позволяет dbt-clickhouse работать с кластером ClickHouse. Если `cluster` задан в профиле, **все модели по умолчанию будут создаваться с конструкцией `ON CLUSTER`** — за исключением моделей, использующих движок **Replicated**. Это включает:

- Создание баз данных
- Материализацию представлений
- Материализацию таблиц и инкрементальную материализацию
- Распределённую материализацию

Движки Replicated **не будут** включать конструкцию `ON CLUSTER`, поскольку они предназначены для внутреннего управления репликацией.

Чтобы **отключить** создание на основе кластера для конкретной модели, добавьте конфигурацию `disable_on_cluster`:

```sql
{{ config(
        engine='MergeTree',
        materialized='table',
        disable_on_cluster='true'
    )
}}

```

Материализация таблиц и инкрементальная материализация с нереплицируемым движком не будут затронуты параметром `cluster` (модель будет создана только на подключённом узле).

**Совместимость**

Если модель была создана без параметра `cluster`, dbt-clickhouse обнаружит эту ситуацию и выполнит все DDL/DML без конструкции `on cluster` для данной модели.

#### Согласованность чтения после записи {#read-after-write-consistency}

dbt полагается на модель согласованности чтения после вставки. Это несовместимо с кластерами ClickHouse, имеющими более одной реплики, если вы не можете гарантировать, что все операции будут направлены на одну и ту же реплику. Вы можете не столкнуться с проблемами при повседневном использовании dbt, но существуют некоторые стратегии в зависимости от вашего кластера для обеспечения этой гарантии:

- Если вы используете кластер ClickHouse Cloud, вам нужно только установить `select_sequential_consistency: 1` в свойстве `custom_settings` вашего профиля. Дополнительную информацию об этой настройке можно найти [здесь](https://clickhouse.com/docs/operations/settings/settings#select_sequential_consistency).
- Если вы используете самостоятельно размещённый кластер, убедитесь, что все запросы dbt отправляются на одну и ту же реплику ClickHouse. Если у вас есть балансировщик нагрузки, попробуйте использовать механизм `replica aware routing`/`sticky sessions`, чтобы всегда обращаться к одной и той же реплике. Добавление настройки `select_sequential_consistency = 1` в кластерах за пределами ClickHouse Cloud [не рекомендуется](https://clickhouse.com/docs/operations/settings/settings#select_sequential_consistency).


## Общая информация о возможностях {#general-information-about-features}

### Общие настройки таблиц {#general-table-configurations}

| Параметр       | Описание                                                                                                                                                                                                      | Значение по умолчанию |
| -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------- |
| engine         | Движок таблицы (тип таблицы), используемый при создании таблиц                                                                                                                                               | `MergeTree()`  |
| order_by       | Кортеж имён столбцов или произвольных выражений. Позволяет создать небольшой разреженный индекс, ускоряющий поиск данных.                                                                    | `tuple()`      |
| partition_by   | Партиция — это логическое объединение записей в таблице по заданному критерию. Ключ партиционирования может быть любым выражением от столбцов таблицы.                                                       |                |
| sharding_key   | Ключ шардирования определяет целевой сервер при вставке данных в таблицу с распределённым движком. Ключ шардирования может быть случайным или результатом хеш-функции                                        | `rand()`)      |
| primary_key    | Как и order_by, выражение первичного ключа ClickHouse. Если не указано, ClickHouse использует выражение order by в качестве первичного ключа                                                          |                |
| unique_key     | Кортеж имён столбцов, которые уникально идентифицируют строки. Используется с инкрементными моделями для обновлений.                                                                                          |                |
| settings       | Словарь настроек таблицы, используемых в DDL-операторах типа 'CREATE TABLE' для данной модели                                                                                                                |                |
| query_settings | Словарь пользовательских настроек ClickHouse, используемых с операторами `INSERT` или `DELETE` в сочетании с данной моделью                                                                                  |                |
| ttl            | Выражение TTL для использования с таблицей. Выражение TTL — это строка, которая используется для указания TTL таблицы.                                                                                |                |
| indexes        | Список [индексов пропуска данных](/optimize/skipping-indexes) для создания. Подробнее см. ниже.                                                                                                               |                |
| sql_security   | Позволяет указать, от имени какого пользователя ClickHouse выполнять базовый запрос представления. `SQL SECURITY` [имеет два допустимых значения](/sql-reference/statements/create/view#sql_security): `definer` и `invoker`. |                |
| definer        | Если `sql_security` установлен в `definer`, необходимо указать любого существующего пользователя или `CURRENT_USER` в предложении `definer`.                                                                  |                |
| projections    | Список [проекций](/data-modeling/projections) для создания. Подробнее см. [О проекциях](#projections).                                                                                                        |                |

#### Об индексах пропуска данных {#data-skipping-indexes}

Индексы пропуска данных доступны только для материализации `table`. Чтобы добавить список индексов пропуска данных к таблице, используйте конфигурацию `indexes`:

```sql
{{ config(
        materialized='table',
        indexes=[{
          'name': 'your_index_name',
          'definition': 'your_column TYPE minmax GRANULARITY 2'
        }]
) }}
```

#### О проекциях {#projections}

Вы можете добавить [проекции](/data-modeling/projections) к материализациям `table` и `distributed_table`, используя конфигурацию `projections`:

```sql
{{ config(
       materialized='table',
       projections=[
           {
               'name': 'your_projection_name',
               'query': 'SELECT department, avg(age) AS avg_age GROUP BY department'
           }
       ]
) }}
```

**Примечание**: Для распределённых таблиц проекция применяется к локальным таблицам `_local`, а не к распределённой прокси-таблице.

### Поддерживаемые движки таблиц {#supported-table-engines}

| Тип                    | Подробности                                                                               |
| ---------------------- | ----------------------------------------------------------------------------------------- |
| MergeTree (по умолчанию) | https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/mergetree/.       |
| HDFS                   | https://clickhouse.com/docs/en/engines/table-engines/integrations/hdfs                    |
| MaterializedPostgreSQL | https://clickhouse.com/docs/en/engines/table-engines/integrations/materialized-postgresql |
| S3                     | https://clickhouse.com/docs/en/engines/table-engines/integrations/s3                      |
| EmbeddedRocksDB        | https://clickhouse.com/docs/en/engines/table-engines/integrations/embedded-rocksdb        |
| Hive                   | https://clickhouse.com/docs/en/engines/table-engines/integrations/hive                    |

### Экспериментально поддерживаемые движки таблиц {#experimental-supported-table-engines}


| Тип                      | Подробности                                                               |
| ------------------------ | ------------------------------------------------------------------------- |
| Распределённая таблица   | https://clickhouse.com/docs/en/engines/table-engines/special/distributed. |
| Словарь                  | https://clickhouse.com/docs/en/engines/table-engines/special/dictionary   |

Если при подключении к ClickHouse из dbt с одним из указанных выше движков возникают проблемы, сообщите о них [здесь](https://github.com/ClickHouse/dbt-clickhouse/issues).

### Примечание о настройках модели {#a-note-on-model-settings}

В ClickHouse существует несколько типов и уровней настроек. В конфигурации модели, описанной выше, можно настроить два типа таких настроек. Параметр `settings` соответствует секции `SETTINGS`, используемой в DDL-операторах типа `CREATE TABLE/VIEW`, то есть это настройки, специфичные для конкретного движка таблиц ClickHouse. Новый параметр `query_settings` используется для добавления секции `SETTINGS` к запросам `INSERT` и `DELETE`, применяемым для материализации модели (включая инкрементальные материализации).
В ClickHouse существуют сотни настроек, и не всегда очевидно, какая настройка является табличной, а какая — пользовательской (хотя последние обычно доступны в таблице `system.settings`). В целом рекомендуется использовать значения по умолчанию, а любое применение этих параметров должно быть тщательно изучено и протестировано.

### Конфигурация столбцов {#column-configuration}

> **_ПРИМЕЧАНИЕ:_** Приведённые ниже параметры конфигурации столбцов требуют включения [контрактов модели](https://docs.getdbt.com/docs/collaborate/govern/model-contracts).

| Параметр | Описание                                                                                                                                                                                                                                                      | Значение по умолчанию |
| -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------- |
| codec    | Строка, состоящая из аргументов, передаваемых в `CODEC()` в DDL столбца. Например: `codec: "Delta, ZSTD"` будет скомпилирована как `CODEC(Delta, ZSTD)`.                                                                                                     |
| ttl      | Строка, состоящая из [выражения TTL (time-to-live)](https://clickhouse.com/docs/guides/developer/ttl), которое определяет правило TTL в DDL столбца. Например: `ttl: ts + INTERVAL 1 DAY` будет скомпилирована как `TTL ts + INTERVAL 1 DAY`. |

#### Пример конфигурации схемы {#example-of-schema-configuration}

```yaml
models:
  - name: table_column_configs
    description: "Тестирование конфигураций на уровне столбцов"
    config:
      contract:
        enforced: true
    columns:
      - name: ts
        data_type: timestamp
        codec: ZSTD
      - name: x
        data_type: UInt8
        ttl: ts + INTERVAL 1 DAY
```

#### Добавление сложных типов {#adding-complex-types}

dbt автоматически определяет тип данных каждого столбца, анализируя SQL, используемый для создания модели. Однако в некоторых случаях этот процесс может неточно определить тип данных, что приводит к конфликтам с типами, указанными в свойстве `data_type` контракта. Для решения этой проблемы рекомендуется использовать функцию `CAST()` в SQL модели для явного определения желаемого типа. Например:

```sql
{{
    config(
        materialized="materialized_view",
        engine="AggregatingMergeTree",
        order_by=["event_type"],
    )
}}

select
  -- event_type может быть выведен как String, но мы можем предпочесть LowCardinality(String):
  CAST(event_type, 'LowCardinality(String)') as event_type,
  -- countState() может быть выведена как `AggregateFunction(count)`, но мы можем предпочесть изменить тип используемого аргумента:
  CAST(countState(), 'AggregateFunction(count, UInt32)') as response_count,
  -- maxSimpleState() может быть выведена как `SimpleAggregateFunction(max, String)`, но мы можем также предпочесть изменить тип используемого аргумента:
  CAST(maxSimpleState(event_type), 'SimpleAggregateFunction(max, LowCardinality(String))') as max_event_type
from {{ ref('user_events') }}
group by event_type
```


## Возможности {#features}

### Материализация: представление {#materialization-view}

Модель dbt может быть создана как [представление ClickHouse](https://clickhouse.com/docs/en/sql-reference/table-functions/view/)
и настроена с помощью следующего синтаксиса:

Файл проекта (`dbt_project.yml`):

```yaml
models:
  <resource-path>:
    +materialized: view
```

Или блок конфигурации (`models/<model_name>.sql`):

```python
{{ config(materialized = "view") }}
```

### Материализация: таблица {#materialization-table}

Модель dbt может быть создана как [таблица ClickHouse](https://clickhouse.com/docs/en/operations/system-tables/tables/) и
настроена с помощью следующего синтаксиса:

Файл проекта (`dbt_project.yml`):

```yaml
models:
  <resource-path>:
    +materialized: table
    +order_by: [<column-name>, ...]
    +engine: <engine-type>
    +partition_by: [<column-name>, ...]
```

Или блок конфигурации (`models/<model_name>.sql`):

```python
{{ config(
    materialized = "table",
    engine = "<engine-type>",
    order_by = [ "<column-name>", ... ],
    partition_by = [ "<column-name>", ... ],
      ...
    ]
) }}
```

### Материализация: инкрементальная {#materialization-incremental}

Табличная модель будет перестраиваться при каждом выполнении dbt. Это может быть нецелесообразно и крайне затратно для больших наборов результатов или сложных преобразований. Для решения этой проблемы и сокращения времени построения модель dbt может быть создана как инкрементальная таблица ClickHouse и настроена с помощью следующего синтаксиса:

Определение модели в `dbt_project.yml`:

```yaml
models:
  <resource-path>:
    +materialized: incremental
    +order_by: [<column-name>, ...]
    +engine: <engine-type>
    +partition_by: [<column-name>, ...]
    +unique_key: [<column-name>, ...]
    +inserts_only: [True|False]
```

Или блок конфигурации в `models/<model_name>.sql`:

```python
{{ config(
    materialized = "incremental",
    engine = "<engine-type>",
    order_by = [ "<column-name>", ... ],
    partition_by = [ "<column-name>", ... ],
    unique_key = [ "<column-name>", ... ],
    inserts_only = [ True|False ],
      ...
    ]
) }}
```

#### Конфигурации {#configurations}

Конфигурации, специфичные для данного типа материализации, перечислены ниже:

| Параметр                 | Описание                                                                                                                                                                                                                                                                                                               | Обязательный?                                                                        |
| ------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------ |
| `unique_key`             | Кортеж имен столбцов, которые однозначно идентифицируют строки. Подробнее об ограничениях уникальности см. [здесь](https://docs.getdbt.com/docs/build/incremental-models#defining-a-unique-key-optional).                                                                                                              | Обязательный. Если не указан, измененные строки будут добавлены дважды в инкрементальную таблицу. |
| `inserts_only`           | Устарел в пользу инкрементальной стратегии `append`, которая работает аналогично. Если установлено значение True для инкрементальной модели, инкрементальные обновления будут вставляться непосредственно в целевую таблицу без создания промежуточной таблицы. Если установлен `inserts_only`, параметр `incremental_strategy` игнорируется. | Необязательный (по умолчанию: `False`)                                               |
| `incremental_strategy`   | Стратегия, используемая для инкрементальной материализации. Поддерживаются `delete+insert`, `append`, `insert_overwrite` или `microbatch`. Дополнительные сведения о стратегиях см. [здесь](/integrations/dbt/features-and-configurations#incremental-model-strategies)                                           | Необязательный (по умолчанию: 'default')                                             |
| `incremental_predicates` | Дополнительные условия, применяемые к инкрементальной материализации (применяются только к стратегии `delete+insert`)                                                                                                                                                                                                 | Необязательный                                                                       |

#### Стратегии инкрементальных моделей {#incremental-model-strategies}

`dbt-clickhouse` поддерживает три стратегии инкрементальных моделей.

##### Стратегия по умолчанию (устаревшая) {#default-legacy-strategy}

Исторически ClickHouse имел лишь ограниченную поддержку обновлений и удалений в форме асинхронных «мутаций».
Для эмуляции ожидаемого поведения dbt
dbt-clickhouse по умолчанию создает новую временную таблицу, содержащую все незатронутые (не удаленные, не измененные) «старые»
записи, а также любые новые или обновленные записи,
а затем заменяет или обменивает эту временную таблицу с существующим отношением инкрементальной модели. Это единственная стратегия,
которая сохраняет исходное отношение в случае,
если что-то пойдет не так до завершения операции; однако, поскольку она включает полное копирование исходной таблицы, она может быть довольно
затратной и медленной в выполнении.

##### Стратегия Delete+Insert {#delete-insert-strategy}


ClickHouse добавил «легковесные удаления» (lightweight deletes) в качестве экспериментальной функции в версии 22.8. Легковесные удаления работают значительно
быстрее операций ALTER TABLE ... DELETE,
поскольку не требуют перезаписи частей данных ClickHouse. Инкрементальная стратегия `delete+insert`
использует легковесные удаления для реализации
инкрементальных материализаций, которые работают значительно быстрее «устаревшей» стратегии. Однако при использовании этой стратегии существуют важные
ограничения:

- Легковесные удаления должны быть включены на вашем сервере ClickHouse с помощью настройки
  `allow_experimental_lightweight_delete=1`, либо вы
  должны установить `use_lw_deletes=true` в вашем профиле (что включит эту настройку для ваших dbt-сессий)
- Легковесные удаления теперь готовы к использованию в продакшене, но на версиях ClickHouse
  ранее 23.3 могут возникать проблемы с производительностью и другие проблемы.
- Эта стратегия работает непосредственно с затронутой таблицей/отношением (без создания промежуточных или временных таблиц),
  поэтому если во время операции возникнет проблема,
  данные в инкрементальной модели, вероятно, окажутся в некорректном состоянии
- При использовании легковесных удалений dbt-clickhouse включает настройку `allow_nondeterministic_mutations`. В некоторых очень
  редких случаях при использовании недетерминированных incremental_predicates
  это может привести к состоянию гонки для обновленных/удаленных элементов (и соответствующим сообщениям в логах ClickHouse).
  Для обеспечения согласованных результатов
  инкрементальные предикаты должны включать только подзапросы к данным, которые не будут изменяться во время инкрементальной
  материализации.

##### Стратегия Microbatch (требуется dbt-core >= 1.9) {#microbatch-strategy}

Инкрементальная стратегия `microbatch` является функцией dbt-core начиная с версии 1.9, предназначенной для эффективной обработки больших
преобразований данных временных рядов. В dbt-clickhouse она основана на существующей инкрементальной
стратегии `delete_insert`, разделяя инкремент на предопределенные пакеты временных рядов на основе конфигураций модели `event_time` и
`batch_size`.

Помимо обработки больших преобразований, microbatch предоставляет возможность:

- [Повторно обрабатывать неудавшиеся пакеты](https://docs.getdbt.com/docs/build/incremental-microbatch#retry).
- Автоматически определять [параллельное выполнение пакетов](https://docs.getdbt.com/docs/build/parallel-batch-execution).
- Устранить необходимость в сложной условной логике при [обратном заполнении](https://docs.getdbt.com/docs/build/incremental-microbatch#backfills).

Для подробного описания использования microbatch обратитесь к [официальной документации](https://docs.getdbt.com/docs/build/incremental-microbatch).

###### Доступные конфигурации Microbatch {#available-microbatch-configurations}

| Параметр           | Описание                                                                                                                                                                                                                                                                                                                                   | Значение по умолчанию |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------- |
| event_time         | Столбец, указывающий «в какое время произошла строка». Обязателен для вашей модели microbatch и любых прямых родительских моделей, которые должны быть отфильтрованы.                                                                                                                                                                      |                |
| begin              | «Начало времени» для модели microbatch. Это начальная точка для любых начальных сборок или полных обновлений. Например, модель microbatch с дневной детализацией, запущенная 2024-10-01 с begin = '2023-10-01, обработает 366 пакетов (это високосный год!) плюс пакет для «сегодня».                                                      |                |
| batch_size         | Детализация ваших пакетов. Поддерживаемые значения: `hour`, `day`, `month` и `year`                                                                                                                                                                                                                                                        |                |
| lookback           | Обработать X пакетов до последней закладки для захвата запоздавших записей.                                                                                                                                                                                                                                                                | 1              |
| concurrent_batches | Переопределяет автоопределение dbt для одновременного выполнения пакетов. Подробнее о [настройке одновременных пакетов](https://docs.getdbt.com/docs/build/incremental-microbatch#configure-concurrent_batches). Установка в true запускает пакеты одновременно (параллельно). false запускает пакеты последовательно (один за другим).    |                |

##### Стратегия Append {#append-strategy}

Эта стратегия заменяет настройку `inserts_only` в предыдущих версиях dbt-clickhouse. Этот подход просто добавляет
новые строки к существующему отношению.
В результате дублирующиеся строки не удаляются, и нет временной или промежуточной таблицы. Это самый быстрый
подход, если дубликаты либо допустимы
в данных, либо исключены условием WHERE/фильтром инкрементального запроса.

##### Стратегия insert_overwrite (экспериментальная) {#insert-overwrite-strategy}

> [ВАЖНО]  
> В настоящее время стратегия insert_overwrite не полностью функциональна с распределенными материализациями.

Выполняет следующие шаги:


1. Создайте промежуточную (временную) таблицу с той же структурой, что и отношение инкрементной модели:
   `CREATE TABLE <staging> AS <target>`.
2. Вставьте только новые записи (полученные с помощью `SELECT`) в промежуточную таблицу.
3. Замените только новые партиции (присутствующие в промежуточной таблице) в целевой таблице.

Этот подход имеет следующие преимущества:

- Он быстрее стратегии по умолчанию, поскольку не копирует всю таблицу целиком.
- Он безопаснее других стратегий, поскольку не изменяет исходную таблицу до успешного завершения операции INSERT:
  в случае промежуточного сбоя исходная таблица остается неизменной.
- Он реализует лучшую практику инженерии данных «неизменяемость партиций», что упрощает инкрементную и параллельную обработку данных,
  откаты и т. д.

Стратегия требует установки `partition_by` в конфигурации модели. Игнорирует все остальные специфичные для стратегий
параметры конфигурации модели.

### Материализация: materialized_view (экспериментальная) {#materialized-view}

Материализация `materialized_view` должна представлять собой `SELECT` из существующей (исходной) таблицы. Адаптер создаст
целевую таблицу с именем модели
и ClickHouse MATERIALIZED VIEW с именем `<model_name>_mv`. В отличие от PostgreSQL, материализованное представление ClickHouse
не является «статическим» (и не имеет
соответствующей операции REFRESH). Вместо этого оно действует как «триггер вставки» и будет вставлять новые строки в целевую
таблицу, используя определенное «преобразование» `SELECT`
в определении представления для строк, вставленных в исходную таблицу. См. [тестовый файл](https://github.com/ClickHouse/dbt-clickhouse/blob/main/tests/integration/adapter/materialized_view/test_materialized_view.py)
для ознакомительного примера
использования этой функциональности.

ClickHouse предоставляет возможность нескольким материализованным представлениям записывать данные в одну и ту же целевую таблицу. Для
поддержки этого в dbt-clickhouse вы можете создать `UNION` в файле модели таким образом, чтобы SQL для каждого из ваших
материализованных представлений был обернут комментариями вида `--my_mv_name:begin` и `--my_mv_name:end`.

Например, следующий код создаст два материализованных представления, оба записывающих данные в одну и ту же целевую таблицу
модели. Имена материализованных представлений будут иметь вид `<model_name>_mv1` и `<model_name>_mv2`:

```sql
--mv1:begin
select a,b,c from {{ source('raw', 'table_1') }}
--mv1:end
union all
--mv2:begin
select a,b,c from {{ source('raw', 'table_2') }}
--mv2:end
```

> ВАЖНО!
>
> При обновлении модели с несколькими материализованными представлениями (MV), особенно при переименовании одного из имен MV,
> dbt-clickhouse не удаляет старое MV автоматически. Вместо этого
> вы получите следующее предупреждение:
> `Warning - Table <previous table name> was detected with the same pattern as model name <your model name> but was not found in this run. In case it is a renamed mv that was previously part of this model, drop it manually (!!!) `

#### Догрузка данных {#data-catch-up}

В настоящее время при создании материализованного представления (MV) целевая таблица сначала заполняется историческими данными, прежде чем само MV будет создано.

Другими словами, dbt-clickhouse сначала создает целевую таблицу и предварительно загружает в нее исторические данные на основе запроса, определенного для MV. Только после этого шага создается само MV.

Если вы предпочитаете не загружать исторические данные при создании MV, вы можете отключить это поведение, установив параметр конфигурации catchup в False:

```python
{{config(
    materialized='materialized_view',
    engine='MergeTree()',
    order_by='(id)',
    catchup=False
)}}
```

#### Обновляемые материализованные представления {#refreshable-materialized-views}

Для использования [обновляемых материализованных представлений](https://clickhouse.com/docs/en/materialized-view/refreshable-materialized-view)
настройте следующие параметры конфигурации по мере необходимости в вашей модели MV (все эти параметры должны быть установлены внутри
объекта конфигурации refreshable):


| Опция                 | Описание                                                                                                                                                                 | Обязательно | Значение по умолчанию |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------- | ------------- |
| refresh_interval      | Условие интервала (обязательно)                                                                                                                                          | Да       |               |
| randomize             | Условие рандомизации, появится после `RANDOMIZE FOR`                                                                                                                     |          |               |
| append                | Если установлено в `True`, каждое обновление вставляет строки в таблицу без удаления существующих строк. Вставка не является атомарной, как и обычный INSERT SELECT.    |          | False         |
| depends_on            | Список зависимостей для обновляемого материализованного представления. Укажите зависимости в следующем формате: `{schema}.{view_name}`                                  |          |               |
| depends_on_validation | Проверять ли существование зависимостей, указанных в `depends_on`. Если зависимость не содержит схему, проверка выполняется для схемы `default`                         |          | False         |

Пример конфигурации для обновляемого материализованного представления:

```python
{{
    config(
        materialized='materialized_view',
        refreshable={
            "interval": "EVERY 5 MINUTE",
            "randomize": "1 MINUTE",
            "append": True,
            "depends_on": ['schema.depend_on_model'],
            "depends_on_validation": True
        }
    )
}}
```

#### Ограничения {#limitations}

- При создании обновляемого материализованного представления (MV) в ClickHouse с зависимостью ClickHouse не выдает
  ошибку, если указанная зависимость не существует на момент создания. Вместо этого обновляемое MV остается в
  неактивном состоянии, ожидая выполнения зависимости перед началом обработки обновлений или обновления.
  Такое поведение является преднамеренным, но может привести к задержкам в доступности данных, если требуемая зависимость не будет
  устранена своевременно. Пользователям рекомендуется убедиться, что все зависимости правильно определены и существуют перед созданием обновляемого
  материализованного представления.
- На данный момент отсутствует фактическая «связь dbt» между материализованным представлением и его зависимостями, поэтому порядок создания не
  гарантируется.
- Функция обновления не тестировалась с несколькими материализованными представлениями, направленными на одну и ту же целевую модель.

### Материализация: dictionary (экспериментальная) {#materialization-dictionary}

См. тесты
в https://github.com/ClickHouse/dbt-clickhouse/blob/main/tests/integration/adapter/dictionary/test_dictionary.py для
примеров реализации
материализаций для словарей ClickHouse

### Материализация: distributed_table (экспериментальная) {#materialization-distributed-table}

Распределенная таблица создается следующими шагами:

1. Создается временное представление с SQL-запросом для получения правильной структуры
2. Создаются пустые локальные таблицы на основе представления
3. Создается распределенная таблица на основе локальных таблиц
4. Данные вставляются в распределенную таблицу, поэтому они распределяются по шардам без дублирования

Примечания:

- Запросы dbt-clickhouse теперь автоматически включают настройку `insert_distributed_sync = 1`, чтобы обеспечить корректное
  выполнение последующих операций инкрементальной
  материализации. Это может привести к более медленному выполнению некоторых вставок в распределенные таблицы, чем
  ожидалось.

#### Пример модели распределенной таблицы {#distributed-table-model-example}

```sql
{{
    config(
        materialized='distributed_table',
        order_by='id, created_at',
        sharding_key='cityHash64(id)',
        engine='ReplacingMergeTree'
    )
}}

select id, created_at, item
from {{ source('db', 'table') }}
```

#### Сгенерированные миграции {#distributed-table-generated-migrations}

```sql
CREATE TABLE db.table_local on cluster cluster (
    `id` UInt64,
    `created_at` DateTime,
    `item` String
)
    ENGINE = ReplacingMergeTree
    ORDER BY (id, created_at)
    SETTINGS index_granularity = 8192;

CREATE TABLE db.table on cluster cluster (
    `id` UInt64,
    `created_at` DateTime,
    `item` String
)
    ENGINE = Distributed ('cluster', 'db', 'table_local', cityHash64(id));
```

### Материализация: distributed_incremental (экспериментальная) {#materialization-distributed-incremental}

Инкрементальная модель основана на той же идее, что и распределенная таблица, основная сложность заключается в корректной обработке всех инкрементальных
стратегий.

1. _Стратегия добавления_ просто вставляет данные в распределенную таблицу.
2. _Стратегия Delete+Insert_ создает распределенную временную таблицу для работы со всеми данными на каждом шарде.
3. _Стратегия по умолчанию (устаревшая)_ создает распределенные временные и промежуточные таблицы по той же причине.

Заменяются только таблицы шардов, поскольку распределенная таблица не хранит данные.
Распределенная таблица перезагружается только при включении режима full_refresh или при возможном изменении структуры таблицы.

#### Пример инкрементальной распределенной модели {#distributed-incremental-model-example}


```sql
{{
    config(
        materialized='distributed_incremental',
        engine='MergeTree',
        incremental_strategy='append',
        unique_key='id,created_at'
    )
}}

select id, created_at, item
from {{ source('db', 'table') }}
```

#### Сгенерированные миграции {#distributed-incremental-generated-migrations}

```sql
CREATE TABLE db.table_local on cluster cluster (
    `id` UInt64,
    `created_at` DateTime,
    `item` String
)
    ENGINE = MergeTree
    SETTINGS index_granularity = 8192;

CREATE TABLE db.table on cluster cluster (
    `id` UInt64,
    `created_at` DateTime,
    `item` String
)
    ENGINE = Distributed ('cluster', 'db', 'table_local', cityHash64(id));
```

### Снимки {#snapshot}

Снимки dbt позволяют фиксировать изменения изменяемой модели с течением времени. Это, в свою очередь, позволяет выполнять запросы к моделям на определённый момент времени, где аналитики могут «заглянуть в прошлое» и увидеть предыдущее состояние модели. Эта функциональность поддерживается коннектором ClickHouse и настраивается с использованием следующего синтаксиса:

Блок конфигурации в `snapshots/<model_name>.sql`:

```python
{{
   config(
     schema = "<schema-name>",
     unique_key = "<column-name>",
     strategy = "<strategy>",
     updated_at = "<updated-at-column-name>",
   )
}}
```

Для получения дополнительной информации о конфигурации обратитесь к справочной странице [конфигурации снимков](https://docs.getdbt.com/docs/build/snapshots#snapshot-configs).

### Контракты и ограничения {#contracts-and-constraints}

Поддерживаются только контракты с точным соответствием типов столбцов. Например, контракт с типом столбца UInt32 завершится ошибкой, если модель возвращает UInt64 или другой целочисленный тип.
ClickHouse также поддерживает _только_ ограничения `CHECK` на всю таблицу/модель. Ограничения первичного ключа, внешнего ключа, уникальности и ограничения CHECK на уровне столбцов не поддерживаются.
(См. документацию ClickHouse по первичным ключам и ключам сортировки.)

### Дополнительные макросы ClickHouse {#additional-clickhouse-macros}

#### Служебные макросы материализации моделей {#model-materialization-utility-macros}

Следующие макросы включены для упрощения создания специфичных для ClickHouse таблиц и представлений:

- `engine_clause` — использует свойство конфигурации модели `engine` для назначения движка таблицы ClickHouse. dbt-clickhouse по умолчанию использует движок `MergeTree`.
- `partition_cols` — использует свойство конфигурации модели `partition_by` для назначения ключа партиционирования ClickHouse. По умолчанию ключ партиционирования не назначается.
- `order_cols` — использует конфигурацию модели `order_by` для назначения ключа сортировки ClickHouse. Если не указано, ClickHouse будет использовать пустой tuple(), и таблица будет несортированной.
- `primary_key_clause` — использует свойство конфигурации модели `primary_key` для назначения первичного ключа ClickHouse. По умолчанию первичный ключ не задан, и ClickHouse будет использовать выражение order by в качестве первичного ключа.
- `on_cluster_clause` — использует свойство профиля `cluster` для добавления выражения `ON CLUSTER` к определённым операциям dbt: распределённым материализациям, созданию представлений, созданию баз данных.
- `ttl_config` — использует свойство конфигурации модели `ttl` для назначения выражения TTL таблицы ClickHouse. По умолчанию TTL не назначается.

#### Вспомогательный макрос s3Source {#s3source-helper-macro}

Макрос `s3source` упрощает процесс выборки данных ClickHouse непосредственно из S3 с использованием табличной функции S3 ClickHouse. Он работает путём заполнения параметров табличной функции S3 из именованного словаря конфигурации (имя словаря должно заканчиваться на `s3`). Макрос сначала ищет словарь в `vars` профиля, а затем в конфигурации модели. Словарь может содержать любые из следующих ключей, используемых для заполнения параметров табличной функции S3:


| Имя аргумента         | Описание                                                                                                                                                                                    |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| bucket                | Базовый URL бакета, например `https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi`. Если протокол не указан, по умолчанию используется `https://`.                          |
| path                  | Путь S3 для запроса к таблице, например `/trips_4.gz`. Поддерживаются подстановочные символы S3.                                                                                           |
| fmt                   | Ожидаемый входной формат ClickHouse (например, `TSV` или `CSVWithNames`) для указанных объектов S3.                                                                                        |
| structure             | Структура столбцов данных в бакете в виде списка пар имя/тип данных, например `['id UInt32', 'date DateTime', 'value String']`. Если не указана, ClickHouse определит структуру автоматически. |
| aws_access_key_id     | Идентификатор ключа доступа S3.                                                                                                                                                             |
| aws_secret_access_key | Секретный ключ S3.                                                                                                                                                                          |
| role_arn              | ARN IAM-роли ClickhouseAccess для безопасного доступа к объектам S3. Дополнительную информацию см. в [документации](https://clickhouse.com/docs/en/cloud/security/secure-s3).              |
| compression           | Метод сжатия, используемый для объектов S3. Если не указан, ClickHouse попытается определить метод сжатия на основе имени файла.                                                           |

Примеры использования этого макроса см. в [тестовом файле S3](https://github.com/ClickHouse/dbt-clickhouse/blob/main/tests/integration/adapter/clickhouse/test_clickhouse_s3.py).

#### Поддержка межбазовых макросов {#cross-database-macro-support}

dbt-clickhouse поддерживает большинство межбазовых макросов, включенных в `dbt Core`, за следующими исключениями:

- SQL-функция `split_part` реализована в ClickHouse с использованием функции splitByChar. Эта функция требует
  использования константной строки в качестве разделителя, поэтому параметр `delimeter` этого макроса будет
  интерпретироваться как строка, а не как имя столбца
- Аналогично, SQL-функция `replace` в ClickHouse требует константных строк для параметров `old_chars` и `new_chars`,
  поэтому эти параметры будут интерпретироваться как строки, а не как имена столбцов при вызове этого макроса.
