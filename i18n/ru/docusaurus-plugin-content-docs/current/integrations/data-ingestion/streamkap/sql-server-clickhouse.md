---
sidebar_label: 'SQL Server CDC для ClickHouse'
sidebar_position: 13
keywords: ['clickhouse', 'Streamkap', 'CDC', 'sql server', 'подключение', 'интеграция', 'etl', 'интеграция данных', 'фиксация изменений данных']
slug: /integrations/data-ingestion/etl-tools/sql-server-clickhouse
description: 'Потоковая передача данных из SQL Server в ClickHouse для быстрой аналитики'
title: 'Потоковая передача данных из SQL Server в ClickHouse для быстрой аналитики'
doc_type: 'guide'
---

import ConnectionDetails from '@site/i18n/ru/docusaurus-plugin-content-docs/current/_snippets/_gather_your_details_http.mdx';
import Image from '@theme/IdealImage';
import image1 from '@site/static/images/integrations/data-ingestion/etl-tools/image1.png';
import image2 from '@site/static/images/integrations/data-ingestion/etl-tools/image2.png';
import image3 from '@site/static/images/integrations/data-ingestion/etl-tools/image3.png';


# Потоковая передача данных из SQL Server в ClickHouse для высокоскоростной аналитики: пошаговое руководство \{#streaming-data-from-sql-server-to-clickhouse-for-fast-analytics-step-by-step-guide\}

В этой статье мы пошагово покажем, как организовать потоковую передачу данных из SQL Server в ClickHouse. ClickHouse идеально подходит, если вам нужна сверхбыстрая аналитика для внутренних отчётных панелей или клиентских дашбордов. Мы по шагам пройдём подготовку обеих баз данных, настройку соединения между ними и, наконец, покажем, как использовать [Streamkap](https://streamkap.com) для потоковой передачи ваших данных. Если SQL Server обслуживает ваши повседневные операции, а для аналитики вам нужна скорость и мощь ClickHouse, вы обратились по адресу.

## Зачем передавать потоковые данные из SQL Server в ClickHouse? \{#why-stream-data-from-sql-server-to-clickhouse\}

Если вы читаете это, значит, вы, вероятно, уже столкнулись с проблемой: SQL Server отлично подходит для транзакций, но он просто не рассчитан на выполнение тяжёлых аналитических запросов в режиме реального времени.

Здесь и раскрываются сильные стороны ClickHouse. ClickHouse создан для аналитики с сверхбыстрыми агрегациями и построением отчётов даже на очень больших наборах данных. Поэтому, если вы настроите потоковый конвейер CDC, который будет передавать ваши транзакционные данные в ClickHouse, вы сможете выполнять молниеносную отчётность — это идеально для операционной аналитики, продуктовых команд или клиентских дашбордов.

Типичные варианты использования:

- Внутренняя отчётность, которая не замедляет production‑приложения
- Клиентские дашборды, которым важны высокая скорость и актуальность данных
- Потоковая обработка событий, например постоянное обновление логов активности пользователей для аналитики

## Что вам понадобится, чтобы начать работу \{#what-youll-need-to-get-started\}

Прежде чем углубляться в подробности, подготовьте следующее:

### Предварительные требования \{#prerequisites\}

- Запущенный экземпляр SQL Server  

- В этом руководстве мы используем AWS RDS для SQL Server, но подойдёт любой современный экземпляр SQL Server. [Настройка AWS SQL Server с нуля.](https://streamkap.com/blog/how-to-stream-data-from-rds-sql-server-to-clickhouse-cloud-using-streamkap%23setting-up-a-new-rds-sql-server-from-scratch)
- Экземпляр ClickHouse  

- Самостоятельно развернутый или облачный. [Настройка ClickHouse с нуля.](https://streamkap.com/blog/how-to-stream-data-from-rds-sql-server-to-clickhouse-cloud-using-streamkap%23creating-a-new-clickhouse-account)
- Streamkap  

- Этот инструмент будет основой вашего конвейера потоковой обработки данных.

### Информация о подключении \{#connection-info\}

Убедитесь, что у вас есть:

- Адрес сервера SQL Server, порт, имя пользователя и пароль. Рекомендуется создать для Streamkap отдельного пользователя и роль для доступа к вашей базе данных SQL Server. [Ознакомьтесь с нашей документацией по конфигурации.](https://www.google.com/url?q=https://docs.streamkap.com/docs/sql-server&sa=D&source=editors&ust=1760992472358213&usg=AOvVaw3jfocCF1VSijgsq1OCpZPj)
- Адрес сервера ClickHouse, порт, имя пользователя и пароль. Списки доступа по IP в ClickHouse определяют, какие сервисы могут подключаться к вашей базе данных ClickHouse. [Следуйте инструкциям здесь.](https://www.google.com/url?q=https://docs.streamkap.com/docs/clickhouse&sa=D&source=editors&ust=1760992472359060&usg=AOvVaw3H1XqqwvqAso_TQPNBKEhD)
- Таблица (или таблицы), из которых вы хотите передавать данные в поток — пока начните с одной

## Настройка SQL Server в качестве источника \{#setting-up-sql-server-as-a-source\}

Давайте приступим!

### Шаг 1: Создание источника SQL Server в Streamkap \{#step-1-creating-a-sql-server-source-in-streamkap\}

Начнём с настройки подключения к источнику. Так Streamkap узнаёт, откуда забирать изменения.

Сделайте следующее:

1. Откройте Streamkap и перейдите в раздел источников.
2. Создайте новый источник.

- Дайте ему понятное имя (например, sqlserver-demo-source).

3. Заполните параметры подключения к SQL Server:

- Host (например, your-db-instance.rds.amazonaws.com)
- Port (порт по умолчанию для SQL Server — 3306)
- Username и Password
- Database name

<Image img={image3} size="lg" />

#### Что происходит за кулисами \{#whats-happening-behind-the-scenes\}

<Image img={image1} size="lg" />

Когда вы всё это настроите, Streamkap подключится к вашему SQL Server и обнаружит таблицы. В этом примере мы выберем таблицу, в которую уже поступают потоковые данные, например события или транзакции.

## Создание назначения ClickHouse \{#creating-a-clickhouse-destination\}

Теперь настроим назначение, в которое будем отправлять все эти данные.

### Шаг 2. Добавьте назначение ClickHouse в Streamkap \{#step-2-add-a-clickhouse-destination-in-streamkap\}

Аналогично источнику данных, создадим назначение, используя наши параметры подключения к ClickHouse.

#### Шаги: \{#steps\}

1. Перейдите в раздел Destinations в Streamkap.
2. Добавьте новое назначение — выберите ClickHouse в качестве типа назначения.
3. Введите данные подключения к ClickHouse:

- Host
- Port (по умолчанию 9000)
- Username и Password
- Имя базы данных

Пример скриншота: добавление нового назначения ClickHouse в панели управления Streamkap.

### Режим upsert: что это такое? \{#upsert-mode-what-is-that\}

Это важный шаг: мы хотим использовать в ClickHouse режим «upsert», который внутренне использует движок ReplacingMergeTree в ClickHouse. Это позволяет эффективно объединять входящие записи и обрабатывать обновления после приёма, используя то, что в ClickHouse называется «слиянием частей данных» (part merging).

- Это гарантирует, что ваша целевая таблица не заполнится дубликатами, когда на стороне SQL Server происходят изменения.

### Обработка изменений схемы \{#handling-schema-evolution\}

У ClickHouse и SQL Server иногда отличаются наборы столбцов — особенно когда приложение уже работает в продакшене, а разработчики продолжают «на лету» добавлять новые столбцы.

- Хорошая новость: Streamkap умеет обрабатывать базовые изменения схемы. Это значит, что если вы добавите новый столбец в SQL Server, он появится и в ClickHouse.

Просто выберите «schema evolution» в настройках назначения. Позже вы всегда сможете при необходимости это изменить.

## Создание конвейера потоковой обработки данных \{#building-the-streaming-pipeline\}

Когда источник и получатель данных настроены, пора перейти к самой интересной части — потоковой передаче данных!

### Шаг 3: Настройка конвейера в Streamkap \{#step-3-set-up-the-pipeline-in-streamkap\}

#### Настройка конвейера \{#pipeline-setup\}

1. Перейдите на вкладку Pipelines в Streamkap.  

2. Создайте новый конвейер.  

3. Выберите ваш источник SQL Server (sqlserver-demo-source).  

4. Выберите ваш приёмник ClickHouse (clickhouse-tutorial-destination).  

5. Выберите таблицу, данные из которой нужно передавать в потоковом режиме — допустим, это events.  

6. Настройте фиксацию изменений данных (CDC).  

- В этом запуске мы будем передавать только новые данные (на первых порах можно пропустить заполнение исторических данных, backfilling, и сосредоточиться на CDC-событиях).

Скриншот настроек конвейера — выбор источника, приёмника и таблицы.

#### Нужно ли выполнять бэкфилл? \{#should-you-backfill\}

<Image img={image2} size="lg" />

Вы можете спросить: нужно ли мне догружать старые данные?

Во многих аналитических сценариях можно просто начать транслировать изменения с текущего момента, но при необходимости вы всегда сможете позже загрузить и исторические данные.

Просто выберите вариант «Don’t backfill» на данном этапе, если у вас нет какой‑то конкретной потребности.

## Стриминг в действии: чего ожидать  \{#streaming-in-action-what-to-expect\}

Теперь ваш конвейер данных настроен и работает!

### Шаг 4. Наблюдайте за потоком данных \{#step-4-watch-the-data-stream\}

Вот что происходит:

* Когда новые данные попадают в исходную таблицу в SQL Server, конвейер данных Streamkap фиксирует изменения и отправляет их в ClickHouse.
* ClickHouse (благодаря ReplacingMergeTree и слиянию частей) принимает эти строки и объединяет обновления.
* Схема не отстаёт — добавьте столбцы в SQL Server, и они появятся в ClickHouse тоже.

Онлайн‑дашборд или логи показывают, как в реальном времени растёт количество строк в ClickHouse и SQL Server.

Вы буквально видите, как число строк в ClickHouse растёт по мере того, как SQL Server получает данные.

```sql
-- Example: Checking rows in ClickHouse 
SELECT COUNT(*) FROM analytics.events; |
```

В сценариях с высокой нагрузкой возможна некоторая задержка, но в большинстве случаев данные поступают практически в режиме реального времени.


## Под капотом: что на самом деле делает Streamkap? \{#under-the-hood-whats-streamkap-actually-doing\}

Чтобы немного прояснить, как это работает:

- Streamkap отслеживает бинарный лог SQL Server (тот же лог, который используется для репликации).
- Как только в вашей таблице вставляется, обновляется или удаляется строка, Streamkap фиксирует это событие.
- Он преобразует событие в формат, понятный ClickHouse, и отправляет его — мгновенно применяя изменения в вашей аналитической базе данных.

Это не просто ETL — это полноценная CDC (фиксация изменений данных) в режиме реального времени.

## Дополнительные параметры \{#advanced-options\}

### Режимы Upsert и Insert \{#upsert-vs-insert-modes\}

В чём разница между простым добавлением каждой строки (режим Insert) и режимом, в котором обновления и удаления тоже корректно отражаются (режим Upsert)?

- Режим Insert: Каждая новая строка добавляется — даже если это обновление, вы получите дубликаты.
- Режим Upsert: Обновления существующих строк перезаписывают уже имеющиеся данные — значительно лучше для поддержания аналитики актуальной и чистой.

### Обработка изменений схемы \{#handling-schema-changes\}

Приложения меняются — и схемы тоже. В этом пайплайне:

- Добавили новый столбец в операционную таблицу?  
  Streamkap автоматически обнаружит его и добавит на стороне ClickHouse.
- Убрали столбец?  
  В зависимости от настроек может понадобиться миграция, но большинство добавлений проходят без проблем.

## Мониторинг в реальной эксплуатации: отслеживание состояния конвейера данных \{#real-world-monitoring-keeping-tabs-on-the-pipeline\}

### Проверка состояния конвейера \{#checking-pipeline-health\}

Streamkap предоставляет панель мониторинга, на которой вы можете:

- Смотреть задержку конвейера (насколько свежие ваши данные?)
- Отслеживать количество строк и пропускную способность
- Получать оповещения, если что-то пошло не так

Пример панели мониторинга: график задержки, количество строк, индикаторы состояния.

### Основные метрики, за которыми следует наблюдать \{#common-metrics-to-watch\}

- Задержка (Lag): насколько сильно ClickHouse отстает от SQL Server?
- Пропускная способность (Throughput): строк в секунду
- Уровень ошибок (Error Rate): должен быть близок к нулю

## Переход к боевой эксплуатации: выполнение запросов в ClickHouse \{#going-live-querying-clickhouse\}

Теперь, когда ваши данные находятся в ClickHouse, вы можете выполнять по ним запросы с помощью всех доступных инструментов для быстрой аналитики. Ниже приведён простой пример:

```sql
-- See top 10 active users in the last hour
SELECT user\_id, COUNT(*) AS actionsFROM analytics.eventsWHERE event\_time >= now() - INTERVAL 1 HOURGROUP BY user\_idORDER BY actions DESCLIMIT 10;
```

Используйте ClickHouse совместно с инструментами для построения дашбордов, такими как Grafana, Superset или Redash, чтобы создать полноценную систему отчетности.


## Следующие шаги и углублённое изучение \{#next-steps-and-deep-dives\}

Этот пошаговый пример лишь слегка приоткрывает ваши возможности. Освоив базу, вы можете изучить следующее:

- Настройку потоков с фильтрацией (синхронизировать только отдельные таблицы/столбцы)
- Потоковую передачу данных из нескольких источников в одну аналитическую БД
- Совместное использование с S3/озёрами данных для холодного хранения
- Автоматизацию миграций схемы при изменении таблиц
- Повышение безопасности конвейера с помощью SSL и правил брандмауэра

Следите за [блогом Streamkap](https://streamkap.com/blog) для более подробных руководств.

## FAQ и устранение неполадок \{#faq-and-troubleshooting\}

Q: Работает ли это с облачными базами данных?  
A: Да! В этом примере мы использовали AWS RDS. Просто убедитесь, что открыты нужные порты.

Q: Что насчёт производительности?  
A: ClickHouse очень быстр. Узким местом обычно является сеть или скорость binlog исходной БД, но в большинстве случаев задержка будет меньше секунды.

Q: Можно ли обрабатывать и операции удаления?  
A: Конечно. В режиме upsert операции удаления также помечаются и обрабатываются в ClickHouse.

## Подводим итоги \{#wrapping-up\}

Теперь у вас есть полное представление о том, как стримить данные из SQL Server в ClickHouse с помощью Streamkap. Это быстро, гибко и идеально подходит для команд, которым нужна аналитика почти в реальном времени без излишней нагрузки на продуктивные базы данных.

Готовы попробовать?  
Перейдите на [страницу регистрации](https://app.streamkap.com/account/sign-up) и дайте нам знать, если вы хотите, чтобы мы осветили такие темы, как:

- Upsert vs. Insert и все технические детали каждого подхода
- Сквозная задержка: насколько быстро вы можете получить финальное аналитическое представление данных?
- Оптимизация производительности и пропускная способность
- Реальные дашборды на основе этого стека

Спасибо, что дочитали! Удачного стриминга.