---
slug: /data-modeling/schema-design
title: 'Проектирование схемы'
description: 'Оптимизация схемы ClickHouse для повышения производительности запросов'
keywords: ['schema', 'schema design', 'query optimization']
doc_type: 'guide'
---

import stackOverflowSchema from '@site/static/images/data-modeling/stackoverflow-schema.png';
import schemaDesignIndices from '@site/static/images/data-modeling/schema-design-indices.png';
import Image from '@theme/IdealImage';

Понимание принципов эффективного проектирования схемы имеет ключевое значение для оптимизации производительности ClickHouse и предполагает выбор решений, часто связанных с компромиссами, при этом оптимальный подход зависит от выполняемых запросов, а также таких факторов, как частота обновления данных, требования к задержке и объем данных. В этом руководстве представлен обзор лучших практик проектирования схем и подходов к моделированию данных для оптимизации производительности ClickHouse.


## Набор данных Stack Overflow {#stack-overflow-dataset}

Для примеров в этом руководстве мы используем подмножество набора данных Stack Overflow. Оно содержит все публикации, голоса, пользователей, комментарии и значки, которые появились на Stack Overflow с 2008 года по апрель 2024 года. Эти данные доступны в формате Parquet по приведенным ниже схемам в корзине S3 `s3://datasets-documentation/stackoverflow/parquet/`:

> Указанные первичные ключи и связи не обеспечиваются ограничениями (Parquet — это формат файла, а не таблицы) и только показывают, как данные связаны между собой и какие уникальные ключи они содержат.

<Image img={stackOverflowSchema} size='lg' alt='Схема Stack Overflow' />

<br />

Набор данных Stack Overflow содержит несколько связанных таблиц. При выполнении любой задачи моделирования данных мы рекомендуем пользователям сначала сосредоточиться на загрузке основной таблицы. Это не обязательно самая большая таблица, а скорее та, на которую вы ожидаете получать большинство аналитических запросов. Это позволит вам ознакомиться с основными концепциями и типами ClickHouse, что особенно важно, если вы работали преимущественно с OLTP-системами. Эта таблица может потребовать переработки по мере добавления дополнительных таблиц для полного использования возможностей ClickHouse и достижения оптимальной производительности.

Приведенная выше схема намеренно не является оптимальной для целей этого руководства.


## Создание начальной схемы {#establish-initial-schema}

Поскольку таблица `posts` будет целью для большинства аналитических запросов, мы сосредоточимся на создании схемы для этой таблицы. Данные доступны в публичном S3-бакете `s3://datasets-documentation/stackoverflow/parquet/posts/*.parquet`, где каждый файл содержит данные за один год.

> Загрузка данных из S3 в формате Parquet является наиболее распространённым и предпочтительным способом загрузки данных в ClickHouse. ClickHouse оптимизирован для обработки Parquet и может считывать и вставлять десятки миллионов строк из S3 в секунду.

ClickHouse предоставляет возможность автоматического определения схемы для идентификации типов данных в наборе данных. Это поддерживается для всех форматов данных, включая Parquet. Мы можем использовать эту возможность для определения типов ClickHouse с помощью табличной функции s3 и команды [`DESCRIBE`](/sql-reference/statements/describe-table). Обратите внимание, что ниже мы используем шаблон `*.parquet` для чтения всех файлов в папке `stackoverflow/parquet/posts`.

```sql
DESCRIBE TABLE s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/*.parquet')
SETTINGS describe_compact_output = 1

┌─name──────────────────┬─type───────────────────────────┐
│ Id                    │ Nullable(Int64)               │
│ PostTypeId            │ Nullable(Int64)               │
│ AcceptedAnswerId      │ Nullable(Int64)               │
│ CreationDate          │ Nullable(DateTime64(3, 'UTC')) │
│ Score                 │ Nullable(Int64)               │
│ ViewCount             │ Nullable(Int64)               │
│ Body                  │ Nullable(String)              │
│ OwnerUserId           │ Nullable(Int64)               │
│ OwnerDisplayName      │ Nullable(String)              │
│ LastEditorUserId      │ Nullable(Int64)               │
│ LastEditorDisplayName │ Nullable(String)              │
│ LastEditDate          │ Nullable(DateTime64(3, 'UTC')) │
│ LastActivityDate      │ Nullable(DateTime64(3, 'UTC')) │
│ Title                 │ Nullable(String)              │
│ Tags                  │ Nullable(String)              │
│ AnswerCount           │ Nullable(Int64)               │
│ CommentCount          │ Nullable(Int64)               │
│ FavoriteCount         │ Nullable(Int64)               │
│ ContentLicense        │ Nullable(String)              │
│ ParentId              │ Nullable(String)              │
│ CommunityOwnedDate    │ Nullable(DateTime64(3, 'UTC')) │
│ ClosedDate            │ Nullable(DateTime64(3, 'UTC')) │
└───────────────────────┴────────────────────────────────┘
```

> [Табличная функция s3](/sql-reference/table-functions/s3) позволяет выполнять запросы к данным в S3 непосредственно из ClickHouse. Эта функция совместима со всеми форматами файлов, поддерживаемыми ClickHouse.

Это даёт нам начальную неоптимизированную схему. По умолчанию ClickHouse сопоставляет эти типы с эквивалентными типами Nullable. Мы можем создать таблицу ClickHouse, используя эти типы, с помощью простой команды `CREATE EMPTY AS SELECT`.

```sql
CREATE TABLE posts
ENGINE = MergeTree
ORDER BY () EMPTY AS
SELECT * FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/*.parquet')
```

Несколько важных моментов:

Наша таблица posts пуста после выполнения этой команды. Данные не были загружены.
Мы указали MergeTree в качестве движка таблицы. MergeTree — это наиболее распространённый движок таблиц ClickHouse, который вы, скорее всего, будете использовать. Это универсальный инструмент в вашем арсенале ClickHouse, способный обрабатывать петабайты данных и обслуживать большинство аналитических сценариев использования. Существуют и другие движки таблиц для таких сценариев, как CDC, которые требуют поддержки эффективных обновлений.

Конструкция `ORDER BY ()` означает, что у нас нет индекса и, более конкретно, нет порядка в наших данных. Подробнее об этом позже. Пока просто имейте в виду, что все запросы будут требовать линейного сканирования.

Чтобы подтвердить, что таблица была создана:

```sql
SHOW CREATE TABLE posts

```


CREATE TABLE posts
(
`Id` Nullable(Int64),
`PostTypeId` Nullable(Int64),
`AcceptedAnswerId` Nullable(Int64),
`CreationDate` Nullable(DateTime64(3, &#39;UTC&#39;)),
`Score` Nullable(Int64),
`ViewCount` Nullable(Int64),
`Body` Nullable(String),
`OwnerUserId` Nullable(Int64),
`OwnerDisplayName` Nullable(String),
`LastEditorUserId` Nullable(Int64),
`LastEditorDisplayName` Nullable(String),
`LastEditDate` Nullable(DateTime64(3, &#39;UTC&#39;)),
`LastActivityDate` Nullable(DateTime64(3, &#39;UTC&#39;)),
`Title` Nullable(String),
`Tags` Nullable(String),
`AnswerCount` Nullable(Int64),
`CommentCount` Nullable(Int64),
`FavoriteCount` Nullable(Int64),
`ContentLicense` Nullable(String),
`ParentId` Nullable(String),
`CommunityOwnedDate` Nullable(DateTime64(3, &#39;UTC&#39;)),
`ClosedDate` Nullable(DateTime64(3, &#39;UTC&#39;))
)
ENGINE = MergeTree(&#39;/clickhouse/tables/{uuid}/{shard}&#39;, &#39;{replica}&#39;)
ORDER BY tuple()

````

После определения начальной схемы мы можем заполнить таблицу данными с помощью `INSERT INTO SELECT`, считывая данные через табличную функцию s3. Следующий запрос загружает данные `posts` примерно за 2 минуты на 8-ядерном инстансе ClickHouse Cloud.

```sql
INSERT INTO posts SELECT * FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/*.parquet')

0 rows in set. Elapsed: 148.140 sec. Processed 59.82 million rows, 38.07 GB (403.80 thousand rows/s., 257.00 MB/s.)
````

> Приведённый выше запрос загружает 60 млн строк. Хотя для ClickHouse это немного, пользователи с более медленным интернет-соединением могут захотеть загружать только часть данных. Это можно сделать, просто указав годы, которые требуется загрузить, с помощью glob-шаблона, например `https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/2008.parquet` или `https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/{2008, 2009}.parquet`. См. [здесь](/sql-reference/table-functions/file#globs-in-path), как glob-шаблоны могут использоваться для выбора подмножеств файлов.


## Оптимизация типов данных {#optimizing-types}

Один из секретов высокой производительности запросов ClickHouse — это сжатие данных.

Меньше данных на диске означает меньше операций ввода-вывода и, следовательно, более быстрые запросы и вставки. Накладные расходы любого алгоритма сжатия на процессор в большинстве случаев компенсируются сокращением операций ввода-вывода. Поэтому улучшение сжатия данных должно быть первоочередной задачей при оптимизации производительности запросов ClickHouse.

> Чтобы понять, почему ClickHouse так эффективно сжимает данные, рекомендуем [эту статью](https://clickhouse.com/blog/optimize-clickhouse-codecs-compression-schema). Вкратце: как колоночная база данных, ClickHouse записывает значения в порядке столбцов. Если эти значения отсортированы, одинаковые значения располагаются рядом друг с другом. Алгоритмы сжатия используют непрерывные шаблоны данных. Кроме того, ClickHouse предоставляет кодеки и детализированные типы данных, которые позволяют пользователям дополнительно настраивать методы сжатия.

На сжатие в ClickHouse влияют три основных фактора: ключ сортировки, типы данных и используемые кодеки. Все они настраиваются через схему.

Наибольшее первоначальное улучшение сжатия и производительности запросов можно получить с помощью простого процесса оптимизации типов. Для оптимизации схемы можно применить несколько простых правил:

- **Используйте строгие типы** — В нашей исходной схеме для многих столбцов, которые явно являются числовыми, использовался тип String. Использование правильных типов обеспечит ожидаемую семантику при фильтрации и агрегации. То же самое относится к типам дат, которые были корректно указаны в файлах Parquet.
- **Избегайте nullable-столбцов** — По умолчанию указанные выше столбцы считаются допускающими Null. Тип Nullable позволяет запросам различать пустое значение и Null. Это создает отдельный столбец типа UInt8. Этот дополнительный столбец должен обрабатываться каждый раз, когда пользователь работает с nullable-столбцом. Это приводит к использованию дополнительного дискового пространства и почти всегда негативно влияет на производительность запросов. Используйте Nullable только в том случае, если существует разница между пустым значением по умолчанию для типа и Null. Например, значение 0 для пустых значений в столбце `ViewCount` будет достаточным для большинства запросов и не повлияет на результаты. Если пустые значения должны обрабатываться по-другому, их часто можно исключить из запросов с помощью фильтра.
- **Используйте минимальную точность для числовых типов** — ClickHouse предоставляет ряд числовых типов, предназначенных для различных числовых диапазонов и точности. Всегда стремитесь минимизировать количество битов, используемых для представления столбца. Помимо целых чисел разного размера, например Int16, ClickHouse предлагает беззнаковые варианты, минимальное значение которых равно 0. Они позволяют использовать меньше битов для столбца, например, UInt16 имеет максимальное значение 65535, что в два раза больше, чем у Int16. По возможности отдавайте предпочтение этим типам перед более крупными знаковыми вариантами.
- **Минимальная точность для типов дат** — ClickHouse поддерживает несколько типов дат и времени. Date и Date32 можно использовать для хранения дат, причем последний поддерживает больший диапазон дат за счет большего количества битов. DateTime и DateTime64 обеспечивают поддержку дат и времени. DateTime ограничен гранулярностью до секунды и использует 32 бита. DateTime64, как следует из названия, использует 64 бита, но обеспечивает поддержку до наносекундной гранулярности. Как всегда, выбирайте более грубую версию, приемлемую для запросов, минимизируя необходимое количество битов.
- **Используйте LowCardinality** — Числовые столбцы, строки, столбцы Date или DateTime с небольшим количеством уникальных значений потенциально могут быть закодированы с использованием типа LowCardinality. Этот словарь кодирует значения, уменьшая размер на диске. Рассмотрите это для столбцов с менее чем 10 тысячами уникальных значений.
- **FixedString для особых случаев** — Строки фиксированной длины можно кодировать с помощью типа FixedString, например, коды языков и валют. Это эффективно, когда данные имеют длину ровно N байт. Во всех остальных случаях это, вероятно, снизит эффективность, и предпочтительнее использовать LowCardinality.
- **Enum для валидации данных** — Тип Enum можно использовать для эффективного кодирования перечислимых типов. Enum может быть 8 или 16 бит в зависимости от количества уникальных значений, которые необходимо хранить. Рассмотрите возможность использования этого типа, если вам нужна соответствующая валидация во время вставки (необъявленные значения будут отклонены) или вы хотите выполнять запросы, использующие естественный порядок значений Enum, например, представьте столбец обратной связи, содержащий ответы пользователей `Enum(':(' = 1, ':|' = 2, ':)' = 3)`.

> Совет: Чтобы найти диапазон всех столбцов и количество различных значений, пользователи могут использовать простой запрос `SELECT * APPLY min, * APPLY  max, * APPLY uniq FROM table FORMAT Vertical`. Рекомендуем выполнять это на меньшем подмножестве данных, так как это может быть ресурсоемко. Этот запрос требует, чтобы числовые значения были определены как таковые для получения точного результата, то есть не как String.

Применяя эти простые правила к нашей таблице постов, мы можем определить оптимальный тип для каждого столбца:


| Колонка                 | Числовой | Мин, Макс                                                    | Уникальные значения | Null | Комментарий                                                                                                       | Оптимальный тип                                                                                                                                              |
| ----------------------- | -------- | ------------------------------------------------------------ | ------------------- | ---- | ----------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `PostTypeId`            | Да       | 1, 8                                                         | 8                   | Нет  |                                                                                                                   | `Enum('Question' = 1, 'Answer' = 2, 'Wiki' = 3, 'TagWikiExcerpt' = 4, 'TagWiki' = 5, 'ModeratorNomination' = 6, 'WikiPlaceholder' = 7, 'PrivilegeWiki' = 8)` |
| `AcceptedAnswerId`      | Да       | 0, 78285170                                                  | 12282094            | Да   | Различать Null и значение 0                                                                                       | UInt32                                                                                                                                                       |
| `CreationDate`          | Нет      | 2008-07-31 21:42:52.667000000, 2024-03-31 23:59:17.697000000 | *                   | Нет  | Если точность до миллисекунд не требуется, используйте DateTime                                                   | DateTime                                                                                                                                                     |
| `Score`                 | Да       | -217, 34970                                                  | 3236                | Нет  |                                                                                                                   | Int32                                                                                                                                                        |
| `ViewCount`             | Да       | 2, 13962748                                                  | 170867              | Нет  |                                                                                                                   | UInt32                                                                                                                                                       |
| `Body`                  | Нет      | -                                                            | *                   | Нет  |                                                                                                                   | Строка                                                                                                                                                       |
| `OwnerUserId`           | Да       | -1, 4056915                                                  | 6256237             | Да   |                                                                                                                   | Int32                                                                                                                                                        |
| `OwnerDisplayName`      | Нет      | -                                                            | 181251              | Да   | Считать Null пустой строкой                                                                                       | Строка                                                                                                                                                       |
| `LastEditorUserId`      | Да       | -1, 9999993                                                  | 1104694             | Да   | 0 — неиспользуемое значение, его можно использовать для Null                                                      | Int32                                                                                                                                                        |
| `LastEditorDisplayName` | Нет      | *                                                            | 70952               | Да   | Рассматривать Null как пустую строку. Протестировали `LowCardinality`, преимуществ нет                            | String                                                                                                                                                       |
| `LastEditDate`          | Нет      | 2008-08-01 13:24:35.051000000, 2024-04-06 21:01:22.697000000 | -                   | Нет  | Миллисекундная точность не нужна, используйте DateTime                                                            | DateTime                                                                                                                                                     |
| `LastActivityDate`      | Нет      | 2008-08-01 12:19:17.417000000, 2024-04-06 21:01:22.697000000 | *                   | Нет  | Если миллисекундная точность не нужна, используйте DateTime                                                       | DateTime                                                                                                                                                     |
| `Название`              | Нет      | -                                                            | *                   | Нет  | Считать Null пустой строкой                                                                                       | Строка                                                                                                                                                       |
| `Теги`                  | Нет      | -                                                            | *                   | Нет  | Считать Null пустой строкой                                                                                       | Строка                                                                                                                                                       |
| `AnswerCount`           | Да       | 0, 518                                                       | 216                 | Нет  | Считать Null и 0 равнозначными                                                                                    | UInt16                                                                                                                                                       |
| `CommentCount`          | Да       | 0, 135                                                       | 100                 | Нет  | Считать Null и 0 одинаковыми значениями                                                                           | UInt8                                                                                                                                                        |
| `FavoriteCount`         | Да       | 0, 225                                                       | 6                   | Да   | Считать Null и 0 одинаковыми значениями                                                                           | UInt8                                                                                                                                                        |
| `ContentLicense`        | Нет      | -                                                            | 3                   | Нет  | LowCardinality быстрее, чем FixedString                                                                           | LowCardinality(String)                                                                                                                                       |
| `ParentId`              | Нет      | *                                                            | 20696028            | Да   | Считать Null пустой строкой                                                                                       | Строка                                                                                                                                                       |
| `CommunityOwnedDate`    | Нет      | 2008-08-12 04:59:35.017000000, 2024-04-01 05:36:41.380000000 | -                   | Да   | Используйте значение по умолчанию 1970-01-01 для Null. Миллисекундная точность не требуется, используйте DateTime | DateTime                                                                                                                                                     |
| `ClosedDate`            | Нет      | 2008-09-04 20:56:44, 2024-04-06 18:49:25.393000000           | *                   | Да   | Используйте значение по умолчанию 1970-01-01 для Null. Миллисекундная точность не требуется, используйте DateTime | DateTime                                                                                                                                                     |

<br />

В итоге мы получаем следующую схему:

```sql
CREATE TABLE posts_v2
(
   `Id` Int32,
   `PostTypeId` Enum('Question' = 1, 'Answer' = 2, 'Wiki' = 3, 'TagWikiExcerpt' = 4, 'TagWiki' = 5, 'ModeratorNomination' = 6, 'WikiPlaceholder' = 7, 'PrivilegeWiki' = 8),
   `AcceptedAnswerId` UInt32,
   `CreationDate` DateTime,
   `Score` Int32,
   `ViewCount` UInt32,
   `Body` String,
   `OwnerUserId` Int32,
   `OwnerDisplayName` String,
   `LastEditorUserId` Int32,
   `LastEditorDisplayName` String,
   `LastEditDate` DateTime,
   `LastActivityDate` DateTime,
   `Title` String,
   `Tags` String,
   `AnswerCount` UInt16,
   `CommentCount` UInt8,
   `FavoriteCount` UInt8,
   `ContentLicense`LowCardinality(String),
   `ParentId` String,
   `CommunityOwnedDate` DateTime,
   `ClosedDate` DateTime
)
ENGINE = MergeTree
ORDER BY tuple()
COMMENT 'Оптимизированные типы данных'
```

Мы можем заполнить эту таблицу с помощью простого запроса `INSERT INTO ... SELECT`, считав данные из нашей предыдущей таблицы и вставив их в эту:

```sql
INSERT INTO posts_v2 SELECT * FROM posts

0 строк в наборе. Прошло: 146.471 сек. Обработано 59.82 млн строк, 83.82 ГБ (408.40 тыс. строк/с., 572.25 МБ/с.)
```

В нашей новой схеме мы не храним значения `null`. Приведённый выше оператор `INSERT` неявно преобразует их в значения по умолчанию для соответствующих типов — 0 для целых чисел и пустую строку для строковых типов. ClickHouse также автоматически приводит любые числовые значения к целевой точности.
Первичные (упорядочивающие) ключи в ClickHouse
Пользователи, переходящие с OLTP-баз данных, часто ищут эквивалентный механизм в ClickHouse.


## Выбор ключа сортировки {#choosing-an-ordering-key}

При масштабах, в которых обычно используется ClickHouse, эффективность использования памяти и дискового пространства имеет первостепенное значение. Данные записываются в таблицы ClickHouse фрагментами, называемыми кусками (parts), с применением правил фонового слияния этих кусков. В ClickHouse каждый кусок имеет свой собственный первичный индекс. При слиянии кусков их первичные индексы также объединяются. Первичный индекс куска содержит одну запись индекса на группу строк — эта техника называется разреженной индексацией.

<Image
  img={schemaDesignIndices}
  size='md'
  alt='Разреженная индексация в ClickHouse'
/>

Выбранный ключ в ClickHouse определяет не только индекс, но и порядок записи данных на диск. Благодаря этому он может существенно влиять на уровень сжатия, что в свою очередь влияет на производительность запросов. Ключ сортировки, обеспечивающий запись значений большинства столбцов в последовательном порядке, позволит выбранному алгоритму сжатия (и кодекам) сжимать данные более эффективно.

> Все столбцы в таблице будут отсортированы на основе значения указанного ключа сортировки, независимо от того, включены ли они в сам ключ. Например, если в качестве ключа используется `CreationDate`, порядок значений во всех остальных столбцах будет соответствовать порядку значений в столбце `CreationDate`. Можно указать несколько ключей сортировки — это будет упорядочивать данные с той же семантикой, что и предложение `ORDER BY` в запросе `SELECT`.

Для выбора ключа сортировки можно применить несколько простых правил. Следующие рекомендации иногда могут противоречить друг другу, поэтому рассматривайте их по порядку. В результате этого процесса можно определить несколько ключей, обычно достаточно 4-5:

- Выбирайте столбцы, которые соответствуют вашим распространенным фильтрам. Если столбец часто используется в предложениях `WHERE`, отдавайте приоритет включению таких столбцов в ключ перед теми, которые используются реже.
  Предпочитайте столбцы, которые помогают исключить большой процент от общего числа строк при фильтрации, тем самым уменьшая объем данных, которые необходимо прочитать.
- Предпочитайте столбцы, которые, вероятно, сильно коррелируют с другими столбцами в таблице. Это поможет обеспечить последовательное хранение этих значений, улучшая сжатие.
  Операции `GROUP BY` и `ORDER BY` для столбцов в ключе сортировки могут быть выполнены более эффективно с точки зрения использования памяти.

При определении подмножества столбцов для ключа сортировки объявляйте столбцы в определенном порядке. Этот порядок может существенно влиять как на эффективность фильтрации по вторичным ключевым столбцам в запросах, так и на коэффициент сжатия файлов данных таблицы. В общем случае лучше всего упорядочивать ключи в порядке возрастания кардинальности. Это следует сбалансировать с тем фактом, что фильтрация по столбцам, расположенным позже в ключе сортировки, будет менее эффективной, чем фильтрация по тем, которые расположены раньше в кортеже. Сбалансируйте эти аспекты и учитывайте ваши шаблоны доступа (и, что наиболее важно, тестируйте варианты).

### Пример {#example}

Применяя приведенные выше рекомендации к нашей таблице `posts`, предположим, что пользователи хотят выполнять аналитику с фильтрацией по дате и типу публикации, например:

«Какие вопросы имели наибольшее количество комментариев за последние 3 месяца».

Запрос для этого вопроса с использованием нашей предыдущей таблицы `posts_v2` с оптимизированными типами, но без ключа сортировки:

```sql
SELECT
    Id,
    Title,
    CommentCount
FROM posts_v2
WHERE (CreationDate >= '2024-01-01') AND (PostTypeId = 'Question')
ORDER BY CommentCount DESC
LIMIT 3

┌───────Id─┬─Title─────────────────────────────────────────────────────────────┬─CommentCount─┐
│ 78203063 │ How to avoid default initialization of objects in std::vector?     │               74 │
│ 78183948 │ About memory barrier                                               │               52 │
│ 77900279 │ Speed Test for Buffer Alignment: IBM's PowerPC results vs. my CPU │        49 │
└──────────┴───────────────────────────────────────────────────────────────────┴──────────────

10 rows in set. Elapsed: 0.070 sec. Processed 59.82 million rows, 569.21 MB (852.55 million rows/s., 8.11 GB/s.)
Peak memory usage: 429.38 MiB.
```

> Запрос здесь выполняется очень быстро, хотя все 60 млн строк были просканированы линейно — ClickHouse просто быстрый :) Вам придется поверить нам на слово, что ключи сортировки стоят того при масштабах в терабайты и петабайты!

Давайте выберем столбцы `PostTypeId` и `CreationDate` в качестве наших ключей сортировки.


Возможно, в нашем случае мы предполагаем, что пользователи всегда будут фильтровать по `PostTypeId`. У этого столбца кардинальность 8, и он является логичным выбором для первого элемента в нашем ключе сортировки. Понимая, что фильтрации по дате с нужной гранулярностью, скорее всего, будет достаточно (она по-прежнему принесёт пользу и фильтрам по `datetime`), мы используем `toDate(CreationDate)` в качестве второго компонента ключа. Это также приведёт к меньшему индексу, так как дата может быть представлена 16 байтами, что ускоряет фильтрацию. Наш последний элемент ключа — `CommentCount`, чтобы упростить поиск наиболее комментируемых постов (финальная сортировка).

```sql
CREATE TABLE posts_v3
(
        `Id` Int32,
        `PostTypeId` Enum('Question' = 1, 'Answer' = 2, 'Wiki' = 3, 'TagWikiExcerpt' = 4, 'TagWiki' = 5, 'ModeratorNomination' = 6, 'WikiPlaceholder' = 7, 'PrivilegeWiki' = 8),
        `AcceptedAnswerId` UInt32,
        `CreationDate` DateTime,
        `Score` Int32,
        `ViewCount` UInt32,
        `Body` String,
        `OwnerUserId` Int32,
        `OwnerDisplayName` String,
        `LastEditorUserId` Int32,
        `LastEditorDisplayName` String,
        `LastEditDate` DateTime,
        `LastActivityDate` DateTime,
        `Title` String,
        `Tags` String,
        `AnswerCount` UInt16,
        `CommentCount` UInt8,
        `FavoriteCount` UInt8,
        `ContentLicense` LowCardinality(String),
        `ParentId` String,
        `CommunityOwnedDate` DateTime,
        `ClosedDate` DateTime
)
ENGINE = MergeTree
ORDER BY (PostTypeId, toDate(CreationDate), CommentCount)
COMMENT 'Ключ сортировки'

--заполнение таблицы из существующей таблицы

INSERT INTO posts_v3 SELECT * FROM posts_v2

0 строк в наборе. Прошло: 158.074 сек. Обработано 59.82 млн строк, 76.21 ГБ (378.42 тыс. строк/с., 482.14 МБ/с.)
Пиковое использование памяти: 6.41 ГиБ.

Наш предыдущий запрос улучшает время ответа более чем в 3 раза:

SELECT
    Id,
    Title,
    CommentCount
FROM posts_v3
WHERE (CreationDate >= '2024-01-01') AND (PostTypeId = 'Question')
ORDER BY CommentCount DESC
LIMIT 3

10 строк в наборе. Прошло: 0.020 сек. Обработано 290.09 тыс. строк, 21.03 МБ (14.65 млн строк/с., 1.06 ГБ/с.)
```

Пользователям, которых интересуют улучшения сжатия, достигаемые за счёт использования определённых типов и подходящих ключей упорядочивания, следует обратиться к разделу [Compression in ClickHouse](/data-compression/compression-in-clickhouse). Если необходимо ещё больше повысить степень сжатия, мы также рекомендуем раздел [Choosing the right column compression codec](/data-compression/compression-in-clickhouse#choosing-the-right-column-compression-codec).


## Далее: Техники моделирования данных {#next-data-modeling-techniques}

До сих пор мы мигрировали только одну таблицу. Хотя это позволило нам познакомиться с некоторыми основными концепциями ClickHouse, большинство схем, к сожалению, устроены сложнее.

В других руководствах, перечисленных ниже, мы рассмотрим ряд техник реструктуризации нашей расширенной схемы для оптимального выполнения запросов в ClickHouse. В ходе этого процесса мы стремимся к тому, чтобы `Posts` оставалась нашей центральной таблицей, через которую выполняется большинство аналитических запросов. Хотя другие таблицы по-прежнему можно запрашивать изолированно, мы предполагаем, что большинство аналитических операций будут выполняться в контексте `posts`.

> В этом разделе мы используем оптимизированные варианты наших других таблиц. Хотя мы предоставляем схемы для них, для краткости мы опускаем описание принятых решений. Они основаны на правилах, описанных ранее, и мы оставляем их интерпретацию читателю.

Все следующие подходы направлены на минимизацию необходимости использования JOIN для оптимизации чтения и улучшения производительности запросов. Хотя JOIN полностью поддерживаются в ClickHouse, мы рекомендуем использовать их умеренно (2–3 таблицы в запросе с JOIN — это нормально) для достижения оптимальной производительности.

> ClickHouse не имеет понятия внешних ключей. Это не запрещает соединения, но означает, что ссылочная целостность остается на усмотрение пользователя и управляется на уровне приложения. В OLAP-системах, таких как ClickHouse, целостность данных часто управляется на уровне приложения или в процессе загрузки данных, а не обеспечивается самой базой данных, где это влечет значительные накладные расходы. Такой подход обеспечивает большую гибкость и более быструю вставку данных. Это соответствует фокусу ClickHouse на скорости и масштабируемости запросов чтения и вставки при работе с очень большими наборами данных.

Чтобы минимизировать использование соединений во время выполнения запросов, пользователи имеют в распоряжении несколько инструментов и подходов:

- [**Денормализация данных**](/data-modeling/denormalization) — денормализация данных путем объединения таблиц и использования сложных типов для отношений, отличных от 1:1. Это часто включает перенос любых соединений с момента выполнения запроса на момент вставки.
- [**Словари**](/dictionary) — специфическая функция ClickHouse для обработки прямых соединений и поиска значений по ключу.
- [**Инкрементальные материализованные представления**](/materialized-view/incremental-materialized-view) — функция ClickHouse для переноса затрат на вычисления с момента выполнения запроса на момент вставки, включая возможность инкрементального вычисления агрегированных значений.
- [**Обновляемые материализованные представления**](/materialized-view/refreshable-materialized-view) — подобно материализованным представлениям, используемым в других продуктах баз данных, это позволяет периодически вычислять результаты запроса и кэшировать результат.

Мы рассматриваем каждый из этих подходов в соответствующих руководствах, указывая, когда каждый из них уместен, с примерами, показывающими, как его можно применить для решения задач с набором данных Stack Overflow.
