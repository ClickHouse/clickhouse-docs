---
slug: /data-modeling/backfilling
title: 'Дозагрузка исторических данных'
description: 'Как дозагружать большие наборы данных в ClickHouse'
keywords: ['материализованные представления', 'дозагрузка исторических данных', 'вставка данных', 'отказоустойчивая загрузка данных']
doc_type: 'guide'
---

import nullTableMV from '@site/static/images/data-modeling/null_table_mv.png';
import Image from '@theme/IdealImage';


# Дозагрузка данных

Независимо от того, начинаете ли вы работать с ClickHouse или управляете существующим развертыванием, рано или поздно возникает необходимость дозагрузить в таблицы исторические данные. В одних случаях это относительно просто, но задача может усложниться, когда требуется заполнить материализованные представления. В этом руководстве описаны некоторые процессы для решения этой задачи, которые пользователи могут применить к своим сценариям.

:::note
В этом руководстве предполагается, что пользователи уже знакомы с концепцией [инкрементальных материализованных представлений](/materialized-view/incremental-materialized-view) и [загрузки данных с использованием табличных функций s3 и gcs](/integrations/s3). Мы также рекомендуем прочитать наше руководство по [оптимизации производительности операций вставки из объектного хранилища](/integrations/s3/performance), рекомендации из которого могут быть применены к вставкам данных во всём этом руководстве.
:::



## Пример набора данных {#example-dataset}

В этом руководстве используется набор данных PyPI. Каждая строка в этом наборе данных представляет загрузку пакета Python с помощью инструмента, такого как `pip`.

Например, подмножество охватывает один день — `2024-12-17` и доступно публично по адресу `https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/`. Пользователи могут выполнить запрос:

```sql
SELECT count()
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/*.parquet')

┌────count()─┐
│ 2039988137 │ -- 2,04 миллиарда
└────────────┘

1 row in set. Elapsed: 32.726 sec. Processed 2.04 billion rows, 170.05 KB (62.34 million rows/s., 5.20 KB/s.)
Пиковое использование памяти: 239.50 MiB.
```

Полный набор данных в этом бакете содержит более 320 ГБ файлов parquet. В приведенных ниже примерах мы намеренно обращаемся к подмножествам, используя glob-шаблоны.

Предполагается, что пользователь потребляет поток этих данных, например, из Kafka или объектного хранилища, для данных после этой даты. Схема этих данных показана ниже:

```sql
DESCRIBE TABLE s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/*.parquet')
FORMAT PrettyCompactNoEscapesMonoBlock
SETTINGS describe_compact_output = 1

┌─name───────────────┬─type────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ timestamp │ Nullable(DateTime64(6))                                                                                                                 │
│ country_code       │ Nullable(String)                                                                                                                        │
│ url │ Nullable(String)                                                                                                                        │
│ project            │ Nullable(String)                                                                                                                        │
│ file │ Tuple(filename Nullable(String), project Nullable(String), version Nullable(String), type Nullable(String))                             │
│ installer          │ Tuple(name Nullable(String), version Nullable(String))                                                                                  │
│ python             │ Nullable(String)                                                                                                                        │
│ implementation     │ Tuple(name Nullable(String), version Nullable(String))                                                                                  │
│ distro             │ Tuple(name Nullable(String), version Nullable(String), id Nullable(String), libc Tuple(lib Nullable(String), version Nullable(String))) │
│ system │ Tuple(name Nullable(String), release Nullable(String))                                                                                  │
│ cpu                │ Nullable(String)                                                                                                                        │
│ openssl_version    │ Nullable(String)                                                                                                                        │
│ setuptools_version │ Nullable(String)                                                                                                                        │
│ rustc_version      │ Nullable(String)                                                                                                                        │
│ tls_protocol       │ Nullable(String)                                                                                                                        │
│ tls_cipher         │ Nullable(String)                                                                                                                        │
└────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

:::note
Полный набор данных PyPI, состоящий из более чем 1 триллиона строк, доступен в нашей публичной демонстрационной среде [clickpy.clickhouse.com](https://clickpy.clickhouse.com). Дополнительную информацию об этом наборе данных, включая то, как демонстрация использует материализованные представления для повышения производительности и как данные пополняются ежедневно, см. [здесь](https://github.com/ClickHouse/clickpy).
:::


## Сценарии загрузки исторических данных {#backfilling-scenarios}

Загрузка исторических данных обычно требуется, когда поток данных начинает обрабатываться с определенного момента времени. Эти данные вставляются в таблицы ClickHouse с помощью [инкрементных материализованных представлений](/materialized-view/incremental-materialized-view), которые срабатывают при вставке блоков. Эти представления могут преобразовывать данные перед вставкой или вычислять агрегаты и отправлять результаты в целевые таблицы для последующего использования в downstream-приложениях.

Мы рассмотрим следующие сценарии:

1. **Загрузка исторических данных при существующей загрузке данных** — загружаются новые данные, и необходимо выполнить загрузку исторических данных. Эти исторические данные были определены.
2. **Добавление материализованных представлений к существующим таблицам** — необходимо добавить новые материализованные представления к конфигурации, для которой исторические данные уже загружены и данные уже поступают потоком.

Мы предполагаем, что данные будут загружаться из объектного хранилища. Во всех случаях мы стремимся избежать пауз при вставке данных.

Мы рекомендуем загружать исторические данные из объектного хранилища. По возможности данные следует экспортировать в формат Parquet для оптимальной производительности чтения и сжатия (уменьшенная передача по сети). Обычно предпочтителен размер файла около 150 МБ, но ClickHouse поддерживает более [70 форматов файлов](/interfaces/formats) и способен обрабатывать файлы любого размера.


## Использование дублирующих таблиц и представлений {#using-duplicate-tables-and-views}

Во всех сценариях мы используем концепцию «дублирующих таблиц и представлений». Эти таблицы и представления являются копиями тех, которые используются для потоковых данных в реальном времени, и позволяют выполнять обратное заполнение изолированно с возможностью простого восстановления в случае сбоя. Например, у нас есть следующая основная таблица `pypi` и материализованное представление, которое вычисляет количество загрузок для каждого проекта Python:

```sql
CREATE TABLE pypi
(
    `timestamp` DateTime,
    `country_code` LowCardinality(String),
    `project` String,
    `type` LowCardinality(String),
    `installer` LowCardinality(String),
    `python_minor` LowCardinality(String),
    `system` LowCardinality(String),
    `on` String
)
ENGINE = MergeTree
ORDER BY (project, timestamp)

CREATE TABLE pypi_downloads
(
    `project` String,
    `count` Int64
)
ENGINE = SummingMergeTree
ORDER BY project

CREATE MATERIALIZED VIEW pypi_downloads_mv TO pypi_downloads
AS SELECT
 project,
    count() AS count
FROM pypi
GROUP BY project
```

Заполним основную таблицу и связанное представление подмножеством данных:

```sql
INSERT INTO pypi SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{000..100}.parquet')

0 строк в наборе. Затрачено: 15.702 сек. Обработано 41.23 млн строк, 3.94 ГБ (2.63 млн строк/с., 251.01 МБ/с.)
Пиковое использование памяти: 977.49 МиБ.

SELECT count() FROM pypi

┌──count()─┐
│ 20612750 │ -- 20.61 млн
└──────────┘

1 строка в наборе. Затрачено: 0.004 сек.

SELECT sum(count)
FROM pypi_downloads

┌─sum(count)─┐
│   20612750 │ -- 20.61 млн
└────────────┘

1 строка в наборе. Затрачено: 0.006 сек. Обработано 96.15 тыс. строк, 769.23 КБ (16.53 млн строк/с., 132.26 МБ/с.)
Пиковое использование памяти: 682.38 КиБ.
```

Предположим, мы хотим загрузить другое подмножество `{101..200}`. Хотя мы могли бы вставить данные напрямую в `pypi`, мы можем выполнить это обратное заполнение изолированно, создав дублирующие таблицы.

В случае сбоя обратного заполнения мы не повлияем на основные таблицы и сможем просто [очистить](/managing-data/truncate) дублирующие таблицы и повторить операцию.

Чтобы создать новые копии этих представлений, можно использовать конструкцию `CREATE TABLE AS` с суффиксом `_v2`:

```sql
CREATE TABLE pypi_v2 AS pypi

CREATE TABLE pypi_downloads_v2 AS pypi_downloads

CREATE MATERIALIZED VIEW pypi_downloads_mv_v2 TO pypi_downloads_v2
AS SELECT
 project,
    count() AS count
FROM pypi_v2
GROUP BY project
```

Заполним её вторым подмножеством примерно того же размера и подтвердим успешную загрузку.

```sql
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{101..200}.parquet')

0 строк в наборе. Затрачено: 17.545 сек. Обработано 40.80 млн строк, 3.90 ГБ (2.33 млн строк/с., 222.29 МБ/с.)
Пиковое использование памяти: 991.50 МиБ.

SELECT count()
FROM pypi_v2

┌──count()─┐
│ 20400020 │ -- 20.40 млн
└──────────┘

1 строка в наборе. Затрачено: 0.004 сек.

SELECT sum(count)
FROM pypi_downloads_v2

┌─sum(count)─┐
│   20400020 │ -- 20.40 млн
└────────────┘

1 строка в наборе. Затрачено: 0.006 сек. Обработано 95.49 тыс. строк, 763.90 КБ (14.81 млн строк/с., 118.45 МБ/с.)
Пиковое использование памяти: 688.77 КиБ.
```


Если во время второй загрузки данных на любом этапе произошёл сбой, мы могли бы просто [очистить](/managing-data/truncate) таблицы `pypi_v2` и `pypi_downloads_v2` и повторить загрузку данных.

После завершения загрузки данных мы можем переместить данные из дублирующих таблиц в основные таблицы с помощью оператора [`ALTER TABLE MOVE PARTITION`](/sql-reference/statements/alter/partition#move-partition-to-table).

```sql
ALTER TABLE pypi_v2 MOVE PARTITION () TO pypi

0 строк в наборе. Прошло: 1.401 сек.

ALTER TABLE pypi_downloads_v2 MOVE PARTITION () TO pypi_downloads

0 строк в наборе. Прошло: 0.389 сек.
```

:::note Имена партиций
Вызов `MOVE PARTITION` выше использует имя партиции `()`. Оно обозначает единственную партицию этой таблицы (которая не разбита на партиции). Для таблиц, которые разбиты на партиции, пользователям необходимо вызывать несколько `MOVE PARTITION` — по одному на каждую партицию. Имена текущих партиций можно получить из таблицы [`system.parts`](/operations/system-tables/parts), например: `SELECT DISTINCT partition FROM system.parts WHERE (table = 'pypi_v2')`.
:::

Теперь мы можем подтвердить, что `pypi` и `pypi_downloads` содержат полный набор данных. Таблицы `pypi_downloads_v2` и `pypi_v2` можно безопасно удалить.

```sql
SELECT count()
FROM pypi

┌──count()─┐
│ 41012770 │ -- 41,01 миллиона
└──────────┘

1 row in set. Elapsed: 0.003 sec.

SELECT sum(count)
FROM pypi_downloads

┌─sum(count)─┐
│   41012770 │ -- 41,01 миллиона
└────────────┘

1 row in set. Elapsed: 0.007 sec. Processed 191.64 thousand rows, 1.53 MB (27.34 million rows/s., 218.74 MB/s.)

SELECT count()
FROM pypi_v2
```

Важно, что операция `MOVE PARTITION` является как лёгкой по ресурсам (использует жёсткие ссылки), так и атомарной, т.е. она либо завершается неудачей, либо успешно, без промежуточных состояний.

Мы активно используем этот процесс в наших сценариях дозагрузки данных, описанных ниже.

Обратите внимание, что этот процесс требует от пользователей выбора размера каждой операции вставки.

Более крупные вставки, т.е. больше строк, означают, что потребуется меньше операций `MOVE PARTITION`. Однако это необходимо сбалансировать с затратами на восстановление в случае неудачной вставки, например из‑за сетевого сбоя. Пользователи могут дополнить этот процесс объединением файлов в пакеты для снижения риска. Это можно выполнять с помощью диапазонных запросов, например `WHERE timestamp BETWEEN 2024-12-17 09:00:00 AND 2024-12-17 10:00:00`, либо glob-шаблонов. Например,

```sql
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{101..200}.parquet')
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{201..300}.parquet')
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{301..400}.parquet')
--продолжается до загрузки всех файлов ИЛИ до выполнения вызова MOVE PARTITION
```

:::note
ClickPipes использует этот подход при загрузке данных из объектного хранилища, автоматически создавая дубликаты целевой таблицы и её материализованных представлений и избавляя пользователя от необходимости выполнять описанные выше шаги. Дополнительно, за счёт использования нескольких рабочих потоков, каждый из которых обрабатывает свой поднабор данных (с помощью glob-шаблонов) и использует собственные таблицы-дубликаты, данные могут быть загружены быстро с обеспечением семантики «ровно один раз». Для заинтересованных читателей дополнительные подробности приведены [в этой статье блога](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part3).
:::


## Сценарий 1: Восстановление данных при существующей загрузке данных {#scenario-1-backfilling-data-with-existing-data-ingestion}

В этом сценарии предполагается, что данные для восстановления находятся не в изолированном бакете, поэтому требуется фильтрация. Данные уже загружаются, и можно определить столбец с временной меткой или монотонно возрастающий столбец, начиная с которого необходимо восстановить исторические данные.

Процесс включает следующие шаги:

1. Определите контрольную точку — временную метку или значение столбца, начиная с которого необходимо восстановить исторические данные.
2. Создайте дубликаты основной таблицы и целевых таблиц для материализованных представлений.
3. Создайте копии всех материализованных представлений, указывающих на целевые таблицы, созданные на шаге (2).
4. Выполните вставку в дублированную основную таблицу, созданную на шаге (2).
5. Переместите все партиции из дублированных таблиц в их исходные версии. Удалите дублированные таблицы.

Например, предположим, что у нас загружены данные PyPI. Мы можем определить минимальную временную метку и, таким образом, нашу «контрольную точку».

```sql
SELECT min(timestamp)
FROM pypi

┌──────min(timestamp)─┐
│ 2024-12-17 09:00:00 │
└─────────────────────┘

1 row in set. Elapsed: 0.163 sec. Processed 1.34 billion rows, 5.37 GB (8.24 billion rows/s., 32.96 GB/s.)
Peak memory usage: 227.84 MiB.
```

Из приведенного выше видно, что нам необходимо загрузить данные до `2024-12-17 09:00:00`. Используя описанный ранее процесс, мы создаем дублированные таблицы и представления и загружаем подмножество данных с применением фильтра по временной метке.

```sql
CREATE TABLE pypi_v2 AS pypi

CREATE TABLE pypi_downloads_v2 AS pypi_downloads

CREATE MATERIALIZED VIEW pypi_downloads_mv_v2 TO pypi_downloads_v2
AS SELECT project, count() AS count
FROM pypi_v2
GROUP BY project

INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-*.parquet')
WHERE timestamp < '2024-12-17 09:00:00'

0 rows in set. Elapsed: 500.152 sec. Processed 2.74 billion rows, 364.40 GB (5.47 million rows/s., 728.59 MB/s.)
```

:::note
Фильтрация по столбцам временных меток в Parquet может быть очень эффективной. ClickHouse будет читать только столбец временной метки для определения полных диапазонов данных для загрузки, минимизируя сетевой трафик. Индексы Parquet, такие как min-max, также могут использоваться движком запросов ClickHouse.
:::

После завершения вставки можно переместить соответствующие партиции.

```sql
ALTER TABLE pypi_v2 MOVE PARTITION () TO pypi

ALTER TABLE pypi_downloads_v2 MOVE PARTITION () TO pypi_downloads
```

Если исторические данные находятся в изолированном бакете, указанный выше фильтр по времени не требуется. Если столбец времени или монотонный столбец недоступен, изолируйте исторические данные.

:::note Просто используйте ClickPipes в ClickHouse Cloud
Пользователям ClickHouse Cloud следует использовать ClickPipes для восстановления исторических резервных копий, если данные могут быть изолированы в отдельном бакете (и фильтр не требуется). Помимо распараллеливания загрузки с использованием нескольких рабочих процессов, что сокращает время загрузки, ClickPipes автоматизирует описанный выше процесс — создает дублированные таблицы как для основной таблицы, так и для материализованных представлений.
:::


## Сценарий 2: Добавление материализованных представлений к существующим таблицам {#scenario-2-adding-materialized-views-to-existing-tables}

Нередко возникает необходимость добавить новые материализованные представления в систему, в которой уже накоплен значительный объём данных и продолжается вставка новых данных. В этом случае полезно иметь столбец с временной меткой или монотонно возрастающий столбец, который можно использовать для определения точки в потоке данных — это позволяет избежать приостановки приёма данных. В приведённых ниже примерах мы рассматриваем оба случая, отдавая предпочтение подходам, которые не требуют приостановки приёма данных.

:::note Избегайте POPULATE
Мы не рекомендуем использовать команду [`POPULATE`](/sql-reference/statements/create/view#materialized-view) для обратного заполнения материализованных представлений, за исключением небольших наборов данных, где приём данных приостановлен. Этот оператор может пропустить строки, вставленные в исходную таблицу после создания материализованного представления, когда заполнение уже завершено. Кроме того, populate обрабатывает все данные и подвержен прерываниям или ограничениям памяти при работе с большими наборами данных.
:::

### Доступен столбец с временной меткой или монотонно возрастающий столбец {#timestamp-or-monotonically-increasing-column-available}

В этом случае мы рекомендуем включить в новое материализованное представление фильтр, который ограничивает строки теми, у которых значение больше произвольной даты в будущем. После этого материализованное представление может быть обратно заполнено с этой даты с использованием исторических данных из основной таблицы. Подход к обратному заполнению зависит от размера данных и сложности связанного запроса.

Наш простейший подход включает следующие шаги:

1. Создать материализованное представление с фильтром, который учитывает только строки с временной меткой больше произвольного времени в ближайшем будущем.
2. Выполнить запрос `INSERT INTO SELECT`, который вставляет данные в целевую таблицу материализованного представления, читая из исходной таблицы с помощью агрегирующего запроса представления.

Это можно дополнительно улучшить, обрабатывая подмножества данных на шаге (2) и/или используя дублирующую целевую таблицу для материализованного представления (присоединяя партиции к оригинальной таблице после завершения вставки) для более простого восстановления после сбоя.

Рассмотрим следующее материализованное представление, которое вычисляет наиболее популярные проекты за каждый час.

```sql
CREATE TABLE pypi_downloads_per_day
(
    `hour` DateTime,
    `project` String,
    `count` Int64
)
ENGINE = SummingMergeTree
ORDER BY (project, hour)

CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi
GROUP BY
    hour,
 project
```

Хотя мы можем добавить целевую таблицу, перед добавлением материализованного представления мы изменяем его предложение `SELECT`, включив фильтр, который учитывает только строки с временной меткой больше произвольного времени в ближайшем будущем — в данном случае мы предполагаем, что `2024-12-17 09:00:00` находится через несколько минут в будущем.

```sql
CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) AS hour,
 project, count() AS count
FROM pypi WHERE timestamp >= '2024-12-17 09:00:00'
GROUP BY hour, project
```

После добавления этого представления мы можем обратно заполнить все данные для материализованного представления до этой даты.

Простейший способ сделать это — выполнить запрос из материализованного представления на основной таблице с фильтром, который игнорирует недавно добавленные данные, вставляя результаты в целевую таблицу представления через `INSERT INTO SELECT`. Например, для приведённого выше представления:

```sql
INSERT INTO pypi_downloads_per_day SELECT
 toStartOfHour(timestamp) AS hour,
 project,
    count() AS count
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
GROUP BY
    hour,
 project

Ok.

0 rows in set. Elapsed: 2.830 sec. Processed 798.89 million rows, 17.40 GB (282.28 million rows/s., 6.15 GB/s.)
Peak memory usage: 543.71 MiB.
```

:::note
В приведённом выше примере наша целевая таблица имеет движок [SummingMergeTree](/engines/table-engines/mergetree-family/summingmergetree). В этом случае мы можем просто использовать наш исходный агрегирующий запрос. Для более сложных случаев использования, которые применяют [AggregatingMergeTree](/engines/table-engines/mergetree-family/aggregatingmergetree), пользователи будут использовать функции `-State` для агрегатов. Пример этого можно найти [здесь](/integrations/s3/performance#be-aware-of-merges).
:::


В нашем случае это относительно лёгкая агрегация, которая завершается менее чем за 3 секунды и использует менее 600 МиБ памяти. Для более сложных или длительных агрегаций можно сделать этот процесс более устойчивым, используя описанный ранее подход с дублирующей таблицей, т.е. создать теневую целевую таблицу, например `pypi_downloads_per_day_v2`, вставить в неё данные и присоединить полученные партиции к `pypi_downloads_per_day`.

Часто запрос материализованного представления может быть более сложным (что неудивительно, иначе пользователи не использовали бы представления!) и потреблять ресурсы. В более редких случаях ресурсов для запроса может не хватить на сервере. Это подчёркивает одно из преимуществ материализованных представлений ClickHouse — они инкрементальны и не обрабатывают весь набор данных за один раз!

В этом случае есть несколько вариантов:

1. Изменить запрос для заполнения диапазонов, например `WHERE timestamp BETWEEN 2024-12-17 08:00:00 AND 2024-12-17 09:00:00`, `WHERE timestamp BETWEEN 2024-12-17 07:00:00 AND 2024-12-17 08:00:00` и т.д.
2. Использовать [движок таблиц Null](/engines/table-engines/special/null) для заполнения материализованного представления. Это воспроизводит типичное инкрементальное заполнение материализованного представления, выполняя его запрос над блоками данных (настраиваемого размера).

Вариант (1) представляет собой простейший подход и часто является достаточным. Для краткости мы не приводим примеры.

Вариант (2) рассмотрим более подробно ниже.

#### Использование движка таблиц Null для заполнения материализованных представлений {#using-a-null-table-engine-for-filling-materialized-views}

[Движок таблиц Null](/engines/table-engines/special/null) предоставляет движок хранения, который не сохраняет данные (можно представить его как `/dev/null` в мире движков таблиц). Хотя это может показаться противоречивым, материализованные представления всё равно будут выполняться для данных, вставляемых в этот движок таблиц. Это позволяет создавать материализованные представления без сохранения исходных данных — избегая операций ввода-вывода и связанных с ними затрат на хранение.

Важно отметить, что любые материализованные представления, присоединённые к движку таблиц, всё равно выполняются над блоками данных при их вставке — отправляя результаты в целевую таблицу. Эти блоки имеют настраиваемый размер. Хотя более крупные блоки потенциально могут быть более эффективными (и быстрее обрабатываться), они потребляют больше ресурсов (в основном памяти). Использование этого движка таблиц означает, что мы можем строить материализованное представление инкрементально, т.е. по одному блоку за раз, избегая необходимости хранить всю агрегацию в памяти.

<Image img={nullTableMV} size='md' alt='Denormalization in ClickHouse' />

<br />

Рассмотрим следующий пример:

```sql
CREATE TABLE pypi_v2
(
    `timestamp` DateTime,
    `project` String
)
ENGINE = Null

CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv_v2 TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi_v2
GROUP BY
    hour,
 project
```

Здесь мы создаём таблицу Null `pypi_v2` для получения строк, которые будут использоваться для построения материализованного представления. Обратите внимание, как мы ограничиваем схему только необходимыми столбцами. Наше материализованное представление выполняет агрегацию над строками, вставляемыми в эту таблицу (по одному блоку за раз), отправляя результаты в целевую таблицу `pypi_downloads_per_day`.

:::note
Мы использовали `pypi_downloads_per_day` в качестве целевой таблицы. Для дополнительной устойчивости можно создать дублирующую таблицу `pypi_downloads_per_day_v2` и использовать её в качестве целевой таблицы представления, как показано в предыдущих примерах. После завершения вставки партиции в `pypi_downloads_per_day_v2` могут быть, в свою очередь, перемещены в `pypi_downloads_per_day`. Это позволит восстановиться в случае, если вставка не удастся из-за проблем с памятью или прерываний сервера, т.е. достаточно очистить `pypi_downloads_per_day_v2`, настроить параметры и повторить попытку.
:::

Чтобы заполнить это материализованное представление, достаточно вставить соответствующие данные для заполнения в `pypi_v2` из `pypi`.

```sql
INSERT INTO pypi_v2 SELECT timestamp, project FROM pypi WHERE timestamp < '2024-12-17 09:00:00'

0 rows in set. Elapsed: 27.325 sec. Processed 1.50 billion rows, 33.48 GB (54.73 million rows/s., 1.23 GB/s.)
Peak memory usage: 639.47 MiB.
```

Обратите внимание, что использование памяти здесь составляет `639.47 МиБ`.


##### Настройка производительности и ресурсов {#tuning-performance--resources}

Производительность и потребление ресурсов в описанном выше сценарии определяются несколькими факторами. Перед началом настройки рекомендуется ознакомиться с механизмами вставки данных, подробно описанными в разделе [Using Threads for Reads](/integrations/s3/performance#using-threads-for-reads) руководства [Optimizing for S3 Insert and Read Performance guide](/integrations/s3/performance). Краткое описание:

- **Параллелизм чтения** — количество потоков, используемых для чтения. Управляется параметром [`max_threads`](/operations/settings/settings#max_threads). В ClickHouse Cloud это значение определяется размером инстанса и по умолчанию равно количеству vCPU. Увеличение этого значения может улучшить производительность чтения за счёт большего потребления памяти.
- **Параллелизм вставки** — количество потоков, используемых для вставки данных. Управляется параметром [`max_insert_threads`](/operations/settings/settings#max_insert_threads). В ClickHouse Cloud это значение определяется размером инстанса (от 2 до 4), в версии с открытым исходным кодом установлено значение 1. Увеличение этого значения может улучшить производительность за счёт большего потребления памяти.
- **Размер блока вставки** — данные обрабатываются в цикле: извлекаются, разбираются и формируются в блоки вставки в памяти на основе [ключа партиционирования](/engines/table-engines/mergetree-family/custom-partitioning-key). Эти блоки сортируются, оптимизируются, сжимаются и записываются в хранилище как новые [куски данных](/parts). Размер блока вставки, управляемый параметрами [`min_insert_block_size_rows`](/operations/settings/settings#min_insert_block_size_rows) и [`min_insert_block_size_bytes`](/operations/settings/settings#min_insert_block_size_bytes) (несжатые данные), влияет на использование памяти и дисковый ввод-вывод. Большие блоки потребляют больше памяти, но создают меньше кусков, сокращая операции ввода-вывода и фоновые слияния. Эти параметры представляют минимальные пороговые значения (достижение любого из них первым инициирует сброс данных).
- **Размер блока материализованного представления** — помимо описанных выше механизмов для основной вставки, перед вставкой в материализованные представления блоки также объединяются для более эффективной обработки. Размер этих блоков определяется параметрами [`min_insert_block_size_bytes_for_materialized_views`](/operations/settings/settings#min_insert_block_size_bytes_for_materialized_views) и [`min_insert_block_size_rows_for_materialized_views`](/operations/settings/settings#min_insert_block_size_rows_for_materialized_views). Большие блоки позволяют более эффективно обрабатывать данные за счёт большего потребления памяти. По умолчанию эти параметры принимают значения параметров исходной таблицы [`min_insert_block_size_rows`](/operations/settings/settings#min_insert_block_size_rows) и [`min_insert_block_size_bytes`](/operations/settings/settings#min_insert_block_size_bytes) соответственно.

Для повышения производительности можно следовать рекомендациям, изложенным в разделе [Tuning Threads and Block Size for Inserts](/integrations/s3/performance#tuning-threads-and-block-size-for-inserts) руководства [Optimizing for S3 Insert and Read Performance guide](/integrations/s3/performance). В большинстве случаев не требуется изменять параметры `min_insert_block_size_bytes_for_materialized_views` и `min_insert_block_size_rows_for_materialized_views` для повышения производительности. Если эти параметры изменяются, следует применять те же рекомендации, что и для `min_insert_block_size_rows` и `min_insert_block_size_bytes`.

Для минимизации потребления памяти можно поэкспериментировать с этими параметрами. Это неизбежно приведёт к снижению производительности. Ниже приведены примеры с использованием предыдущего запроса.

Снижение `max_insert_threads` до 1 уменьшает накладные расходы памяти.

```sql
INSERT INTO pypi_v2
SELECT
    timestamp,
 project
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
SETTINGS max_insert_threads = 1

0 rows in set. Elapsed: 27.752 sec. Processed 1.50 billion rows, 33.48 GB (53.89 million rows/s., 1.21 GB/s.)
Peak memory usage: 506.78 MiB.
```

Можно ещё больше снизить потребление памяти, уменьшив параметр `max_threads` до 1.

```sql
INSERT INTO pypi_v2
SELECT timestamp, project
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
SETTINGS max_insert_threads = 1, max_threads = 1

Ok.

0 rows in set. Elapsed: 43.907 sec. Processed 1.50 billion rows, 33.48 GB (34.06 million rows/s., 762.54 MB/s.)
Peak memory usage: 272.53 MiB.
```


Наконец, мы можем дополнительно снизить потребление памяти, установив `min_insert_block_size_rows` в 0 (отключает его как определяющий фактор размера блока) и `min_insert_block_size_bytes` в 10485760 (10 МиБ).

```sql
INSERT INTO pypi_v2
SELECT
    timestamp,
 project
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
SETTINGS max_insert_threads = 1, max_threads = 1, min_insert_block_size_rows = 0, min_insert_block_size_bytes = 10485760

0 строк в наборе. Затрачено: 43.293 сек. Обработано 1.50 млрд строк, 33.48 ГБ (34.54 млн строк/с., 773.36 МБ/с.)
Пиковое использование памяти: 218.64 МиБ.
```

Наконец, имейте в виду, что уменьшение размеров блоков приводит к созданию большего количества частей и увеличивает нагрузку на слияния. Как обсуждалось [здесь](/integrations/s3/performance#be-aware-of-merges), эти настройки следует изменять с осторожностью.

### Отсутствие временной метки или монотонно возрастающего столбца {#no-timestamp-or-monotonically-increasing-column}

Описанные выше процессы предполагают наличие у пользователя временной метки или монотонно возрастающего столбца. В некоторых случаях это просто недоступно. В этом случае мы рекомендуем следующий процесс, который использует многие из ранее описанных шагов, но требует приостановки загрузки данных.

1. Приостановите вставки в основную таблицу.
2. Создайте дубликат основной целевой таблицы, используя синтаксис `CREATE AS`.
3. Присоедините партиции из исходной целевой таблицы к дубликату, используя [`ALTER TABLE ATTACH`](/sql-reference/statements/alter/partition#attach-partitionpart). **Примечание:** Эта операция присоединения отличается от использованной ранее операции перемещения. Хотя она опирается на жесткие ссылки, данные в исходной таблице сохраняются.
4. Создайте новые материализованные представления.
5. Возобновите вставки. **Примечание:** Вставки будут обновлять только целевую таблицу, а не дубликат, который будет ссылаться только на исходные данные.
6. Выполните обратное заполнение материализованного представления, применяя тот же процесс, который использовался выше для данных с временными метками, используя дубликат таблицы в качестве источника.

Рассмотрим следующий пример с использованием PyPI и нашего предыдущего нового материализованного представления `pypi_downloads_per_day` (предположим, что мы не можем использовать временную метку):

```sql
SELECT count() FROM pypi

┌────count()─┐
│ 2039988137 │ -- 2.04 миллиарда
└────────────┘

1 строка в наборе. Затрачено: 0.003 сек.

-- (1) Приостанавливаем вставки
-- (2) Создаем дубликат нашей целевой таблицы

CREATE TABLE pypi_v2 AS pypi

SELECT count() FROM pypi_v2

┌────count()─┐
│ 2039988137 │ -- 2.04 миллиарда
└────────────┘

1 строка в наборе. Затрачено: 0.004 сек.

-- (3) Присоединяем партиции из исходной целевой таблицы к дубликату.

ALTER TABLE pypi_v2
 (ATTACH PARTITION tuple() FROM pypi)

-- (4) Создаем наши новые материализованные представления

CREATE TABLE pypi_downloads_per_day
(
    `hour` DateTime,
    `project` String,
    `count` Int64
)
ENGINE = SummingMergeTree
ORDER BY (project, hour)

CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi
GROUP BY
    hour,
 project

-- (4) Возобновляем вставки. Здесь мы имитируем это, вставляя одну строку.

INSERT INTO pypi SELECT *
FROM pypi
LIMIT 1

SELECT count() FROM pypi

┌────count()─┐
│ 2039988138 │ -- 2.04 миллиарда
└────────────┘

1 строка в наборе. Затрачено: 0.003 сек.

-- обратите внимание, что pypi_v2 содержит то же количество строк, что и раньше

SELECT count() FROM pypi_v2
┌────count()─┐
│ 2039988137 │ -- 2.04 миллиарда
└────────────┘

-- (5) Выполняем обратное заполнение представления, используя резервную копию pypi_v2

INSERT INTO pypi_downloads_per_day SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi_v2
GROUP BY
    hour,
 project

0 строк в наборе. Затрачено: 3.719 сек. Обработано 2.04 млрд строк, 47.15 ГБ (548.57 млн строк/с., 12.68 ГБ/с.)
```


DROP TABLE pypi&#95;v2;

```

На предпоследнем шаге мы выполняем обратное заполнение `pypi_downloads_per_day` с помощью простого подхода `INSERT INTO SELECT`, описанного [ранее](#timestamp-or-monotonically-increasing-column-available). Этот процесс также можно улучшить, используя подход с таблицей Null, описанный [выше](#using-a-null-table-engine-for-filling-materialized-views), с опциональным использованием дублирующей таблицы для повышения отказоустойчивости.

Хотя эта операция требует приостановки вставок, промежуточные операции обычно выполняются быстро, что минимизирует перерывы в работе с данными.
```
