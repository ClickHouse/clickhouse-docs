---
slug: /data-modeling/backfilling
title: 'Дополнение исторических данных'
description: 'Как дополнять большие исторические наборы данных в ClickHouse'
keywords: ['materialized views', 'backfilling', 'inserting data', 'resilient data load']
doc_type: 'guide'
---

import nullTableMV from '@site/static/images/data-modeling/null_table_mv.png';
import Image from '@theme/IdealImage';


# Дополнение данных задним числом

Независимо от того, являетесь ли вы новым пользователем ClickHouse или отвечаете за существующее развертывание, рано или поздно потребуется дополнить таблицы историческими данными. В некоторых случаях это относительно просто, но задача может усложниться, когда требуется заполнить материализованные представления. В этом руководстве описаны некоторые процессы для решения этой задачи, которые пользователи могут адаптировать под свои сценарии.

:::note
В этом руководстве предполагается, что пользователям уже знакома концепция [инкрементных материализованных представлений](/materialized-view/incremental-materialized-view) и [загрузки данных с использованием табличных функций, таких как s3 и gcs](/integrations/s3). Мы также рекомендуем прочитать наше руководство по [оптимизации производительности вставки из объектного хранилища](/integrations/s3/performance), советы из которого применимы к операциям вставки во всём этом руководстве.
:::



## Пример набора данных {#example-dataset}

В этом руководстве используется набор данных PyPI. Каждая строка в этом наборе данных представляет загрузку пакета Python с помощью инструмента, такого как `pip`.

Например, подмножество охватывает один день — `2024-12-17` и доступно публично по адресу `https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/`. Пользователи могут выполнить запрос:

```sql
SELECT count()
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/*.parquet')

┌────count()─┐
│ 2039988137 │ -- 2,04 миллиарда
└────────────┘

1 row in set. Elapsed: 32.726 sec. Processed 2.04 billion rows, 170.05 KB (62.34 million rows/s., 5.20 KB/s.)
Пиковое использование памяти: 239.50 MiB.
```

Полный набор данных в этом бакете содержит более 320 ГБ файлов Parquet. В примерах ниже мы намеренно обращаемся к подмножествам, используя glob-шаблоны.

Предполагается, что пользователь потребляет поток этих данных, например, из Kafka или объектного хранилища, для данных после этой даты. Схема данных показана ниже:

```sql
DESCRIBE TABLE s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/*.parquet')
FORMAT PrettyCompactNoEscapesMonoBlock
SETTINGS describe_compact_output = 1

┌─name───────────────┬─type────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ timestamp │ Nullable(DateTime64(6))                                                                                                                 │
│ country_code       │ Nullable(String)                                                                                                                        │
│ url │ Nullable(String)                                                                                                                        │
│ project            │ Nullable(String)                                                                                                                        │
│ file │ Tuple(filename Nullable(String), project Nullable(String), version Nullable(String), type Nullable(String))                             │
│ installer          │ Tuple(name Nullable(String), version Nullable(String))                                                                                  │
│ python             │ Nullable(String)                                                                                                                        │
│ implementation     │ Tuple(name Nullable(String), version Nullable(String))                                                                                  │
│ distro             │ Tuple(name Nullable(String), version Nullable(String), id Nullable(String), libc Tuple(lib Nullable(String), version Nullable(String))) │
│ system │ Tuple(name Nullable(String), release Nullable(String))                                                                                  │
│ cpu                │ Nullable(String)                                                                                                                        │
│ openssl_version    │ Nullable(String)                                                                                                                        │
│ setuptools_version │ Nullable(String)                                                                                                                        │
│ rustc_version      │ Nullable(String)                                                                                                                        │
│ tls_protocol       │ Nullable(String)                                                                                                                        │
│ tls_cipher         │ Nullable(String)                                                                                                                        │
└────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

:::note
Полный набор данных PyPI, состоящий из более чем 1 триллиона строк, доступен в нашей публичной демонстрационной среде [clickpy.clickhouse.com](https://clickpy.clickhouse.com). Дополнительную информацию об этом наборе данных, включая то, как демонстрация использует материализованные представления для повышения производительности и как данные пополняются ежедневно, см. [здесь](https://github.com/ClickHouse/clickpy).
:::


## Сценарии догрузки данных {#backfilling-scenarios}

Догрузка данных обычно требуется, когда поток данных начинает обрабатываться с определенного момента времени. Эти данные вставляются в таблицы ClickHouse с использованием [инкрементных материализованных представлений](/materialized-view/incremental-materialized-view), которые срабатывают при вставке блоков. Эти представления могут преобразовывать данные перед вставкой или вычислять агрегаты и отправлять результаты в целевые таблицы для последующего использования в нижестоящих приложениях.

Мы рассмотрим следующие сценарии:

1. **Догрузка данных при существующей загрузке данных** — загружаются новые данные, и необходимо выполнить догрузку исторических данных. Эти исторические данные уже определены.
2. **Добавление материализованных представлений к существующим таблицам** — необходимо добавить новые материализованные представления к конфигурации, для которой исторические данные уже загружены и данные продолжают поступать.

Мы предполагаем, что догрузка данных будет выполняться из объектного хранилища. Во всех случаях мы стремимся избежать пауз во вставке данных.

Мы рекомендуем выполнять догрузку исторических данных из объектного хранилища. По возможности данные следует экспортировать в формат Parquet для оптимальной производительности чтения и сжатия (что снижает объем передачи по сети). Обычно предпочтителен размер файла около 150 МБ, но ClickHouse поддерживает более [70 форматов файлов](/interfaces/formats) и способен обрабатывать файлы любого размера.


## Использование дублирующих таблиц и представлений {#using-duplicate-tables-and-views}

Во всех сценариях мы опираемся на концепцию «дублирующих таблиц и представлений». Эти таблицы и представления являются копиями объектов, используемых для стриминга данных в реальном времени, и позволяют выполнять дозагрузку изолированно, с простым механизмом восстановления в случае сбоя. Например, у нас есть следующая основная таблица `pypi` и материализованное представление, которое вычисляет количество скачиваний для каждого Python‑проекта:

```sql
CREATE TABLE pypi
(
    `timestamp` DateTime,
    `country_code` LowCardinality(String),
    `project` String,
    `type` LowCardinality(String),
    `installer` LowCardinality(String),
    `python_minor` LowCardinality(String),
    `system` LowCardinality(String),
    `on` String
)
ENGINE = MergeTree
ORDER BY (project, timestamp)

CREATE TABLE pypi_downloads
(
    `project` String,
    `count` Int64
)
ENGINE = SummingMergeTree
ORDER BY project

CREATE MATERIALIZED VIEW pypi_downloads_mv TO pypi_downloads
AS SELECT
 project,
    count() AS count
FROM pypi
GROUP BY project
```

Мы заполняем основную таблицу и связанное с ней представление подмножеством данных:

```sql
INSERT INTO pypi SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{000..100}.parquet')

0 rows in set. Elapsed: 15.702 sec. Processed 41.23 million rows, 3.94 GB (2.63 million rows/s., 251.01 MB/s.)
Peak memory usage: 977.49 MiB.

SELECT count() FROM pypi

┌──count()─┐
│ 20612750 │ -- 20.61 million
└──────────┘

1 row in set. Elapsed: 0.004 sec.

SELECT sum(count)
FROM pypi_downloads

┌─sum(count)─┐
│   20612750 │ -- 20.61 million
└────────────┘

1 row in set. Elapsed: 0.006 sec. Processed 96.15 thousand rows, 769.23 KB (16.53 million rows/s., 132.26 MB/s.)
Peak memory usage: 682.38 KiB.
```

Предположим, мы хотим загрузить ещё одно подмножество `{101..200}`. Хотя мы могли бы вставить данные напрямую в `pypi`, дозагрузку можно выполнить изолированно, создав дублирующие таблицы.

Если дозагрузка завершится с ошибкой, наши основные таблицы не пострадают, и мы сможем просто [очистить](/managing-data/truncate) дублирующие таблицы и повторить операцию.

Чтобы создать новые копии этих представлений, можно использовать конструкцию `CREATE TABLE AS` с суффиксом `_v2`:

```sql
CREATE TABLE pypi_v2 AS pypi

CREATE TABLE pypi_downloads_v2 AS pypi_downloads

CREATE MATERIALIZED VIEW pypi_downloads_mv_v2 TO pypi_downloads_v2
AS SELECT
 project,
    count() AS count
FROM pypi_v2
GROUP BY project
```

Мы заполняем её вторым подмножеством примерно того же объёма и убеждаемся, что загрузка прошла успешно.

```sql
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{101..200}.parquet')

0 rows in set. Elapsed: 17.545 sec. Processed 40.80 million rows, 3.90 GB (2.33 million rows/s., 222.29 MB/s.)
Peak memory usage: 991.50 MiB.

SELECT count()
FROM pypi_v2

┌──count()─┐
│ 20400020 │ -- 20.40 million
└──────────┘

1 row in set. Elapsed: 0.004 sec.

SELECT sum(count)
FROM pypi_downloads_v2

┌─sum(count)─┐
│   20400020 │ -- 20.40 million
└────────────┘

1 row in set. Elapsed: 0.006 sec. Processed 95.49 thousand rows, 763.90 KB (14.81 million rows/s., 118.45 MB/s.)
Peak memory usage: 688.77 KiB.
```


Если бы на каком-либо этапе второй загрузки произошёл сбой, мы могли бы просто [очистить](/managing-data/truncate) таблицы `pypi_v2` и `pypi_downloads_v2` и повторить загрузку данных.

После завершения загрузки данных мы можем переместить данные из наших дублирующих таблиц в основные таблицы с помощью оператора [`ALTER TABLE MOVE PARTITION`](/sql-reference/statements/alter/partition#move-partition-to-table).

```sql
ALTER TABLE pypi_v2 MOVE PARTITION () TO pypi

0 строк в наборе. Прошло: 1.401 сек.

ALTER TABLE pypi_downloads_v2 MOVE PARTITION () TO pypi_downloads

0 строк в наборе. Прошло: 0.389 сек.
```

:::note Имена партиций
Вызов `MOVE PARTITION` выше использует имя партиции `()`. Это обозначает единственную партицию для этой таблицы (которая не разбита на партиции). Для таблиц, которые разбиты на партиции, пользователям потребуется выполнить несколько вызовов `MOVE PARTITION` — по одному для каждой партиции. Имена текущих партиций можно получить из таблицы [`system.parts`](/operations/system-tables/parts), например: `SELECT DISTINCT partition FROM system.parts WHERE (table = 'pypi_v2')`.
:::

Теперь мы можем подтвердить, что `pypi` и `pypi_downloads` содержат все данные. `pypi_downloads_v2` и `pypi_v2` можно безопасно удалить.

```sql
SELECT count()
FROM pypi

┌──count()─┐
│ 41012770 │ -- 41.01 million
└──────────┘

1 строка в наборе. Время выполнения: 0,003 сек.

SELECT sum(count)
FROM pypi_downloads

┌─sum(count)─┐
│   41012770 │ -- 41.01 million
└────────────┘

1 строка в наборе. Время выполнения: 0,007 сек. Обработано 191,64 тыс. строк, 1,53 МБ (27,34 млн строк/с, 218,74 МБ/с).

SELECT count()
FROM pypi_v2
```

Важно, что операция `MOVE PARTITION` одновременно и легковесна (использует жёсткие ссылки), и атомарна, т.е. либо завершается неудачей, либо выполняется успешно, без промежуточного состояния.

Мы активно используем этот подход в сценариях последующей дозагрузки данных, описанных ниже.

Обратите внимание, что этот процесс требует от пользователей выбора размера каждой операции вставки.

Более крупные вставки, т.е. больше строк, означают, что потребуется меньше операций `MOVE PARTITION`. Однако это необходимо сбалансировать со стоимостью восстановления в случае сбоя вставки, например из‑за обрыва сети. Пользователи могут дополнить этот процесс пакетной обработкой файлов, чтобы снизить риск. Это можно выполнять либо с помощью запросов по диапазону, например `WHERE timestamp BETWEEN 2024-12-17 09:00:00 AND 2024-12-17 10:00:00`, либо с помощью glob‑шаблонов. Например,

```sql
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{101..200}.parquet')
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{201..300}.parquet')
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{301..400}.parquet')
--продолжается до загрузки всех файлов ИЛИ выполнения команды MOVE PARTITION
```

:::note
ClickPipes использует этот подход при загрузке данных из объектного хранилища, автоматически создавая дубликаты целевой таблицы и её материализованных представлений и избавляя пользователя от необходимости выполнять описанные выше шаги. Благодаря использованию нескольких рабочих потоков, каждый из которых обрабатывает свой поднабор данных (с помощью glob-шаблонов) и использует собственные дубликаты таблиц, данные могут загружаться быстро с семантикой «ровно один раз». Дополнительные подробности можно найти [в этой записи в блоге](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part3).
:::


## Сценарий 1: Обратная загрузка данных при существующем процессе приёма данных {#scenario-1-backfilling-data-with-existing-data-ingestion}

В этом сценарии предполагается, что данные для обратной загрузки находятся не в изолированном бакете, поэтому требуется фильтрация. Данные уже поступают, и можно определить столбец с временной меткой или монотонно возрастающий столбец, начиная с которого необходимо выполнить обратную загрузку исторических данных.

Процесс включает следующие шаги:

1. Определите контрольную точку — временную метку или значение столбца, начиная с которого необходимо восстановить исторические данные.
2. Создайте дубликаты основной таблицы и целевых таблиц для материализованных представлений.
3. Создайте копии всех материализованных представлений, указывающих на целевые таблицы, созданные на шаге (2).
4. Выполните вставку в дублированную основную таблицу, созданную на шаге (2).
5. Переместите все партиции из дублированных таблиц в их исходные версии. Удалите дублированные таблицы.

Например, предположим, что у нас загружены данные PyPI. Мы можем определить минимальную временную метку и, таким образом, нашу «контрольную точку».

```sql
SELECT min(timestamp)
FROM pypi

┌──────min(timestamp)─┐
│ 2024-12-17 09:00:00 │
└─────────────────────┘

1 row in set. Elapsed: 0.163 sec. Processed 1.34 billion rows, 5.37 GB (8.24 billion rows/s., 32.96 GB/s.)
Peak memory usage: 227.84 MiB.
```

Из приведённого выше видно, что нам необходимо загрузить данные до `2024-12-17 09:00:00`. Используя описанный ранее процесс, мы создаём дублированные таблицы и представления и загружаем подмножество данных с применением фильтра по временной метке.

```sql
CREATE TABLE pypi_v2 AS pypi

CREATE TABLE pypi_downloads_v2 AS pypi_downloads

CREATE MATERIALIZED VIEW pypi_downloads_mv_v2 TO pypi_downloads_v2
AS SELECT project, count() AS count
FROM pypi_v2
GROUP BY project

INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-*.parquet')
WHERE timestamp < '2024-12-17 09:00:00'

0 rows in set. Elapsed: 500.152 sec. Processed 2.74 billion rows, 364.40 GB (5.47 million rows/s., 728.59 MB/s.)
```

:::note
Фильтрация по столбцам временных меток в Parquet может быть очень эффективной. ClickHouse будет читать только столбец временной метки для определения полных диапазонов данных для загрузки, минимизируя сетевой трафик. Индексы Parquet, такие как min-max, также могут использоваться движком запросов ClickHouse.
:::

После завершения вставки мы можем переместить соответствующие партиции.

```sql
ALTER TABLE pypi_v2 MOVE PARTITION () TO pypi

ALTER TABLE pypi_downloads_v2 MOVE PARTITION () TO pypi_downloads
```

Если исторические данные находятся в изолированном бакете, указанный выше фильтр по времени не требуется. Если столбец времени или монотонный столбец недоступен, изолируйте ваши исторические данные.

:::note Просто используйте ClickPipes в ClickHouse Cloud
Пользователям ClickHouse Cloud следует использовать ClickPipes для восстановления исторических резервных копий, если данные могут быть изолированы в отдельном бакете (и фильтр не требуется). Помимо распараллеливания загрузки с использованием нескольких воркеров, что сокращает время загрузки, ClickPipes автоматизирует описанный выше процесс — создаёт дублированные таблицы как для основной таблицы, так и для материализованных представлений.
:::


## Сценарий 2: Добавление материализованных представлений к существующим таблицам {#scenario-2-adding-materialized-views-to-existing-tables}

Нередко возникает необходимость добавить новые материализованные представления в систему, в которой уже накоплен значительный объём данных и продолжается вставка новых данных. В этом случае полезно иметь столбец с временной меткой или монотонно возрастающий столбец, который можно использовать для определения точки в потоке данных — это позволяет избежать приостановки приёма данных. В приведённых ниже примерах мы рассматриваем оба случая, отдавая предпочтение подходам, которые не требуют приостановки приёма данных.

:::note Избегайте POPULATE
Мы не рекомендуем использовать команду [`POPULATE`](/sql-reference/statements/create/view#materialized-view) для обратного заполнения материализованных представлений, за исключением небольших наборов данных, где приём данных приостановлен. Этот оператор может пропустить строки, вставленные в исходную таблицу после создания материализованного представления, когда заполнение уже завершено. Кроме того, заполнение обрабатывает все данные и подвержено прерываниям или ограничениям памяти на больших наборах данных.
:::

### Доступен столбец с временной меткой или монотонно возрастающий столбец {#timestamp-or-monotonically-increasing-column-available}

В этом случае мы рекомендуем, чтобы новое материализованное представление включало фильтр, ограничивающий строки теми, у которых значение больше произвольной даты в будущем. После этого материализованное представление можно обратно заполнить с этой даты, используя исторические данные из основной таблицы. Подход к обратному заполнению зависит от размера данных и сложности связанного запроса.

Наш простейший подход включает следующие шаги:

1. Создать материализованное представление с фильтром, который учитывает только строки с временной меткой больше произвольного времени в ближайшем будущем.
2. Выполнить запрос `INSERT INTO SELECT`, который вставляет данные в целевую таблицу материализованного представления, читая из исходной таблицы с агрегирующим запросом представления.

Это можно дополнительно улучшить, обрабатывая подмножества данных на шаге (2) и/или используя дублирующую целевую таблицу для материализованного представления (присоединить партиции к оригинальной таблице после завершения вставки) для более простого восстановления после сбоя.

Рассмотрим следующее материализованное представление, которое вычисляет наиболее популярные проекты за час.

```sql
CREATE TABLE pypi_downloads_per_day
(
    `hour` DateTime,
    `project` String,
    `count` Int64
)
ENGINE = SummingMergeTree
ORDER BY (project, hour)

CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi
GROUP BY
    hour,
 project
```

Хотя мы можем добавить целевую таблицу, перед добавлением материализованного представления мы изменяем его секцию `SELECT`, чтобы включить фильтр, который учитывает только строки с временной меткой больше произвольного времени в ближайшем будущем — в данном случае мы предполагаем, что `2024-12-17 09:00:00` находится на несколько минут в будущем.

```sql
CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) AS hour,
 project, count() AS count
FROM pypi WHERE timestamp >= '2024-12-17 09:00:00'
GROUP BY hour, project
```

После добавления этого представления мы можем обратно заполнить все данные для материализованного представления до этой даты.

Простейший способ сделать это — просто выполнить запрос из материализованного представления на основной таблице с фильтром, который игнорирует недавно добавленные данные, вставляя результаты в целевую таблицу представления через `INSERT INTO SELECT`. Например, для приведённого выше представления:

```sql
INSERT INTO pypi_downloads_per_day SELECT
 toStartOfHour(timestamp) AS hour,
 project,
    count() AS count
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
GROUP BY
    hour,
 project

Ok.

0 rows in set. Elapsed: 2.830 sec. Processed 798.89 million rows, 17.40 GB (282.28 million rows/s., 6.15 GB/s.)
Peak memory usage: 543.71 MiB.
```

:::note
В приведённом выше примере наша целевая таблица использует движок [SummingMergeTree](/engines/table-engines/mergetree-family/summingmergetree). В этом случае мы можем просто использовать наш исходный агрегирующий запрос. Для более сложных случаев использования, которые задействуют [AggregatingMergeTree](/engines/table-engines/mergetree-family/aggregatingmergetree), пользователи будут использовать функции `-State` для агрегатов. Пример этого можно найти [здесь](/integrations/s3/performance#be-aware-of-merges).
:::


В нашем случае это относительно легковесная агрегация, которая завершается менее чем за 3 секунды и использует менее 600 МиБ памяти. Для более сложных или длительных агрегаций можно повысить устойчивость процесса, используя описанный ранее подход с дублирующей таблицей, т.е. создать теневую целевую таблицу, например `pypi_downloads_per_day_v2`, вставить данные в неё и присоединить полученные партиции к `pypi_downloads_per_day`.

Часто запрос материализованного представления может быть более сложным (что неудивительно, иначе пользователи не стали бы использовать представление!) и потреблять ресурсы. В редких случаях ресурсы для запроса превышают возможности сервера. Это подчёркивает одно из преимуществ материализованных представлений ClickHouse — они инкрементальны и не обрабатывают весь набор данных за один раз!

В этом случае доступны несколько вариантов:

1. Изменить запрос для заполнения диапазонов, например `WHERE timestamp BETWEEN 2024-12-17 08:00:00 AND 2024-12-17 09:00:00`, `WHERE timestamp BETWEEN 2024-12-17 07:00:00 AND 2024-12-17 08:00:00` и т.д.
2. Использовать [движок таблиц Null](/engines/table-engines/special/null) для заполнения материализованного представления. Это воспроизводит типичное инкрементальное наполнение материализованного представления, выполняя его запрос над блоками данных (настраиваемого размера).

Вариант (1) представляет собой простейший подход и часто является достаточным. Для краткости мы не приводим примеры.

Вариант (2) рассмотрим подробнее ниже.

#### Использование движка таблиц Null для заполнения материализованных представлений {#using-a-null-table-engine-for-filling-materialized-views}

[Движок таблиц Null](/engines/table-engines/special/null) предоставляет движок хранения, который не сохраняет данные (можно представить его как `/dev/null` в мире движков таблиц). Хотя это кажется противоречивым, материализованные представления всё равно будут выполняться для данных, вставляемых в этот движок таблиц. Это позволяет создавать материализованные представления без сохранения исходных данных — избегая операций ввода-вывода и связанных с ними затрат на хранение.

Важно отметить, что любые материализованные представления, привязанные к движку таблиц, всё равно выполняются над блоками данных при их вставке — отправляя результаты в целевую таблицу. Эти блоки имеют настраиваемый размер. Хотя более крупные блоки потенциально могут быть более эффективными (и быстрее обрабатываться), они потребляют больше ресурсов (в основном памяти). Использование этого движка таблиц означает, что мы можем строить материализованное представление инкрементально, т.е. по одному блоку за раз, избегая необходимости хранить всю агрегацию в памяти.

<Image img={nullTableMV} size='md' alt='Denormalization in ClickHouse' />

<br />

Рассмотрим следующий пример:

```sql
CREATE TABLE pypi_v2
(
    `timestamp` DateTime,
    `project` String
)
ENGINE = Null

CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv_v2 TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi_v2
GROUP BY
    hour,
 project
```

Здесь мы создаём таблицу Null `pypi_v2` для получения строк, которые будут использоваться для построения материализованного представления. Обратите внимание, как мы ограничиваем схему только необходимыми столбцами. Наше материализованное представление выполняет агрегацию над строками, вставляемыми в эту таблицу (по одному блоку за раз), отправляя результаты в целевую таблицу `pypi_downloads_per_day`.

:::note
Мы использовали `pypi_downloads_per_day` в качестве целевой таблицы. Для дополнительной устойчивости можно создать дублирующую таблицу `pypi_downloads_per_day_v2` и использовать её в качестве целевой таблицы представления, как показано в предыдущих примерах. После завершения вставки партиции из `pypi_downloads_per_day_v2` могут быть, в свою очередь, перемещены в `pypi_downloads_per_day`. Это позволит восстановиться в случае, если вставка не удастся из-за проблем с памятью или прерываний сервера, т.е. достаточно очистить `pypi_downloads_per_day_v2`, настроить параметры и повторить попытку.
:::

Чтобы заполнить это материализованное представление, достаточно вставить соответствующие данные для заполнения в `pypi_v2` из `pypi`.

```sql
INSERT INTO pypi_v2 SELECT timestamp, project FROM pypi WHERE timestamp < '2024-12-17 09:00:00'

0 rows in set. Elapsed: 27.325 sec. Processed 1.50 billion rows, 33.48 GB (54.73 million rows/s., 1.23 GB/s.)
Peak memory usage: 639.47 MiB.
```

Обратите внимание, что использование памяти здесь составляет `639.47 МиБ`.


##### Настройка производительности и ресурсов {#tuning-performance--resources}

Несколько факторов определяют производительность и используемые ресурсы в описанном выше сценарии. Перед началом настройки рекомендуется ознакомиться с механизмом вставки данных, подробно описанным в разделе [Использование потоков для чтения](/integrations/s3/performance#using-threads-for-reads) руководства [Оптимизация производительности вставки и чтения для S3](/integrations/s3/performance). Краткое изложение:

- **Параллелизм чтения** — количество потоков, используемых для чтения. Управляется параметром [`max_threads`](/operations/settings/settings#max_threads). В ClickHouse Cloud это значение определяется размером инстанса и по умолчанию равно количеству vCPU. Увеличение этого значения может улучшить производительность чтения за счёт большего потребления памяти.
- **Параллелизм вставки** — количество потоков вставки, используемых для записи данных. Управляется параметром [`max_insert_threads`](/operations/settings/settings#max_insert_threads). В ClickHouse Cloud это значение определяется размером инстанса (от 2 до 4), а в OSS-версии установлено в 1. Увеличение этого значения может улучшить производительность за счёт большего потребления памяти.
- **Размер блока вставки** — данные обрабатываются в цикле, где они извлекаются, парсятся и формируются в блоки вставки в памяти на основе [ключа партиционирования](/engines/table-engines/mergetree-family/custom-partitioning-key). Эти блоки сортируются, оптимизируются, сжимаются и записываются в хранилище как новые [куски данных](/parts). Размер блока вставки, управляемый параметрами [`min_insert_block_size_rows`](/operations/settings/settings#min_insert_block_size_rows) и [`min_insert_block_size_bytes`](/operations/settings/settings#min_insert_block_size_bytes) (несжатые данные), влияет на использование памяти и дисковый ввод-вывод. Большие блоки используют больше памяти, но создают меньше кусков, снижая нагрузку на ввод-вывод и фоновые слияния. Эти параметры представляют минимальные пороговые значения (сброс происходит при достижении любого из них).
- **Размер блока материализованного представления** — помимо описанной выше механики для основной вставки, перед вставкой в материализованные представления блоки также уплотняются для более эффективной обработки. Размер этих блоков определяется параметрами [`min_insert_block_size_bytes_for_materialized_views`](/operations/settings/settings#min_insert_block_size_bytes_for_materialized_views) и [`min_insert_block_size_rows_for_materialized_views`](/operations/settings/settings#min_insert_block_size_rows_for_materialized_views). Большие блоки обеспечивают более эффективную обработку за счёт большего потребления памяти. По умолчанию эти параметры принимают значения соответствующих параметров исходной таблицы [`min_insert_block_size_rows`](/operations/settings/settings#min_insert_block_size_rows) и [`min_insert_block_size_bytes`](/operations/settings/settings#min_insert_block_size_bytes).

Для повышения производительности пользователи могут следовать рекомендациям, изложенным в разделе [Настройка потоков и размера блока для вставки](/integrations/s3/performance#tuning-threads-and-block-size-for-inserts) руководства [Оптимизация производительности вставки и чтения для S3](/integrations/s3/performance). В большинстве случаев не требуется изменять параметры `min_insert_block_size_bytes_for_materialized_views` и `min_insert_block_size_rows_for_materialized_views` для улучшения производительности. Если эти параметры изменяются, используйте те же рекомендации, что и для `min_insert_block_size_rows` и `min_insert_block_size_bytes`.

Для минимизации использования памяти пользователи могут поэкспериментировать с этими параметрами. Это неизбежно снизит производительность. Используя предыдущий запрос, приведём примеры ниже.

Снижение `max_insert_threads` до 1 уменьшает потребление памяти.

```sql
INSERT INTO pypi_v2
SELECT
    timestamp,
 project
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
SETTINGS max_insert_threads = 1

0 строк в наборе. Затрачено: 27.752 сек. Обработано 1.50 млрд строк, 33.48 ГБ (53.89 млн строк/с., 1.21 ГБ/с.)
Пиковое использование памяти: 506.78 МиБ.
```

Мы можем ещё больше снизить потребление памяти, уменьшив параметр `max_threads` до 1.

```sql
INSERT INTO pypi_v2
SELECT timestamp, project
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
SETTINGS max_insert_threads = 1, max_threads = 1

Ok.

0 строк в наборе. Затрачено: 43.907 сек. Обработано 1.50 млрд строк, 33.48 ГБ (34.06 млн строк/с., 762.54 МБ/с.)
Пиковое использование памяти: 272.53 МиБ.
```


Наконец, мы можем ещё больше снизить потребление памяти, установив `min_insert_block_size_rows` в 0 (отключает этот параметр как фактор, определяющий размер блока) и `min_insert_block_size_bytes` в 10485760 (10 МиБ).

```sql
INSERT INTO pypi_v2
SELECT
    timestamp,
 project
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
SETTINGS max_insert_threads = 1, max_threads = 1, min_insert_block_size_rows = 0, min_insert_block_size_bytes = 10485760

0 строк в наборе. Время: 43.293 сек. Обработано 1.50 млрд строк, 33.48 ГБ (34.54 млн строк/с, 773.36 МБ/с).
Пиковое потребление памяти: 218.64 МиБ.
```

Наконец, имейте в виду, что уменьшение размеров блоков приводит к увеличению числа кусков и повышает нагрузку на слияния. Как описано [здесь](/integrations/s3/performance#be-aware-of-merges), эти настройки следует изменять с осторожностью.

### Отсутствует метка времени или монотонно возрастающий столбец {#no-timestamp-or-monotonically-increasing-column}

Описанные выше процессы предполагают наличие у пользователя метки времени или монотонно возрастающего столбца. В некоторых случаях этого просто нет. В таком случае мы рекомендуем следующий процесс, который использует многие из уже описанных шагов, но требует приостановки приёма данных.

1. Приостановите вставки в основную таблицу.
2. Создайте дубликат основной целевой таблицы, используя синтаксис `CREATE AS`.
3. Присоедините разделы из исходной целевой таблицы к дубликату с помощью [`ALTER TABLE ATTACH`](/sql-reference/statements/alter/partition#attach-partitionpart). **Примечание:** Эта операция присоединения отличается от ранее использованного перемещения. Несмотря на использование жёстких ссылок, данные в исходной таблице сохраняются.
4. Создайте новые материализованные представления.
5. Возобновите вставки. **Примечание:** Вставки будут обновлять только целевую таблицу, а не дубликат, который будет ссылаться только на исходные данные.
6. Выполните до-заполнение (backfill) материализованного представления, применяя тот же процесс, что и выше для данных с метками времени, используя дубликат таблицы в качестве источника.

Рассмотрим следующий пример с PyPI и созданным ранее новым материализованным представлением `pypi_downloads_per_day` (предположим, что мы не можем использовать метку времени):

```sql
SELECT count() FROM pypi

┌────count()─┐
│ 2039988137 │ -- 2.04 billion
└────────────┘

1 row in set. Elapsed: 0.003 sec.

-- (1) Приостановить вставки
-- (2) Создать дубликат нашей целевой таблицы

CREATE TABLE pypi_v2 AS pypi

SELECT count() FROM pypi_v2

┌────count()─┐
│ 2039988137 │ -- 2.04 billion
└────────────┘

1 row in set. Elapsed: 0.004 sec.

-- (3) Присоединить разделы из исходной целевой таблицы к дубликату.

ALTER TABLE pypi_v2
 (ATTACH PARTITION tuple() FROM pypi)

-- (4) Создать наши новые материализованные представления

CREATE TABLE pypi_downloads_per_day
(
    `hour` DateTime,
    `project` String,
    `count` Int64
)
ENGINE = SummingMergeTree
ORDER BY (project, hour)

CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi
GROUP BY
    hour,
 project

-- (4) Возобновить вставки. Здесь мы эмулируем это, вставляя одну строку.

INSERT INTO pypi SELECT *
FROM pypi
LIMIT 1

SELECT count() FROM pypi

┌────count()─┐
│ 2039988138 │ -- 2.04 billion
└────────────┘

1 row in set. Elapsed: 0.003 sec.

-- обратите внимание, что pypi_v2 содержит то же количество строк, что и раньше

SELECT count() FROM pypi_v2
┌────count()─┐
│ 2039988137 │ -- 2.04 billion
└────────────┘

-- (5) Выполнить до-заполнение представления, используя резервную таблицу pypi_v2

INSERT INTO pypi_downloads_per_day SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi_v2
GROUP BY
    hour,
 project

0 строк в наборе. Время: 3.719 сек. Обработано 2.04 млрд строк, 47.15 ГБ (548.57 млн строк/с, 12.68 ГБ/с).
```


DROP TABLE pypi&#95;v2;

```

На предпоследнем шаге выполняется обратное заполнение `pypi_downloads_per_day` с помощью простого подхода `INSERT INTO SELECT`, описанного [ранее](#timestamp-or-monotonically-increasing-column-available). Этот процесс можно оптимизировать, используя подход с таблицей Null, описанный [выше](#using-a-null-table-engine-for-filling-materialized-views), с опциональным использованием дублирующей таблицы для повышения отказоустойчивости.

Хотя эта операция требует приостановки вставок, промежуточные операции обычно выполняются быстро — это минимизирует перерывы в работе с данными.
```
