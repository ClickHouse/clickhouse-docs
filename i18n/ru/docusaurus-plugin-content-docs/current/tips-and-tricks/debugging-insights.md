---
sidebar_position: 1
slug: /community-wisdom/debugging-insights
sidebar_label: 'Отладка: ключевые рекомендации'
doc_type: 'guide'
keywords: [
  'устранение неполадок clickhouse',
  'ошибки clickhouse',
  'медленные запросы',
  'проблемы с памятью', 
  'проблемы с подключением',
  'оптимизация производительности',
  'ошибки базы данных',
  'проблемы конфигурации',
  'отладка',
  'решения'
]
title: 'Уроки — рекомендации по отладке'
description: 'Найдите решения наиболее распространённых проблем в ClickHouse, включая медленные запросы, ошибки, связанные с памятью, а также проблемы с подключением и конфигурацией.'
---



# Эксплуатация ClickHouse: практический опыт отладки от сообщества {#clickhouse-operations-community-debugging-insights}

_Это руководство является частью коллекции знаний, полученных на встречах сообщества. Больше практических решений и рекомендаций можно найти, [выбрав конкретную проблему](./community-wisdom.md)._
_Столкнулись с высокими эксплуатационными расходами? Ознакомьтесь с руководством сообщества по [оптимизации затрат](./cost-optimization.md)._


## Основные системные таблицы {#essential-system-tables}

Эти системные таблицы необходимы для отладки в продуктивной среде:

### system.errors {#system-errors}

Показывает все активные ошибки в вашем экземпляре ClickHouse.

```sql
SELECT name, value, changed
FROM system.errors
WHERE value > 0
ORDER BY value DESC;
```

### system.replicas {#system-replicas}

Содержит информацию о задержке репликации и статусе для мониторинга работоспособности кластера.

```sql
SELECT database, table, replica_name, absolute_delay, queue_size, inserts_in_queue
FROM system.replicas
WHERE absolute_delay > 60
ORDER BY absolute_delay DESC;
```

### system.replication_queue {#system-replication-queue}

Предоставляет подробную информацию для диагностики проблем с репликацией.

```sql
SELECT database, table, replica_name, position, type, create_time, last_exception
FROM system.replication_queue
WHERE last_exception != ''
ORDER BY create_time DESC;
```

### system.merges {#system-merges}

Показывает текущие операции слияния и позволяет выявлять зависшие процессы.

```sql
SELECT database, table, elapsed, progress, is_mutation, total_size_bytes_compressed
FROM system.merges
ORDER BY elapsed DESC;
```

### system.parts {#system-parts}

Необходима для мониторинга количества кусков данных и выявления проблем фрагментации.

```sql
SELECT database, table, count() as part_count
FROM system.parts
WHERE active = 1
GROUP BY database, table
ORDER BY count() DESC;
```


## Распространённые проблемы в production-среде {#common-production-issues}

### Проблемы с дисковым пространством {#disk-space-problems}

Исчерпание дискового пространства в реплицируемых конфигурациях создаёт каскадные проблемы. Когда на одном узле заканчивается место, другие узлы продолжают попытки синхронизации с ним, что вызывает всплески сетевого трафика и неочевидные симптомы. Один из участников сообщества потратил 4 часа на отладку проблемы, которая оказалась простой нехваткой дискового пространства. Используйте этот [запрос](/knowledgebase/useful-queries-for-troubleshooting#show-disk-storage-number-of-parts-number-of-rows-in-systemparts-and-marks-across-databases) для мониторинга дискового хранилища на конкретном кластере.

Пользователям AWS следует учитывать, что стандартные универсальные тома EBS имеют ограничение в 16 ТБ.

### Ошибка «слишком много частей» {#too-many-parts-error}

Небольшие частые вставки создают проблемы с производительностью. Сообщество выявило, что частота вставок выше 10 в секунду часто вызывает ошибки «слишком много частей», поскольку ClickHouse не успевает достаточно быстро объединять части.

**Решения:**

- Группируйте данные с использованием порогов в 30 секунд или 200 МБ
- Включите async_insert для автоматической группировки
- Используйте буферные таблицы для группировки на стороне сервера
- Настройте Kafka для контролируемых размеров пакетов

[Официальная рекомендация](/best-practices/selecting-an-insert-strategy#batch-inserts-if-synchronous): минимум 1 000 строк на вставку, в идеале от 10 000 до 100 000.

### Проблемы с некорректными временными метками {#data-quality-issues}

Приложения, отправляющие данные с произвольными временными метками, создают проблемы с партициями. Это приводит к партициям с данными из нереалистичных дат (например, 1998 или 2050), что вызывает неожиданное поведение хранилища.

### Риски операций `ALTER` {#alter-operation-risks}

Крупные операции `ALTER` на многотерабайтных таблицах могут потреблять значительные ресурсы и потенциально блокировать базы данных. Один пример из сообщества включал изменение типа Integer на Float для 14 ТБ данных, что заблокировало всю базу данных и потребовало восстановления из резервных копий.

**Мониторинг ресурсоёмких мутаций:**

```sql
SELECT database, table, mutation_id, command, parts_to_do, is_done
FROM system.mutations
WHERE is_done = 0;
```

Сначала тестируйте изменения схемы на меньших наборах данных.


## Память и производительность {#memory-and-performance}

### Внешняя агрегация {#external-aggregation}

Включите внешнюю агрегацию для операций, требующих большого объёма памяти. Это медленнее, но предотвращает сбои из-за нехватки памяти за счёт выгрузки данных на диск. Для этого используйте параметр `max_bytes_before_external_group_by`, который помогает предотвратить сбои из-за нехватки памяти при выполнении больших операций `GROUP BY`. Подробнее об этом параметре можно узнать [здесь](/operations/settings/settings#max_bytes_before_external_group_by).

```sql
SELECT
    column1,
    column2,
    COUNT(*) as count,
    SUM(value) as total
FROM large_table
GROUP BY column1, column2
SETTINGS max_bytes_before_external_group_by = 1000000000; -- порог 1 ГБ
```

### Детали асинхронной вставки {#async-insert-details}

Асинхронная вставка автоматически группирует небольшие вставки на стороне сервера для повышения производительности. Вы можете настроить, нужно ли ожидать записи данных на диск перед возвратом подтверждения — немедленный возврат быстрее, но менее надёжен. Современные версии поддерживают дедупликацию для обработки дублирующихся данных внутри пакетов.

**Связанная документация**

- [Выбор стратегии вставки](/best-practices/selecting-an-insert-strategy#asynchronous-inserts)

### Конфигурация распределённых таблиц {#distributed-table-configuration}

По умолчанию распределённые таблицы используют однопоточные вставки. Включите `insert_distributed_sync` для параллельной обработки и немедленной отправки данных на шарды.

Отслеживайте накопление временных данных при использовании распределённых таблиц.

### Пороговые значения мониторинга производительности {#performance-monitoring-thresholds}

Рекомендуемые сообществом пороговые значения мониторинга:

- Кусков на партицию: предпочтительно менее 100
- Отложенные вставки: должны оставаться на нуле
- Частота вставок: ограничьте примерно до 1 в секунду для оптимальной производительности

**Связанная документация**

- [Пользовательский ключ партиционирования](/engines/table-engines/mergetree-family/custom-partitioning-key)


## Краткий справочник {#quick-reference}

| Проблема        | Обнаружение                      | Решение                            |
| --------------- | -------------------------------- | ---------------------------------- |
| Дисковое пространство | Проверьте общий размер в `system.parts` | Отслеживайте использование, планируйте масштабирование |
| Слишком много частей | Подсчитайте количество частей на таблицу | Используйте пакетные вставки, включите async_insert |
| Отставание репликации | Проверьте задержку в `system.replicas` | Отслеживайте сеть, перезапустите реплики |
| Некорректные данные | Проверьте даты партиций | Внедрите валидацию временных меток |
| Зависшие мутации | Проверьте статус в `system.mutations` | Сначала протестируйте на небольшом объеме данных |

### Видеоматериалы {#video-sources}

- [10 уроков эксплуатации ClickHouse](https://www.youtube.com/watch?v=liTgGiTuhJE)
- [Быстрые, параллельные и согласованные асинхронные вставки в ClickHouse](https://www.youtube.com/watch?v=AsMPEfN5QtM)
