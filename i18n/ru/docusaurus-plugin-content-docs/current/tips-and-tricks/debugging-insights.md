---
sidebar_position: 1
slug: /community-wisdom/debugging-insights
sidebar_label: 'Отладка: практические рекомендации'
doc_type: 'guide'
keywords: [
  'clickhouse troubleshooting',
  'ошибки clickhouse',
  'медленные запросы',
  'проблемы с памятью', 
  'проблемы с подключением',
  'оптимизация производительности',
  'ошибки базы данных',
  'проблемы с конфигурацией',
  'отладка',
  'решения'
]
title: 'Уроки — практические советы по отладке'
description: 'Найдите решения наиболее распространённых проблем ClickHouse: от медленных запросов и ошибок памяти до проблем с подключением и конфигурацией.'
---



# Эксплуатация ClickHouse: опыт отладки от сообщества {#clickhouse-operations-community-debugging-insights}

_Это руководство является частью сборника материалов, полученных на встречах сообщества. Больше практических решений и рекомендаций можно найти, [выбрав конкретную проблему](./community-wisdom.md)._
_Высокие эксплуатационные расходы? Ознакомьтесь с руководством сообщества по [оптимизации затрат](./cost-optimization.md)._


## Основные системные таблицы {#essential-system-tables}

Эти системные таблицы необходимы для отладки в production-среде:

### system.errors {#system-errors}

Показывает все активные ошибки в вашем экземпляре ClickHouse.

```sql
SELECT name, value, changed
FROM system.errors
WHERE value > 0
ORDER BY value DESC;
```

### system.replicas {#system-replicas}

Содержит информацию о задержке репликации и статусе для мониторинга работоспособности кластера.

```sql
SELECT database, table, replica_name, absolute_delay, queue_size, inserts_in_queue
FROM system.replicas
WHERE absolute_delay > 60
ORDER BY absolute_delay DESC;
```

### system.replication_queue {#system-replication-queue}

Предоставляет подробную информацию для диагностики проблем репликации.

```sql
SELECT database, table, replica_name, position, type, create_time, last_exception
FROM system.replication_queue
WHERE last_exception != ''
ORDER BY create_time DESC;
```

### system.merges {#system-merges}

Показывает текущие операции слияния и позволяет выявить зависшие процессы.

```sql
SELECT database, table, elapsed, progress, is_mutation, total_size_bytes_compressed
FROM system.merges
ORDER BY elapsed DESC;
```

### system.parts {#system-parts}

Необходима для мониторинга количества партов и выявления проблем фрагментации.

```sql
SELECT database, table, count() as part_count
FROM system.parts
WHERE active = 1
GROUP BY database, table
ORDER BY count() DESC;
```


## Распространённые проблемы в production-окружении {#common-production-issues}

### Проблемы с дисковым пространством {#disk-space-problems}

Исчерпание дискового пространства в реплицируемых конфигурациях создаёт каскадные проблемы. Когда на одном узле заканчивается место, другие узлы продолжают пытаться синхронизироваться с ним, что вызывает всплески сетевого трафика и неочевидные симптомы. Один из участников сообщества потратил 4 часа на отладку проблемы, которая оказалась простой нехваткой дискового пространства. Используйте этот [запрос](/knowledgebase/useful-queries-for-troubleshooting#show-disk-storage-number-of-parts-number-of-rows-in-systemparts-and-marks-across-databases) для мониторинга дискового хранилища на конкретном кластере.

Пользователям AWS следует учитывать, что стандартные тома EBS общего назначения имеют ограничение в 16 ТБ.

### Ошибка «слишком много кусков» {#too-many-parts-error}

Небольшие частые вставки создают проблемы с производительностью. Сообщество выявило, что частота вставок выше 10 в секунду часто вызывает ошибки «слишком много кусков», поскольку ClickHouse не успевает достаточно быстро объединять куски.

**Решения:**

- Группируйте данные с использованием порогов в 30 секунд или 200 МБ
- Включите async_insert для автоматической группировки
- Используйте буферные таблицы для группировки на стороне сервера
- Настройте Kafka для контролируемых размеров батчей

[Официальная рекомендация](/best-practices/selecting-an-insert-strategy#batch-inserts-if-synchronous): минимум 1000 строк на вставку, в идеале от 10 000 до 100 000.

### Проблемы с некорректными временными метками {#data-quality-issues}

Приложения, отправляющие данные с произвольными временными метками, создают проблемы с партициями. Это приводит к партициям с данными из нереалистичных дат (например, 1998 или 2050), что вызывает неожиданное поведение хранилища.

### Риски операций `ALTER` {#alter-operation-risks}

Крупные операции `ALTER` на многотерабайтных таблицах могут потреблять значительные ресурсы и потенциально блокировать базы данных. Один пример из сообщества включал изменение типа Integer на Float для 14 ТБ данных, что заблокировало всю базу данных и потребовало восстановления из резервных копий.

**Мониторинг ресурсоёмких мутаций:**

```sql
SELECT database, table, mutation_id, command, parts_to_do, is_done
FROM system.mutations
WHERE is_done = 0;
```

Сначала тестируйте изменения схемы на меньших наборах данных.


## Память и производительность {#memory-and-performance}

### Внешняя агрегация {#external-aggregation}

Включите внешнюю агрегацию для операций, интенсивно потребляющих память. Она работает медленнее, но предотвращает сбои из-за исчерпания памяти путём слива на диск. Для этого используйте настройку `max_bytes_before_external_group_by`, которая поможет избежать сбоев при выполнении крупных операций `GROUP BY`. Подробнее об этой настройке — [здесь](/operations/settings/settings#max_bytes_before_external_group_by).

```sql
SELECT
    column1,
    column2,
    COUNT(*) as count,
    SUM(value) as total
FROM large_table
GROUP BY column1, column2
SETTINGS max_bytes_before_external_group_by = 1000000000; -- порог в 1 ГБ
```

### Детали асинхронной вставки {#async-insert-details}

Асинхронная вставка автоматически собирает небольшие вставки в батчи на стороне сервера для повышения производительности. Вы можете настроить, ожидать ли записи данных на диск перед возвратом подтверждения: немедленный возврат быстрее, но обеспечивает меньшую надёжность. Современные версии поддерживают дедупликацию для обработки дублирующихся данных внутри батчей.

**Связанная документация**

- [Выбор стратегии вставки](/best-practices/selecting-an-insert-strategy#asynchronous-inserts)

### Конфигурация распределённых таблиц {#distributed-table-configuration}

По умолчанию распределённые таблицы используют однопоточные вставки. Включите `insert_distributed_sync` для параллельной обработки и немедленной отправки данных на шарды.

Отслеживайте накопление временных данных при использовании распределённых таблиц.

### Пороги мониторинга производительности {#performance-monitoring-thresholds}

Рекомендуемые сообществом пороги мониторинга:

- Количество частей на партицию: предпочтительно менее 100
- Задержанные вставки: должны оставаться на нуле
- Частота вставок: ограничивайте примерно 1 в секунду для оптимальной производительности

**Связанная документация**

- [Пользовательский ключ партиционирования](/engines/table-engines/mergetree-family/custom-partitioning-key)


## Краткий справочник {#quick-reference}

| Проблема        | Обнаружение                      | Решение                            |
| --------------- | -------------------------------- | ---------------------------------- |
| Дисковое пространство | Проверить общий размер в `system.parts` | Отслеживать использование, планировать масштабирование |
| Слишком много частей | Подсчитать количество частей на таблицу | Пакетные вставки, включить async_insert |
| Отставание репликации | Проверить задержку в `system.replicas` | Отслеживать сеть, перезапустить реплики |
| Некорректные данные | Проверить даты партиций | Реализовать валидацию временных меток |
| Зависшие мутации | Проверить статус в `system.mutations` | Сначала протестировать на небольших данных |

### Видеоматериалы {#video-sources}

- [10 уроков эксплуатации ClickHouse](https://www.youtube.com/watch?v=liTgGiTuhJE)
- [Быстрые, параллельные и согласованные асинхронные вставки в ClickHouse](https://www.youtube.com/watch?v=AsMPEfN5QtM)
