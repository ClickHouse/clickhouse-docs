---
sidebar_position: 1
slug: /community-wisdom/debugging-insights
sidebar_label: 'Рекомендации по отладке'
doc_type: 'guide'
keywords: [
  'устранение неполадок ClickHouse',
  'ошибки ClickHouse',
  'медленные запросы',
  'проблемы с памятью', 
  'проблемы с подключением',
  'оптимизация производительности',
  'ошибки базы данных',
  'проблемы с конфигурацией',
  'отладка',
  'решения'
]
title: 'Уроки — рекомендации по отладке'
description: 'Найдите решения наиболее распространённых проблем ClickHouse, включая медленные запросы, ошибки, связанные с памятью, а также проблемы с подключением и конфигурацией.'
---

# Операции ClickHouse: практические советы по отладке от сообщества \\{#clickhouse-operations-community-debugging-insights\\}

*Это руководство является частью подборки материалов, подготовленной на основе встреч сообщества. Для дополнительных практических решений и рекомендаций вы можете [подобрать материалы под конкретную проблему](./community-wisdom.md).*
*Столкнулись с высокими операционными затратами? Ознакомьтесь с руководством сообщества по [оптимизации затрат](./cost-optimization.md).*

## Основные системные таблицы \\{#essential-system-tables\\}

Эти системные таблицы являются важнейшими для отладки в продакшене:

### system.errors \{#system-errors\}

Показывает все активные ошибки в вашем экземпляре ClickHouse.

```sql
SELECT name, value, changed 
FROM system.errors 
WHERE value > 0 
ORDER BY value DESC;
```


### system.replicas \{#system-replicas\}

Содержит информацию о задержке и статусе репликации для мониторинга состояния кластера.

```sql
SELECT database, table, replica_name, absolute_delay, queue_size, inserts_in_queue
FROM system.replicas 
WHERE absolute_delay > 60
ORDER BY absolute_delay DESC;
```


### system.replication&#95;queue \{#system-replication-queue\}

Предоставляет подробные сведения для диагностики проблем с репликацией.

```sql
SELECT database, table, replica_name, position, type, create_time, last_exception
FROM system.replication_queue 
WHERE last_exception != ''
ORDER BY create_time DESC;
```


### system.merges \{#system-merges\}

Отображает текущие операции слияния и может помочь выявить зависшие процессы.

```sql
SELECT database, table, elapsed, progress, is_mutation, total_size_bytes_compressed
FROM system.merges 
ORDER BY elapsed DESC;
```


### system.parts \{#system-parts\}

Ключевая таблица для мониторинга количества частей и выявления проблем с фрагментацией.

```sql
SELECT database, table, count() as part_count
FROM system.parts 
WHERE active = 1
GROUP BY database, table
ORDER BY count() DESC;
```


## Распространённые проблемы в продакшене \\{#common-production-issues\\}

### Проблемы с дисковым пространством \\{#disk-space-problems\\}

Исчерпание дискового пространства в реплицируемых конфигурациях приводит к каскадным проблемам. Когда на одном узле заканчивается место, другие узлы продолжают пытаться синхронизироваться с ним, что вызывает всплески сетевого трафика и запутанные симптомы. Один из участников сообщества потратил 4 часа на отладку того, что оказалось просто нехваткой дискового пространства. Ознакомьтесь с этим [запросом](/knowledgebase/useful-queries-for-troubleshooting#show-disk-storage-number-of-parts-number-of-rows-in-systemparts-and-marks-across-databases), чтобы отслеживать использование дискового пространства в конкретном кластере.

Если вы используете AWS, следует учитывать, что стандартные универсальные EBS-тома имеют ограничение 16 ТБ.

### Ошибка &quot;too many parts&quot; \\{#too-many-parts-error\\}

Частые мелкие вставки создают проблемы с производительностью. Сообщество отмечает, что скорость вставок более 10 в секунду часто приводит к ошибкам &quot;too many parts&quot;, поскольку ClickHouse не успевает достаточно быстро сливать части.

**Решения:**

* Группировать данные с порогами в 30 секунд или 200 МБ
* Включить async&#95;insert для автоматического формирования батчей
* Использовать buffer-таблицы для батчинга на стороне сервера
* Настроить Kafka для контролируемого размера батчей

[Официальная рекомендация](/best-practices/selecting-an-insert-strategy#batch-inserts-if-synchronous): минимум 1 000 строк на одну вставку, в идеале от 10 000 до 100 000.

### Проблемы с некорректными временными метками \\{#data-quality-issues\\}

Приложения, отправляющие данные с произвольными временными метками, создают проблемы с партиционированием. Это приводит к партициям с данными из нереалистичных дат (например, 1998 или 2050 год), вызывая непредсказуемое поведение при хранении.

### Риски операций `ALTER` \{#alter-operation-risks\}

Крупные операции `ALTER` над многотерабайтными таблицами могут потреблять значительные ресурсы и потенциально блокировать базы данных. В одном примере из сообщества изменение типа Integer на Float для 14 ТБ данных заблокировало всю базу данных и потребовало восстановления из резервных копий.

**Мониторинг ресурсоёмких мутаций:**

```sql
SELECT database, table, mutation_id, command, parts_to_do, is_done
FROM system.mutations 
WHERE is_done = 0;
```

Сначала тестируйте изменения схемы на небольших наборах данных.


## Память и производительность \\{#memory-and-performance\\}

### Внешняя агрегация \{#external-aggregation\}

Включите внешнюю агрегацию для операций с большим потреблением памяти. Она работает медленнее, но предотвращает аварийные завершения из-за нехватки памяти за счёт выгрузки данных на диск. Это можно сделать с помощью настройки `max_bytes_before_external_group_by`, которая поможет избежать ошибок «недостаточно памяти» при больших операциях `GROUP BY`. Подробнее об этой настройке можно узнать [здесь](/operations/settings/settings#max_bytes_before_external_group_by).

```sql
SELECT 
    column1,
    column2,
    COUNT(*) as count,
    SUM(value) as total
FROM large_table
GROUP BY column1, column2
SETTINGS max_bytes_before_external_group_by = 1000000000; -- 1GB threshold
```


### Подробности об асинхронной вставке \\{#async-insert-details\\}

Асинхронная вставка автоматически объединяет небольшие операции вставки в пакеты на стороне сервера для повышения производительности. Вы можете настроить, нужно ли ждать записи данных на диск перед возвратом подтверждения — немедленный возврат быстрее, но менее надёжен. Современные версии поддерживают дедупликацию для обработки дублирующихся данных внутри пакетов.

**Связанные документы**

* [Выбор стратегии вставки](/best-practices/selecting-an-insert-strategy#asynchronous-inserts)

### Конфигурация распределённой таблицы \\{#distributed-table-configuration\\}

По умолчанию распределённые таблицы используют однопоточные вставки. Включите `insert_distributed_sync` для параллельной обработки и немедленной отправки данных на сегменты.

Отслеживайте накопление временных данных при использовании распределённых таблиц.

### Пороговые значения для мониторинга производительности \\{#performance-monitoring-thresholds\\}

Рекомендуемые сообществом пороговые значения мониторинга:

* Частей на партицию: желательно менее 100
* Задержанные вставки: должны оставаться на нуле
* Скорость вставки: ограничьте примерно до 1 операции в секунду для оптимальной производительности

**Связанные документы**

* [Пользовательский ключ партиционирования](/engines/table-engines/mergetree-family/custom-partitioning-key)

## Краткая справка \\{#quick-reference\\}

| Проблема | Обнаружение | Решение |
|-------|-----------|----------|
| Дисковое пространство | Проверить суммарный объём байт в `system.parts` | Отслеживать использование, планировать масштабирование |
| Слишком много частей | Посчитать количество частей на таблицу | Пакетные вставки, включить async_insert |
| Задержка репликации | Проверить задержку в `system.replicas` | Отслеживать состояние сети, перезапустить реплики |
| Некорректные данные | Проверить даты партиций | Реализовать проверку меток времени |
| Застрявшие мутации | Проверить статус в `system.mutations` | Сначала протестировать на небольшом объёме данных |

### Видео-материалы \\{#video-sources\\}

- [10 уроков эксплуатации ClickHouse](https://www.youtube.com/watch?v=liTgGiTuhJE)
- [Быстрые, параллельные и согласованные асинхронные операции INSERT в ClickHouse](https://www.youtube.com/watch?v=AsMPEfN5QtM)