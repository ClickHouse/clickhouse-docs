---
slug: /getting-started/quick-start
sidebar_label: 'Быстрый старт'
sidebar_position: 1
keywords: ['clickhouse', 'установка', 'начало работы', 'быстрый старт']
pagination_next: 'getting-started/index'
title: 'Быстрый старт'
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

## Обзор

Настройте ClickHouse быстро. Скачайте подходящий бинарный файл для вашей ОС, узнайте, как запустить сервер ClickHouse, создать таблицу, вставить в нее данные и выполнить запрос к вашей таблице с помощью клиента ClickHouse.

### Предварительные требования

Вам потребуется curl или другой HTTP-клиент командной строки, чтобы скачать бинарный файл ClickHouse.

## Скачайте бинарный файл

ClickHouse работает нативно на Linux, FreeBSD и macOS, а также работает на Windows через [WSL](https://learn.microsoft.com/en-us/windows/wsl/about). Самый простой способ скачать ClickHouse локально — запустить следующую команду `curl`. Она определяет, поддерживается ли ваша операционная система, а затем скачивает соответствующий бинарный файл ClickHouse.

:::note
Рекомендуем выполнить команду ниже из новой и пустой подпапки, так как некоторые конфигурационные файлы будут созданы в директории, в которой находится бинарный файл при первом запуске сервера ClickHouse.
:::

```bash
curl https://clickhouse.com/ | sh
```

Вы должны увидеть:

```
Успешно скачан бинарный файл ClickHouse, вы можете запустить его, как:
    ./clickhouse

Также вы можете его установить:
sudo ./clickhouse install
```

На этом этапе вы можете проигнорировать подсказку о запуске команды `install`.

:::note
Для пользователей Mac: Если вы получаете ошибки, что разработчик бинарного файла не может быть проверен, пожалуйста, смотрите ["Исправление ошибки проверки разработчика в MacOS"](https://clickhouse.com/docs/knowledgebase/fix-developer-verification-error-in-macos).
:::


## Запустите сервер

Запустите следующую команду, чтобы запустить сервер ClickHouse:

```bash
./clickhouse server
```

Вы должны увидеть, как терминал заполняется логами. Это ожидаемо. В ClickHouse [уровень логирования по умолчанию](https://clickhouse.com/docs/knowledgebase/why_default_logging_verbose) установлен на `trace`, а не на `warning`.

## Запустите клиент

Используйте `clickhouse-client`, чтобы подключиться к вашему сервису ClickHouse. Откройте новый терминал, перейдите в директорию, где сохранен ваш бинарный файл `clickhouse`, и выполните следующую команду:

```bash
./clickhouse client
```

Вы должны увидеть улыбающееся лицо, когда он подключается к вашему сервису, работающему на localhost:

```response
my-host :)
```

## Создайте таблицу

Используйте `CREATE TABLE`, чтобы определить новую таблицу. Типичные команды SQL DDL работают в ClickHouse с одним дополнением — таблицы в ClickHouse требуют наличие параметра `ENGINE`. Используйте [`MergeTree`](/engines/table-engines/mergetree-family/mergetree), чтобы воспользоваться преимуществами производительности ClickHouse:

```sql
CREATE TABLE my_first_table
(
    user_id UInt32,
    message String,
    timestamp DateTime,
    metric Float32
)
ENGINE = MergeTree
PRIMARY KEY (user_id, timestamp)
```

## Вставьте данные

Вы можете использовать знакомую команду `INSERT INTO TABLE` с ClickHouse, но важно понимать, что каждое вставление в таблицу `MergeTree` вызывает создание того, что мы называем **part** в ClickHouse, в хранилище. Эти части позже объединяются в фоновом режиме ClickHouse.

В ClickHouse мы стремимся выполнять массовую вставку большого количества строк за раз (десятки тысяч или даже миллионы сразу), чтобы минимизировать количество [**parts**](/parts), которые необходимо объединить в фоновом процессе.

В этом руководстве мы пока не будем об этом беспокоиться. Выполните следующую команду, чтобы вставить несколько строк данных в вашу таблицу:

```sql
INSERT INTO my_first_table (user_id, message, timestamp, metric) VALUES
    (101, 'Привет, ClickHouse!',                                  now(),       -1.0    ),
    (102, 'Вставить много строк за раз',                        yesterday(), 1.41421 ),
    (102, 'Сортируйте ваши данные на основе часто используемых запросов', today(),     2.718   ),
    (101, 'Гранулы — это самые маленькие части данных, которые читаются', now() + 5,   3.14159 )
```

## Выполните запрос к вашей новой таблице

Вы можете написать запрос `SELECT` так же, как вы бы сделали это с любой SQL-базой данных:

```sql
SELECT *
FROM my_first_table
ORDER BY timestamp
```
Обратите внимание, что ответ возвращается в красивом табличном формате:

```response
┌─user_id─┬─message────────────────────────────────────────────┬───────────timestamp─┬──metric─┐
│     102 │ Вставить много строк за раз                        │ 2022-03-21 00:00:00 │ 1.41421 │
│     102 │ Сортируйте ваши данные на основе часто используемых запросов │ 2022-03-22 00:00:00 │   2.718 │
│     101 │ Привет, ClickHouse!                                 │ 2022-03-22 14:04:09 │      -1 │
│     101 │ Гранулы — это самые маленькие части данных, которые читаются │ 2022-03-22 14:04:14 │ 3.14159 │
└─────────┴────────────────────────────────────────────────────┴─────────────────────┴─────────┘

4 строки в наборе. Затраченное время: 0.008 сек.
```

## Вставьте свои данные

Следующий шаг — это загрузка ваших собственных данных в ClickHouse. У нас есть множество [табличных функций](/sql-reference/table-functions/index.md) и [интеграций](/integrations) для загрузки данных. У нас есть примеры в вкладках ниже, или вы можете ознакомиться с нашей страницей [Интеграции](/integrations) для получения длинного списка технологий, которые интегрируются с ClickHouse.

<Tabs groupId="read_data">
<TabItem value="S3" label="S3" default>

Используйте [`s3` таблицу функцию](/sql-reference/table-functions/s3.md), чтобы читать файлы из S3. Это таблица-функция, что означает, что результатом является таблица, которая может быть:

1. использована в качестве источника для запроса `SELECT` (что позволяет вам выполнять произвольные запросы и оставлять ваши данные в S3), или...
2. вставить полученную таблицу в таблицу `MergeTree` (когда вы готовы переместить ваши данные в ClickHouse)

Произвольный запрос выглядит следующим образом:

```sql
SELECT
   passenger_count,
   avg(toFloat32(total_amount))
FROM s3(
    'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
    'TabSeparatedWithNames'
)
GROUP BY passenger_count
ORDER BY passenger_count;
```

Перемещение данных в таблицу ClickHouse выглядит следующим образом, где `nyc_taxi` — это таблица `MergeTree`:

```sql
INSERT INTO nyc_taxi
   SELECT * FROM s3(
    'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
    'TabSeparatedWithNames'
)
SETTINGS input_format_allow_errors_num=25000;
```

Посмотрите нашу [коллекцию страниц документации по AWS S3](/integrations/data-ingestion/s3/index.md) для получения множества подробностей и примеров использования S3 с ClickHouse.
<br/>
</TabItem>
<TabItem value="GCS" label="GCS">

Таблица функция [`s3` ](/sql-reference/table-functions/s3.md), используемая для чтения данных в AWS S3, также работает с файлами в Google Cloud Storage.

Например:

```sql
SELECT
   *
FROM s3(
  'https://storage.googleapis.com/my-bucket/trips.parquet',
  'MY_GCS_HMAC_KEY',
  'MY_GCS_HMAC_SECRET_KEY',
  'Parquet'
)
LIMIT 1000
```

Найдите больше подробностей на странице [`s3` таблицы функции](/sql-reference/table-functions/s3.md).
<br/>
</TabItem>
<TabItem value="URL" label="Web">

Таблица функция [`url` ](/sql-reference/table-functions/url) читает файлы, доступные из интернета:

```sql
--По умолчанию ClickHouse предотвращает перенаправления для защиты от атак SSRF.
--URL ниже требует перенаправления, поэтому мы должны установить max_http_get_redirects > 0.
SET max_http_get_redirects=10;

SELECT *
FROM url(
    'http://prod2.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv',
    'CSV'
  );
```

Найдите больше подробностей на странице [`url` таблицы функции](/sql-reference/table-functions/url).
<br/>
</TabItem>
<TabItem value="local_file" label="Локальный">

Используйте [`file` таблицы функции](/sql-reference/table-functions/file), чтобы читать локальный файл. Для простоты скопируйте файл в директорию `user_files` (которая находится в директории, куда вы скачали бинарный файл ClickHouse).

```sql
DESCRIBE TABLE file('comments.tsv')

Query id: 8ca9b2f9-65a2-4982-954a-890de710a336

┌─name──────┬─type────────────────────┬─default_type─┬─default_expression─┬─comment─┬─codec_expression─┬─ttl_expression─┐
│ id        │ Nullable(Int64)         │              │                    │         │                  │                │
│ type      │ Nullable(String)        │              │                    │         │                  │                │
│ author    │ Nullable(String)        │              │                    │         │                  │                │
│ timestamp │ Nullable(DateTime64(9)) │              │                    │         │                  │                │
│ comment   │ Nullable(String)        │              │                    │         │                  │                │
│ children  │ Array(Nullable(Int64))  │              │                    │         │                  │                │
└───────────┴─────────────────────────┴──────────────┴────────────────────┴─────────┴──────────────────┴────────────────┘
```

Обратите внимание, что ClickHouse определяет имена и типы данных ваших колонок, анализируя большой пакет строк. Если ClickHouse не может определить тип хранения из имени файла, вы можете указать его в качестве второго аргумента:

```sql
SELECT count()
FROM file(
  'comments.tsv',
  'TabSeparatedWithNames'
)
```

Посмотрите страницу документации по [`file` таблицы функции](/sql-reference/table-functions/file) для получения большей информации.
<br/>
</TabItem>
<TabItem value="PostgreSQL" label="PostgreSQL">

Используйте [`postgresql` таблицы функции](/sql-reference/table-functions/postgresql), чтобы читать данные из таблицы в PostgreSQL:

```sql
SELECT *
FROM
   postgresql(
    'localhost:5432',
    'my_database',
    'my_table',
    'postgresql_user',
    'password')
;
```

Посмотрите страницу документации по [`postgresql` таблицы функции](/sql-reference/table-functions/postgresql) для получения большей информации.
<br/>
</TabItem>
<TabItem value="MySQL" label="MySQL">

Используйте [`mysql` таблицы функции](/sql-reference/table-functions/mysql), чтобы читать данные из таблицы в MySQL:

```sql
SELECT *
FROM
   mysql(
    'localhost:3306',
    'my_database',
    'my_table',
    'postgresql_user',
    'password')
;
```

Посмотрите страницу документации по [`mysql` таблицы функции](/sql-reference/table-functions/mysql) для получения большей информации.
<br/>
</TabItem>
<TabItem value="Other DBMS" label="ODBC/JDBC">

ClickHouse может читать данные из любого источника ODBC или JDBC:

```sql
SELECT *
FROM
   odbc(
    'DSN=mysqlconn',
    'my_database',
    'my_table'
  );
```

Посмотрите страницы документации по [`odbc` таблицы функции](/sql-reference/table-functions/odbc) и [`jdbc` таблицы функции](/sql-reference/table-functions/jdbc) для получения большей информации.
<br/>
</TabItem>
<TabItem value="messagequeue" label="Сообщения">

Очереди сообщений могут передавать данные в ClickHouse с использованием соответствующего движка таблицы, включая:

- **Kafka**: интеграция с Kafka с использованием [`Kafka` движка таблицы](/engines/table-engines/integrations/kafka)
- **Amazon MSK**: интеграция с [Управляемой потоковой передачей для Apache Kafka Amazon (MSK)](/integrations/kafka/cloud/amazon-msk/)
- **RabbitMQ**: интеграция с RabbitMQ с использованием [`RabbitMQ` движка таблицы](/engines/table-engines/integrations/rabbitmq)
<br/>
</TabItem>
<TabItem value="datalake" label="Хранилища данных">

ClickHouse имеет таблицы функции для чтения данных из следующих источников:

- **Hadoop**: интеграция с Apache Hadoop с использованием [`hdfs` таблицы функции](/sql-reference/table-functions/hdfs)
- **Hudi**: чтение из существующих таблиц Apache Hudi в S3 с использованием [`hudi` таблицы функции](/sql-reference/table-functions/hudi)
- **Iceberg**: чтение из существующих таблиц Apache Iceberg в S3 с использованием [`iceberg` таблицы функции](/sql-reference/table-functions/iceberg)
- **DeltaLake**: чтение из существующих таблиц Delta Lake в S3 с использованием [`deltaLake` таблицы функции](/sql-reference/table-functions/deltalake)
<br/>
</TabItem>
<TabItem value="Other" label="Другие">

Посмотрите наш [длинный список интеграций ClickHouse](/integrations), чтобы узнать, как подключить ваши существующие фреймворки и источники данных к ClickHouse.
<br/>
</TabItem>
</Tabs>

## Следующие шаги

- Ознакомьтесь с нашим разделом [Основные концепции](/managing-data/core-concepts), чтобы узнать некоторые из основ, как ClickHouse работает под капотом.
- Ознакомьтесь с [Расширенным учебником](tutorial.md), который более подробно рассматривает ключевые концепции и возможности ClickHouse.
- Продолжайте обучение, пройдя наши бесплатные курсы по запросу на [ClickHouse Academy](https://learn.clickhouse.com/visitor_class_catalog).
- У нас есть список [примеров наборов данных](/getting-started/example-datasets/) с инструкциями о том, как их вставить.
- Если ваши данные поступают из внешнего источника, посмотрите нашу [коллекцию руководств по интеграции](/integrations/) для подключения к очередям сообщений, базам данных, конвейерам и прочему.
- Если вы используете инструмент визуализации UI/BI, ознакомьтесь с [руководствами для пользователей по подключению UI к ClickHouse](/integrations/data-visualization/).
- Руководство пользователя по [первичным ключам](/guides/best-practices/sparse-primary-indexes.md) — это все, что вам нужно знать о первичных ключах и о том, как их определять.
