---
description: 'Позволяет параллельно обрабатывать файлы из HDFS на множестве узлов указанного кластера.'
sidebar_label: 'hdfsCluster'
sidebar_position: 81
slug: /sql-reference/table-functions/hdfsCluster
title: 'hdfsCluster'
doc_type: 'reference'
---



# Табличная функция hdfsCluster

Позволяет обрабатывать файлы из HDFS параллельно с множества узлов в указанном кластере. На инициирующем узле создаётся соединение со всеми узлами кластера, раскрываются символы `*` в пути к файлам HDFS, и каждый файл динамически распределяется по узлам. Рабочий узел запрашивает у инициирующего узла следующую задачу и обрабатывает её. Это повторяется до тех пор, пока все задачи не будут выполнены.



## Синтаксис

```sql
hdfsCluster(cluster_name, URI, format, structure)
```


## Аргументы {#arguments}

| Аргумент       | Описание                                                                                                                                                                                                                                                                                         |
|----------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `cluster_name` | Имя кластера, используемое для построения набора адресов и параметров подключения к удалённым и локальным серверам.                                                                                                                                                                             |
| `URI`          | URI файла или группы файлов. Поддерживает следующие подстановочные шаблоны в режиме только для чтения: `*`, `**`, `?`, `{'abc','def'}` и `{N..M}`, где `N`, `M` — числа, `abc`, `def` — строки. Для получения дополнительной информации см. [подстановочные шаблоны в пути](../../engines/table-engines/integrations/s3.md#wildcards-in-path). |
| `format`       | [Формат](/sql-reference/formats) файла.                                                                                                                                                                                                                                                          |
| `structure`    | Структура таблицы. Формат: `'column1_name column1_type, column2_name column2_type, ...'`.                                                                                                                                                                                                        |



## Возвращаемое значение {#returned_value}

Таблица с указанной структурой, предназначенная для чтения данных из указанного файла.



## Примеры

1. Предположим, что у нас есть кластер ClickHouse с именем `cluster_simple` и несколько файлов со следующими URI в HDFS:

* &#39;hdfs://hdfs1:9000/some&#95;dir/some&#95;file&#95;1&#39;
* &#39;hdfs://hdfs1:9000/some&#95;dir/some&#95;file&#95;2&#39;
* &#39;hdfs://hdfs1:9000/some&#95;dir/some&#95;file&#95;3&#39;
* &#39;hdfs://hdfs1:9000/another&#95;dir/some&#95;file&#95;1&#39;
* &#39;hdfs://hdfs1:9000/another&#95;dir/some&#95;file&#95;2&#39;
* &#39;hdfs://hdfs1:9000/another&#95;dir/some&#95;file&#95;3&#39;

2. Выполните запрос для подсчёта количества строк в этих файлах:

```sql
SELECT count(*)
FROM hdfsCluster('cluster_simple', 'hdfs://hdfs1:9000/{some,another}_dir/some_file_{1..3}', 'TSV', 'name String, value UInt32')
```

3. Получите количество строк во всех файлах этих двух каталогов:

```sql
SELECT count(*)
FROM hdfsCluster('cluster_simple', 'hdfs://hdfs1:9000/{some,another}_dir/*', 'TSV', 'name String, value UInt32')
```

:::note
Если в списке файлов встречаются числовые диапазоны с ведущими нулями, используйте фигурные скобки для каждой цифры по отдельности или символ `?`.
:::


## См. также {#related}

- [Движок HDFS](../../engines/table-engines/integrations/hdfs.md)
- [Табличная функция HDFS](../../sql-reference/table-functions/hdfs.md)
