---
title: 'Частые вопросы по BYOC'
slug: /cloud/reference/byoc/reference/faq
sidebar_label: 'FAQ'
keywords: ['BYOC', 'cloud', 'bring your own cloud', 'FAQ']
description: 'Развертывание ClickHouse в собственной облачной инфраструктуре'
doc_type: 'reference'
---

## FAQ \{#faq\}

### Вычислительные ресурсы \{#compute\}

<details>
<summary>Могу ли я создать несколько сервисов в этом кластере EKS?</summary>

Да. Инфраструктуру нужно подготовить только один раз для каждой комбинации учетной записи AWS и региона.

</details>

<details>
<summary>Какие регионы вы поддерживаете для BYOC?</summary>

Все **публичные регионы**, перечисленные в нашей документации по [поддерживаемым регионам](https://clickhouse.com/docs/cloud/reference/supported-regions), доступны для развертывания BYOC. Приватные регионы не поддерживаются.

</details>

<details>
<summary>Будут ли накладные расходы по ресурсам? Какие ресурсы нужны для запуска сервисов, кроме инстансов ClickHouse?</summary>

Помимо самих инстансов ClickHouse (серверов ClickHouse и ClickHouse Keeper), мы также запускаем вспомогательные сервисы, такие как `clickhouse-operator`, `aws-cluster-autoscaler`, Istio и стек мониторинга.

Потребление ресурсов этими общими компонентами относительно стабильно и не растет линейно с количеством или размером ваших сервисов ClickHouse. В качестве грубого ориентира в AWS мы обычно используем отдельную группу узлов примерно из четырех инстансов EC2 типа `4xlarge` для запуска этих рабочих нагрузок.

</details>

### Сеть и безопасность \{#network-and-security\}

<details>
<summary>Можем ли мы отозвать разрешения, настроенные во время установки, после завершения настройки?</summary>

В настоящее время это невозможно.

</details>

<details>
<summary>Рассматривается ли внедрение дополнительных средств безопасности для доступа инженеров ClickHouse к инфраструктуре клиента для устранения неполадок?</summary>

Да. Реализация управляемого клиентом механизма, при котором клиенты могут одобрять доступ инженеров к кластеру, находится в нашем плане. На данный момент инженеры должны проходить через наш внутренний процесс эскалации, чтобы получить доступ к кластеру в режиме just-in-time. Этот доступ протоколируется и аудируется нашей командой безопасности.

</details>

<details>
<summary>Каков размер диапазона IP-адресов создаваемой VPC?</summary>

По умолчанию мы используем `10.0.0.0/16` для BYOC VPC. Мы рекомендуем резервировать как минимум /22 для потенциального будущего масштабирования,
но если вы предпочитаете ограничить размер, можно использовать /23, если, вероятно, вы будете ограничены
30 серверными подами.

</details>

<details>
<summary>Могу ли я сам задавать частоту обслуживания?</summary>

Свяжитесь со службой поддержки, чтобы запланировать окна обслуживания. Ожидайте как минимум еженедельную периодичность обновлений.

</details>

<details>
<summary>Как работает взаимодействие с хранилищем между BYOC VPC и S3?</summary>

Трафик между вашим клиентским BYOC VPC и S3 использует HTTPS (порт 443) через AWS S3 API для табличных данных, резервных копий и логов. При использовании конечных точек S3 VPC этот трафик остается внутри сети AWS и не проходит через общедоступный интернет.

</details>

<details>
<summary>Какие порты используются для внутреннего взаимодействия в кластере ClickHouse?</summary>

Внутреннее взаимодействие кластера ClickHouse внутри клиентского BYOC VPC использует:
- нативный протокол ClickHouse на порту 9000
- HTTP/HTTPS на портах 8123/8443
- межсерверное взаимодействие на порту 9009 для репликации и распределённых запросов

</details>

### Гарантии доступности (uptime SLA) \{#uptime-sla\}

<details>
<summary>Предоставляет ли ClickHouse гарантию доступности (SLA) для BYOC?</summary>

Нет. Поскольку плоскость данных размещается в облачной среде клиента, доступность сервиса зависит от ресурсов, которые не контролируются ClickHouse. Поэтому ClickHouse не предоставляет формальное соглашение об уровне доступности (uptime SLA) для развертываний BYOC. Если у вас есть дополнительные вопросы, свяжитесь с support@clickhouse.com.

</details>