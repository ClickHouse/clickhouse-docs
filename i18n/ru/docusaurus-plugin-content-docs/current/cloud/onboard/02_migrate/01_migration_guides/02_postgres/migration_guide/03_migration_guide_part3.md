---
slug: /migrations/postgresql/data-modeling-techniques
title: 'Методы моделирования данных'
description: 'Часть 3 руководства по миграции с PostgreSQL на ClickHouse'
keywords: ['postgres', 'postgresql']
show_related_blogs: true
sidebar_label: 'Часть 3'
doc_type: 'guide'
---

import postgres_b_tree from '@site/static/images/migrations/postgres-b-tree.png';
import postgres_sparse_index from '@site/static/images/migrations/postgres-sparse-index.png';
import postgres_partitions from '@site/static/images/migrations/postgres-partitions.png';
import postgres_projections from '@site/static/images/migrations/postgres-projections.png';
import Image from '@theme/IdealImage';

> Это **Часть 3** руководства по миграции с PostgreSQL на ClickHouse. На практическом примере в ней демонстрируется, как моделировать данные в ClickHouse при миграции с PostgreSQL.

Мы рекомендуем пользователям, мигрирующим с Postgres, ознакомиться с [руководством по моделированию данных в ClickHouse](/data-modeling/schema-design). В этом руководстве используется тот же набор данных Stack Overflow и рассматриваются несколько подходов с использованием возможностей ClickHouse.


## Первичные (упорядочивающие) ключи в ClickHouse {#primary-ordering-keys-in-clickhouse}

Пользователи, переходящие с OLTP-баз данных, часто ищут аналогичную концепцию в ClickHouse. Обнаружив, что ClickHouse поддерживает синтаксис `PRIMARY KEY`, пользователи могут попытаться определить схему таблицы, используя те же ключи, что и в исходной OLTP-базе данных. Это неправильный подход.

### Чем отличаются первичные ключи ClickHouse? {#how-are-clickhouse-primary-keys-different}

Чтобы понять, почему использование первичного ключа OLTP в ClickHouse неуместно, необходимо разобраться в основах индексирования в ClickHouse. Мы используем Postgres в качестве примера для сравнения, но эти общие концепции применимы и к другим OLTP-базам данных.

- Первичные ключи Postgres по определению уникальны для каждой строки. Использование [структур B-tree](/guides/best-practices/sparse-primary-indexes#an-index-design-for-massive-data-scales) позволяет эффективно искать отдельные строки по этому ключу. Хотя ClickHouse может быть оптимизирован для поиска значения одной строки, аналитические рабочие нагрузки обычно требуют чтения нескольких столбцов для множества строк. Фильтры чаще всего должны идентифицировать **подмножество строк**, для которых будет выполняться агрегация.
- Эффективность использования памяти и диска имеет первостепенное значение для масштабов, в которых обычно используется ClickHouse. Данные записываются в таблицы ClickHouse фрагментами, называемыми кусками (parts), с применением правил для слияния кусков в фоновом режиме. В ClickHouse каждый кусок имеет свой собственный первичный индекс. При слиянии кусков первичные индексы объединённого куска также объединяются. В отличие от Postgres, эти индексы не создаются для каждой строки. Вместо этого первичный индекс куска содержит одну запись индекса на группу строк — эта техника называется **разреженным индексированием**.
- **Разреженное индексирование** возможно потому, что ClickHouse хранит строки куска на диске, упорядоченные по указанному ключу. Вместо прямого поиска отдельных строк (как в индексе на основе B-Tree), разреженный первичный индекс позволяет быстро (с помощью бинарного поиска по записям индекса) идентифицировать группы строк, которые потенциально могут соответствовать запросу. Найденные группы потенциально подходящих строк затем параллельно передаются в движок ClickHouse для поиска совпадений. Такая конструкция индекса позволяет первичному индексу оставаться небольшим (он полностью помещается в оперативную память), при этом значительно ускоряя время выполнения запросов, особенно для диапазонных запросов, типичных для сценариев аналитики данных.

Для получения более подробной информации рекомендуем ознакомиться с этим [подробным руководством](/guides/best-practices/sparse-primary-indexes).

<Image img={postgres_b_tree} size='lg' alt='Индекс B-Tree в PostgreSQL' />

<Image img={postgres_sparse_index} size='lg' alt='Разреженный индекс в PostgreSQL' />

Выбранный ключ в ClickHouse определяет не только индекс, но и порядок, в котором данные записываются на диск. Из-за этого он может существенно влиять на уровни сжатия, что, в свою очередь, может влиять на производительность запросов. Ключ упорядочивания, который обеспечивает запись значений большинства столбцов в последовательном порядке, позволит выбранному алгоритму сжатия (и кодекам) сжимать данные более эффективно.

> Все столбцы в таблице будут отсортированы на основе значения указанного ключа упорядочивания, независимо от того, включены ли они в сам ключ. Например, если в качестве ключа используется `CreationDate`, порядок значений во всех остальных столбцах будет соответствовать порядку значений в столбце `CreationDate`. Можно указать несколько ключей упорядочивания — это будет работать с той же семантикой, что и предложение `ORDER BY` в запросе `SELECT`.

### Выбор ключа упорядочивания {#choosing-an-ordering-key}

Соображения и шаги по выбору ключа упорядочивания на примере таблицы постов см. [здесь](/data-modeling/schema-design#choosing-an-ordering-key).

При использовании репликации в реальном времени с CDC необходимо учитывать дополнительные ограничения. Обратитесь к этой [документации](/integrations/clickpipes/postgres/ordering_keys) для получения информации о методах настройки ключей упорядочивания с CDC.


## Партиции {#partitions}

Пользователи Postgres знакомы с концепцией партиционирования таблиц для повышения производительности и управляемости больших баз данных путём разделения таблиц на более мелкие, управляемые части, называемые партициями. Такое партиционирование может быть реализовано с использованием диапазона по указанному столбцу (например, даты), определённых списков или хеширования по ключу. Это позволяет администраторам организовывать данные на основе определённых критериев, таких как диапазоны дат или географическое расположение. Партиционирование помогает улучшить производительность запросов, обеспечивая более быстрый доступ к данным через отсечение партиций и более эффективное индексирование. Оно также упрощает задачи обслуживания, такие как резервное копирование и очистка данных, позволяя выполнять операции над отдельными партициями, а не над всей таблицей. Кроме того, партиционирование может значительно улучшить масштабируемость баз данных PostgreSQL, распределяя нагрузку по нескольким партициям.

В ClickHouse партиционирование указывается для таблицы при её первоначальном определении через конструкцию `PARTITION BY`. Эта конструкция может содержать SQL-выражение для любых столбцов, результаты которого определят, в какую партицию будет отправлена строка.

<Image
  img={postgres_partitions}
  size='md'
  alt='Партиции PostgreSQL в партиции ClickHouse'
/>

Части данных логически связаны с каждой партицией на диске и могут запрашиваться изолированно. В приведённом ниже примере мы партиционируем таблицу `posts` по годам, используя выражение `toYear(CreationDate)`. По мере вставки строк в ClickHouse это выражение будет вычисляться для каждой строки, и строка будет направлена в соответствующую партицию, если она существует (если строка является первой для данного года, партиция будет создана).

```sql
 CREATE TABLE posts
(
        `Id` Int32 CODEC(Delta(4), ZSTD(1)),
        `PostTypeId` Enum8('Question' = 1, 'Answer' = 2, 'Wiki' = 3, 'TagWikiExcerpt' = 4, 'TagWiki' = 5, 'ModeratorNomination' = 6, 'WikiPlaceholder' = 7, 'PrivilegeWiki' = 8),
        `AcceptedAnswerId` UInt32,
        `CreationDate` DateTime64(3, 'UTC'),
...
        `ClosedDate` DateTime64(3, 'UTC')
)
ENGINE = MergeTree
ORDER BY (PostTypeId, toDate(CreationDate), CreationDate)
PARTITION BY toYear(CreationDate)
```

Полное описание партиционирования см. в разделе [«Партиции таблиц»](/partitions).

### Применение партиций {#applications-of-partitions}

Партиционирование в ClickHouse имеет схожие применения, как и в Postgres, но с некоторыми тонкими различиями. Более конкретно:

- **Управление данными** — в ClickHouse пользователи должны в первую очередь рассматривать партиционирование как функцию управления данными, а не как технику оптимизации запросов. Разделяя данные логически на основе ключа, каждая партиция может обрабатываться независимо, например, удаляться. Это позволяет пользователям эффективно перемещать партиции и, следовательно, подмножества данных между [уровнями хранения](/integrations/s3#storage-tiers) по времени или [устаревать данные/эффективно удалять из кластера](/sql-reference/statements/alter/partition). В примере ниже мы удаляем посты за 2008 год.

```sql
SELECT DISTINCT partition
FROM system.parts
WHERE `table` = 'posts'

┌─partition─┐
│ 2008      │
│ 2009      │
│ 2010      │
│ 2011      │
│ 2012      │
│ 2013      │
│ 2014      │
│ 2015      │
│ 2016      │
│ 2017      │
│ 2018      │
│ 2019      │
│ 2020      │
│ 2021      │
│ 2022      │
│ 2023      │
│ 2024      │
└───────────┘

Получено 17 строк. Затрачено: 0.002 сек.

ALTER TABLE posts
(DROP PARTITION '2008')

Ok.

Получено 0 строк. Затрачено: 0.103 сек.
```


- **Оптимизация запросов** - Хотя партиции могут улучшить производительность запросов, это в значительной степени зависит от шаблонов доступа к данным. Если запросы обращаются только к нескольким партициям (в идеале к одной), производительность может потенциально улучшиться. Это обычно полезно только в том случае, если ключ партиционирования не входит в первичный ключ и вы выполняете фильтрацию по нему. Однако запросы, которым необходимо охватить множество партиций, могут работать хуже, чем при отсутствии партиционирования (поскольку в результате партиционирования может образоваться больше кусков данных). Преимущество обращения к одной партиции будет еще менее выраженным или вовсе отсутствовать, если ключ партиционирования уже находится в начале первичного ключа. Партиционирование также может использоваться для [оптимизации запросов GROUP BY](/engines/table-engines/mergetree-family/custom-partitioning-key#group-by-optimisation-using-partition-key), если значения в каждой партиции уникальны. Однако в целом пользователям следует убедиться, что первичный ключ оптимизирован, и рассматривать партиционирование как метод оптимизации запросов только в исключительных случаях, когда шаблоны доступа обращаются к определенному предсказуемому подмножеству данных, например, партиционирование по дням с большинством запросов за последний день.

### Рекомендации по партициям {#recommendations-for-partitions}

Пользователям следует рассматривать партиционирование как метод управления данными. Оно идеально подходит, когда данные необходимо удалять из кластера при работе с временными рядами, например, самая старая партиция может [просто быть удалена](/sql-reference/statements/alter/partition#drop-partitionpart).

**Важно:** Убедитесь, что выражение ключа партиционирования не приводит к набору с высокой кардинальностью, то есть следует избегать создания более 100 партиций. Например, не партиционируйте данные по столбцам с высокой кардинальностью, таким как идентификаторы или имена клиентов. Вместо этого сделайте идентификатор или имя клиента первым столбцом в выражении ORDER BY.

> Внутренне ClickHouse [создает куски данных](/guides/best-practices/sparse-primary-indexes#clickhouse-index-design) для вставляемых данных. По мере вставки большего количества данных число кусков увеличивается. Чтобы предотвратить чрезмерно большое количество кусков, которое ухудшит производительность запросов (больше файлов для чтения), куски объединяются в фоновом асинхронном процессе. Если количество кусков превышает предварительно настроенный лимит, ClickHouse выбросит исключение при вставке — ошибку «too many parts». Это не должно происходить при нормальной работе и возникает только в случае неправильной настройки или некорректного использования ClickHouse, например, при множестве мелких вставок.

> Поскольку куски создаются для каждой партиции изолированно, увеличение количества партиций приводит к увеличению количества кусков, то есть оно кратно количеству партиций. Ключи партиционирования с высокой кардинальностью могут, следовательно, вызвать эту ошибку, и их следует избегать.


## Материализованные представления и проекции {#materialized-views-vs-projections}

Postgres позволяет создавать несколько индексов для одной таблицы, обеспечивая оптимизацию для различных паттернов доступа. Эта гибкость позволяет администраторам и разработчикам настраивать производительность базы данных под конкретные запросы и операционные потребности. Концепция проекций в ClickHouse, хотя и не полностью аналогична этому, позволяет пользователям указывать несколько выражений `ORDER BY` для таблицы.

В [документации по моделированию данных](/data-modeling/schema-design) ClickHouse мы рассматриваем, как материализованные представления могут использоваться в ClickHouse для предварительного вычисления агрегаций, преобразования строк и оптимизации запросов для различных паттернов доступа.

Для последнего из этих случаев мы предоставили [пример](/materialized-view/incremental-materialized-view#lookup-table), где материализованное представление отправляет строки в целевую таблицу с ключом сортировки, отличным от исходной таблицы, принимающей вставки.

Например, рассмотрим следующий запрос:

```sql
SELECT avg(Score)
FROM comments
WHERE UserId = 8592047

   ┌──────────avg(Score)─┐
1. │ 0.18181818181818182 │
   └─────────────────────┘

1 row in set. Elapsed: 0.040 sec. Processed 90.38 million rows, 361.59 MB (2.25 billion rows/s., 9.01 GB/s.)
Peak memory usage: 201.93 MiB.
```

Этот запрос требует сканирования всех 90 млн строк (хотя и быстро), поскольку `UserId` не является ключом сортировки.
Ранее мы решали эту проблему с помощью материализованного представления, выступающего в качестве таблицы поиска для `PostId`. Та же проблема может быть решена
с помощью [проекции](/data-modeling/projections). Команда ниже добавляет
проекцию для `ORDER BY user_id`.

```sql
ALTER TABLE comments ADD PROJECTION comments_user_id (
SELECT * ORDER BY UserId
)

ALTER TABLE comments MATERIALIZE PROJECTION comments_user_id
```

Обратите внимание, что сначала необходимо создать проекцию, а затем материализовать её. Эта последняя команда приводит к тому, что данные сохраняются на диске дважды в двух различных порядках. Проекция также может быть определена при создании таблицы, как показано ниже, и будет автоматически поддерживаться при вставке данных.

```sql
CREATE TABLE comments
(
        `Id` UInt32,
        `PostId` UInt32,
        `Score` UInt16,
        `Text` String,
        `CreationDate` DateTime64(3, 'UTC'),
        `UserId` Int32,
        `UserDisplayName` LowCardinality(String),
        PROJECTION comments_user_id
        (
        SELECT *
        ORDER BY UserId
        )
)
ENGINE = MergeTree
ORDER BY PostId
```

Если проекция создаётся с помощью `ALTER`, создание выполняется асинхронно при выполнении команды `MATERIALIZE PROJECTION`. Пользователи могут проверить прогресс этой операции следующим запросом, ожидая `is_done=1`.

```sql
SELECT
        parts_to_do,
        is_done,
        latest_fail_reason
FROM system.mutations
WHERE (`table` = 'comments') AND (command LIKE '%MATERIALIZE%')

   ┌─parts_to_do─┬─is_done─┬─latest_fail_reason─┐
1. │           1 │       0 │                    │
   └─────────────┴─────────┴────────────────────┘

1 row in set. Elapsed: 0.003 sec.
```

Если мы повторим приведённый выше запрос, мы увидим, что производительность значительно улучшилась за счёт дополнительного хранилища.

```sql
SELECT avg(Score)
FROM comments
WHERE UserId = 8592047

   ┌──────────avg(Score)─┐
1. │ 0.18181818181818182 │
   └─────────────────────┘

1 row in set. Elapsed: 0.008 sec. Processed 16.36 thousand rows, 98.17 KB (2.15 million rows/s., 12.92 MB/s.)
Peak memory usage: 4.06 MiB.
```

С помощью команды `EXPLAIN` мы также подтверждаем, что для выполнения этого запроса использовалась проекция:

```sql
EXPLAIN indexes = 1
SELECT avg(Score)
FROM comments
WHERE UserId = 8592047

```


┌─explain─────────────────────────────────────────────┐

1. │ Выражение ((Projection + Before ORDER BY))          │
2. │   Агрегирование                                     │
3. │   Фильтр                                            │
4. │           ReadFromMergeTree (comments&#95;user&#95;id)      │
5. │           Индексы:                                  │
6. │           PrimaryKey                                │
7. │           Ключи:                                     │
8. │           UserId                                    │
9. │           Условие: (UserId in [8592047, 8592047])   │
10. │           Части: 2/2                               │
11. │           Гранулы: 2/11360                         │
    └─────────────────────────────────────────────────────┘

11 строк в наборе. Прошло: 0.004 сек.

```

### Когда использовать проекции {#when-to-use-projections}

Проекции являются привлекательной функцией для новых пользователей, так как они автоматически 
поддерживаются при вставке данных. Кроме того, запросы можно отправлять в одну 
таблицу, где проекции используются при возможности для ускорения времени 
отклика.

<Image img={postgres_projections} size="md" alt="Проекции PostgreSQL в ClickHouse"/>

В отличие от материализованных представлений, где пользователь должен выбрать 
соответствующую оптимизированную целевую таблицу или переписать запрос в зависимости от фильтров.
Это повышает требования к пользовательским приложениям и увеличивает сложность на стороне клиента.

Несмотря на эти преимущества, проекции имеют некоторые [присущие им ограничения](/data-modeling/projections#when-to-use-projections), 
о которых пользователи должны знать, поэтому их следует применять с осторожностью.

Мы рекомендуем использовать проекции, когда:

- Требуется полная переупорядочивание данных. Хотя выражение в 
  проекции теоретически может использовать `GROUP BY`, материализованные представления более 
  эффективны для поддержания агрегатов. Оптимизатор запросов также с большей вероятностью 
  использует проекции с простым переупорядочиванием, т. е. `SELECT * ORDER BY x`. 
  Пользователи могут выбрать подмножество столбцов в этом выражении для уменьшения объема хранилища.
- Пользователи готовы к связанному с этим увеличению объема хранилища и 
  накладным расходам на двойную запись данных. Проверьте влияние на скорость вставки и 
  [оцените накладные расходы на хранение](/data-compression/compression-in-clickhouse).

:::note
Начиная с версии 25.5, ClickHouse поддерживает виртуальный столбец `_part_offset` в 
проекциях. Это открывает более эффективный с точки зрения использования пространства способ хранения проекций.

Для получения дополнительной информации см. [«Проекции»](/data-modeling/projections)
:::
```


## Денормализация {#denormalization}

Поскольку Postgres является реляционной базой данных, её модель данных сильно [нормализована](https://en.wikipedia.org/wiki/Database_normalization) и часто включает сотни таблиц. В ClickHouse денормализация иногда может быть полезна для оптимизации производительности операций JOIN.

Обратитесь к [руководству](/data-modeling/denormalization), которое демонстрирует преимущества денормализации набора данных Stack Overflow в ClickHouse.

На этом завершается базовое руководство для пользователей, мигрирующих с Postgres на ClickHouse. Пользователям, переходящим с Postgres, рекомендуется ознакомиться с [руководством по моделированию данных в ClickHouse](/data-modeling/schema-design), чтобы узнать больше о расширенных возможностях ClickHouse.
