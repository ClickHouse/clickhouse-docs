---
slug: /migrations/postgresql/appendix
title: 'Приложение'
keywords: ['postgres', 'postgresql', 'data types', 'types']
description: 'Дополнительная информация, касающаяся миграции с PostgreSQL'
doc_type: 'reference'
---

import postgresReplicas from '@site/static/images/integrations/data-ingestion/dbms/postgres-replicas.png';
import Image from '@theme/IdealImage';


## Postgres и ClickHouse: эквивалентные и различающиеся концепции {#postgres-vs-clickhouse-equivalent-and-different-concepts}

Пользователям, переходящим из OLTP-систем и привыкшим к ACID-транзакциям, следует знать, что ClickHouse сознательно идёт на компромиссы, не предоставляя их в полной мере в обмен на производительность. При правильном понимании семантика ClickHouse может обеспечить высокие гарантии долговечности и высокую пропускную способность записи. Ниже мы выделяем ключевые концепции, с которыми пользователям следует ознакомиться перед началом работы с ClickHouse при переходе с Postgres.

### Шарды и реплики {#shards-vs-replicas}

Шардирование и репликация — это две стратегии масштабирования за пределы одного экземпляра Postgres, когда хранилище и/или вычислительные ресурсы становятся узким местом производительности. Шардирование в Postgres подразумевает разделение большой базы данных на более мелкие, управляемые части на нескольких узлах. Однако Postgres не поддерживает шардирование нативно. Вместо этого шардирование может быть реализовано с помощью расширений, таких как [Citus](https://www.citusdata.com/), превращающих Postgres в распределённую базу данных, способную к горизонтальному масштабированию. Этот подход позволяет Postgres обрабатывать более высокие скорости транзакций и большие наборы данных, распределяя нагрузку на несколько машин. Шарды могут быть основаны на строках или схемах, чтобы обеспечить гибкость для различных типов рабочих нагрузок, таких как транзакционные или аналитические. Шардирование может привнести значительную сложность в управление данными и выполнение запросов, поскольку требует координации между несколькими машинами и гарантий согласованности.

В отличие от шардов, реплики — это дополнительные экземпляры Postgres, содержащие все или часть данных с основного узла. Реплики используются по различным причинам, включая повышение производительности чтения и сценарии высокой доступности (HA). Физическая репликация — это встроенная функция Postgres, которая включает копирование всей базы данных или значительных её частей на другой сервер, включая все базы данных, таблицы и индексы. Это подразумевает потоковую передачу сегментов WAL с основного узла на реплики по TCP/IP. В отличие от этого, логическая репликация — это более высокий уровень абстракции, который передаёт изменения на основе операций `INSERT`, `UPDATE` и `DELETE`. Хотя те же результаты могут быть достигнуты и при физической репликации, логическая репликация обеспечивает большую гибкость для работы с конкретными таблицами и операциями, а также для преобразования данных и поддержки различных версий Postgres.

**В отличие от этого, шарды и реплики ClickHouse — это две ключевые концепции, связанные с распределением данных и избыточностью**. Реплики ClickHouse можно рассматривать как аналог реплик Postgres, хотя репликация является в конечном итоге согласованной без понятия основного узла. Шардирование, в отличие от Postgres, поддерживается нативно.

Шард — это часть данных вашей таблицы. У вас всегда есть как минимум один шард. Шардирование данных на нескольких серверах может использоваться для распределения нагрузки, если вы превышаете ёмкость одного сервера, при этом все шарды используются для параллельного выполнения запроса. Пользователи могут вручную создавать шарды для таблицы на разных серверах и вставлять данные непосредственно в них. В качестве альтернативы можно использовать распределённую таблицу с ключом шардирования, определяющим, на какой шард направляются данные. Ключ шардирования может быть случайным или результатом хеш-функции. Важно отметить, что шард может состоять из нескольких реплик.

Реплика — это копия ваших данных. ClickHouse всегда имеет как минимум одну копию ваших данных, поэтому минимальное количество реплик — одна. Добавление второй реплики ваших данных обеспечивает отказоустойчивость и потенциально дополнительные вычислительные ресурсы для обработки большего количества запросов ([Parallel Replicas](https://clickhouse.com/blog/clickhouse-release-23-03#parallel-replicas-for-utilizing-the-full-power-of-your-replicas-nikita-mikhailov) также можно использовать для распределения вычислений для одного запроса, тем самым снижая задержку). Реплики реализуются с помощью [движка таблиц ReplicatedMergeTree](/engines/table-engines/mergetree-family/replication), который позволяет ClickHouse поддерживать синхронизацию нескольких копий данных на разных серверах. Репликация является физической: между узлами передаются только сжатые части, а не запросы.

Таким образом, реплика — это копия данных, обеспечивающая избыточность и надёжность (и потенциально распределённую обработку), в то время как шард — это подмножество данных, позволяющее распределённую обработку и балансировку нагрузки.

> ClickHouse Cloud использует единственную копию данных, хранящуюся в S3, с несколькими вычислительными репликами. Данные доступны каждому узлу реплики, каждый из которых имеет локальный SSD-кеш. Это основано только на репликации метаданных через ClickHouse Keeper.


## Итоговая согласованность {#eventual-consistency}

ClickHouse использует ClickHouse Keeper (реализация ZooKeeper на C++; также может использоваться ZooKeeper) для управления внутренним механизмом репликации, уделяя основное внимание хранению метаданных и обеспечению итоговой согласованности. Keeper используется для назначения уникальных последовательных номеров каждой вставке в распределённой среде. Это критически важно для поддержания порядка и согласованности операций. Эта система также обрабатывает фоновые операции, такие как слияния и мутации, обеспечивая распределение работы и гарантируя их выполнение в одинаковом порядке на всех репликах. Помимо метаданных, Keeper функционирует как комплексный центр управления репликацией, включая отслеживание контрольных сумм хранимых частей данных, и выступает в роли распределённой системы уведомлений между репликами.

Процесс репликации в ClickHouse (1) начинается с вставки данных в любую реплику. Эти данные в исходной форме вставки (2) записываются на диск вместе с контрольными суммами. После записи реплика (3) пытается зарегистрировать эту новую часть данных в Keeper, выделяя уникальный номер блока и фиксируя детали новой части. Другие реплики при (4) обнаружении новых записей в журнале репликации (5) загружают соответствующую часть данных через внутренний HTTP-протокол, проверяя её по контрольным суммам, указанным в ZooKeeper. Этот метод гарантирует, что все реплики в конечном итоге содержат согласованные и актуальные данные, несмотря на различную скорость обработки или возможные задержки. Более того, система способна обрабатывать множество операций одновременно, оптимизируя процессы управления данными и обеспечивая масштабируемость системы и устойчивость к аппаратным различиям.

<Image img={postgresReplicas} size='md' alt='Итоговая согласованность' />

Обратите внимание, что ClickHouse Cloud использует [облачно-оптимизированный механизм репликации](https://clickhouse.com/blog/clickhouse-cloud-boosts-performance-with-sharedmergetree-and-lightweight-updates), адаптированный к архитектуре с разделением хранилища и вычислений. Благодаря хранению данных в общем объектном хранилище данные автоматически доступны для всех вычислительных узлов без необходимости физической репликации данных между узлами. Вместо этого Keeper используется только для обмена метаданными (какие данные существуют и где в объектном хранилище) между вычислительными узлами.

PostgreSQL использует иную стратегию репликации по сравнению с ClickHouse, в основном применяя потоковую репликацию, которая включает модель «первичный узел — реплики», где данные непрерывно передаются потоком от первичного узла к одному или нескольким узлам-репликам. Этот тип репликации обеспечивает согласованность, близкую к реальному времени, и может быть синхронным или асинхронным, предоставляя администраторам контроль над балансом между доступностью и согласованностью. В отличие от ClickHouse, PostgreSQL использует WAL (журнал упреждающей записи) с логической репликацией и декодированием для передачи потоком объектов данных и изменений между узлами. Этот подход в PostgreSQL более прямолинеен, но может не обеспечивать тот же уровень масштабируемости и отказоустойчивости в высокораспределённых средах, которого ClickHouse достигает благодаря сложному использованию Keeper для координации распределённых операций и итоговой согласованности.


## Последствия для пользователей {#user-implications}

В ClickHouse возможность «грязных» чтений — когда пользователи могут записать данные в одну реплику, а затем прочитать потенциально нереплицированные данные из другой — возникает из-за модели репликации с итоговой согласованностью, управляемой через Keeper. Эта модель делает акцент на производительности и масштабируемости в распределённых системах, позволяя репликам работать независимо и синхронизироваться асинхронно. В результате только что вставленные данные могут быть не сразу видны на всех репликах в зависимости от задержки репликации и времени, необходимого для распространения изменений по системе.

Напротив, модель потоковой репликации PostgreSQL обычно может предотвратить «грязные» чтения, используя параметры синхронной репликации, при которых первичный сервер ожидает подтверждения получения данных хотя бы от одной реплики перед фиксацией транзакций. Это гарантирует, что после фиксации транзакции данные доступны на другой реплике. В случае отказа первичного сервера реплика обеспечит видимость зафиксированных данных для запросов, тем самым поддерживая более строгий уровень согласованности.


## Рекомендации {#recommendations}

Пользователям, начинающим работу с ClickHouse, следует учитывать эти различия, которые проявляются в реплицируемых окружениях. Как правило, eventual consistency (согласованность в конечном счёте) является достаточной для аналитики над миллиардами, если не триллионами, точек данных — где метрики либо более стабильны, либо приближённые оценки являются приемлемыми, поскольку новые данные непрерывно вставляются с высокой скоростью.

Существует несколько вариантов повышения согласованности чтений при необходимости. Оба примера требуют либо повышенной сложности, либо дополнительных накладных расходов, что снижает производительность запросов и усложняет масштабирование ClickHouse. **Мы рекомендуем эти подходы только в случае крайней необходимости.**


## Согласованная маршрутизация {#consistent-routing}

Чтобы преодолеть некоторые ограничения модели согласованности в конечном итоге, пользователи могут обеспечить маршрутизацию клиентов к одним и тем же репликам. Это полезно в случаях, когда несколько пользователей выполняют запросы к ClickHouse и результаты должны быть детерминированными для всех запросов. Хотя результаты могут различаться по мере вставки новых данных, запросы должны направляться к одним и тем же репликам, обеспечивая согласованное представление данных.

Это можно реализовать несколькими способами в зависимости от вашей архитектуры и того, используете ли вы ClickHouse OSS или ClickHouse Cloud.


## ClickHouse Cloud {#clickhouse-cloud}

ClickHouse Cloud использует единственную копию данных, размещённую в S3, с несколькими вычислительными репликами. Данные доступны каждому узлу реплики, имеющему локальный SSD-кеш. Для обеспечения согласованных результатов пользователям необходимо лишь гарантировать последовательную маршрутизацию на один и тот же узел.

Взаимодействие с узлами сервиса ClickHouse Cloud происходит через прокси-сервер. HTTP-соединения и соединения по нативному протоколу маршрутизируются на один и тот же узел в течение всего времени, пока они остаются открытыми. В случае HTTP 1.1 соединений от большинства клиентов это зависит от окна Keep-Alive. Это можно настроить на большинстве клиентов, например Node.js. Также требуется конфигурация на стороне сервера, значение которой будет выше, чем на клиенте, и в ClickHouse Cloud установлено в 10 секунд.

Для обеспечения последовательной маршрутизации между соединениями, например при использовании пула соединений или при истечении срока действия соединений, пользователи могут либо гарантировать использование одного и того же соединения (проще для нативного протокола), либо запросить предоставление закреплённых эндпоинтов. Это обеспечивает набор эндпоинтов для каждого узла в кластере, позволяя клиентам гарантировать детерминированную маршрутизацию запросов.

> Обратитесь в службу поддержки для получения доступа к закреплённым эндпоинтам.


## ClickHouse OSS {#clickhouse-oss}

Для достижения такого поведения в OSS необходимо учитывать топологию шардов и реплик, а также то, используется ли [распределённая таблица](/engines/table-engines/special/distributed) для выполнения запросов.

Если у вас только один шард с репликами (распространённый случай, поскольку ClickHouse хорошо масштабируется вертикально), пользователи выбирают узел на уровне клиента и выполняют запросы непосредственно к реплике, обеспечивая детерминированный выбор узла.

Хотя топологии с несколькими шардами и репликами возможны без распределённой таблицы, такие сложные развёртывания обычно имеют собственную инфраструктуру маршрутизации. Поэтому мы предполагаем, что развёртывания с более чем одним шардом используют распределённую таблицу (распределённые таблицы можно использовать и с одношардовыми развёртываниями, но обычно в этом нет необходимости).

В этом случае пользователи должны обеспечить согласованную маршрутизацию узлов на основе какого-либо свойства, например `session_id` или `user_id`. Настройки [`prefer_localhost_replica=0`](/operations/settings/settings#prefer_localhost_replica) и [`load_balancing=in_order`](/operations/settings/settings#load_balancing) должны быть [установлены в запросе](/operations/settings/query-level). Это обеспечит предпочтение локальных реплик шардов, а в остальных случаях реплики будут выбираться в порядке, указанном в конфигурации — при условии одинакового количества ошибок; если количество ошибок больше, переключение будет происходить со случайным выбором. В качестве альтернативы для детерминированного выбора шарда также можно использовать [`load_balancing=nearest_hostname`](/operations/settings/settings#load_balancing).

> При создании распределённой таблицы пользователи указывают кластер. Определение этого кластера, заданное в config.xml, содержит список шардов (и их реплик), что позволяет пользователям контролировать порядок их использования с каждого узла. Таким образом, пользователи могут обеспечить детерминированный выбор.


## Последовательная согласованность {#sequential-consistency}

В исключительных случаях пользователям может потребоваться последовательная согласованность.

Последовательная согласованность в базах данных — это режим, при котором операции с базой данных выполняются в определённом последовательном порядке, и этот порядок одинаков для всех процессов, взаимодействующих с базой данных. Это означает, что каждая операция вступает в силу мгновенно между её вызовом и завершением, и существует единый согласованный порядок, в котором все операции наблюдаются любым процессом.

С точки зрения пользователя это обычно проявляется как необходимость записывать данные в ClickHouse и при чтении данных гарантировать, что возвращаются последние вставленные строки.
Этого можно достичь несколькими способами (в порядке предпочтения):

1. **Чтение/запись на один и тот же узел** — если вы используете нативный протокол или [сессию для записи/чтения через HTTP](/interfaces/http#default-database), вы будете подключены к одной и той же реплике: в этом сценарии вы читаете непосредственно с узла, на который выполняете запись, поэтому ваше чтение всегда будет согласованным.
1. **Синхронизация реплик вручную** — если вы пишете на одну реплику и читаете с другой, вы можете выполнить команду `SYSTEM SYNC REPLICA LIGHTWEIGHT` перед чтением.
1. **Включение последовательной согласованности** — через настройку запроса [`select_sequential_consistency = 1`](/operations/settings/settings#select_sequential_consistency). В версии с открытым исходным кодом также необходимо указать настройку `insert_quorum = 'auto'`.

<br />

Подробнее о включении этих настроек см. [здесь](/cloud/reference/shared-merge-tree#consistency).

> Использование последовательной согласованности создаст повышенную нагрузку на ClickHouse Keeper. Это может
> привести к замедлению вставок и чтений. SharedMergeTree, используемый в ClickHouse Cloud в качестве основного движка таблиц, при последовательной согласованности [создаёт меньше накладных расходов и лучше масштабируется](/cloud/reference/shared-merge-tree#consistency). Пользователям версии с открытым исходным кодом следует применять этот подход осторожно и контролировать нагрузку на Keeper.


## Поддержка транзакций (ACID) {#transactional-acid-support}

Пользователи, переходящие с PostgreSQL, могут быть привычны к его надёжной поддержке свойств ACID (атомарность, согласованность, изолированность, долговечность), что делает его надёжным выбором для транзакционных баз данных. Атомарность в PostgreSQL гарантирует, что каждая транзакция обрабатывается как единое целое, которое либо полностью выполняется, либо полностью откатывается, предотвращая частичные обновления. Согласованность поддерживается путём применения ограничений, триггеров и правил, которые гарантируют, что все транзакции базы данных приводят к корректному состоянию. Уровни изолированности, от Read Committed до Serializable, поддерживаются в PostgreSQL, обеспечивая точный контроль над видимостью изменений, выполненных параллельными транзакциями. Наконец, долговечность достигается с помощью журнала упреждающей записи (WAL), гарантируя, что после фиксации транзакции она сохраняется даже в случае сбоя системы.

Эти свойства характерны для OLTP-баз данных, которые выступают в качестве источника достоверных данных.

Несмотря на мощность, это влечёт за собой присущие ограничения и делает масштабирование до петабайтов сложной задачей. ClickHouse идёт на компромисс в отношении этих свойств, чтобы обеспечить быстрые аналитические запросы в масштабе при сохранении высокой пропускной способности записи.

ClickHouse обеспечивает свойства ACID при [ограниченных конфигурациях](/guides/developer/transactional) — проще всего при использовании нереплицируемого экземпляра движка таблиц MergeTree с одной партицией. Пользователям не следует ожидать этих свойств за пределами указанных случаев и необходимо убедиться, что они не являются обязательным требованием.


## Сжатие {#compression}

Колоночное хранилище ClickHouse обеспечивает значительно более эффективное сжатие по сравнению с Postgres. Это наглядно демонстрируется при сравнении объёма хранения всех таблиц Stack Overflow в обеих базах данных:

```sql title="Запрос (Postgres)"
SELECT
    schemaname,
    tablename,
    pg_total_relation_size(schemaname || '.' || tablename) AS total_size_bytes,
    pg_total_relation_size(schemaname || '.' || tablename) / (1024 * 1024 * 1024) AS total_size_gb
FROM
    pg_tables s
WHERE
    schemaname = 'public';
```

```sql title="Запрос (ClickHouse)"
SELECT
        `table`,
        formatReadableSize(sum(data_compressed_bytes)) AS compressed_size
FROM system.parts
WHERE (database = 'stackoverflow') AND active
GROUP BY `table`
```

```response title="Результат"
┌─table───────┬─compressed_size─┐
│ posts       │ 25.17 GiB       │
│ users       │ 846.57 MiB      │
│ badges      │ 513.13 MiB      │
│ comments    │ 7.11 GiB        │
│ votes       │ 1.28 GiB        │
│ posthistory │ 40.44 GiB       │
│ postlinks   │ 79.22 MiB       │
└─────────────┴─────────────────┘
```

Подробнее об оптимизации и измерении сжатия можно узнать [здесь](/data-compression/compression-in-clickhouse).


## Соответствие типов данных {#data-type-mappings}

В следующей таблице показаны эквивалентные типы данных ClickHouse для PostgreSQL.

| Тип данных PostgreSQL | Тип ClickHouse                                                                                                                                                                                                                      |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `DATE`               | [Date](/sql-reference/data-types/date)                                                                                                                                                                                               |
| `TIMESTAMP`          | [DateTime](/sql-reference/data-types/datetime)                                                                                                                                                                                       |
| `REAL`               | [Float32](/sql-reference/data-types/float)                                                                                                                                                                                           |
| `DOUBLE`             | [Float64](/sql-reference/data-types/float)                                                                                                                                                                                           |
| `DECIMAL, NUMERIC`   | [Decimal](/sql-reference/data-types/decimal)                                                                                                                                                                                         |
| `SMALLINT`           | [Int16](/sql-reference/data-types/int-uint)                                                                                                                                                                                          |
| `INTEGER`            | [Int32](/sql-reference/data-types/int-uint)                                                                                                                                                                                          |
| `BIGINT`             | [Int64](/sql-reference/data-types/int-uint)                                                                                                                                                                                          |
| `SERIAL`             | [UInt32](/sql-reference/data-types/int-uint)                                                                                                                                                                                         |
| `BIGSERIAL`          | [UInt64](/sql-reference/data-types/int-uint)                                                                                                                                                                                         |
| `TEXT, CHAR, BPCHAR` | [String](/sql-reference/data-types/string)                                                                                                                                                                                           |
| `INTEGER`            | Nullable([Int32](/sql-reference/data-types/int-uint))                                                                                                                                                                                |
| `ARRAY`              | [Array](/sql-reference/data-types/array)                                                                                                                                                                                             |
| `FLOAT4`             | [Float32](/sql-reference/data-types/float)                                                                                                                                                                                           |
| `BOOLEAN`            | [Bool](/sql-reference/data-types/boolean)                                                                                                                                                                                            |
| `VARCHAR`            | [String](/sql-reference/data-types/string)                                                                                                                                                                                           |
| `BIT`                | [String](/sql-reference/data-types/string)                                                                                                                                                                                           |
| `BIT VARYING`        | [String](/sql-reference/data-types/string)                                                                                                                                                                                           |
| `BYTEA`              | [String](/sql-reference/data-types/string)                                                                                                                                                                                           |
| `NUMERIC`            | [Decimal](/sql-reference/data-types/decimal)                                                                                                                                                                                         |
| `GEOGRAPHY`          | [Point](/sql-reference/data-types/geo#point), [Ring](/sql-reference/data-types/geo#ring), [Polygon](/sql-reference/data-types/geo#polygon), [MultiPolygon](/sql-reference/data-types/geo#multipolygon)                               |
| `GEOMETRY`           | [Point](/sql-reference/data-types/geo#point), [Ring](/sql-reference/data-types/geo#ring), [Polygon](/sql-reference/data-types/geo#polygon), [MultiPolygon](/sql-reference/data-types/geo#multipolygon)                               |
| `INET`               | [IPv4](/sql-reference/data-types/ipv4), [IPv6](/sql-reference/data-types/ipv6)                                                                                                                                                       |
| `MACADDR`            | [String](/sql-reference/data-types/string)                                                                                                                                                                                           |
| `CIDR`               | [String](/sql-reference/data-types/string)                                                                                                                                                                                           |
| `HSTORE`             | [Map(K, V)](/sql-reference/data-types/map), [Map](/sql-reference/data-types/map)(K,[Variant](/sql-reference/data-types/variant))                                                                                                     |
| `UUID`               | [UUID](/sql-reference/data-types/uuid)                                                                                                                                                                                               |
| `ARRAY<T>`           | [ARRAY(T)](/sql-reference/data-types/array)                                                                                                                                                                                          |
| `JSON*`              | [String](/sql-reference/data-types/string), [Variant](/sql-reference/data-types/variant), [Nested](/sql-reference/data-types/nested-data-structures/nested#nestedname1-type1-name2-type2-), [Tuple](/sql-reference/data-types/tuple) |
| `JSONB`              | [String](/sql-reference/data-types/string)                                                                                                                                                                                           |

_\* Промышленная поддержка JSON в ClickHouse находится в разработке. В настоящее время пользователи могут либо сопоставлять JSON с типом String и использовать [функции JSON](/sql-reference/functions/json-functions), либо напрямую сопоставлять JSON с типами [Tuple](/sql-reference/data-types/tuple) и [Nested](/sql-reference/data-types/nested-data-structures/nested), если структура предсказуема. Подробнее о JSON читайте [здесь](/integrations/data-formats/json/overview)._
