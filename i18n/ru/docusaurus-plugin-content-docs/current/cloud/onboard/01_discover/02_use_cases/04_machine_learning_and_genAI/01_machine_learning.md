---
'slug': '/cloud/get-started/cloud/use-cases/AI_ML'
'title': 'Машинное обучение'
'description': 'Узнайте, как ClickHouse поддерживает приложения машинного обучения
  на протяжении всего ML конвейера.'
'keywords':
- 'use cases'
- 'Machine Learning'
- 'Generative AI'
'sidebar_label': 'Машинное обучение'
'doc_type': 'guide'
---
import machine_learning_data_layer from '@site/static/images/cloud/onboard/discover/use_cases/ml_data_layer.png'
import online_feature_store from '@site/static/images/cloud/onboard/discover/use_cases/ml_data_layer.png'
import Image from '@theme/IdealImage';

## Слой данных для машинного обучения {#machine-learning-data-layer}

Вы, вероятно, слышали легенду о том, что 80% времени практикующего в области машинного обучения уходит на очистку данных. Независимо от того, верна ли эта миф, одно остается неизменным: данные находятся в центре проблемы машинного обучения, от начала до конца. Независимо от того, строите ли вы RAG конвейеры, проводите дообучение, обучаете свою модель или оцениваете производительность модели, данные являются корнем каждой проблемы.

Управление данными может быть сложной задачей, и как побочный продукт, в этой области происходит распространение инструментов, разработанных для повышения производительности путем решения конкретного аспекта проблемы данных в машинном обучении. Часто это принимает форму уровня абстракции вокруг более универсального решения с предвзятым интерфейсом, который, на первый взгляд, упрощает применение к специфической подзадаче. На практике это снижает гибкость, присущую универсальному решению, в угоду простоте использования и легкости выполнения конкретной задачи.

<Image img={machine_learning_data_layer} size="sm"/>

У этого подхода есть несколько недостатков. Каскадный набор специализированных инструментов, продуктов и услуг, в контексте общего решения, сопряженного с поддерживающим кодом приложения, несет риск большей архитектурной сложности и затрат на данные, чем это необходимо. Легко случайно оказаться с бесконечным списком инструментов и услуг, каждый из которых используется только для одного шага.

Существуют два общих аспекта этих рисков:

1. **Затраты на изучение, обслуживание и переключение**

Архитектуры машинного обучения могут стать настолько переполненными различными инструментами и компонентами, что это создает фрагментированную и сложную среду для изучения и управления, с увеличением точек отказа и непредвиденных затрат.

2. **Затраты на дублирование и передачу данных**

Использование нескольких разрозненных, но пересекающихся систем данных в конвейере машинного обучения может привести к ненужным и зачастую дорогим затратам на перемещение данных между ними.

Отличным примером этой подводной камни является векторная база данных. Векторные базы данных предназначены для гиперспецифической задачи машинного обучения по хранению и поиску векторов. Хотя это может быть правильным выбором в некоторых архитектурах, векторная база данных может оказаться ненужным новым дополнением к техническому стеку в других, так как это еще одна система, которую нужно интегрировать, управлять и перемещать данные к ней и от неё. Большинство современных универсальных баз данных поддерживают векторные данные "из коробки" (или через плагин) и обладают более обширными и пересекающимися возможностями. Говоря иначе, может не понадобиться новая база данных, чтобы специализированно обрабатывать векторы в этих архитектурах. Важность сводится к тому, критически ли важны удобные функции, специфичные для векторов (например, встроенные модели встроения), и стоят ли они своих затрат.

### Исследование данных {#data-exploration}

После определения проблемы в машинном обучении, целей и критериев успеха, общим первым шагом является исследование соответствующих данных, которые будут использоваться для обучения модели и оценки.

На этом этапе данные анализируются, чтобы понять их характеристики, распределения и взаимосвязи. Этот процесс оценки и понимания является итеративным, часто приводя к выполнению серии случайных запросов по наборам данных, где скорость ответа на запросы критически важна (наряду с другими факторами, такими как стоимость и точность). По мере того как компании хранят все больше данных для использования в целях машинного обучения, проблема изучения имеющихся данных становится сложнее.

Это связано с тем, что аналитические и оценочные запросы часто становятся утомительно или невыносимо медленными при масштабировании с традиционными системами данных. Некоторые крупные игроки значительно увеличивают расходы, чтобы сократить время выполнения запросов, и препятствуют случайной оценке, взимая плату за запрос или за количество обработанных байтов. Инженеры могут прибегнуть к тому, чтобы загружать подмножества данных на свои локальные машины в качестве компромисса по этим ограничениям.

ClickHouse, с другой стороны, является хранилищем данных в реальном времени, поэтому пользователи получают выгоду от выдающейся скорости выполнения запросов для аналитических вычислений. Более того, ClickHouse обеспечивает высокую производительность с самого начала и не ограничивает критически важные функции ускорения запросов более высокими ценовыми категориями. ClickHouse также может выполнять запросы данных напрямую из объектного хранилища или ДатаЛэйков, поддерживая общие форматы, такие как Iceberg, Delta Lake и Hudi. Это означает, что независимо от того, где хранятся ваши данные, ClickHouse может служить унифицированным уровнем доступа и вычислений для ваших рабочих нагрузок машинного обучения.

ClickHouse также имеет обширный набор готовых статистических и агрегатных функций, которые масштабируются на петабайты данных, что упрощает процесс написания и поддержания простого SQL, выполняющего сложные вычисления. С поддержкой самых детализированных типов данных и кодеков вам не нужно беспокоиться о снижении детализации ваших данных.

Хотя пользователи могут трансформировать данные напрямую в ClickHouse или перед вставкой с помощью SQL запросов, ClickHouse также может использоваться в программных средах, таких как Python, через [chDB](/chdb). Это позволяет встраиваемому ClickHouse быть представленным в качестве модуля Python и использоваться для преобразования и манипуляции большими датафреймами внутри ноутбуков. Инженеры по данным могут выполнять работы по преобразованию, чтобы выполнять их на стороне клиента, с результатами, которые потенциально могут быть материализованы в таблицах признаков в централизованном экземпляре ClickHouse.

### Подготовка данных и извлечение признаков {#data-preparation-and-feature-extraction}

Данные затем подготавливаются: очищаются, преобразуются и используются для извлечения признаков, по которым будет произведено обучение и оценка модели. Этот компонент иногда называется конвейером генерации или извлечения признаков и является еще одним аспектом слоя данных машинного обучения, где часто вводятся новые инструменты. MLOps игроки, такие как Neptune и Hopsworks, предоставляют примеры множества различных продуктов преобразования данных, которые используются для оркестрации таких конвейеров. Однако, поскольку это отдельные инструменты от базы данных, с которой они работают, они могут быть хрупкими и вызывать сбои, которые нужно вручную устранять.

В отличие от этого, преобразования данных легко выполняются непосредственно в ClickHouse через [материализованные представления](/materialized-views). Они автоматически срабатывают, когда новые данные вставляются в исходные таблицы ClickHouse и используются для легкого извлечения, преобразования и модификации данных по мере их поступления, что исключает необходимость самостоятельно строить и контролировать специализированные конвейеры. Когда эти преобразования требуют агрегаций по полному набору данных, который может не вмещаться в память, использование ClickHouse гарантирует, что вам не нужно пытаться адаптировать этот шаг для работы с датафреймами на вашей локальной машине. Для тех наборов данных, которые удобнее оценивать локально, [ClickHouse local](/operations/utilities/clickhouse-local) является отличной альтернативой, наряду с [chDB](/chdb), который позволяет пользователям использовать ClickHouse с стандартными библиотеками данных Python, такими как Pandas.

### Обучение и оценка {#training-and-evaluation}

На этом этапе признаки будут разделены на тренировочные, валидационные и тестовые наборы. Эти наборы данных версионируются и затем используются в соответствующих этапах.

На этой фазе конвейера часто вводится еще один специализированный инструмент для слоя данных машинного обучения - хранилище признаков. Хранилище признаков обычно представляет собой уровень абстракции вокруг базы данных, который предоставляет удобные функции, специфичные для управления данными для обучения модели, вывода и оценки. Примеры таких удобных функций включают версионирование, управление доступом и автоматическую трансляцию определения признаков в SQL команды.

Для хранилищ признаков ClickHouse может выступать в роли:

**Источник данных** - Обладая возможностью запрашивать или загружать данные в более чем 70 различных форматах файлов, включая форматы ДатаЛэйков, такие как Iceberg и Delta Lake, ClickHouse идеален как долгосрочное хранилище для хранения или запроса данных. Разделяя хранение и вычисления с помощью объектного хранилища, ClickHouse Cloud также позволяет хранить данные неограниченно - с расчетами, уменьшенными или полностью остановленными, чтобы минимизировать затраты. Гибкие кодеки в сочетании со столбцовой архитектурой хранения и упорядочиванием данных на диске максимизируют коэффициенты сжатия, тем самым минимизируя необходимое хранилище. Пользователи могут легко комбинировать ClickHouse с ДатаЛэйками, используя встроенные функции для запроса данных непосредственно на объектном хранилище.

**Двигатель преобразований** - SQL предоставляет естественное средство для объявления преобразований данных. Когда он расширен аналитическими и статистическими функциями ClickHouse, эти преобразования становятся лаконичными и оптимизированными. Помимо применения к таблицам ClickHouse, в случаях, когда ClickHouse используется как хранилище данных, табличные функции позволяют писать SQL запросы к данным, хранящимся в таких форматах, как Parquet, на диске или в объектном хранилище, или даже в других хранилищах данных, таких как Postgres и MySQL. Полностью параллельный исполнитель запросов, в сочетании со столбцовым форматом хранения, позволяет ClickHouse выполнять агрегации по ПБ данных за считанные секунды - в отличие от преобразований в памяти, пользователи не связаны по памяти. Более того, материализованные представления позволяют преобразовывать данные во время вставки, таким образом, перегружая вычисления до времени загрузки данных вместо времени запроса. Эти представления могут использовать тот же спектр аналитических и статистических функций, идеальных для анализа и обобщения данных. Если какие-либо из существующих аналитических функций ClickHouse оказываются недостаточными или необходимо интегрировать пользовательские библиотеки, пользователи также могут использовать Пользовательские Функции (UDFs).

#### Офлайн хранилище признаков {#offline-feature-store}

Офлайн хранилище признаков используется для обучения модели. Это обычно означает, что сами признаки производятся через пакетные процессы преобразования данных (как описано в предыдущем разделе), и, как правило, нет строгих требований к задержке в доступности этих признаков.

С возможностями считывания данных из нескольких источников и применения преобразований с помощью SQL запросов результаты этих запросов также могут быть сохранены в ClickHouse через команды `INSERT INTO SELECT`. Поскольку преобразования часто группируются по идентификатору сущности и возвращают множество столбцов в виде результатов, вывод схемы ClickHouse может автоматически определить необходимые типы из этих результатов и создать соответствующую схему таблицы для их хранения. Функции для генерации случайных чисел и статистической выборки позволяют эффективно итеративно масштабировать данные до миллионов строк в секунду для подачи на конвейеры обучения модели.

Часто признаки представлены в таблицах с временной меткой, указывающей на значение для сущности и признака в конкретный момент времени. Как уже упоминалось, конвейеры обучения часто требуют состояния признаков в определенные моменты времени и в группах. Разреженные индексы ClickHouse позволяют быстро фильтровать данные, чтобы удовлетворить запросы на конкретный момент времени и фильтры выбора признаков. В то время как другие технологии, такие как Spark, Redshift и BigQuery, полагаются на медленные состояния оконных подходов для идентификации состояния признаков в конкретный момент времени, ClickHouse поддерживает запрос LEFT JOIN типа ASOF (as-of-this-time) и функцию argMax. Помимо упрощения синтаксиса, этот подход показывает высокую производительность на больших наборах данных благодаря использованию алгоритма сортировки и слияния. Это позволяет быстро строить группы признаков, сокращая время подготовки данных перед обучением.

#### Онлайн хранилище признаков {#online-feature-store}

Онлайн хранилища признаков используются для хранения последней версии признаков, используемых для вывода, и применяются в реальном времени. Это означает, что эти признаки должны рассчитываться с минимальной задержкой, так как они используются как часть сервиса машинного обучения в реальном времени.

<Image img={online_feature_store} size="sm"/>

В качестве базы данных для аналитики в реальном времени ClickHouse может обрабатывать высококонкурентные рабочие нагрузки запросов с низкой задержкой. Хотя это требует, чтобы данные обычно были денормализованы, это согласуется с хранением групп признаков, использованных как во время обучения, так и во время вывода. Важно, что ClickHouse может обеспечить эту производительность запросов, оставаясь под высоким рабочим нагрузками записи благодаря своей логически структурируемой дереву слияния. Эти свойства необходимы в онлайн хранилище, чтобы поддерживать признаки актуальными. Поскольку признаки уже доступны в офлайн хранилище, их можно легко материализовать в новые таблицы как в том же кластере ClickHouse, так и в другом экземпляре через существующие возможности, например, `remoteSecure`. Интеграции с Kafka, как через предложение Kafka Connect с гарантией "точно один раз", так и через [ClickPipes](/integrations/clickpipes/kafka) в ClickHouse Cloud, также делают простым и надежным получение данных из потоковых источников.

Многие современные системы требуют как оффлайн, так и онлайн хранилищ, и легко прийти к выводу, что здесь требуются два специализированных хранилища признаков. Однако это вводит дополнительную сложность синхронизации этих обоих хранилищ, что, конечно, также включает затраты на репликацию данных между ними.

Хранилище данных в реальном времени, такое как ClickHouse, - это единственная система, которая может обеспечить управление как офлайн, так и онлайн признаками. ClickHouse эффективно обрабатывает потоковые и исторические данные и обладает неограниченной масштабируемостью, производительностью и параллельностью, необходимыми для надежного предоставления признаков для реального вывода и оффлайн обучения.

В рассматривая компромиссы между использованием продукта хранилища признаков на этой стадии и непосредственным использованием хранилища данных в реальном времени, стоит подчеркнуть, что удобные функции, такие как версионирование, могут быть достигнуты через давние парадигмы баз данных, такие как проектирование таблиц или схем. Другие функции, такие как конвертация определения признаков в SQL команды, могут предоставить большую гибкость как часть логики бизнес-приложений, а не находиться в предвзятом уровне абстракции.

### Выводы {#inference}

Вывод модели - это процесс запуска обученной модели для получения результата. Когда вывод инициируется действиями базы данных - например, вставкой новой записи или запросом записей - шаг вывода может управляться с помощью специализированных заданий или кода приложения.

С другой стороны, его можно управлять непосредственно на уровне данных. Пользовательские Функции (UDFs) ClickHouse позволяют пользователям вызывать модель непосредственно из ClickHouse во время вставки или выполнения запроса. Это предоставляет возможность передавать входящие данные модели, получать вывод и автоматически сохранять эти результаты вместе с загруженными данными - все это без необходимости запуска других процессов или заданий. Это также предоставляет единый интерфейс, SQL, с помощью которого можно управлять этим шагом.

### Векторное хранилище {#vector-store}

Векторное хранилище - это специфический тип базы данных, оптимизированный для хранения и извлечения векторов, как правило, встраиваний части данных (таких как текст или изображения), которые численно захватывают их основное значение. Векторы находятся в центре текущей волны генеративного ИИ и используются в бесчисленных приложения.

Основной операцией в векторной базе данных является "поиск по схожести", чтобы найти векторы, которые "ближе" друг к другу согласно математической мере. Векторные базы данных стали популярными, потому что они используют специфические приемы, направленные на то, чтобы сделать это изучение - сравнение векторов - как можно быстрее. Эти технологии, как правило, означают, что они приближают сравнение векторов, вместо того чтобы сравнивать входной вектор со всеми хранящимися векторами.

Проблема с этой новой категорией инструментов в том, что многие универсальные базы данных, включая ClickHouse, предоставляют поддержку векторов "из коробки", и также часто имеют встроенные реализации этих приближенных подходов. ClickHouse, в частности, разработан для высокопроизводительной крупномасштабной аналитики - что позволяет вам выполнять непрерывные сравнения векторов очень эффективно. Это означает, что вы можете получить точные результаты, а не полагаться на приближения, все это не жертвуя скоростью.

### Наблюдаемость {#observability}

После того как ваше приложение для машинного обучения становится активным, оно будет генерировать данные, включая журналы и данные отслеживания, которые предлагают ценные инсайты о поведении модели, производительности и потенциальных областях для улучшения.

Наблюдаемость на основе SQL является еще одним ключевым случаем использования ClickHouse, где было установлено, что ClickHouse оказывается от 10 до 100 раз более эффективным по затратам, чем альтернативы. На самом деле, многие продукты наблюдаемости сами построены с использованием ClickHouse в качестве основы. С лучшими в своем классе показателями потребления и коэффициентами сжатия, ClickHouse обеспечивает экономичность и молниеносную скорость для поддержки наблюдаемости машинного обучения в любых масштабах.