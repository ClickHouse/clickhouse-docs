---
slug: /cloud/get-started/cloud/use-cases/AI_ML
title: 'Машинное обучение'
description: 'Узнайте, как ClickHouse используется в приложениях машинного обучения на всех этапах ML-пайплайна.'
keywords: ['сценарии использования', 'Машинное обучение', 'Генеративный ИИ']
sidebar_label: 'Машинное обучение'
doc_type: 'guide'
---

import machine_learning_data_layer from '@site/static/images/cloud/onboard/discover/use_cases/ml_data_layer.png'
import online_feature_store from '@site/static/images/cloud/onboard/discover/use_cases/ml_data_layer.png'
import Image from '@theme/IdealImage';


## Уровень данных для машинного обучения {#machine-learning-data-layer}

Вы, вероятно, слышали утверждение, что 80% времени специалиста по машинному обучению уходит на очистку данных.
Независимо от того, соответствует ли этот миф действительности, неоспоримым остается факт, что данные находятся в центре задачи машинного обучения от начала до конца.
Независимо от того, создаете ли вы конвейеры RAG, выполняете тонкую настройку, обучаете собственную модель или оцениваете производительность модели, данные лежат в основе каждой задачи.

Управление данными может быть сложным, и как следствие, в этой области наблюдается распространение инструментов, предназначенных для повышения производительности путем решения конкретного аспекта проблемы данных в машинном обучении.
Зачастую это принимает форму уровня абстракции вокруг более универсального решения с определенным интерфейсом, который на первый взгляд упрощает применение к конкретной подзадаче.
Фактически это снижает гибкость, присущую универсальному решению, в пользу простоты использования и упрощения конкретной задачи.

<Image img={machine_learning_data_layer} size='sm' />

У этого подхода есть несколько недостатков.
Каскадный набор специализированных инструментов, продуктов и сервисов, в отличие от универсального решения в сочетании с поддерживающим кодом приложения, создает риск избыточной архитектурной сложности и затрат на данные.
Легко случайно оказаться с бесконечным списком инструментов и сервисов, каждый из которых используется только для одного шага.

Эти риски имеют два общих аспекта:

1. **Затраты на обучение, обслуживание и переход**

Архитектуры машинного обучения могут стать настолько перегруженными различными инструментами и компонентами, что это создает фрагментированную и сложную среду для изучения и управления, с увеличением точек отказа и незаметным ростом расходов.

2. **Затраты на дублирование и передачу данных**

Использование нескольких дискретных, но пересекающихся систем данных в конвейере машинного обучения может привести к ненужным и часто дорогостоящим накладным расходам на передачу данных между ними.

Отличной иллюстрацией этого компромисса является векторная база данных.
Векторные базы данных предназначены для узкоспециализированной задачи машинного обучения — хранения и поиска по векторам.
Хотя это может быть правильным выбором в некоторых архитектурах, векторная база данных может оказаться ненужным новым дополнением к технологическому стеку в других случаях, поскольку это еще одна система для интеграции, управления и передачи данных.
Большинство современных универсальных баз данных поставляются с поддержкой векторов из коробки (или через плагин) и обладают более широкими и сквозными возможностями.
Другими словами, в таких архитектурах может вообще не быть необходимости в новой базе данных специально для работы с векторами.
Важность сводится к тому, являются ли специфичные для векторов удобные функции (например, встроенные модели эмбеддингов) критически важными и стоят ли они затрат.

### Исследование данных {#data-exploration}

После определения задачи машинного обучения, целей и критериев успеха обычным первым шагом является исследование соответствующих данных, которые будут использоваться для обучения и оценки модели.

На этом этапе данные анализируются для понимания их характеристик, распределений и взаимосвязей.
Этот процесс оценки и понимания является итеративным и часто приводит к выполнению серии специальных запросов к наборам данных, где скорость отклика запросов критична (наряду с другими факторами, такими как экономическая эффективность и точность).
По мере того как компании хранят все больше данных для использования в целях машинного обучения, задача изучения имеющихся данных становится сложнее.

Это происходит потому, что аналитические запросы и запросы оценки часто становятся утомительно или недопустимо медленными при масштабировании в традиционных системах данных.
Некоторые крупные игроки значительно увеличивают затраты для сокращения времени выполнения запросов и препятствуют специальной оценке, взимая плату за запрос или по количеству просканированных байтов.
Инженеры могут прибегать к загрузке подмножеств данных на свои локальные машины в качестве компромисса при таких ограничениях.

ClickHouse, с другой стороны, является хранилищем данных реального времени, поэтому пользователи получают преимущество от лидирующей в отрасли скорости выполнения запросов для аналитических вычислений.
Кроме того, ClickHouse обеспечивает высокую производительность с самого начала и не ограничивает критически важные функции ускорения запросов более высокими ценовыми уровнями.
ClickHouse также может выполнять запросы к данным напрямую из объектного хранилища или озер данных с поддержкой распространенных форматов, таких как Iceberg, Delta Lake и Hudi.
Это означает, что независимо от того, где находятся ваши данные, ClickHouse может служить единым уровнем доступа и вычислений для ваших рабочих нагрузок машинного обучения.

ClickHouse также имеет обширный набор готовых статистических и агрегатных функций, которые масштабируются на петабайты данных, что упрощает написание и поддержку простого SQL, выполняющего сложные вычисления.
Благодаря поддержке типов данных и кодеков с максимальной детализацией вам не нужно беспокоиться о снижении детализации ваших данных.


Хотя пользователи могут преобразовывать данные непосредственно в ClickHouse или перед вставкой с помощью SQL-запросов, ClickHouse также можно использовать в средах программирования, таких как Python, через [chDB](/chdb).
Это позволяет использовать встроенный ClickHouse в качестве модуля Python для преобразования и обработки больших датафреймов в блокнотах.
Таким образом, инженеры данных могут выполнять преобразования на стороне клиента, при этом результаты могут материализоваться в виде таблиц признаков в централизованном экземпляре ClickHouse.

### Подготовка данных и извлечение признаков {#data-preparation-and-feature-extraction}

Затем данные подготавливаются: очищаются, преобразуются и используются для извлечения признаков, по которым модель будет обучаться и оцениваться.
Этот компонент иногда называют конвейером генерации или извлечения признаков, и это еще один элемент уровня данных машинного обучения, где часто внедряются новые инструменты.
Игроки в области MLOps, такие как Neptune и Hopsworks, предоставляют примеры множества различных продуктов для преобразования данных, которые используются для оркестрации подобных конвейеров.
Однако, поскольку они являются отдельными инструментами от базы данных, с которой работают, они могут быть ненадежными и вызывать сбои, которые необходимо устранять вручную.

В отличие от этого, преобразования данных легко выполняются непосредственно в ClickHouse с помощью [материализованных представлений](/materialized-views).
Они автоматически запускаются при вставке новых данных в исходные таблицы ClickHouse и используются для простого извлечения, преобразования и изменения данных по мере их поступления — устраняя необходимость самостоятельно создавать и контролировать специализированные конвейеры.
Когда эти преобразования требуют агрегаций по полному набору данных, который может не поместиться в память, использование ClickHouse гарантирует, что вам не придется пытаться адаптировать этот шаг для работы с датафреймами на локальной машине.
Для тех наборов данных, которые удобнее обрабатывать локально, [ClickHouse local](/operations/utilities/clickhouse-local) является отличной альтернативой, наряду с [chDB](/chdb), которые позволяют пользователям использовать ClickHouse со стандартными библиотеками данных Python, такими как Pandas.

### Обучение и оценка {#training-and-evaluation}

На этом этапе признаки будут разделены на обучающие, валидационные и тестовые наборы.
Эти наборы данных версионируются, а затем используются на соответствующих этапах.

На этом этапе конвейера обычно вводится еще один специализированный инструмент в уровень данных машинного обучения — хранилище признаков.
Хранилище признаков чаще всего представляет собой уровень абстракции вокруг базы данных, который предоставляет удобные функции, специфичные для управления данными для обучения, вывода и оценки модели.
Примеры таких удобных функций включают версионирование, управление доступом и автоматический перевод определений признаков в SQL-операторы.

Для хранилищ признаков ClickHouse может выступать в качестве:

**Источника данных** — Благодаря возможности запрашивать или загружать данные в более чем 70 различных форматах файлов, включая форматы озер данных, такие как Iceberg и Delta Lake, ClickHouse является идеальным долгосрочным хранилищем для хранения или запроса данных.
Разделяя хранение и вычисления с помощью объектного хранилища, ClickHouse Cloud дополнительно позволяет хранить данные неограниченно долго — с уменьшением вычислительных ресурсов или полным переводом их в режим простоя для минимизации затрат.
Гибкие кодеки в сочетании с колоночным хранением и упорядочиванием данных на диске максимизируют степень сжатия, тем самым минимизируя требуемый объем хранилища.
Пользователи могут легко комбинировать ClickHouse с озерами данных, используя встроенные функции для запроса данных непосредственно в объектном хранилище.

**Движка преобразований** — SQL предоставляет естественный способ объявления преобразований данных.
При расширении аналитическими и статистическими функциями ClickHouse эти преобразования становятся лаконичными и оптимизированными.
Помимо применения к таблицам ClickHouse в случаях, когда ClickHouse используется в качестве хранилища данных, табличные функции позволяют писать SQL-запросы к данным, хранящимся в таких форматах, как Parquet, на диске или в объектном хранилище, или даже в других хранилищах данных, таких как Postgres и MySQL.
Полностью параллелизованный движок выполнения запросов в сочетании с колоночным форматом хранения позволяет ClickHouse выполнять агрегации по петабайтам данных за секунды — в отличие от преобразований датафреймов в памяти, пользователи не ограничены объемом памяти.
Кроме того, материализованные представления позволяют преобразовывать данные во время вставки, тем самым перенося вычислительную нагрузку со времени выполнения запроса на время загрузки данных.
Эти представления могут использовать тот же набор аналитических и статистических функций, идеальных для анализа и обобщения данных.
Если каких-либо существующих аналитических функций ClickHouse недостаточно или необходимо интегрировать пользовательские библиотеки, пользователи также могут использовать пользовательские функции (UDF).

#### Офлайн-хранилище признаков {#offline-feature-store}

Офлайн-хранилище признаков используется для обучения модели.
Это обычно означает, что сами признаки создаются через конвейеры пакетного преобразования данных (как описано в разделе выше), и, как правило, нет строгих требований к задержке доступности этих признаков.


Благодаря возможностям чтения данных из множества источников и применения преобразований через SQL-запросы, результаты этих запросов также могут быть сохранены в ClickHouse с помощью операторов `INSERT INTO SELECT`.
Поскольку преобразования часто группируются по идентификатору сущности и возвращают несколько столбцов в качестве результатов, автоматический вывод схемы ClickHouse может определить необходимые типы данных из этих результатов и создать соответствующую схему таблицы для их хранения.
Функции для генерации случайных чисел и статистической выборки позволяют эффективно обрабатывать и масштабировать данные со скоростью миллионы строк в секунду для передачи в конвейеры обучения моделей.

Часто признаки представлены в таблицах с временной меткой, указывающей значение для сущности и признака в конкретный момент времени.
Как было описано ранее, конвейеры обучения часто требуют состояния признаков в определенные моменты времени и в группах. Разреженные индексы ClickHouse обеспечивают быструю фильтрацию данных для выполнения запросов на определенный момент времени и фильтров выбора признаков. В то время как другие технологии, такие как Spark, Redshift и BigQuery, полагаются на медленные оконные подходы с сохранением состояния для определения состояния признаков в конкретный момент времени, ClickHouse поддерживает запрос ASOF (на момент времени) LEFT JOIN и функцию argMax.
Помимо упрощения синтаксиса, этот подход обеспечивает высокую производительность на больших наборах данных благодаря использованию алгоритма сортировки и слияния.
Это позволяет быстро создавать группы признаков, сокращая время подготовки данных перед обучением.

#### Онлайн-хранилище признаков {#online-feature-store}

Онлайн-хранилища признаков используются для хранения последней версии признаков, применяемых для вывода, и работают в режиме реального времени.
Это означает, что эти признаки должны вычисляться с минимальной задержкой, поскольку они используются в составе сервиса машинного обучения в режиме реального времени.

<Image img={online_feature_store} size='sm' />

Как база данных для аналитики в режиме реального времени, ClickHouse способна обрабатывать высококонкурентные запросы с низкой задержкой.
Хотя это требует денормализации данных, это соответствует хранению групп признаков, используемых как при обучении, так и при выводе.
Важно отметить, что ClickHouse способна обеспечивать такую производительность запросов при высоких нагрузках на запись благодаря своей структуре log-structured merge tree.
Эти свойства необходимы в онлайн-хранилище для поддержания актуальности признаков.
Поскольку признаки уже доступны в офлайн-хранилище, их можно легко материализовать в новые таблицы либо в том же кластере ClickHouse, либо в другом экземпляре с помощью существующих возможностей, например `remoteSecure`.
Интеграции с Kafka через решение Kafka Connect с гарантией exactly-once или через [ClickPipes](/integrations/clickpipes/kafka) в ClickHouse Cloud также делают потребление потоковых данных из потоковых источников простым и надежным.

Многие современные системы требуют как офлайн-, так и онлайн-хранилищ, и легко прийти к выводу, что здесь необходимы два специализированных хранилища признаков.
Однако это вносит дополнительную сложность поддержания синхронизации обоих хранилищ, что, конечно же, также включает затраты на репликацию данных между ними.

Хранилище данных реального времени, такое как ClickHouse, представляет собой единую систему, которая может обеспечивать как офлайн-, так и онлайн-управление признаками.
ClickHouse эффективно обрабатывает потоковые и исторические данные и обладает неограниченной масштабируемостью, производительностью и конкурентностью, необходимыми для надежного предоставления признаков для вывода в режиме реального времени и офлайн-обучения.

При рассмотрении компромиссов между использованием продукта хранилища признаков на этом этапе и прямым использованием хранилища данных реального времени стоит подчеркнуть, что удобные функции, такие как версионирование, могут быть реализованы с помощью проверенных временем парадигм баз данных, таких как проектирование таблиц или схем.
Другие функции, такие как преобразование определений признаков в SQL-операторы, могут обеспечить большую гибкость в составе прикладной или бизнес-логики, а не существовать в виде предписывающего уровня абстракции.

### Вывод {#inference}

Вывод модели — это процесс запуска обученной модели для получения результата.
Когда вывод инициируется действиями базы данных — например, вставкой новой записи или запросом записей — этап вывода может управляться через специализированные задания или код приложения.

С другой стороны, это может управляться на уровне данных. [Пользовательские функции (UDF)](/sql-reference/functions/udf) ClickHouse предоставляют пользователям возможность вызывать модель непосредственно из ClickHouse во время вставки или запроса.
Это обеспечивает возможность передавать входящие данные в модель, получать результат и автоматически сохранять эти результаты вместе с загруженными данными — все это без необходимости запуска других процессов или заданий.
Это также обеспечивает единый интерфейс, SQL, для управления этим этапом.

### Векторное хранилище {#vector-store}

Векторное хранилище — это специализированный тип базы данных, оптимизированный для хранения и извлечения векторов, обычно представляющих собой векторные представления фрагментов данных (таких как текст или изображения), которые численно отражают их смысловое содержание.
Векторы лежат в основе современной волны генеративного искусственного интеллекта и используются в бесчисленных приложениях.


Основной операцией в векторной базе данных является «поиск по сходству» для нахождения векторов, которые являются «наиболее близкими» друг к другу в соответствии с математической метрикой.
Векторные базы данных стали популярными благодаря использованию специальных методов, направленных на максимальное ускорение этого процесса — сравнения векторов.
Эти методы, как правило, подразумевают приближенное сравнение векторов вместо сравнения входного вектора с каждым сохраненным вектором.

Проблема этого нового класса инструментов заключается в том, что многие универсальные базы данных, включая ClickHouse, предоставляют встроенную поддержку векторов, а также часто имеют встроенные реализации этих приближенных подходов.
ClickHouse, в частности, разработан для высокопроизводительной крупномасштабной аналитики, что позволяет выполнять точные сравнения векторов с высокой эффективностью.
Это означает, что вы можете получать точные результаты без необходимости полагаться на приближения и при этом не жертвовать скоростью.

### Наблюдаемость {#observability}

После запуска вашего приложения машинного обучения оно будет генерировать данные, включая журналы и данные трассировки, которые предоставляют ценную информацию о поведении модели, производительности и потенциальных областях для улучшения.

Наблюдаемость на основе SQL является еще одним ключевым сценарием использования ClickHouse, где ClickHouse демонстрирует в 10-100 раз большую экономическую эффективность по сравнению с альтернативами.
Фактически, многие продукты для наблюдаемости сами построены на основе ClickHouse.
Благодаря лучшим в своем классе скоростям приема данных и коэффициентам сжатия ClickHouse обеспечивает экономическую эффективность и высочайшую скорость для поддержки наблюдаемости машинного обучения в любом масштабе.
