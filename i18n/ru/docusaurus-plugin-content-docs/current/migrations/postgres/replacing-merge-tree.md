---
slug: /guides/replacing-merge-tree
title: ReplacingMergeTree
description: Использование движка ReplacingMergeTree в ClickHouse
keywords: [replacingmergetree, inserts, deduplication]
---

import postgres_replacingmergetree from '@site/static/images/migrations/postgres-replacingmergetree.png';

Хотя транзакционные базы данных оптимизированы для транзакционных операций обновления и удаления, OLAP базы данных предлагают сниженные гарантии для таких операций. Вместо этого они оптимизируют работу с неизменяемыми данными, вставленными партиями, что позволяет значительно ускорить аналитические запросы. Хотя ClickHouse предоставляет операции обновления через мутации, а также легкий способ удаления строк, его колоночная структура означает, что эти операции следует планировать внимательно, как описано выше. Эти операции обрабатываются асинхронно, обрабатываются с помощью одного потока и требуют (в случае обновлений) переписывания данных на диск. Поэтому их не следует использовать для большого количества мелких изменений. Для обработки потока обновлений и удаленных строк, избегая указанных выше шаблонов использования, мы можем использовать движок таблицы ClickHouse ReplacingMergeTree.

## Автоматические апсерты вставленных строк {#automatic-upserts-of-inserted-rows}

[Движок таблицы ReplacingMergeTree](/engines/table-engines/mergetree-family/replacingmergetree) позволяет применять операции обновления к строкам, не требуя использования неэффективных операторов `ALTER` или `DELETE`, предоставляя пользователям возможность вставлять несколько копий одной и той же строки и обозначать одну из них как последнюю версию. Фоновый процесс, в свою очередь, асинхронно удаляет более старые версии одной и той же строки, эффективно имитируя операцию обновления за счет использования неизменяемых вставок. Это зависит от способности движка таблицы идентифицировать дублирующиеся строки. Это достигается с помощью предложения `ORDER BY`, чтобы определить уникальность, т.е. если две строки имеют одинаковые значения для колонок, указанных в `ORDER BY`, они считаются дубликатами. Колонка `version`, заданная при определении таблицы, позволяет сохранить последнюю версию строки, когда две строки идентифицируются как дубликаты, т.е. сохраняется строка с наибольшим значением версии. Мы иллюстрируем этот процесс в приведенном ниже примере. Здесь строки уникально идентифицируются по колонке A (это `ORDER BY` для таблицы). Мы предполагаем, что эти строки были вставлены как две партии, в результате чего на диске сформировались две части данных. Позже, в ходе асинхронного фонового процесса, эти части объединяются.

ReplacingMergeTree дополнительно позволяет указать колонку для удаления. Она может содержать либо 0, либо 1, где значение 1 указывает на то, что строка (и ее дубликаты) были удалены, а ноль используется в противном случае. **Примечание: Удаленные строки никогда не будут удалены во время слияния.**

В процессе слияния частей происходит следующее:

- Строка, идентифицируемая значением 1 для колонки A, имеет как обновленную строку с версией 2, так и строку удаления с версией 3 (и значением колонки для удаления 1). Последняя строка, помеченная как удаленная, поэтому сохраняется.
- Строка, идентифицируемая значением 2 для колонки A, имеет две обновленные строки. Последняя строка сохраняется со значением 6 для колонки цены.
- Строка, идентифицируемая значением 3 для колонки A, имеет строку с версией 1 и строку удаления с версией 2. Эта строка удаления сохраняется.

В результате этого процесса слияния у нас есть четыре строки, представляющие конечное состояние:

<br />

<img src={postgres_replacingmergetree} class="image" alt="Процесс ReplacingMergeTree" style={{width: '800px', background: 'none'}} />

<br />

Обратите внимание, что удаленные строки никогда не удаляются. Их можно принудительно удалить с помощью `OPTIMIZE table FINAL CLEANUP`. Для этого требуется экспериментальная настройка `allow_experimental_replacing_merge_with_cleanup=1`. Это следует делать только при следующих условиях:

1. Вы можете быть уверены, что после выполнения операции не будут вставлены строки со старыми версиями (для тех, которые удаляются с помощью очистки). Если они будут вставлены, они будут неверно сохранены, поскольку удаленные строки больше не будут присутствовать.
2. Убедитесь, что все реплики синхронизированы перед выполнением очистки. Это можно сделать с помощью команды:

<br />

```sql
SYSTEM SYNC REPLICA table
```

Рекомендуется приостановить вставки, как только (1) будет гарантировано, и до завершения этой команды и последующей очистки.

> Обработка удалений с помощью ReplacingMergeTree рекомендуется только для таблиц с низким или умеренным количеством удалений (менее 10%), если не могут быть запланированы периоды для очистки с вышеупомянутыми условиями.

> Совет: Пользователи также могут выполнить `OPTIMIZE FINAL CLEANUP` против избирательных партиций, больше не подлежащих изменениям.

## Выбор первичного/ключа дедупликации {#choosing-a-primarydeduplication-key}

Выше мы подчеркнули важное дополнительное ограничение, которое также должно быть выполнено в случае ReplacingMergeTree: значения колонок в `ORDER BY` уникально идентифицируют строку при изменениях. Если вы мигрируете из транзакционной базы данных, такой как Postgres, исходный первичный ключ Postgres должен быть включен в `ORDER BY` Clickhouse.

Пользователи ClickHouse знакомы с выбором колонок в предложении `ORDER BY` своих таблиц для [оптимизации производительности запросов](/data-modeling/schema-design#choosing-an-ordering-key). Обычно эти колонки следует выбирать на основе ваших [часто используемых запросов и перечислять в порядке возрастания кардинальности](/guides/best-practices/sparse-primary-indexes#an-index-design-for-massive-data-scales). Важно, что ReplacingMergeTree накладывает дополнительное ограничение – эти колонки должны быть неизменяемыми, т.е. если вы реплицируете из Postgres, добавляйте колонки в это предложение, только если они не меняются в исходных данных Postgres. Хотя другие колонки могут меняться, они должны быть согласованными для уникальной идентификации строки.
Для аналитических нагрузок первичный ключ Postgres обычно мало полезен, так как пользователи редко выполняют точечные запросы на строки. Учитывая, что мы рекомендуем размещать колонки в порядке возрастания кардинальности, а также то, что совпадения с [колонками, перечисленными раньше в ORDER BY, будут обычно быстрее](/guides/best-practices/sparse-primary-indexes#ordering-key-columns-efficiently), первичный ключ Postgres следует добавлять в конец `ORDER BY` (если он не имеет аналитической ценности). В случае, если несколько колонок формируют первичный ключ в Postgres, их следует добавлять в `ORDER BY`, учитывая кардинальность и вероятность значения запроса. Пользователи также могут пожелать сгенерировать уникальный первичный ключ, используя конкатенацию значений через колонку `MATERIALIZED`.

Рассмотрим таблицу постов из набора данных Stack Overflow.

```sql
CREATE TABLE stackoverflow.posts_updateable
(
       `Version` UInt32,
       `Deleted` UInt8,
	`Id` Int32 CODEC(Delta(4), ZSTD(1)),
	`PostTypeId` Enum8('Question' = 1, 'Answer' = 2, 'Wiki' = 3, 'TagWikiExcerpt' = 4, 'TagWiki' = 5, 'ModeratorNomination' = 6, 'WikiPlaceholder' = 7, 'PrivilegeWiki' = 8),
	`AcceptedAnswerId` UInt32,
	`CreationDate` DateTime64(3, 'UTC'),
	`Score` Int32,
	`ViewCount` UInt32 CODEC(Delta(4), ZSTD(1)),
	`Body` String,
	`OwnerUserId` Int32,
	`OwnerDisplayName` String,
	`LastEditorUserId` Int32,
	`LastEditorDisplayName` String,
	`LastEditDate` DateTime64(3, 'UTC') CODEC(Delta(8), ZSTD(1)),
	`LastActivityDate` DateTime64(3, 'UTC'),
	`Title` String,
	`Tags` String,
	`AnswerCount` UInt16 CODEC(Delta(2), ZSTD(1)),
	`CommentCount` UInt8,
	`FavoriteCount` UInt8,
	`ContentLicense` LowCardinality(String),
	`ParentId` String,
	`CommunityOwnedDate` DateTime64(3, 'UTC'),
	`ClosedDate` DateTime64(3, 'UTC')
)
ENGINE = ReplacingMergeTree(Version, Deleted)
PARTITION BY toYear(CreationDate)
ORDER BY (PostTypeId, toDate(CreationDate), CreationDate, Id)
```

Мы используем ключ `ORDER BY` `(PostTypeId, toDate(CreationDate), CreationDate, Id)`. Колонка `Id`, уникальная для каждого поста, гарантирует возможность дедупликации строк. Колонки `Version` и `Deleted` добавлены в схему по мере необходимости.

## Запросы к ReplacingMergeTree {#querying-replacingmergetree}

Во время слияния ReplacingMergeTree идентифицирует дублирующиеся строки, используя значения колонок `ORDER BY` в качестве уникального идентификатора, и либо сохраняет только наивысшую версию, либо удаляет все дубликаты, если последняя версия указывает на удаление. Однако это обеспечивает только конечную корректность - это не гарантирует, что строки будут дедуплицированы, и на это не следует полагаться. Следовательно, запросы могут выдавать неверные результаты, поскольку в запросах учитываются строки обновления и удаления.

Чтобы получить правильные ответы, пользователям необходимо дополнить фоновые слияния дедупликацией и удалением на уровне запроса. Это можно сделать с помощью оператора `FINAL`.

Рассмотрим вышеуказанную таблицу постов. Мы можем использовать обычный метод загрузки этого набора данных, но указать колонку удаления и версию в дополнение к значениям 0. Для примера мы загружаем только 10000 строк.

```sql
INSERT INTO stackoverflow.posts_updateable SELECT 0 AS Version, 0 AS Deleted, *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/*.parquet') WHERE AnswerCount > 0 LIMIT 10000

0 rows in set. Elapsed: 1.980 sec. Processed 8.19 thousand rows, 3.52 MB (4.14 thousand rows/s., 1.78 MB/s.)
```

Давайте подтвердим количество строк:

```sql
SELECT count() FROM stackoverflow.posts_updateable

┌─count()─┐
│   10000 │
└─────────┘

1 row in set. Elapsed: 0.002 sec.
```

Теперь мы обновляем статистику постов и ответов. Вместо обновления этих значений мы вставляем новые копии 5000 строк и увеличиваем их номер версии на 1 (это означает, что 150 строк будет существовать в таблице). Мы можем смоделировать это простым `INSERT INTO SELECT`:

```sql
INSERT INTO posts_updateable SELECT
	Version + 1 AS Version,
	Deleted,
	Id,
	PostTypeId,
	AcceptedAnswerId,
	CreationDate,
	Score,
	ViewCount,
	Body,
	OwnerUserId,
	OwnerDisplayName,
	LastEditorUserId,
	LastEditorDisplayName,
	LastEditDate,
	LastActivityDate,
	Title,
	Tags,
	AnswerCount,
	CommentCount,
	FavoriteCount,
	ContentLicense,
	ParentId,
	CommunityOwnedDate,
	ClosedDate
FROM posts_updateable --select 100 random rows
WHERE (Id % toInt32(floor(randUniform(1, 11)))) = 0
LIMIT 5000

0 rows in set. Elapsed: 4.056 sec. Processed 1.42 million rows, 2.20 GB (349.63 thousand rows/s., 543.39 MB/s.)
```

Кроме того, мы удаляем 1000 случайных постов, повторно вставляя строки, но со значением колонки удаления равным 1. Опять же, это можно смоделировать простым `INSERT INTO SELECT`.

```sql
INSERT INTO posts_updateable SELECT
	Version + 1 AS Version,
	1 AS Deleted,
	Id,
	PostTypeId,
	AcceptedAnswerId,
	CreationDate,
	Score,
	ViewCount,
	Body,
	OwnerUserId,
	OwnerDisplayName,
	LastEditorUserId,
	LastEditorDisplayName,
	LastEditDate,
	LastActivityDate,
	Title,
	Tags,
	AnswerCount + 1 AS AnswerCount,
	CommentCount,
	FavoriteCount,
	ContentLicense,
	ParentId,
	CommunityOwnedDate,
	ClosedDate
FROM posts_updateable --select 100 random rows
WHERE (Id % toInt32(floor(randUniform(1, 11)))) = 0 AND AnswerCount > 0
LIMIT 1000

0 rows in set. Elapsed: 0.166 sec. Processed 135.53 thousand rows, 212.65 MB (816.30 thousand rows/s., 1.28 GB/s.)
```

Результат вышеуказанных операций составит 16,000 строк, т.е. 10,000 + 5000 + 1000. Правильный итог здесь - на самом деле у нас должно быть только 1000 строк меньше, чем наш оригинальный общий состав, т.е. 10,000 - 1000 = 9000.

```sql
SELECT count()
FROM posts_updateable

┌─count()─┐
│   10000 │
└─────────┘
1 row in set. Elapsed: 0.002 sec.
```

Ваши результаты будут варьироваться в зависимости от произошедших слияний. Мы видим, что здесь общее количество отличается, так как у нас есть дублирующиеся строки. Применение `FINAL` к таблице дает правильный результат.

```sql
SELECT count()
FROM posts_updateable
FINAL

┌─count()─┐
│	9000 │
└─────────┘

1 row in set. Elapsed: 0.006 sec. Processed 11.81 thousand rows, 212.54 KB (2.14 million rows/s., 38.61 MB/s.)
Пиковое использование памяти: 8.14 MiB.
```

## Производительность FINAL {#final-performance}

Оператор `FINAL` будет иметь накладные расходы на производительность для запросов, несмотря на постоянные улучшения. Это будет наиболее заметно, когда запросы не фильтруются по ключевым колонкам, что приводит к увеличению объема считываемых данных и накладным расходам на дедупликацию. Если пользователи фильтруют по ключевым колонкам, используя условие `WHERE`, загружаемые и передаваемые для дедупликации данные будут уменьшены.

Если условие `WHERE` не использует ключевую колонку, ClickHouse в настоящее время не использует оптимизацию `PREWHERE`, когда используется `FINAL`. Эта оптимизация стремится уменьшить количество считываемых строк для неотфильтрованных колонок. Примеры имитации этого `PREWHERE`, а значит, потенциального улучшения производительности можно найти [здесь](https://clickhouse.com/blog/clickhouse-postgresql-change-data-capture-cdc-part-1#final-performance).

## Использование партиций с ReplacingMergeTree {#exploiting-partitions-with-replacingmergetree}

Слияние данных в ClickHouse происходит на уровне партиций. При использовании ReplacingMergeTree мы рекомендуем пользователям делить свою таблицу в соответствии с лучшими практиками, если пользователи могут гарантировать, что **ключ партиционирования не меняется для строки**. Это обеспечит, что обновления, относящиеся к одной и той же строке, будут отправляться в одну и ту же партицию ClickHouse. Вы можете повторно использовать тот же ключ партиционирования, что и в Postgres, если соблюдаете лучшие практики, описанные здесь.

Предполагая, что это так, пользователи могут использовать настройку `do_not_merge_across_partitions_select_final=1` для улучшения производительности запроса `FINAL`. Эта настройка заставляет партиции сливаться и обрабатываться независимо при использовании FINAL.

Рассмотрим следующую таблицу постов, где мы не используем партиционирование:

```sql
CREATE TABLE stackoverflow.posts_no_part
(
	`Version` UInt32,
	`Deleted` UInt8,
	`Id` Int32 CODEC(Delta(4), ZSTD(1)),
	…
)
ENGINE = ReplacingMergeTree
ORDER BY (PostTypeId, toDate(CreationDate), CreationDate, Id)

INSERT INTO stackoverflow.posts_no_part SELECT 0 AS Version, 0 AS Deleted, *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/*.parquet')

0 rows in set. Elapsed: 182.895 sec. Processed 59.82 million rows, 38.07 GB (327.07 thousand rows/s., 208.17 MB/s.)
```

Чтобы гарантировать, что `FINAL` должно будет немного поработать, мы обновляем 1 миллион строк - увеличивая их `AnswerCount`, вставляя дублирующиеся строки.

```sql
INSERT INTO posts_no_part SELECT Version + 1 AS Version, Deleted, Id, PostTypeId, AcceptedAnswerId, CreationDate, Score, ViewCount, Body, OwnerUserId, OwnerDisplayName, LastEditorUserId, LastEditorDisplayName, LastEditDate, LastActivityDate, Title, Tags, AnswerCount + 1 AS AnswerCount, CommentCount, FavoriteCount, ContentLicense, ParentId, CommunityOwnedDate, ClosedDate
FROM posts_no_part
LIMIT 1000000
```

Вычисляя сумму ответов за год с `FINAL`:

```sql
SELECT toYear(CreationDate) AS year, sum(AnswerCount) AS total_answers
FROM posts_no_part
FINAL
GROUP BY year
ORDER BY year ASC

┌─year─┬─total_answers─┐
│ 2008 │    	371480 │
…
│ 2024 │    	127765 │
└──────┴───────────────┘

17 rows in set. Elapsed: 2.338 sec. Processed 122.94 million rows, 1.84 GB (52.57 million rows/s., 788.58 MB/s.)
Пиковое использование памяти: 2.09 GiB.
```

Повторяя те же самые шаги для таблицы, которая делится по годам, и повторяя вышеуказанный запрос с `do_not_merge_across_partitions_select_final=1`.

```sql
CREATE TABLE stackoverflow.posts_with_part
(
	`Version` UInt32,
	`Deleted` UInt8,
	`Id` Int32 CODEC(Delta(4), ZSTD(1)),
	...
)
ENGINE = ReplacingMergeTree
PARTITION BY toYear(CreationDate)
ORDER BY (PostTypeId, toDate(CreationDate), CreationDate, Id)

// наполнение и обновление опущено

SELECT toYear(CreationDate) AS year, sum(AnswerCount) AS total_answers
FROM posts_with_part
FINAL
GROUP BY year
ORDER BY year ASC

┌─year─┬─total_answers─┐
│ 2008 │    	387832 │
│ 2009 │   	1165506 │
│ 2010 │   	1755437 │
...
│ 2023 │    	787032 │
│ 2024 │    	127765 │
└──────┴───────────────┘

17 rows in set. Elapsed: 0.994 sec. Processed 64.65 million rows, 983.64 MB (65.02 million rows/s., 989.23 MB/s.)
```

Как показано, партиционирование значительно улучшило производительность запроса в этом случае за счет того, что процесс дедупликации происходит на уровне партиции параллельно.

## Соображения относительно поведения слияния {#merge-behavior-considerations}

Механизм выбора слияния ClickHouse выходит за простое объединение частей. Ниже мы рассматриваем это поведение в контексте ReplacingMergeTree, включая параметры конфигурации для включения более агрессивного слияния старых данных и соображения для больших частей.

### Логика выбора слияния {#merge-selection-logic}

Хотя слияние направлено на минимизацию количества частей, оно также балансирует эту цель с затратами на увеличение записи. Следовательно, некоторые диапазоны частей исключаются из слияния, если это приведет к чрезмерному увеличению записи, основываясь на внутренних расчетах. Это поведение помогает предотвратить ненужное использование ресурсов и продлить срок службы компонентов хранения.

### Поведение слияния для больших частей {#merging-behavior-on-large-parts}

Движок ReplacingMergeTree в ClickHouse оптимизирован для управления дублирующимися строками, сливая части данных и сохраняя только последнюю версию каждой строки на основе заданного уникального ключа. Однако, когда объединенная часть достигает порога max_bytes_to_merge_at_max_space_in_pool, она больше не будет выбрана для дальнейшего слияния, даже если min_age_to_force_merge_seconds установлен. В результате автоматические слияния больше не могут гарантировать удаление дубликатов, которые могут накапливаться при продолжающейся вставке данных.

Чтобы справиться с этим, пользователи могут вызывать OPTIMIZE FINAL для ручного слияния частей и удаления дубликатов. В отличие от автоматических слияний, OPTIMIZE FINAL игнорирует порог max_bytes_to_merge_at_max_space_in_pool, сливая части исключительно на основе доступных ресурсов, в частности, дискового пространства, пока в каждой партиции не останется одна часть. Однако этот подход может требовать значительных затрат оперативной памяти на больших таблицах и может требовать повторного выполнения по мере добавления новых данных.

Для более устойчивого решения, которое сохраняет производительность, рекомендуется партиционировать таблицу. Это может помочь предотвратить достижение частями данных максимального размера слияния и уменьшить необходимость в постоянных ручных оптимизациях.

### Партиционирование и слияние между партициями {#partitioning-and-merging-across-partitions}

Как обсуждалось в разделе Использование партиций с ReplacingMergeTree, мы рекомендуем партиционировать таблицы в качестве лучшей практики. Партиционирование изолирует данные для более эффективных слияний и предотвращает слияние между партициями, особенно во время выполнения запроса. Это поведение улучшено в версиях с 23.12 и далее: если ключ партиционирования является префиксом ключа сортировки, то слияние между партициями не выполняется во время выполнения запроса, что приводит к более высокой производительности запросов.

### Настройка слияний для лучшей производительности запросов {#tuning-merges-for-better-query-performance}

По умолчанию min_age_to_force_merge_seconds и min_age_to_force_merge_on_partition_only установлены в 0 и false, соответственно, отключая эти функции. В этой конфигурации ClickHouse будет применять стандартное поведение слияния без принудительного слияния на основе возраста партиции.

Если задано значение для min_age_to_force_merge_seconds, ClickHouse будет игнорировать обычные эвристики слияния для частей, старше указанного периода. Хотя это, как правило, эффективно только в случае, если цель состоит в том, чтобы минимизировать общее количество частей, это может улучшить производительность запросов в ReplacingMergeTree, сократив количество частей, требующих слияния во время выполнения запроса.

Это поведение можно дополнительно настроить, установив min_age_to_force_merge_on_partition_only=true, что требует, чтобы все части в партиции были старше min_age_to_force_merge_seconds для агрессивного слияния. Эта конфигурация позволяет старым партициям сливаться в одну часть со временем, что консолидирует данные и поддерживает производительность запросов.

### Рекомендуемые настройки {#recommended-settings}

:::warning
Настройка поведения слияния - это сложная операция. Мы рекомендуем проконсультироваться с поддержкой ClickHouse перед включением этих настроек в производственных нагрузках.
:::

В большинстве случаев рекомендуется установить min_age_to_force_merge_seconds на низкое значение, значительно меньшее периода партиционирования. Это минимизирует количество частей и предотвращает ненужное слияние во время выполнения запроса с оператором FINAL.

Например, рассмотрим месячную партицию, которая уже была объединена в одну часть. Если небольшая, случайная вставка создает новую часть в этой партиции, производительность запроса может пострадать, поскольку ClickHouse должен прочитать несколько частей, пока слияние не завершится. Установка min_age_to_force_merge_seconds может гарантировать, что эти части будут объединены агрессивно, предотвращая ухудшение производительности запросов.
