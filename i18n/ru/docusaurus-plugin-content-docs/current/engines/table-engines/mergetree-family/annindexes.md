---
description: 'Документация по точному и приближённому векторному поиску'
keywords: ['vector similarity search', 'ann', 'knn', 'hnsw', 'indices', 'index', 'nearest neighbor', 'vector search']
sidebar_label: 'Точный и приближённый векторный поиск'
slug: /engines/table-engines/mergetree-family/annindexes
title: 'Точный и приближённый векторный поиск'
doc_type: 'guide'
---

import ExperimentalBadge from '@theme/badges/ExperimentalBadge';


# Точный и приближённый векторный поиск

Задача поиска N ближайших точек в многомерном (векторном) пространстве для заданной точки известна как [поиск ближайших соседей](https://en.wikipedia.org/wiki/Nearest_neighbor_search) или, кратко, векторный поиск.
Существует два основных подхода к решению задачи векторного поиска:

* Точный векторный поиск вычисляет расстояние между заданной точкой и всеми точками в векторном пространстве. Это обеспечивает максимально возможную точность, то есть возвращаемые точки гарантированно являются действительно ближайшими соседями. Поскольку векторное пространство исследуется исчерпывающим образом, точный векторный поиск может быть слишком медленным для использования в реальных условиях.
* Приближённый векторный поиск относится к группе методов (например, специальных структур данных, таких как графы и случайные леса), которые вычисляют результаты значительно быстрее, чем точный векторный поиск. Точность результата, как правило, «достаточно хороша» для практического использования. Многие приближённые методы предоставляют параметры для настройки баланса между точностью результата и временем поиска.

Векторный поиск (точный или приближённый) можно записать на языке SQL следующим образом:

```sql
WITH [...] AS reference_vector
SELECT [...]
FROM table
WHERE [...] -- оператор WHERE необязателен
ORDER BY <DistanceFunction>(vectors, reference_vector)
LIMIT <N>
```

Точки в векторном пространстве хранятся в столбце `vectors` типа массива, например [Array(Float64)](../../../sql-reference/data-types/array.md), [Array(Float32)](../../../sql-reference/data-types/array.md) или [Array(BFloat16)](../../../sql-reference/data-types/array.md).
Опорный вектор задаётся как константный массив и передаётся в виде общего табличного выражения.
`&lt;DistanceFunction&gt;` вычисляет расстояние между опорной точкой и всеми сохранёнными точками.
Для этого может быть использована любая доступная [функция расстояния](/sql-reference/functions/distance-functions).
`&lt;N&gt;` указывает, сколько соседей следует вернуть.


## Точный векторный поиск {#exact-nearest-neighbor-search}

Точный векторный поиск можно выполнить, используя приведённый выше запрос SELECT без изменений.
Время выполнения таких запросов обычно пропорционально количеству хранимых векторов и их размерности, то есть количеству элементов массива.
Кроме того, поскольку ClickHouse выполняет полный перебор всех векторов, время выполнения также зависит от количества потоков запроса (см. настройку [max_threads](../../../operations/settings/settings.md#max_threads)).

### Пример {#exact-nearest-neighbor-search-example}

```sql
CREATE TABLE tab(id Int32, vec Array(Float32)) ENGINE = MergeTree ORDER BY id;

INSERT INTO tab VALUES (0, [1.0, 0.0]), (1, [1.1, 0.0]), (2, [1.2, 0.0]), (3, [1.3, 0.0]), (4, [1.4, 0.0]), (5, [1.5, 0.0]), (6, [0.0, 2.0]), (7, [0.0, 2.1]), (8, [0.0, 2.2]), (9, [0.0, 2.3]), (10, [0.0, 2.4]), (11, [0.0, 2.5]);

WITH [0., 2.] AS reference_vec
SELECT id, vec
FROM tab
ORDER BY L2Distance(vec, reference_vec) ASC
LIMIT 3;
```

возвращает

```result
   ┌─id─┬─vec─────┐
1. │  6 │ [0,2]   │
2. │  7 │ [0,2.1] │
3. │  8 │ [0,2.2] │
   └────┴─────────┘
```


## Приближенный векторный поиск {#approximate-nearest-neighbor-search}

### Индексы векторного сходства {#vector-similarity-index}

ClickHouse предоставляет специальный индекс векторного сходства для выполнения приближенного векторного поиска.

:::note
Индексы векторного сходства доступны в ClickHouse версии 25.8 и выше.
Если вы столкнетесь с проблемами, пожалуйста, создайте issue в [репозитории ClickHouse](https://github.com/clickhouse/clickhouse/issues).
:::

#### Создание индекса векторного сходства {#creating-a-vector-similarity-index}

Индекс векторного сходства можно создать для новой таблицы следующим образом:

```sql
CREATE TABLE table
(
  [...],
  vectors Array(Float*),
  INDEX <index_name> vectors TYPE vector_similarity(<type>, <distance_function>, <dimensions>) [GRANULARITY <N>]
)
ENGINE = MergeTree
ORDER BY [...]
```

Альтернативный способ — добавить индекс векторного сходства к существующей таблице:

```sql
ALTER TABLE table ADD INDEX <index_name> vectors TYPE vector_similarity(<type>, <distance_function>, <dimensions>) [GRANULARITY <N>];
```

Индексы векторного сходства являются специальным видом индексов с пропуском данных (см. [здесь](mergetree.md#table_engine-mergetree-data_skipping-indexes) и [здесь](../../../optimize/skipping-indexes)).
Соответственно, приведенная выше инструкция `ALTER TABLE` приводит к построению индекса только для новых данных, которые будут вставлены в таблицу в будущем.
Чтобы построить индекс также для существующих данных, необходимо его материализовать:

```sql
ALTER TABLE table MATERIALIZE INDEX <index_name> SETTINGS mutations_sync = 2;
```

Функция `<distance_function>` должна быть одной из следующих:

- `L2Distance` — [евклидово расстояние](https://en.wikipedia.org/wiki/Euclidean_distance), представляющее длину отрезка между двумя точками в евклидовом пространстве, или
- `cosineDistance` — [косинусное расстояние](https://en.wikipedia.org/wiki/Cosine_similarity#Cosine_distance), представляющее угол между двумя ненулевыми векторами.

Для нормализованных данных `L2Distance` обычно является лучшим выбором, в противном случае рекомендуется использовать `cosineDistance` для компенсации масштаба.

Параметр `<dimensions>` указывает размерность массива (количество элементов) в базовом столбце.
Если ClickHouse обнаружит массив с другой размерностью во время создания индекса, индекс будет отброшен и возвращена ошибка.

Необязательный параметр GRANULARITY `<N>` определяет размер гранул индекса (см. [здесь](../../../optimize/skipping-indexes)).
Значение по умолчанию в 100 миллионов должно хорошо работать для большинства случаев использования, но его также можно настроить.
Мы рекомендуем настройку только для опытных пользователей, которые понимают последствия своих действий (см. [ниже](#differences-to-regular-skipping-indexes)).

Индексы векторного сходства являются универсальными в том смысле, что они могут использовать различные методы приближенного поиска.
Фактически используемый метод указывается параметром `<type>`.
На данный момент единственным доступным методом является HNSW ([научная статья](https://arxiv.org/abs/1603.09320)) — популярная и современная техника приближенного векторного поиска, основанная на иерархических графах близости.
При использовании HNSW в качестве типа пользователи могут дополнительно указать специфичные для HNSW параметры:

```sql
CREATE TABLE table
(
  [...],
  vectors Array(Float*),
  INDEX index_name vectors TYPE vector_similarity('hnsw', <distance_function>, <dimensions>[, <quantization>, <hnsw_max_connections_per_layer>, <hnsw_candidate_list_size_for_construction>]) [GRANULARITY N]
)
ENGINE = MergeTree
ORDER BY [...]
```

Доступны следующие специфичные для HNSW параметры:

- `<quantization>` управляет квантованием векторов в графе близости. Возможные значения: `f64`, `f32`, `f16`, `bf16`, `i8` или `b1`. Значение по умолчанию — `bf16`. Обратите внимание, что этот параметр не влияет на представление векторов в базовом столбце.
- `<hnsw_max_connections_per_layer>` управляет количеством соседей на узел графа, также известным как гиперпараметр HNSW `M`. Значение по умолчанию — `32`. Значение `0` означает использование значения по умолчанию.
- `<hnsw_candidate_list_size_for_construction>` управляет размером динамического списка кандидатов во время построения графа HNSW, также известным как гиперпараметр HNSW `ef_construction`. Значение по умолчанию — `128`. Значение `0` означает использование значения по умолчанию.

Значения по умолчанию всех специфичных для HNSW параметров хорошо работают в большинстве случаев использования.
Поэтому мы не рекомендуем изменять специфичные для HNSW параметры.


Применяются следующие ограничения:

- Индексы векторного сходства могут быть построены только на столбцах типа [Array(Float32)](../../../sql-reference/data-types/array.md), [Array(Float64)](../../../sql-reference/data-types/array.md) или [Array(BFloat16)](../../../sql-reference/data-types/array.md). Массивы nullable и low-cardinality значений с плавающей точкой, такие как `Array(Nullable(Float32))` и `Array(LowCardinality(Float32))`, не допускаются.
- Индексы векторного сходства должны быть построены на одиночных столбцах.
- Индексы векторного сходства могут быть построены на вычисляемых выражениях (например, `INDEX index_name arraySort(vectors) TYPE vector_similarity([...])`), но такие индексы не могут быть использованы для приближённого поиска ближайших соседей.
- Индексы векторного сходства требуют, чтобы все массивы в базовом столбце содержали `<dimension>` элементов — это проверяется при создании индекса. Чтобы обнаружить нарушения этого требования как можно раньше, пользователи могут добавить [ограничение](/sql-reference/statements/create/table.md#constraints) для векторного столбца, например: `CONSTRAINT same_length CHECK length(vectors) = 256`.
- Аналогично, значения массивов в базовом столбце не должны быть пустыми (`[]`) или иметь значение по умолчанию (также `[]`).

**Оценка потребления хранилища и памяти**

Вектор, сгенерированный для использования с типичной моделью искусственного интеллекта (например, большой языковой моделью, [LLM](https://en.wikipedia.org/wiki/Large_language_model)), состоит из сотен или тысяч значений с плавающей точкой.
Таким образом, одно векторное значение может потреблять несколько килобайт памяти.
Пользователи, желающие оценить объём хранилища, необходимый для базового векторного столбца в таблице, а также оперативную память, необходимую для индекса векторного сходства, могут использовать следующие две формулы:

Потребление хранилища векторным столбцом в таблице (несжатым):

```text
Потребление хранилища = Количество векторов * Размерность * Размер типа данных столбца
```

Пример для [набора данных dbpedia](https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M):

```text
Потребление хранилища = 1 миллион * 1536 * 4 (для Float32) = 6,1 ГБ
```

Индекс векторного сходства должен быть полностью загружен с диска в оперативную память для выполнения поиска.
Аналогично, векторный индекс также полностью строится в памяти, а затем сохраняется на диск.

Потребление памяти, необходимое для загрузки векторного индекса:

```text
Память для векторов в индексе (mv) = Количество векторов * Размерность * Размер квантованного типа данных
Память для графа в памяти (mg) = Количество векторов * hnsw_max_connections_per_layer * Байт_на_идентификатор_узла (= 4) * Коэффициент_повторения_узлов_слоя (= 2)

Потребление памяти: mv + mg
```

Пример для [набора данных dbpedia](https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M):

```text
Память для векторов в индексе (mv) = 1 миллион * 1536 * 2 (для BFloat16) = 3072 МБ
Память для графа в памяти (mg) = 1 миллион * 64 * 2 * 4 = 512 МБ

Потребление памяти = 3072 + 512 = 3584 МБ
```

Приведённые выше формулы не учитывают дополнительную память, необходимую индексам векторного сходства для выделения структур данных времени выполнения, таких как предварительно выделенные буферы и кэши.

#### Использование индекса векторного сходства {#using-a-vector-similarity-index}

:::note
Для использования индексов векторного сходства настройка [compatibility](../../../operations/settings/settings.md) должна быть `''` (значение по умолчанию), `'25.1'` или новее.
:::

Индексы векторного сходства поддерживают SELECT-запросы следующего вида:

```sql
WITH [...] AS reference_vector
SELECT [...]
FROM table
WHERE [...] -- секция WHERE необязательна
ORDER BY <ФункцияРасстояния>(vectors, reference_vector)
LIMIT <N>
```

Оптимизатор запросов ClickHouse пытается сопоставить приведённый выше шаблон запроса и использовать доступные индексы векторного сходства.
Запрос может использовать индекс векторного сходства только в том случае, если функция расстояния в SELECT-запросе совпадает с функцией расстояния в определении индекса.

Опытные пользователи могут указать пользовательское значение для настройки [hnsw_candidate_list_size_for_search](../../../operations/settings/settings.md#hnsw_candidate_list_size_for_search) (также известной как гиперпараметр HNSW «ef_search») для настройки размера списка кандидатов во время поиска (например, `SELECT [...] SETTINGS hnsw_candidate_list_size_for_search = <значение>`).
Значение настройки по умолчанию 256 хорошо работает в большинстве случаев использования.
Более высокие значения настройки означают лучшую точность за счёт снижения производительности.


Если запрос может использовать индекс по векторному сходству, ClickHouse проверяет, что значение LIMIT `<N>`, указанное в запросах SELECT, находится в разумных пределах.
Более точно, будет возвращена ошибка, если `<N>` больше значения настройки [max&#95;limit&#95;for&#95;vector&#95;search&#95;queries](../../../operations/settings/settings.md#max_limit_for_vector_search_queries), значение по умолчанию для которой — 100.
Слишком большие значения LIMIT могут замедлить поиск и обычно указывают на некорректное использование.

Чтобы проверить, использует ли запрос SELECT индекс по векторному сходству, вы можете добавить к запросу префикс `EXPLAIN indexes = 1`.

В качестве примера, запрос

```sql
EXPLAIN indexes = 1
WITH [0.462, 0.084, ..., -0.110] AS reference_vec
SELECT id, vec
FROM tab
ORDER BY L2Distance(vec, reference_vec) ASC
LIMIT 10;
```

может возвращать

```result
    ┌─explain─────────────────────────────────────────────────────────────────────────────────────────┐
 1. │ Expression (Проекция имён)                                                                      │
 2. │   Limit (предварительный LIMIT (без OFFSET))                                                    │
 3. │     Sorting (Сортировка для ORDER BY)                                                              │
 4. │       Expression ((Перед ORDER BY + (Проекция + Преобразование имён столбцов в идентификаторы))) │
 5. │         ReadFromMergeTree (default.tab)                                                         │
 6. │         Индексы:                                                                                │
 7. │           PrimaryKey                                                                            │
 8. │             Условие: true                                                                     │
 9. │             Части: 1/1                                                                          │
10. │             Гранулы: 575/575                                                                   │
11. │           Skip                                                                                  │
12. │             Имя: idx                                                                           │
13. │             Описание: vector_similarity GRANULARITY 100000000                                │
14. │             Части: 1/1                                                                          │
15. │             Гранулы: 10/575                                                                    │
    └─────────────────────────────────────────────────────────────────────────────────────────────────┘
```

В этом примере 1 миллион векторов из [набора данных dbpedia](https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M), каждый размерностью 1536, хранятся в 575 гранулах, т.е. по 1,7 тыс. строк на гранулу.
В запросе запрашиваются 10 соседей, и индекс векторного сходства находит этих 10 соседей в 10 отдельных гранулах.
Эти 10 гранул будут прочитаны во время выполнения запроса.

Индексы векторного сходства используются, если вывод содержит `Skip`, а также имя и тип векторного индекса (в примере — `idx` и `vector_similarity`).
В этом случае индекс векторного сходства отбросил две из четырех гранул, т.е. 50% данных.
Чем больше гранул можно отбросить, тем эффективнее используется индекс.

:::tip
Чтобы принудительно задействовать индекс, вы можете выполнить запрос SELECT с настройкой [force&#95;data&#95;skipping&#95;indexes](../../../operations/settings/settings#force_data_skipping_indices) (укажите имя индекса в качестве значения настройки).
:::

**Постфильтрация и префильтрация**

Пользователи могут дополнительно указать предложение `WHERE` с дополнительными условиями фильтрации для запроса SELECT.
ClickHouse будет вычислять эти условия фильтрации, используя стратегию постфильтрации или префильтрации.
Кратко, обе стратегии определяют порядок, в котором оцениваются фильтры:

* Постфильтрация означает, что сначала вычисляется индекс векторного сходства, а затем ClickHouse вычисляет дополнительный(ые) фильтр(ы), указанные в предложении `WHERE`.
* Префильтрация означает, что порядок вычисления фильтров обратный.

У стратегий разные компромиссы:

* Общая проблема постфильтрации заключается в том, что она может вернуть меньше строк, чем указано в предложении `LIMIT <N>`. Такая ситуация возникает, когда одна или несколько строк результата, возвращенных индексом векторного сходства, не удовлетворяют дополнительным фильтрам.
* Префильтрация в целом является нерешенной задачей. Некоторые специализированные векторные базы данных предоставляют алгоритмы префильтрации, но большинство реляционных СУБД (включая ClickHouse) будут возвращаться к точному поиску соседей, т.е. переборному сканированию без индекса.

Используемая стратегия зависит от условия фильтрации.

*Дополнительные фильтры являются частью ключа партиционирования*

Если дополнительное условие фильтрации является частью ключа партиционирования, то ClickHouse применит отсечение партиций (partition pruning).
В качестве примера рассмотрим таблицу, разбитую на партиции по диапазону значений столбца `year`, и выполним следующий запрос:

```sql
WITH [0., 2.] AS reference_vec
SELECT id, vec
FROM tab
WHERE year = 2025
ORDER BY L2Distance(vec, reference_vec) ASC
LIMIT 3;
```

ClickHouse отбросит все разделы, кроме раздела за 2025 год.

*Дополнительные фильтры не могут быть выполнены по индексам*

Если дополнительные условия фильтрации не могут быть выполнены по индексам (индекс по первичному ключу, пропускающий индекс), ClickHouse выполнит пост-фильтрацию результатов.


*Дополнительные фильтры могут вычисляться с использованием индекса первичного ключа*

Если дополнительные фильтрующие условия могут быть вычислены с использованием [первичного ключа](mergetree.md#primary-key) (то есть образуют префикс первичного ключа) и

* фильтрующее условие исключает как минимум одну строку в пределах части, ClickHouse использует предварительную фильтрацию для «выживших» диапазонов внутри части,
* фильтрующее условие не исключает ни одной строки в пределах части, ClickHouse выполнит постфильтрацию для этой части.

На практике второй случай встречается довольно редко.

*Дополнительные фильтры могут вычисляться с использованием пропускающего индекса*

Если дополнительные фильтрующие условия могут быть вычислены с использованием [пропускающих индексов](mergetree.md#table_engine-mergetree-data_skipping-indexes) (minmax-индекс, set-индекс и т.д.), ClickHouse выполняет постфильтрацию.
В таких случаях векторный индекс сходства вычисляется первым, поскольку ожидается, что он отфильтрует наибольшее количество строк по сравнению с другими пропускающими индексами.

Для более тонкого управления постфильтрацией и предварительной фильтрацией можно использовать два параметра:

Параметр [vector&#95;search&#95;filter&#95;strategy](../../../operations/settings/settings#vector_search_filter_strategy) (по умолчанию: `auto`, который реализует описанную выше эвристику) может быть установлен в значение `prefilter`.
Это полезно для принудительной предварительной фильтрации в случаях, когда дополнительные фильтрующие условия являются крайне селективными.
В качестве примера, следующий запрос может выиграть от предварительной фильтрации:

```sql
SELECT bookid, author, title
FROM books
WHERE price < 2.00
ORDER BY cosineDistance(book_vector, getEmbedding('Книги о древних азиатских империях'))
LIMIT 10
```

Предположим, что только очень небольшое число книг стоит меньше 2 долларов, тогда при постфильтрации запрос может вернуть ноль строк, потому что все 10 лучших совпадений, возвращённых векторным индексом, могут иметь цену выше 2 долларов.
Принудительно включив предфильтрацию (добавьте `SETTINGS vector_search_filter_strategy = 'prefilter'` к запросу), ClickHouse сначала находит все книги с ценой менее 2 долларов, а затем выполняет векторный поиск «полным перебором» по найденным книгам.

В качестве альтернативного подхода для решения описанной выше проблемы можно задать параметр [vector&#95;search&#95;index&#95;fetch&#95;multiplier](../../../operations/settings/settings#vector_search_index_fetch_multiplier) (по умолчанию: `1.0`, максимум: `1000.0`) в значение больше `1.0` (например, `2.0`).
Количество ближайших соседей, выбираемых из векторного индекса, умножается на значение этой настройки, после чего к этим строкам применяется дополнительный фильтр, чтобы вернуть строки в количестве, указанном в LIMIT.
Например, мы можем выполнить запрос ещё раз, но с множителем `3.0`:

```sql
SELECT bookid, author, title
FROM books
WHERE price < 2.00
ORDER BY cosineDistance(book_vector, getEmbedding('Books on ancient Asian empires'))
LIMIT 10
SETTING vector_search_index_fetch_multiplier = 3.0;
```

ClickHouse выберет 3.0 x 10 = 30 ближайших соседей из векторного индекса в каждой партиции и затем применит дополнительные фильтры.
Будут возвращены только десять ближайших соседей.
Отметим, что настройка `vector_search_index_fetch_multiplier` может смягчить проблему, но в крайних случаях (при очень селективном условии WHERE) все еще возможно, что будет возвращено меньше, чем N запрошенных строк.

**Пересчет оценок (rescoring)**

Skip-индексы в ClickHouse, как правило, фильтруют на уровне гранул, т.е. поиск в skip-индексе (внутренне) возвращает список потенциально подходящих гранул, что уменьшает объем читаемых данных при последующем сканировании.
Это хорошо работает для skip-индексов в целом, но в случае индексов векторного сходства создает «несоответствие гранулярности».
Более детально: индекс векторного сходства определяет номера строк N наиболее похожих векторов для заданного опорного вектора, но затем ему необходимо сопоставить эти номера строк с номерами гранул.
ClickHouse затем загружает эти гранулы с диска и повторяет вычисление расстояния для всех векторов в этих гранулах.
Этот шаг называется пересчетом оценок (rescoring), и хотя теоретически он может повысить точность — помните, индекс векторного сходства возвращает лишь *приближенный* результат, — очевидно, что он не оптимален с точки зрения производительности.

Поэтому ClickHouse предоставляет оптимизацию, которая отключает пересчет оценок и возвращает наиболее похожие векторы и их расстояния непосредственно из индекса.
Оптимизация включена по умолчанию, см. настройку [vector&#95;search&#95;with&#95;rescoring](../../../operations/settings/settings#vector_search_with_rescoring).
В общих чертах она работает так: ClickHouse делает наиболее похожие векторы и их расстояния доступными как виртуальный столбец `_distances`.
Чтобы увидеть это, выполните запрос векторного поиска с `EXPLAIN header = 1`:


```sql
EXPLAIN header = 1
WITH [0., 2.] AS reference_vec
SELECT id
FROM tab
ORDER BY L2Distance(vec, reference_vec) ASC
LIMIT 3
SETTINGS vector_search_with_rescoring = 0
```

```result
Query id: a2a9d0c8-a525-45c1-96ca-c5a11fa66f47

    ┌─explain─────────────────────────────────────────────────────────────────────────────────────────────────┐
 1. │ Expression (Project names)                                                                              │
 2. │ Header: id Int32                                                                                        │
 3. │   Limit (preliminary LIMIT (without OFFSET))                                                            │
 4. │   Header: L2Distance(__table1.vec, _CAST([0., 2.]_Array(Float64), 'Array(Float64)'_String)) Float64     │
 5. │           __table1.id Int32                                                                             │
 6. │     Sorting (Sorting for ORDER BY)                                                                      │
 7. │     Header: L2Distance(__table1.vec, _CAST([0., 2.]_Array(Float64), 'Array(Float64)'_String)) Float64   │
 8. │             __table1.id Int32                                                                           │
 9. │       Expression ((Before ORDER BY + (Projection + Change column names to column identifiers)))         │
10. │       Header: L2Distance(__table1.vec, _CAST([0., 2.]_Array(Float64), 'Array(Float64)'_String)) Float64 │
11. │               __table1.id Int32                                                                         │
12. │         ReadFromMergeTree (default.tab)                                                                 │
13. │         Header: id Int32                                                                                │
14. │                 _distance Float32                                                                       │
    └─────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

:::note
Запрос, выполняемый без повторного скоринга (`vector_search_with_rescoring = 0`) и с включёнными параллельными репликами, может переключиться на повторный скоринг.
:::

#### Настройка производительности {#performance-tuning}

**Настройка сжатия**

Практически во всех сценариях использования векторы в базовом столбце являются плотными и плохо сжимаются.
В результате [сжатие](/sql-reference/statements/create/table.md#column_compression_codec) замедляет операции вставки и чтения данных в векторный столбец и из него.
Поэтому рекомендуется отключить сжатие.
Для этого укажите `CODEC(NONE)` для векторного столбца следующим образом:

```sql
CREATE TABLE tab(id Int32, vec Array(Float32) CODEC(NONE), INDEX idx vec TYPE vector_similarity('hnsw', 'L2Distance', 2)) ENGINE = MergeTree ORDER BY id;
```

**Настройка создания индекса**

Жизненный цикл индексов векторного сходства связан с жизненным циклом кусков данных.
Другими словами, при создании нового куска с определённым индексом векторного сходства индекс также создаётся.
Обычно это происходит при [вставке данных](https://clickhouse.com/docs/guides/inserting-data) или во время [слияний](https://clickhouse.com/docs/merges).
К сожалению, HNSW характеризуется длительным временем создания индекса, что может существенно замедлить операции вставки и слияния данных.
Индексы векторного сходства в идеале следует использовать только в том случае, если данные неизменяемы или редко изменяются.

Для ускорения создания индекса можно использовать следующие методы:

Во-первых, создание индекса можно распараллелить.
Максимальное количество потоков для создания индекса настраивается с помощью серверного параметра [max_build_vector_similarity_index_thread_pool_size](/operations/server-configuration-parameters/settings#max_build_vector_similarity_index_thread_pool_size).
Для оптимальной производительности значение параметра следует установить равным количеству ядер процессора.

Во-вторых, для ускорения операций INSERT можно отключить создание индексов пропуска для вновь вставленных кусков с помощью параметра сеанса [materialize_skip_indexes_on_insert](../../../operations/settings/settings.md#materialize_skip_indexes_on_insert).
Запросы SELECT к таким кускам будут использовать точный поиск.
Поскольку вставленные куски обычно малы по сравнению с общим размером таблицы, ожидается, что влияние на производительность будет незначительным.

В-третьих, для ускорения слияний можно отключить создание индексов пропуска для объединённых кусков с помощью параметра сеанса [materialize_skip_indexes_on_merge](../../../operations/settings/merge-tree-settings.md#materialize_skip_indexes_on_merge).
Это, в сочетании с оператором [ALTER TABLE \[...\] MATERIALIZE INDEX \[...\]](../../../sql-reference/statements/alter/skipping-index.md#materialize-index), обеспечивает явный контроль над жизненным циклом индексов векторного сходства.
Например, создание индекса можно отложить до завершения загрузки всех данных или до периода низкой нагрузки на систему, например, до выходных.

**Настройка использования индекса**


Запросы SELECT должны загружать индексы векторного сходства в оперативную память, чтобы использовать их.
Чтобы избежать повторной загрузки одного и того же индекса векторного сходства в оперативную память, ClickHouse предоставляет специальный кэш в памяти для таких индексов.
Чем больше этот кэш, тем меньше будет лишних загрузок.
Максимальный размер кэша можно настроить с помощью серверного параметра [vector&#95;similarity&#95;index&#95;cache&#95;size](../../../operations/server-configuration-parameters/settings.md#vector_similarity_index_cache_size).
По умолчанию кэш может увеличиваться до 5 ГБ.

:::note
Кэш индекса векторного сходства хранит гранулы векторного индекса.
Если отдельные гранулы векторного индекса больше размера кэша, они не будут кэшироваться.
Поэтому убедитесь, что вы рассчитали размер векторного индекса (на основе формулы из раздела «Оценка объема хранения и потребления памяти» или [system.data&#95;skipping&#95;indices](../../../operations/system-tables/data_skipping_indices)) и соответствующим образом подобрали размер кэша.
:::

Текущий размер кэша индекса векторного сходства отображается в [system.metrics](../../../operations/system-tables/metrics.md):

```sql
SELECT metric, value
FROM system.metrics
WHERE metric = 'VectorSimilarityIndexCacheBytes'
```

Информацию о попаданиях в кэш и промахах кэша для запроса по его идентификатору можно получить из [system.query&#95;log](../../../operations/system-tables/query_log.md):

```sql
SYSTEM FLUSH LOGS query_log;

SELECT ProfileEvents['VectorSimilarityIndexCacheHits'], ProfileEvents['VectorSimilarityIndexCacheMisses']
FROM system.query_log
WHERE type = 'QueryFinish' AND query_id = '<...>'
ORDER BY event_time_microseconds;
```

Для продакшн-сценариев мы рекомендуем выбирать размер кэша таким образом, чтобы все векторные индексы постоянно находились в памяти.

**Настройка квантования**

[Квантование](https://huggingface.co/blog/embedding-quantization) — это техника уменьшения объёма памяти, занимаемой векторами, и вычислительных затрат на построение и обход векторных индексов.
Векторные индексы ClickHouse поддерживают следующие варианты квантования:

| Quantization   | Name                         | Storage per dimension |
| -------------- | ---------------------------- | --------------------- |
| f32            | Single precision             | 4 bytes               |
| f16            | Half precision               | 2 bytes               |
| bf16 (default) | Half precision (brain float) | 2 bytes               |
| i8             | Quarter precision            | 1 byte                |
| b1             | Binary                       | 1 bit                 |

Квантование снижает точность векторного поиска по сравнению с поиском по исходным значениям с плавающей запятой одинарной точности (`f32`).
Однако на большинстве наборов данных квантование brain float с половинной точностью (`bf16`) приводит к пренебрежимо малой потере точности, поэтому индексы векторного сходства по умолчанию используют именно эту технику квантования.
Квантование с четвертью точности (`i8`) и бинарное (`b1`) приводит к заметной потере точности при векторном поиске.
Мы рекомендуем эти два типа квантования только в том случае, если размер индекса векторного сходства существенно превышает доступный объём DRAM.
В этом случае мы также рекомендуем включить пересчёт результатов ([vector&#95;search&#95;index&#95;fetch&#95;multiplier](../../../operations/settings/settings#vector_search_index_fetch_multiplier), [vector&#95;search&#95;with&#95;rescoring](../../../operations/settings/settings#vector_search_with_rescoring)) для повышения точности.
Бинарное квантование рекомендуется только для 1) нормализованных эмбеддингов (т.е. длина вектора = 1, модели OpenAI обычно нормализованы) и 2) если в качестве функции расстояния используется косинусное расстояние.
Бинарное квантование внутренне использует расстояние Хэмминга для построения и поиска по графу близости.
На этапе пересчёта используются исходные векторы с полной точностью, хранящиеся в таблице, для определения ближайших соседей по косинусному расстоянию.

**Настройка передачи данных**

Опорный вектор в запросе векторного поиска задаётся пользователем и обычно получается путём вызова большой языковой модели (Large Language Model, LLM).
Типичный фрагмент Python-кода, выполняющий векторный поиск в ClickHouse, может выглядеть так:

```python
search_v = openai_client.embeddings.create(input = "[Хорошие книги]", model='text-embedding-3-large', dimensions=1536).data[0].embedding

params = {'search_v': search_v}
result = chclient.query(
   "SELECT id FROM items
    ORDER BY cosineDistance(vector, %(search_v)s)
    LIMIT 10",
    parameters = params)
```


Векторы эмбеддингов (`search_v` в приведённом выше фрагменте) могут иметь очень большую размерность.
Например, OpenAI предоставляет модели, которые генерируют векторы эмбеддингов с 1536 или даже 3072 измерениями.
В приведённом выше коде драйвер ClickHouse для Python заменяет вектор эмбеддинга читаемой строкой и затем отправляет запрос SELECT полностью в виде строки.
Если предположить, что вектор эмбеддинга состоит из 1536 значений с плавающей точкой одинарной точности, отправляемая строка достигает длины 20 КБ.
Это создаёт высокую нагрузку на процессор для токенизации, парсинга и выполнения тысяч преобразований строк в числа с плавающей точкой.
Кроме того, требуется значительное пространство в файле журнала сервера ClickHouse, что также приводит к разрастанию `system.query_log`.

Обратите внимание, что большинство моделей LLM возвращают вектор эмбеддинга в виде списка или массива NumPy из нативных чисел с плавающей точкой.
Поэтому мы рекомендуем приложениям на Python передавать параметр эталонного вектора в бинарной форме, используя следующий стиль:

```python
search_v = openai_client.embeddings.create(input = "[Good Books]", model='text-embedding-3-large', dimensions=1536).data[0].embedding

params = {'$search_v_binary$': np.array(search_v, dtype=np.float32).tobytes()}
result = chclient.query(
   "SELECT id FROM items
    ORDER BY cosineDistance(vector, (SELECT reinterpret($search_v_binary$, 'Array(Float32)')))
    LIMIT 10"
    parameters = params)
```

В этом примере эталонный вектор отправляется как есть в бинарной форме и переинтерпретируется как массив чисел с плавающей точкой на сервере.
Это экономит процессорное время на стороне сервера и предотвращает разрастание журналов сервера и `system.query_log`.

#### Администрирование и мониторинг {#administration}

Размер индексов векторного сходства на диске можно получить из [system.data_skipping_indices](../../../operations/system-tables/data_skipping_indices):

```sql
SELECT database, table, name, formatReadableSize(data_compressed_bytes)
FROM system.data_skipping_indices
WHERE type = 'vector_similarity';
```

Пример вывода:

```result
┌─database─┬─table─┬─name─┬─formatReadab⋯ssed_bytes)─┐
│ default  │ tab   │ idx  │ 348.00 MB                │
└──────────┴───────┴──────┴──────────────────────────┘
```

#### Отличия от обычных индексов пропуска {#differences-to-regular-skipping-indexes}

Как и все обычные [индексы пропуска](/optimize/skipping-indexes), индексы векторного сходства строятся по гранулам, и каждый индексированный блок состоит из `GRANULARITY = [N]` гранул (`[N]` = 1 по умолчанию для обычных индексов пропуска).
Например, если гранулярность первичного индекса таблицы равна 8192 (настройка `index_granularity = 8192`) и `GRANULARITY = 2`, то каждый индексированный блок будет содержать 16384 строки.
Однако структуры данных и алгоритмы для приближённого поиска ближайших соседей по своей природе ориентированы на строки.
Они хранят компактное представление набора строк и также возвращают строки для запросов векторного поиска.
Это приводит к некоторым довольно неинтуитивным различиям в поведении индексов векторного сходства по сравнению с обычными индексами пропуска.

Когда пользователь определяет индекс векторного сходства для столбца, ClickHouse внутренне создаёт «подиндекс» векторного сходства для каждого индексного блока.
Подиндекс является «локальным» в том смысле, что он знает только о строках содержащего его индексного блока.
В предыдущем примере, если предположить, что столбец имеет 65536 строк, мы получаем четыре индексных блока (охватывающих восемь гранул) и подиндекс векторного сходства для каждого индексного блока.
Подиндекс теоретически способен напрямую возвращать строки с N ближайшими точками в пределах своего индексного блока.
Однако, поскольку ClickHouse загружает данные с диска в память с гранулярностью гранул, подиндексы экстраполируют совпадающие строки до гранулярности гранул.
Это отличается от обычных индексов пропуска, которые пропускают данные с гранулярностью индексных блоков.


Параметр `GRANULARITY` определяет, сколько подиндексов векторного сходства будет создано.
Большие значения `GRANULARITY` означают меньшее количество, но более крупные подиндексы векторного сходства, вплоть до того момента, когда столбец (или часть данных столбца) имеет только один подиндекс.
В этом случае подиндекс имеет «глобальное» представление обо всех строках столбца и может напрямую вернуть все гранулы столбца (части) с релевантными строками (таких гранул не более `LIMIT [N]`).
На втором этапе ClickHouse загружает эти гранулы и определяет фактически лучшие строки, выполняя полный перебор для вычисления расстояния по всем строкам гранул.
При малом значении `GRANULARITY` каждый из подиндексов возвращает до `LIMIT N` гранул.
В результате необходимо загрузить и отфильтровать больше гранул.
Обратите внимание, что точность поиска в обоих случаях одинаково высока, различается только производительность обработки.
Обычно рекомендуется использовать большое значение `GRANULARITY` для индексов векторного сходства и переходить к меньшим значениям `GRANULARITY` только в случае проблем, таких как чрезмерное потребление памяти структурами векторного сходства.
Если для индексов векторного сходства не указан параметр `GRANULARITY`, значение по умолчанию составляет 100 миллионов.

#### Пример {#approximate-nearest-neighbor-search-example}

```sql
CREATE TABLE tab(id Int32, vec Array(Float32), INDEX idx vec TYPE vector_similarity('hnsw', 'L2Distance', 2)) ENGINE = MergeTree ORDER BY id;

INSERT INTO tab VALUES (0, [1.0, 0.0]), (1, [1.1, 0.0]), (2, [1.2, 0.0]), (3, [1.3, 0.0]), (4, [1.4, 0.0]), (5, [1.5, 0.0]), (6, [0.0, 2.0]), (7, [0.0, 2.1]), (8, [0.0, 2.2]), (9, [0.0, 2.3]), (10, [0.0, 2.4]), (11, [0.0, 2.5]);

WITH [0., 2.] AS reference_vec
SELECT id, vec
FROM tab
ORDER BY L2Distance(vec, reference_vec) ASC
LIMIT 3;
```

возвращает

```result
   ┌─id─┬─vec─────┐
1. │  6 │ [0,2]   │
2. │  7 │ [0,2.1] │
3. │  8 │ [0,2.2] │
   └────┴─────────┘
```

Дополнительные примеры наборов данных, использующих приближенный векторный поиск:

- [LAION-400M](../../../getting-started/example-datasets/laion-400m-dataset)
- [LAION-5B](../../../getting-started/example-datasets/laion-5b-dataset)
- [dbpedia](../../../getting-started/example-datasets/dbpedia-dataset)
- [hackernews](../../../getting-started/example-datasets/hackernews-vector-search-dataset)

### Квантованный бит (QBit) {#approximate-nearest-neighbor-search-qbit}

<ExperimentalBadge />

Один из распространенных подходов к ускорению точного векторного поиска — использование [типа данных с плавающей точкой](../../../sql-reference/data-types/float.md) меньшей точности.
Например, если векторы хранятся как `Array(BFloat16)` вместо `Array(Float32)`, размер данных уменьшается вдвое, и ожидается пропорциональное сокращение времени выполнения запросов.
Этот метод известен как квантование. Хотя он ускоряет вычисления, он может снизить точность результатов, несмотря на выполнение полного сканирования всех векторов.

При традиционном квантовании мы теряем точность как при поиске, так и при хранении данных. В приведенном выше примере мы бы хранили `BFloat16` вместо `Float32`, что означает, что мы никогда не сможем выполнить более точный поиск позже, даже если это потребуется. Один из альтернативных подходов — хранить две копии данных: квантованную и с полной точностью. Хотя это работает, требуется избыточное хранение. Рассмотрим сценарий, в котором у нас есть `Float64` в качестве исходных данных, и мы хотим выполнять поиск с различной точностью (16-битной, 32-битной или полной 64-битной). Нам потребуется хранить три отдельные копии данных.

ClickHouse предлагает тип данных Quantized Bit (`QBit`), который устраняет эти ограничения следующим образом:

1. Хранение исходных данных с полной точностью.
2. Возможность указания точности квантования во время выполнения запроса.


Это достигается путем хранения данных в побитово-группированном формате (то есть все i-е биты всех векторов хранятся вместе), что позволяет выполнять чтение только на запрошенном уровне точности. Вы получаете преимущества в скорости за счет сокращения операций ввода-вывода и вычислений благодаря квантованию, при этом все исходные данные остаются доступными при необходимости. При выборе максимальной точности поиск становится точным.

:::note
Тип данных `QBit` и связанные с ним функции расстояния в настоящее время являются экспериментальными. Чтобы включить их, выполните `SET allow_experimental_qbit_type = 1`.
Если вы столкнетесь с проблемами, пожалуйста, создайте issue в [репозитории ClickHouse](https://github.com/clickhouse/clickhouse/issues).
:::

Чтобы объявить столбец типа `QBit`, используйте следующий синтаксис:

```sql
column_name QBit(element_type, dimension)
```

Где:

- `element_type` – тип каждого элемента вектора. Поддерживаемые типы: `BFloat16`, `Float32` и `Float64`
- `dimension` – количество элементов в каждом векторе

#### Создание таблицы `QBit` и добавление данных {#qbit-create}

```sql
CREATE TABLE fruit_animal (
    word String,
    vec QBit(Float64, 5)
) ENGINE = MergeTree
ORDER BY word;

INSERT INTO fruit_animal VALUES
    ('apple', [-0.99105519, 1.28887844, -0.43526649, -0.98520696, 0.66154391]),
    ('banana', [-0.69372815, 0.25587061, -0.88226235, -2.54593015, 0.05300475]),
    ('orange', [0.93338752, 2.06571317, -0.54612565, -1.51625717, 0.69775337]),
    ('dog', [0.72138876, 1.55757105, 2.10953259, -0.33961248, -0.62217325]),
    ('cat', [-0.56611276, 0.52267331, 1.27839863, -0.59809804, -1.26721048]),
    ('horse', [-0.61435682, 0.48542571, 1.21091247, -0.62530446, -1.33082533]);
```

#### Векторный поиск с `QBit` {#qbit-search}

Найдем ближайших соседей к вектору, представляющему слово 'lemon', используя расстояние L2. Третий параметр в функции расстояния указывает точность в битах — более высокие значения обеспечивают большую точность, но требуют больше вычислений.

Все доступные функции расстояния для `QBit` можно найти [здесь](../../../sql-reference/data-types/qbit.md#vector-search-functions).

**Поиск с полной точностью (64-бит):**

```sql
SELECT
    word,
    L2DistanceTransposed(vec, [-0.88693672, 1.31532824, -0.51182908, -0.99652702, 0.59907770], 64) AS distance
FROM fruit_animal
ORDER BY distance;
```

```text
   ┌─word───┬────────────distance─┐
1. │ apple  │ 0.14639757188169716 │
2. │ banana │   1.998961369007679 │
3. │ orange │   2.039041552613732 │
4. │ cat    │   2.752802631487914 │
5. │ horse  │  2.7555776805484813 │
6. │ dog    │   3.382295083120104 │
   └────────┴─────────────────────┘
```

**Поиск со сниженной точностью:**

```sql
SELECT
    word,
    L2DistanceTransposed(vec, [-0.88693672, 1.31532824, -0.51182908, -0.99652702, 0.59907770], 12) AS distance
FROM fruit_animal
ORDER BY distance;
```

```text
   ┌─word───┬───────────distance─┐
1. │ apple  │  0.757668703053566 │
2. │ orange │ 1.5499475034938677 │
3. │ banana │ 1.6168396735102937 │
4. │ cat    │  2.429752230904804 │
5. │ horse  │  2.524650475528617 │
6. │ dog    │   3.17766975527459 │
   └────────┴────────────────────┘
```


Обратите внимание, что при 12-битном квантовании мы получаем хорошее приближение расстояний при более быстром выполнении запросов. Относительный порядок остается в основном неизменным, при этом 'apple' по-прежнему является наиболее близким совпадением.

:::note
В текущей реализации ускорение достигается за счет сокращения операций ввода-вывода, поскольку считывается меньше данных. Если исходные данные имели большую разрядность, например `Float64`, выбор более низкой точности все равно приведет к вычислению расстояний на данных той же разрядности – просто с меньшей точностью.
:::

#### Вопросы производительности {#qbit-performance}

Преимущество `QBit` в производительности достигается за счет сокращения операций ввода-вывода, поскольку при использовании более низкой точности требуется считывать меньше данных из хранилища. Кроме того, когда `QBit` содержит данные `Float32` и параметр точности равен 16 или меньше, появляются дополнительные преимущества от сокращения вычислений. Параметр точности напрямую управляет балансом между точностью и скоростью:

- **Более высокая точность** (ближе к исходной разрядности данных): более точные результаты, более медленные запросы
- **Более низкая точность**: более быстрые запросы с приближенными результатами, сниженное потребление памяти

### Справочные материалы {#references}

Блоги:

- [Векторный поиск с ClickHouse — Часть 1](https://clickhouse.com/blog/vector-search-clickhouse-p1)
- [Векторный поиск с ClickHouse — Часть 2](https://clickhouse.com/blog/vector-search-clickhouse-p2)
