---
slug: '/engines/table-engines/log-family/log'
description: 'Документация для Log'
title: Log
doc_type: reference
toc_priority: 33
toc_title: Log
---
# Лог

Движок относится к семейству `Log` движков. Смотрите общие свойства `Log` движков и их отличия в статье [Семейство движков Log](../../../engines/table-engines/log-family/index.md).

`Log` отличается от [TinyLog](../../../engines/table-engines/log-family/tinylog.md) тем, что с файлом колонки соседствует небольшой файл "меток". Эти метки записываются в каждом блоке данных и содержат смещения, которые указывают, с какого места начинать чтение файла, чтобы пропустить указанное количество строк. Это позволяет читать данные таблицы в нескольких потоках. Для одновременного доступа к данным операции чтения могут выполняться одновременно, в то время как операции записи блокируют чтения и друг друга. Движок `Log` не поддерживает индексы. Аналогично, если запись в таблицу не удалась, таблица становится поврежденной, и чтение из нее возвращает ошибку. Движок `Log` подходит для временных данных, таблиц с одноразовой записью, а также для тестирования или демонстрационных целей.

## Создание таблицы {#table_engines-log-creating-a-table}

```sql
CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]
(
    column1_name [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],
    column2_name [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],
    ...
) ENGINE = Log
```

Смотрите подробное описание запроса [CREATE TABLE](/sql-reference/statements/create/table).

## Запись данных {#table_engines-log-writing-the-data}

Движок `Log` эффективно хранит данные, записывая каждую колонку в свой файл. Для каждой таблицы движок Log записывает следующие файлы в указанном пути хранения:

- `<column>.bin`: Файл данных для каждой колонки, содержащий сериализованные и сжатые данные.
`__marks.mrk`: Файл меток, хранящий смещения и количество строк для каждого вставленного блока данных. Метки используются для упрощения эффективного выполнения запросов, позволяя движку пропускать нерелевантные блоки данных во время чтения.

### Процесс записи {#writing-process}

Когда данные записываются в таблицу `Log`:

1.    Данные сериализуются и сжимаются в блоки.
2.    Для каждой колонки сжатые данные добавляются в соответствующий файл `<column>.bin`.
3.    Соответствующие записи добавляются в файл `__marks.mrk`, чтобы зафиксировать смещение и количество строк вновь вставленных данных.

## Чтение данных {#table_engines-log-reading-the-data}

Файл с метками позволяет ClickHouse параллелизировать чтение данных. Это означает, что запрос `SELECT` возвращает строки в непредсказуемом порядке. Используйте оператор `ORDER BY`, чтобы отсортировать строки.

## Пример использования {#table_engines-log-example-of-use}

Создание таблицы:

```sql
CREATE TABLE log_table
(
    timestamp DateTime,
    message_type String,
    message String
)
ENGINE = Log
```

Вставка данных:

```sql
INSERT INTO log_table VALUES (now(),'REGULAR','The first regular message')
INSERT INTO log_table VALUES (now(),'REGULAR','The second regular message'),(now(),'WARNING','The first warning message')
```

Мы использовали два запроса `INSERT`, чтобы создать два блока данных внутри файлов `<column>.bin`.

ClickHouse использует несколько потоков при выборе данных. Каждый поток читает отдельный блок данных и возвращает результирующие строки независимо по мере завершения. В результате порядок блоков строк в выходе может не совпадать с порядком тех же блоков во входных данных. Например:

```sql
SELECT * FROM log_table
```

```text
┌───────────timestamp─┬─message_type─┬─message────────────────────┐
│ 2019-01-18 14:27:32 │ REGULAR      │ The second regular message │
│ 2019-01-18 14:34:53 │ WARNING      │ The first warning message  │
└─────────────────────┴──────────────┴────────────────────────────┘
┌───────────timestamp─┬─message_type─┬─message───────────────────┐
│ 2019-01-18 14:23:43 │ REGULAR      │ The first regular message │
└─────────────────────┴──────────────┴───────────────────────────┘
```

Сортировка результатов (по умолчанию по возрастанию):

```sql
SELECT * FROM log_table ORDER BY timestamp
```

```text
┌───────────timestamp─┬─message_type─┬─message────────────────────┐
│ 2019-01-18 14:23:43 │ REGULAR      │ The first regular message  │
│ 2019-01-18 14:27:32 │ REGULAR      │ The second regular message │
│ 2019-01-18 14:34:53 │ WARNING      │ The first warning message  │
└─────────────────────┴──────────────┴────────────────────────────┘
```