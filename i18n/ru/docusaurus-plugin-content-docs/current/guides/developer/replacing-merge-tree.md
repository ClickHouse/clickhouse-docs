---
slug: /guides/replacing-merge-tree
title: 'ReplacingMergeTree'
description: 'Использование движка ReplacingMergeTree в ClickHouse'
keywords: ['replacingmergetree', 'inserts', 'deduplication']
doc_type: 'guide'
---

import postgres_replacingmergetree from '@site/static/images/migrations/postgres-replacingmergetree.png';
import Image from '@theme/IdealImage';

В то время как транзакционные базы данных оптимизированы под рабочие нагрузки с частыми операциями обновления и удаления, OLAP-базы данных предоставляют ослабленные гарантии для таких операций. Вместо этого они оптимизируются под неизменяемые данные, вставляемые пакетами, что позволяет значительно ускорить аналитические запросы. Хотя ClickHouse предоставляет операции обновления через мутации, а также легковесный способ удаления строк, его колоночная структура означает, что такие операции следует планировать с осторожностью, как описано выше. Эти операции обрабатываются асинхронно, выполняются в одном потоке и требуют (в случае обновлений) перезаписи данных на диске. Поэтому их не следует использовать для большого числа мелких изменений.
Чтобы обрабатывать поток строк с операциями обновления и удаления, избегая описанных выше шаблонов использования, можно использовать табличный движок ClickHouse ReplacingMergeTree.


## Автоматические операции upsert для вставляемых строк {#automatic-upserts-of-inserted-rows}

[Движок таблиц ReplacingMergeTree](/engines/table-engines/mergetree-family/replacingmergetree) позволяет применять операции обновления к строкам без необходимости использования неэффективных операторов `ALTER` или `DELETE`, предоставляя пользователям возможность вставлять несколько копий одной и той же строки и помечать одну из них как последнюю версию. Фоновый процесс, в свою очередь, асинхронно удаляет старые версии той же строки, эффективно имитируя операцию обновления посредством неизменяемых вставок.
Это основано на способности движка таблиц идентифицировать дублирующиеся строки. Это достигается с помощью секции `ORDER BY` для определения уникальности, то есть если две строки имеют одинаковые значения для столбцов, указанных в `ORDER BY`, они считаются дубликатами. Столбец `version`, указанный при определении таблицы, позволяет сохранить последнюю версию строки, когда две строки идентифицированы как дубликаты, то есть сохраняется строка с наибольшим значением версии.
Мы проиллюстрируем этот процесс в примере ниже. Здесь строки однозначно идентифицируются столбцом A (`ORDER BY` для таблицы). Предполагается, что эти строки были вставлены двумя пакетами, что привело к формированию двух частей данных на диске. Позже, во время асинхронного фонового процесса, эти части объединяются.

ReplacingMergeTree дополнительно позволяет указать столбец deleted. Он может содержать либо 0, либо 1, где значение 1 указывает, что строка (и её дубликаты) была удалена, а ноль используется в противном случае. **Примечание: Удалённые строки не будут удалены во время слияния.**

Во время этого процесса при слиянии частей происходит следующее:

- Строка, идентифицированная значением 1 для столбца A, имеет как строку обновления с версией 2, так и строку удаления с версией 3 (и значением столбца deleted равным 1). Таким образом, сохраняется последняя строка, помеченная как удалённая.
- Строка, идентифицированная значением 2 для столбца A, имеет две строки обновления. Сохраняется последняя строка со значением 6 для столбца price.
- Строка, идентифицированная значением 3 для столбца A, имеет строку с версией 1 и строку удаления с версией 2. Сохраняется эта строка удаления.

В результате этого процесса слияния мы имеем четыре строки, представляющие конечное состояние:

<br />

<Image
  img={postgres_replacingmergetree}
  size='md'
  alt='Процесс ReplacingMergeTree'
/>

<br />

Обратите внимание, что удалённые строки никогда не удаляются физически. Их можно принудительно удалить с помощью команды `OPTIMIZE table FINAL CLEANUP`. Это требует экспериментальной настройки `allow_experimental_replacing_merge_with_cleanup=1`. Эту команду следует выполнять только при следующих условиях:

1. Вы можете быть уверены, что никакие строки со старыми версиями (для тех, которые удаляются при очистке) не будут вставлены после выполнения операции. Если они будут вставлены, они будут неправильно сохранены, так как удалённых строк больше не будет.
2. Убедитесь, что все реплики синхронизированы перед выполнением очистки. Это можно достичь с помощью команды:

<br />

```sql
SYSTEM SYNC REPLICA table
```

Мы рекомендуем приостановить вставки после того, как условие (1) гарантировано, и до завершения этой команды и последующей очистки.

> Обработка удалений с помощью ReplacingMergeTree рекомендуется только для таблиц с низким или умеренным количеством удалений (менее 10%), если только не могут быть запланированы периоды для очистки при соблюдении вышеуказанных условий.

> Совет: Пользователи также могут выполнять `OPTIMIZE FINAL CLEANUP` для отдельных партиций, которые больше не подлежат изменениям.


## Выбор первичного ключа/ключа дедупликации {#choosing-a-primarydeduplication-key}

Выше мы отметили важное дополнительное ограничение, которое также должно соблюдаться в случае ReplacingMergeTree: значения столбцов в `ORDER BY` должны уникально идентифицировать строку при изменениях. При миграции из транзакционной базы данных, такой как Postgres, исходный первичный ключ Postgres должен быть включён в выражение `ORDER BY` в ClickHouse.

Пользователи ClickHouse знакомы с выбором столбцов в выражении `ORDER BY` своих таблиц для [оптимизации производительности запросов](/data-modeling/schema-design#choosing-an-ordering-key). Как правило, эти столбцы следует выбирать на основе [частых запросов и перечислять в порядке возрастания кардинальности](/guides/best-practices/sparse-primary-indexes#an-index-design-for-massive-data-scales). Важно отметить, что ReplacingMergeTree накладывает дополнительное ограничение — эти столбцы должны быть неизменяемыми, то есть при репликации из Postgres добавляйте в это выражение только те столбцы, которые не изменяются в исходных данных Postgres. Хотя другие столбцы могут изменяться, эти столбцы должны оставаться неизменными для уникальной идентификации строк.
Для аналитических нагрузок первичный ключ Postgres обычно малополезен, поскольку пользователи редко выполняют точечный поиск строк. Учитывая, что мы рекомендуем упорядочивать столбцы в порядке возрастания кардинальности, а также тот факт, что совпадения по [столбцам, перечисленным раньше в ORDER BY, обычно выполняются быстрее](/guides/best-practices/sparse-primary-indexes#ordering-key-columns-efficiently), первичный ключ Postgres следует добавлять в конец `ORDER BY` (если только он не имеет аналитической ценности). В случае, когда первичный ключ в Postgres состоит из нескольких столбцов, их следует добавить в `ORDER BY` с учётом кардинальности и вероятности использования в запросах. Пользователи также могут создать уникальный первичный ключ, используя конкатенацию значений через столбец `MATERIALIZED`.

Рассмотрим таблицу постов из набора данных Stack Overflow.

```sql
CREATE TABLE stackoverflow.posts_updateable
(
       `Version` UInt32,
       `Deleted` UInt8,
        `Id` Int32 CODEC(Delta(4), ZSTD(1)),
        `PostTypeId` Enum8('Question' = 1, 'Answer' = 2, 'Wiki' = 3, 'TagWikiExcerpt' = 4, 'TagWiki' = 5, 'ModeratorNomination' = 6, 'WikiPlaceholder' = 7, 'PrivilegeWiki' = 8),
        `AcceptedAnswerId` UInt32,
        `CreationDate` DateTime64(3, 'UTC'),
        `Score` Int32,
        `ViewCount` UInt32 CODEC(Delta(4), ZSTD(1)),
        `Body` String,
        `OwnerUserId` Int32,
        `OwnerDisplayName` String,
        `LastEditorUserId` Int32,
        `LastEditorDisplayName` String,
        `LastEditDate` DateTime64(3, 'UTC') CODEC(Delta(8), ZSTD(1)),
        `LastActivityDate` DateTime64(3, 'UTC'),
        `Title` String,
        `Tags` String,
        `AnswerCount` UInt16 CODEC(Delta(2), ZSTD(1)),
        `CommentCount` UInt8,
        `FavoriteCount` UInt8,
        `ContentLicense` LowCardinality(String),
        `ParentId` String,
        `CommunityOwnedDate` DateTime64(3, 'UTC'),
        `ClosedDate` DateTime64(3, 'UTC')
)
ENGINE = ReplacingMergeTree(Version, Deleted)
PARTITION BY toYear(CreationDate)
ORDER BY (PostTypeId, toDate(CreationDate), CreationDate, Id)
```

Мы используем ключ `ORDER BY` вида `(PostTypeId, toDate(CreationDate), CreationDate, Id)`. Столбец `Id`, уникальный для каждого поста, обеспечивает возможность дедупликации строк. Столбцы `Version` и `Deleted` добавлены в схему в соответствии с требованиями.


## Запросы к ReplacingMergeTree {#querying-replacingmergetree}

Во время слияния ReplacingMergeTree идентифицирует дублирующиеся строки, используя значения столбцов `ORDER BY` в качестве уникального идентификатора, и либо сохраняет только версию с наибольшим номером, либо удаляет все дубликаты, если последняя версия указывает на удаление. Однако это обеспечивает только итоговую корректность — не гарантируется, что строки будут дедуплицированы, и на это не следует полагаться. Поэтому запросы могут давать неверные результаты из-за того, что строки обновлений и удалений учитываются при выполнении запросов.

Для получения корректных результатов пользователям необходимо дополнить фоновые слияния дедупликацией и удалением строк во время выполнения запроса. Это можно реализовать с помощью оператора `FINAL`.

Рассмотрим таблицу posts, описанную выше. Мы можем использовать стандартный метод загрузки этого набора данных, но дополнительно указать столбцы deleted и version со значением 0. Для примера загрузим только 10000 строк.

```sql
INSERT INTO stackoverflow.posts_updateable SELECT 0 AS Version, 0 AS Deleted, *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/*.parquet') WHERE AnswerCount > 0 LIMIT 10000

0 rows in set. Elapsed: 1.980 sec. Processed 8.19 thousand rows, 3.52 MB (4.14 thousand rows/s., 1.78 MB/s.)
```

Проверим количество строк:

```sql
SELECT count() FROM stackoverflow.posts_updateable

┌─count()─┐
│   10000 │
└─────────┘

1 row in set. Elapsed: 0.002 sec.
```

Теперь обновим статистику ответов на посты. Вместо обновления этих значений мы вставим новые копии 5000 строк и увеличим их номер версии на единицу (это означает, что в таблице будет 15000 строк). Смоделируем это с помощью простого `INSERT INTO SELECT`:

```sql
INSERT INTO posts_updateable SELECT
        Version + 1 AS Version,
        Deleted,
        Id,
        PostTypeId,
        AcceptedAnswerId,
        CreationDate,
        Score,
        ViewCount,
        Body,
        OwnerUserId,
        OwnerDisplayName,
        LastEditorUserId,
        LastEditorDisplayName,
        LastEditDate,
        LastActivityDate,
        Title,
        Tags,
        AnswerCount,
        CommentCount,
        FavoriteCount,
        ContentLicense,
        ParentId,
        CommunityOwnedDate,
        ClosedDate
FROM posts_updateable --select 100 random rows
WHERE (Id % toInt32(floor(randUniform(1, 11)))) = 0
LIMIT 5000

0 rows in set. Elapsed: 4.056 sec. Processed 1.42 million rows, 2.20 GB (349.63 thousand rows/s., 543.39 MB/s.)
```

Кроме того, удалим 1000 случайных постов, повторно вставив строки со значением столбца deleted равным 1. Это также можно смоделировать с помощью простого `INSERT INTO SELECT`.

```sql
INSERT INTO posts_updateable SELECT
        Version + 1 AS Version,
        1 AS Deleted,
        Id,
        PostTypeId,
        AcceptedAnswerId,
        CreationDate,
        Score,
        ViewCount,
        Body,
        OwnerUserId,
        OwnerDisplayName,
        LastEditorUserId,
        LastEditorDisplayName,
        LastEditDate,
        LastActivityDate,
        Title,
        Tags,
        AnswerCount + 1 AS AnswerCount,
        CommentCount,
        FavoriteCount,
        ContentLicense,
        ParentId,
        CommunityOwnedDate,
        ClosedDate
FROM posts_updateable --select 100 random rows
WHERE (Id % toInt32(floor(randUniform(1, 11)))) = 0 AND AnswerCount > 0
LIMIT 1000

0 rows in set. Elapsed: 0.166 sec. Processed 135.53 thousand rows, 212.65 MB (816.30 thousand rows/s., 1.28 GB/s.)
```

Результатом вышеуказанных операций будет 16 000 строк, то есть 10 000 + 5000 + 1000. Корректный итог — в действительности у нас должно быть на 1000 строк меньше, чем исходное количество, то есть 10 000 - 1000 = 9000.

```sql
SELECT count()
FROM posts_updateable

┌─count()─┐
│   10000 │
└─────────┘
1 row in set. Elapsed: 0.002 sec.
```

Ваши результаты будут различаться в зависимости от произошедших слияний. Мы видим, что итоговое значение отличается, поскольку у нас есть дублирующиеся строки. Применение `FINAL` к таблице дает корректный результат.


```sql
SELECT count()
FROM posts_updateable
FINAL

┌─count()─┐
│    9000 │
└─────────┘

Получена 1 строка. Время выполнения: 0.006 сек. Обработано 11.81 тыс. строк, 212.54 КБ (2.14 млн строк/сек., 38.61 МБ/сек.)
Пиковое потребление памяти: 8.14 МиБ.
```


## Производительность FINAL {#final-performance}

Оператор `FINAL` вносит небольшие накладные расходы на производительность запросов.
Это наиболее заметно, когда запросы не фильтруют данные по столбцам первичного ключа,
что приводит к чтению большего объёма данных и увеличению накладных расходов на дедупликацию. Если пользователи
фильтруют данные по ключевым столбцам с помощью условия `WHERE`, объём данных, загружаемых и передаваемых для
дедупликации, будет сокращён.

Если условие `WHERE` не использует ключевой столбец, ClickHouse в настоящее время не применяет оптимизацию `PREWHERE` при использовании `FINAL`. Эта оптимизация направлена на сокращение количества строк, считываемых для нефильтруемых столбцов. Примеры эмуляции `PREWHERE` и, следовательно, потенциального улучшения производительности можно найти [здесь](https://clickhouse.com/blog/clickhouse-postgresql-change-data-capture-cdc-part-1#final-performance).


## Использование партиций с ReplacingMergeTree {#exploiting-partitions-with-replacingmergetree}

Слияние данных в ClickHouse происходит на уровне партиций. При использовании ReplacingMergeTree рекомендуется партиционировать таблицу в соответствии с лучшими практиками, при условии что **ключ партиционирования не изменяется для строки**. Это гарантирует, что обновления одной и той же строки будут направлены в одну и ту же партицию ClickHouse. Вы можете использовать тот же ключ партиционирования, что и в Postgres, при условии соблюдения изложенных здесь лучших практик.

В этом случае можно использовать настройку `do_not_merge_across_partitions_select_final=1` для улучшения производительности запросов с `FINAL`. Эта настройка обеспечивает независимое слияние и обработку партиций при использовании FINAL.

Рассмотрим следующую таблицу posts без партиционирования:

```sql
CREATE TABLE stackoverflow.posts_no_part
(
        `Version` UInt32,
        `Deleted` UInt8,
        `Id` Int32 CODEC(Delta(4), ZSTD(1)),
        ...
)
ENGINE = ReplacingMergeTree
ORDER BY (PostTypeId, toDate(CreationDate), CreationDate, Id)

INSERT INTO stackoverflow.posts_no_part SELECT 0 AS Version, 0 AS Deleted, *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/*.parquet')

0 rows in set. Elapsed: 182.895 sec. Processed 59.82 million rows, 38.07 GB (327.07 thousand rows/s., 208.17 MB/s.)
```

Чтобы `FINAL` выполнял реальную работу, обновим 1 млн строк, увеличив их `AnswerCount` путем вставки дублирующих строк.

```sql
INSERT INTO posts_no_part SELECT Version + 1 AS Version, Deleted, Id, PostTypeId, AcceptedAnswerId, CreationDate, Score, ViewCount, Body, OwnerUserId, OwnerDisplayName, LastEditorUserId, LastEditorDisplayName, LastEditDate, LastActivityDate, Title, Tags, AnswerCount + 1 AS AnswerCount, CommentCount, FavoriteCount, ContentLicense, ParentId, CommunityOwnedDate, ClosedDate
FROM posts_no_part
LIMIT 1000000
```

Вычисление суммы ответов по годам с `FINAL`:

```sql
SELECT toYear(CreationDate) AS year, sum(AnswerCount) AS total_answers
FROM posts_no_part
FINAL
GROUP BY year
ORDER BY year ASC

┌─year─┬─total_answers─┐
│ 2008 │        371480 │
...
│ 2024 │        127765 │
└──────┴───────────────┘

17 rows in set. Elapsed: 2.338 sec. Processed 122.94 million rows, 1.84 GB (52.57 million rows/s., 788.58 MB/s.)
Peak memory usage: 2.09 GiB.
```

Повторим те же шаги для таблицы с партиционированием по годам и выполним приведенный выше запрос с `do_not_merge_across_partitions_select_final=1`.

```sql
CREATE TABLE stackoverflow.posts_with_part
(
        `Version` UInt32,
        `Deleted` UInt8,
        `Id` Int32 CODEC(Delta(4), ZSTD(1)),
        ...
)
ENGINE = ReplacingMergeTree
PARTITION BY toYear(CreationDate)
ORDER BY (PostTypeId, toDate(CreationDate), CreationDate, Id)

// заполнение и обновление опущены

SELECT toYear(CreationDate) AS year, sum(AnswerCount) AS total_answers
FROM posts_with_part
FINAL
GROUP BY year
ORDER BY year ASC

┌─year─┬─total_answers─┐
│ 2008 │       387832  │
│ 2009 │       1165506 │
│ 2010 │       1755437 │
...
│ 2023 │       787032  │
│ 2024 │       127765  │
└──────┴───────────────┘

17 rows in set. Elapsed: 0.994 sec. Processed 64.65 million rows, 983.64 MB (65.02 million rows/s., 989.23 MB/s.)
```

Как видно, партиционирование значительно улучшило производительность запроса в данном случае, позволив процессу дедупликации выполняться параллельно на уровне партиций.


## Особенности поведения слияний {#merge-behavior-considerations}

Механизм выбора слияний в ClickHouse выходит за рамки простого объединения частей. Ниже мы рассмотрим это поведение в контексте ReplacingMergeTree, включая параметры конфигурации для более агрессивного слияния старых данных и особенности работы с большими частями.

### Логика выбора слияний {#merge-selection-logic}

Хотя слияние направлено на минимизацию количества частей, оно также балансирует эту цель с издержками на усиление записи. Следовательно, некоторые диапазоны частей исключаются из слияния, если они приведут к чрезмерному усилению записи, на основе внутренних расчетов. Такое поведение помогает предотвратить избыточное использование ресурсов и продлевает срок службы компонентов хранилища.

### Поведение слияния для больших частей {#merging-behavior-on-large-parts}

Движок ReplacingMergeTree в ClickHouse оптимизирован для управления дублирующимися строками путем слияния частей данных с сохранением только последней версии каждой строки на основе указанного уникального ключа. Однако когда объединенная часть достигает порога max_bytes_to_merge_at_max_space_in_pool, она больше не будет выбрана для дальнейшего слияния, даже если установлен параметр min_age_to_force_merge_seconds. В результате автоматические слияния больше нельзя использовать для удаления дубликатов, которые могут накапливаться при продолжающейся вставке данных.

Для решения этой проблемы пользователи могут вызвать OPTIMIZE FINAL для ручного слияния частей и удаления дубликатов. В отличие от автоматических слияний, OPTIMIZE FINAL обходит порог max_bytes_to_merge_at_max_space_in_pool, объединяя части исключительно на основе доступных ресурсов, в частности дискового пространства, пока в каждой партиции не останется одна часть. Однако этот подход может быть ресурсоемким по памяти на больших таблицах и может требовать повторного выполнения по мере добавления новых данных.

Для более устойчивого решения, поддерживающего производительность, рекомендуется партиционирование таблицы. Это может помочь предотвратить достижение частями данных максимального размера слияния и снижает необходимость в постоянных ручных оптимизациях.

### Партиционирование и слияние между партициями {#partitioning-and-merging-across-partitions}

Как обсуждалось в разделе «Использование партиций с ReplacingMergeTree», мы рекомендуем партиционирование таблиц в качестве лучшей практики. Партиционирование изолирует данные для более эффективных слияний и предотвращает слияние между партициями, особенно во время выполнения запросов. Это поведение улучшено в версиях начиная с 23.12: если ключ партиционирования является префиксом ключа сортировки, слияние между партициями не выполняется во время запроса, что приводит к более высокой производительности запросов.

### Настройка слияний для улучшения производительности запросов {#tuning-merges-for-better-query-performance}

По умолчанию параметры min_age_to_force_merge_seconds и min_age_to_force_merge_on_partition_only установлены в 0 и false соответственно, что отключает эти функции. В этой конфигурации ClickHouse будет применять стандартное поведение слияния без принудительного слияния на основе возраста партиции.

Если указано значение для min_age_to_force_merge_seconds, ClickHouse будет игнорировать обычную эвристику слияния для частей старше указанного периода. Хотя это обычно эффективно только в том случае, если цель состоит в минимизации общего количества частей, это может улучшить производительность запросов в ReplacingMergeTree за счет уменьшения количества частей, требующих слияния во время выполнения запроса.

Это поведение можно дополнительно настроить, установив min_age_to_force_merge_on_partition_only=true, что требует, чтобы все части в партиции были старше min_age_to_force_merge_seconds для агрессивного слияния. Эта конфигурация позволяет старым партициям со временем объединяться в одну часть, что консолидирует данные и поддерживает производительность запросов.

### Рекомендуемые настройки {#recommended-settings}

:::warning
Настройка поведения слияний является расширенной операцией. Мы рекомендуем проконсультироваться со службой поддержки ClickHouse перед включением этих настроек в производственных нагрузках.
:::

В большинстве случаев предпочтительно устанавливать min_age_to_force_merge_seconds на низкое значение — значительно меньше периода партиционирования. Это минимизирует количество частей и предотвращает избыточное слияние во время выполнения запроса с оператором FINAL.

Например, рассмотрим месячную партицию, которая уже была объединена в одну часть. Если небольшая случайная вставка создает новую часть в этой партиции, производительность запросов может пострадать, поскольку ClickHouse должен читать несколько частей до завершения слияния. Установка min_age_to_force_merge_seconds может обеспечить агрессивное слияние этих частей, предотвращая снижение производительности запросов.
