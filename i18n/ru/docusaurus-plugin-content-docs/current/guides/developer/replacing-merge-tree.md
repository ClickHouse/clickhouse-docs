---
slug: /guides/replacing-merge-tree
title: 'ReplacingMergeTree'
description: 'Использование движка ReplacingMergeTree в ClickHouse'
keywords: ['replacingmergetree', 'inserts', 'deduplication']
doc_type: 'guide'
---

import postgres_replacingmergetree from '@site/static/images/migrations/postgres-replacingmergetree.png';
import Image from '@theme/IdealImage';

В то время как транзакционные базы данных оптимизированы под нагрузки, содержащие транзакционные операции обновления и удаления, OLAP-базы данных предоставляют более слабые гарантии для таких операций. Вместо этого они оптимизируются под неизменяемые данные, вставляемые пакетами, что обеспечивает значительно более высокую скорость выполнения аналитических запросов. Хотя ClickHouse поддерживает операции обновления с помощью мутаций, а также облегчённый механизм удаления строк, его колонко-ориентированная структура означает, что такие операции следует планировать с осторожностью, как описано выше. Эти операции обрабатываются асинхронно, выполняются в одном потоке и требуют (в случае обновлений) перезаписи данных на диск. Поэтому их не следует использовать для большого количества мелких изменений.
Чтобы обрабатывать поток строк с операциями обновления и удаления, избегая описанных выше сценариев использования, можно использовать движок таблиц ClickHouse ReplacingMergeTree.


## Автоматические upsert-операции для вставляемых строк {#automatic-upserts-of-inserted-rows}

[Движок таблиц ReplacingMergeTree](/engines/table-engines/mergetree-family/replacingmergetree) позволяет применять операции обновления к строкам без необходимости использования неэффективных операторов `ALTER` или `DELETE`, предоставляя пользователям возможность вставлять несколько копий одной и той же строки и помечать одну из них как последнюю версию. Фоновый процесс, в свою очередь, асинхронно удаляет старые версии той же строки, эффективно имитируя операцию обновления посредством неизменяемых вставок.
Это основано на способности движка таблиц идентифицировать дублирующиеся строки. Это достигается с помощью секции `ORDER BY` для определения уникальности: если две строки имеют одинаковые значения для столбцов, указанных в `ORDER BY`, они считаются дубликатами. Столбец `version`, указанный при определении таблицы, позволяет сохранить последнюю версию строки, когда две строки идентифицированы как дубликаты, то есть сохраняется строка с наибольшим значением версии.
Мы иллюстрируем этот процесс в примере ниже. Здесь строки однозначно идентифицируются столбцом A (`ORDER BY` для таблицы). Предполагается, что эти строки были вставлены двумя пакетами, что привело к формированию двух частей данных на диске. Позже, во время асинхронного фонового процесса, эти части объединяются.

ReplacingMergeTree дополнительно позволяет указать столбец deleted. Он может содержать либо 0, либо 1, где значение 1 указывает, что строка (и её дубликаты) была удалена, а ноль используется в противном случае. **Примечание: Удалённые строки не будут удалены во время слияния.**

Во время этого процесса при слиянии частей происходит следующее:

- Строка, идентифицированная значением 1 для столбца A, имеет как строку обновления с версией 2, так и строку удаления с версией 3 (и значением столбца deleted равным 1). Поэтому сохраняется последняя строка, помеченная как удалённая.
- Строка, идентифицированная значением 2 для столбца A, имеет две строки обновления. Сохраняется последняя строка со значением 6 для столбца price.
- Строка, идентифицированная значением 3 для столбца A, имеет строку с версией 1 и строку удаления с версией 2. Сохраняется эта строка удаления.

В результате этого процесса слияния получаем четыре строки, представляющие конечное состояние:

<br />

<Image
  img={postgres_replacingmergetree}
  size='md'
  alt='Процесс ReplacingMergeTree'
/>

<br />

Обратите внимание, что удалённые строки никогда не удаляются физически. Они могут быть принудительно удалены с помощью `OPTIMIZE table FINAL CLEANUP`. Это требует экспериментальной настройки `allow_experimental_replacing_merge_with_cleanup=1`. Эту операцию следует выполнять только при следующих условиях:

1. Вы можете быть уверены, что никакие строки со старыми версиями (для тех, которые удаляются с помощью cleanup) не будут вставлены после выполнения операции. Если они будут вставлены, они будут ошибочно сохранены, так как удалённые строки больше не будут присутствовать.
2. Убедитесь, что все реплики синхронизированы перед выполнением cleanup. Это можно достичь с помощью команды:

<br />

```sql
SYSTEM SYNC REPLICA table
```

Мы рекомендуем приостановить вставки после того, как условие (1) гарантировано, и до завершения этой команды и последующей очистки.

> Обработка удалений с помощью ReplacingMergeTree рекомендуется только для таблиц с низким или умеренным количеством удалений (менее 10%), если только не могут быть запланированы периоды для очистки при соблюдении вышеуказанных условий.

> Совет: Пользователи также могут выполнять `OPTIMIZE FINAL CLEANUP` для отдельных партиций, которые больше не подвержены изменениям.


## Выбор первичного ключа/ключа дедупликации {#choosing-a-primarydeduplication-key}

Выше мы отметили важное дополнительное ограничение, которое также должно соблюдаться в случае ReplacingMergeTree: значения столбцов в `ORDER BY` должны уникально идентифицировать строку при изменениях. При миграции из транзакционной базы данных, такой как Postgres, исходный первичный ключ Postgres должен быть включен в выражение `ORDER BY` в ClickHouse.

Пользователи ClickHouse знакомы с выбором столбцов в выражении `ORDER BY` своих таблиц для [оптимизации производительности запросов](/data-modeling/schema-design#choosing-an-ordering-key). Как правило, эти столбцы следует выбирать на основе [частых запросов и перечислять в порядке возрастания кардинальности](/guides/best-practices/sparse-primary-indexes#an-index-design-for-massive-data-scales). Важно отметить, что ReplacingMergeTree накладывает дополнительное ограничение — эти столбцы должны быть неизменяемыми, то есть при репликации из Postgres добавляйте в это выражение только те столбцы, которые не изменяются в исходных данных Postgres. Хотя другие столбцы могут изменяться, эти столбцы должны оставаться неизменными для уникальной идентификации строк.
Для аналитических нагрузок первичный ключ Postgres обычно малополезен, поскольку пользователи редко выполняют точечные поиски строк. Учитывая, что мы рекомендуем упорядочивать столбцы в порядке возрастания кардинальности, а также то, что совпадения по [столбцам, перечисленным раньше в ORDER BY, обычно выполняются быстрее](/guides/best-practices/sparse-primary-indexes#ordering-key-columns-efficiently), первичный ключ Postgres следует добавлять в конец `ORDER BY` (если только он не имеет аналитической ценности). В случае, когда первичный ключ в Postgres состоит из нескольких столбцов, их следует добавлять в `ORDER BY` с учетом кардинальности и вероятности использования в запросах. Пользователи также могут создать уникальный первичный ключ путем конкатенации значений с помощью столбца `MATERIALIZED`.

Рассмотрим таблицу постов из набора данных Stack Overflow.

```sql
CREATE TABLE stackoverflow.posts_updateable
(
       `Version` UInt32,
       `Deleted` UInt8,
        `Id` Int32 CODEC(Delta(4), ZSTD(1)),
        `PostTypeId` Enum8('Question' = 1, 'Answer' = 2, 'Wiki' = 3, 'TagWikiExcerpt' = 4, 'TagWiki' = 5, 'ModeratorNomination' = 6, 'WikiPlaceholder' = 7, 'PrivilegeWiki' = 8),
        `AcceptedAnswerId` UInt32,
        `CreationDate` DateTime64(3, 'UTC'),
        `Score` Int32,
        `ViewCount` UInt32 CODEC(Delta(4), ZSTD(1)),
        `Body` String,
        `OwnerUserId` Int32,
        `OwnerDisplayName` String,
        `LastEditorUserId` Int32,
        `LastEditorDisplayName` String,
        `LastEditDate` DateTime64(3, 'UTC') CODEC(Delta(8), ZSTD(1)),
        `LastActivityDate` DateTime64(3, 'UTC'),
        `Title` String,
        `Tags` String,
        `AnswerCount` UInt16 CODEC(Delta(2), ZSTD(1)),
        `CommentCount` UInt8,
        `FavoriteCount` UInt8,
        `ContentLicense` LowCardinality(String),
        `ParentId` String,
        `CommunityOwnedDate` DateTime64(3, 'UTC'),
        `ClosedDate` DateTime64(3, 'UTC')
)
ENGINE = ReplacingMergeTree(Version, Deleted)
PARTITION BY toYear(CreationDate)
ORDER BY (PostTypeId, toDate(CreationDate), CreationDate, Id)
```

Мы используем ключ `ORDER BY` вида `(PostTypeId, toDate(CreationDate), CreationDate, Id)`. Столбец `Id`, уникальный для каждого поста, обеспечивает возможность дедупликации строк. Столбцы `Version` и `Deleted` добавлены в схему в соответствии с требованиями.


## Запросы к ReplacingMergeTree {#querying-replacingmergetree}

Во время слияния ReplacingMergeTree идентифицирует дублирующиеся строки, используя значения столбцов `ORDER BY` в качестве уникального идентификатора, и либо сохраняет только самую последнюю версию, либо удаляет все дубликаты, если последняя версия указывает на удаление. Однако это обеспечивает лишь итоговую корректность — не гарантируется, что строки будут дедуплицированы, и на это не следует полагаться. Поэтому запросы могут давать неверные результаты из-за того, что строки обновлений и удалений учитываются при выполнении запросов.

Чтобы получить корректные результаты, пользователям необходимо дополнить фоновые слияния дедупликацией и удалением строк во время выполнения запроса. Это можно сделать с помощью оператора `FINAL`.

Рассмотрим таблицу posts, описанную выше. Мы можем использовать обычный метод загрузки этого набора данных, но дополнительно указать столбцы deleted и version со значением 0. Для примера загрузим только 10000 строк.

```sql
INSERT INTO stackoverflow.posts_updateable SELECT 0 AS Version, 0 AS Deleted, *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/*.parquet') WHERE AnswerCount > 0 LIMIT 10000

0 rows in set. Elapsed: 1.980 sec. Processed 8.19 thousand rows, 3.52 MB (4.14 thousand rows/s., 1.78 MB/s.)
```

Проверим количество строк:

```sql
SELECT count() FROM stackoverflow.posts_updateable

┌─count()─┐
│   10000 │
└─────────┘

1 row in set. Elapsed: 0.002 sec.
```

Теперь обновим статистику ответов на посты. Вместо обновления этих значений мы вставим новые копии 5000 строк и увеличим их номер версии на единицу (это означает, что в таблице будет 15000 строк). Смоделируем это с помощью простого `INSERT INTO SELECT`:

```sql
INSERT INTO posts_updateable SELECT
        Version + 1 AS Version,
        Deleted,
        Id,
        PostTypeId,
        AcceptedAnswerId,
        CreationDate,
        Score,
        ViewCount,
        Body,
        OwnerUserId,
        OwnerDisplayName,
        LastEditorUserId,
        LastEditorDisplayName,
        LastEditDate,
        LastActivityDate,
        Title,
        Tags,
        AnswerCount,
        CommentCount,
        FavoriteCount,
        ContentLicense,
        ParentId,
        CommunityOwnedDate,
        ClosedDate
FROM posts_updateable --select 100 random rows
WHERE (Id % toInt32(floor(randUniform(1, 11)))) = 0
LIMIT 5000

0 rows in set. Elapsed: 4.056 sec. Processed 1.42 million rows, 2.20 GB (349.63 thousand rows/s., 543.39 MB/s.)
```

Кроме того, удалим 1000 случайных постов, повторно вставив строки со значением столбца deleted равным 1. Это также можно смоделировать с помощью простого `INSERT INTO SELECT`.

```sql
INSERT INTO posts_updateable SELECT
        Version + 1 AS Version,
        1 AS Deleted,
        Id,
        PostTypeId,
        AcceptedAnswerId,
        CreationDate,
        Score,
        ViewCount,
        Body,
        OwnerUserId,
        OwnerDisplayName,
        LastEditorUserId,
        LastEditorDisplayName,
        LastEditDate,
        LastActivityDate,
        Title,
        Tags,
        AnswerCount + 1 AS AnswerCount,
        CommentCount,
        FavoriteCount,
        ContentLicense,
        ParentId,
        CommunityOwnedDate,
        ClosedDate
FROM posts_updateable --select 100 random rows
WHERE (Id % toInt32(floor(randUniform(1, 11)))) = 0 AND AnswerCount > 0
LIMIT 1000

0 rows in set. Elapsed: 0.166 sec. Processed 135.53 thousand rows, 212.65 MB (816.30 thousand rows/s., 1.28 GB/s.)
```

Результатом вышеуказанных операций будет 16 000 строк, то есть 10 000 + 5000 + 1000. Корректный итог — в действительности у нас должно быть на 1000 строк меньше, чем исходное количество, то есть 10 000 - 1000 = 9000.

```sql
SELECT count()
FROM posts_updateable

┌─count()─┐
│   10000 │
└─────────┘
1 row in set. Elapsed: 0.002 sec.
```

Ваши результаты будут различаться в зависимости от произошедших слияний. Мы видим, что итоговое значение отличается, поскольку у нас есть дублирующиеся строки. Применение `FINAL` к таблице дает корректный результат.


```sql
SELECT count()
FROM posts_updateable
FINAL

┌─count()─┐
│    9000 │
└─────────┘

Получена 1 строка. Время выполнения: 0.006 сек. Обработано 11.81 тыс. строк, 212.54 КБ (2.14 млн строк/сек., 38.61 МБ/сек.)
Пиковое потребление памяти: 8.14 МиБ.
```


## Производительность FINAL {#final-performance}

Оператор `FINAL` вносит небольшие накладные расходы на производительность запросов.
Это наиболее заметно, когда запросы не фильтруют данные по столбцам первичного ключа,
что приводит к чтению большего объёма данных и увеличению накладных расходов на дедупликацию. Если пользователи
фильтруют данные по ключевым столбцам с помощью условия `WHERE`, объём данных, загружаемых и передаваемых для
дедупликации, будет сокращён.

Если условие `WHERE` не использует ключевой столбец, ClickHouse в настоящее время не применяет оптимизацию `PREWHERE` при использовании `FINAL`. Эта оптимизация направлена на сокращение количества строк, считываемых для нефильтруемых столбцов. Примеры эмуляции `PREWHERE` и, следовательно, потенциального улучшения производительности можно найти [здесь](https://clickhouse.com/blog/clickhouse-postgresql-change-data-capture-cdc-part-1#final-performance).


## Использование партиций с ReplacingMergeTree {#exploiting-partitions-with-replacingmergetree}

Слияние данных в ClickHouse происходит на уровне партиций. При использовании ReplacingMergeTree рекомендуется партиционировать таблицу в соответствии с лучшими практиками, при условии что **ключ партиционирования не изменяется для строки**. Это гарантирует, что обновления одной и той же строки будут направлены в одну и ту же партицию ClickHouse. Вы можете использовать тот же ключ партиционирования, что и в Postgres, при условии соблюдения изложенных здесь лучших практик.

При соблюдении этого условия можно использовать настройку `do_not_merge_across_partitions_select_final=1` для улучшения производительности запросов с `FINAL`. Эта настройка обеспечивает независимое слияние и обработку партиций при использовании FINAL.

Рассмотрим следующую таблицу posts без партиционирования:

```sql
CREATE TABLE stackoverflow.posts_no_part
(
        `Version` UInt32,
        `Deleted` UInt8,
        `Id` Int32 CODEC(Delta(4), ZSTD(1)),
        ...
)
ENGINE = ReplacingMergeTree
ORDER BY (PostTypeId, toDate(CreationDate), CreationDate, Id)

INSERT INTO stackoverflow.posts_no_part SELECT 0 AS Version, 0 AS Deleted, *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/*.parquet')

0 rows in set. Elapsed: 182.895 sec. Processed 59.82 million rows, 38.07 GB (327.07 thousand rows/s., 208.17 MB/s.)
```

Чтобы убедиться, что `FINAL` выполняет определенную работу, обновим 1 млн строк, увеличивая их `AnswerCount` путем вставки дублирующих строк.

```sql
INSERT INTO posts_no_part SELECT Version + 1 AS Version, Deleted, Id, PostTypeId, AcceptedAnswerId, CreationDate, Score, ViewCount, Body, OwnerUserId, OwnerDisplayName, LastEditorUserId, LastEditorDisplayName, LastEditDate, LastActivityDate, Title, Tags, AnswerCount + 1 AS AnswerCount, CommentCount, FavoriteCount, ContentLicense, ParentId, CommunityOwnedDate, ClosedDate
FROM posts_no_part
LIMIT 1000000
```

Вычисление суммы ответов по годам с `FINAL`:

```sql
SELECT toYear(CreationDate) AS year, sum(AnswerCount) AS total_answers
FROM posts_no_part
FINAL
GROUP BY year
ORDER BY year ASC

┌─year─┬─total_answers─┐
│ 2008 │        371480 │
...
│ 2024 │        127765 │
└──────┴───────────────┘

17 rows in set. Elapsed: 2.338 sec. Processed 122.94 million rows, 1.84 GB (52.57 million rows/s., 788.58 MB/s.)
Peak memory usage: 2.09 GiB.
```

Повторим те же шаги для таблицы с партиционированием по годам и выполним приведенный выше запрос с `do_not_merge_across_partitions_select_final=1`.

```sql
CREATE TABLE stackoverflow.posts_with_part
(
        `Version` UInt32,
        `Deleted` UInt8,
        `Id` Int32 CODEC(Delta(4), ZSTD(1)),
        ...
)
ENGINE = ReplacingMergeTree
PARTITION BY toYear(CreationDate)
ORDER BY (PostTypeId, toDate(CreationDate), CreationDate, Id)

// заполнение и обновление опущены

SELECT toYear(CreationDate) AS year, sum(AnswerCount) AS total_answers
FROM posts_with_part
FINAL
GROUP BY year
ORDER BY year ASC

┌─year─┬─total_answers─┐
│ 2008 │       387832  │
│ 2009 │       1165506 │
│ 2010 │       1755437 │
...
│ 2023 │       787032  │
│ 2024 │       127765  │
└──────┴───────────────┘

17 rows in set. Elapsed: 0.994 sec. Processed 64.65 million rows, 983.64 MB (65.02 million rows/s., 989.23 MB/s.)
```

Как видно, партиционирование значительно улучшило производительность запроса в данном случае, позволив процессу дедупликации выполняться параллельно на уровне партиций.


## Особенности поведения слияний {#merge-behavior-considerations}

Механизм выбора слияний в ClickHouse выходит за рамки простого объединения кусков данных. Ниже мы рассмотрим это поведение в контексте ReplacingMergeTree, включая параметры конфигурации для более агрессивного слияния старых данных и особенности работы с большими кусками.

### Логика выбора слияний {#merge-selection-logic}

Хотя слияние направлено на минимизацию количества кусков, оно также балансирует эту цель с издержками на усиление записи. Следовательно, некоторые диапазоны кусков исключаются из слияния, если они приведут к чрезмерному усилению записи, на основе внутренних расчетов. Такое поведение помогает предотвратить избыточное использование ресурсов и продлевает срок службы компонентов хранилища.

### Поведение слияния для больших кусков {#merging-behavior-on-large-parts}

Движок ReplacingMergeTree в ClickHouse оптимизирован для управления дублирующимися строками путем слияния кусков данных, сохраняя только последнюю версию каждой строки на основе указанного уникального ключа. Однако когда объединенный кусок достигает порога max_bytes_to_merge_at_max_space_in_pool, он больше не будет выбран для дальнейшего слияния, даже если установлен параметр min_age_to_force_merge_seconds. В результате автоматические слияния больше нельзя использовать для удаления дубликатов, которые могут накапливаться при продолжающейся вставке данных.

Для решения этой проблемы пользователи могут вызвать OPTIMIZE FINAL для ручного слияния кусков и удаления дубликатов. В отличие от автоматических слияний, OPTIMIZE FINAL обходит порог max_bytes_to_merge_at_max_space_in_pool, объединяя куски исключительно на основе доступных ресурсов, в частности дискового пространства, пока в каждой партиции не останется один кусок. Однако этот подход может быть ресурсоемким по памяти на больших таблицах и может требовать повторного выполнения по мере добавления новых данных.

Для более устойчивого решения, сохраняющего производительность, рекомендуется партиционирование таблицы. Это может помочь предотвратить достижение кусками данных максимального размера слияния и снижает необходимость в постоянных ручных оптимизациях.

### Партиционирование и слияние между партициями {#partitioning-and-merging-across-partitions}

Как обсуждалось в разделе «Использование партиций с ReplacingMergeTree», мы рекомендуем партиционирование таблиц в качестве лучшей практики. Партиционирование изолирует данные для более эффективных слияний и предотвращает слияние между партициями, особенно во время выполнения запросов. Это поведение улучшено в версиях начиная с 23.12: если ключ партиционирования является префиксом ключа сортировки, слияние между партициями не выполняется во время запроса, что приводит к более быстрому выполнению запросов.

### Настройка слияний для улучшения производительности запросов {#tuning-merges-for-better-query-performance}

По умолчанию параметры min_age_to_force_merge_seconds и min_age_to_force_merge_on_partition_only установлены в 0 и false соответственно, что отключает эти функции. В этой конфигурации ClickHouse будет применять стандартное поведение слияния без принудительного слияния на основе возраста партиции.

Если указано значение для min_age_to_force_merge_seconds, ClickHouse будет игнорировать обычную эвристику слияния для кусков старше указанного периода. Хотя это обычно эффективно только в том случае, если цель состоит в минимизации общего количества кусков, это может улучшить производительность запросов в ReplacingMergeTree за счет уменьшения количества кусков, требующих слияния во время запроса.

Это поведение можно дополнительно настроить, установив min_age_to_force_merge_on_partition_only=true, требуя, чтобы все куски в партиции были старше min_age_to_force_merge_seconds для агрессивного слияния. Эта конфигурация позволяет старым партициям со временем объединяться в один кусок, что консолидирует данные и поддерживает производительность запросов.

### Рекомендуемые настройки {#recommended-settings}

:::warning
Настройка поведения слияний является продвинутой операцией. Мы рекомендуем проконсультироваться со службой поддержки ClickHouse перед включением этих настроек в производственных нагрузках.
:::

В большинстве случаев предпочтительно устанавливать min_age_to_force_merge_seconds на низкое значение — значительно меньше периода партиционирования. Это минимизирует количество кусков и предотвращает избыточное слияние во время запроса с оператором FINAL.

Например, рассмотрим месячную партицию, которая уже была объединена в один кусок. Если небольшая случайная вставка создает новый кусок в этой партиции, производительность запросов может пострадать, поскольку ClickHouse должен читать несколько кусков до завершения слияния. Установка min_age_to_force_merge_seconds может обеспечить агрессивное слияние этих кусков, предотвращая снижение производительности запросов.
