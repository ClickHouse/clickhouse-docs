---
slug: /guides/sre/scaling-clusters
sidebar_label: 'Ребалансировка шардов'
sidebar_position: 20
description: 'ClickHouse не поддерживает автоматическую ребалансировку шардов, поэтому мы приводим рекомендации по тому, как выполнять ребалансировку шардов.'
title: 'Ребалансировка данных'
doc_type: 'guide'
keywords: ['scaling', 'clusters', 'horizontal scaling', 'capacity planning', 'performance']
---

# Перебалансировка данных

ClickHouse не поддерживает автоматическую перебалансировку шардов. Однако существуют способы перебалансировать шарды в следующем порядке предпочтения:

1. Настроить шард для [распределённой таблицы](/engines/table-engines/special/distributed.md), чтобы направлять большее количество записей на новый шард. Это потенциально может привести к дисбалансу нагрузки и «горячим» точкам в кластере, но может быть приемлемо в большинстве сценариев, где пропускная способность по записи не крайне высока. Это не требует от пользователя изменения целевой таблицы для записи, т.е. можно по-прежнему писать в распределённую таблицу. Этот подход не помогает при перебалансировке уже существующих данных.

2. В качестве альтернативы пункту (1), изменить конфигурацию существующего кластера и записывать данные исключительно на новый шард до тех пор, пока кластер не будет сбалансирован, — фактически вручную регулируя распределение записей. Имеет те же ограничения, что и пункт (1).

3. Если необходимо перебалансировать уже существующие данные и они разбиты на партиции, рассмотрите возможность отсоединения партиций и их ручного переноса на другой узел с последующим присоединением к новому шарду. Это более ручной подход, чем последующие техники, но он может быть быстрее и менее ресурсоёмким. Это ручная операция и, следовательно, при её выполнении необходимо отдельно продумывать стратегию перебалансировки данных.

4. Экспортировать данные из исходного кластера в новый кластер с помощью [INSERT FROM SELECT](/sql-reference/statements/insert-into.md/#inserting-the-results-of-select). Этот способ будет недостаточно производительным на очень больших наборах данных и потенциально приведёт к значительной нагрузке на подсистему ввода-вывода исходного кластера, а также к существенному потреблению сетевых ресурсов. Это следует рассматривать как крайнюю меру.