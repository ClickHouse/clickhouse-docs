---
'description': 'ClickHouse 아키텍처와 그 컬럼형 디자인에 대한 포괄적인 개요'
'sidebar_label': '아키텍처 개요'
'sidebar_position': 50
'slug': '/development/architecture'
'title': '아키텍처 개요'
'doc_type': 'reference'
---


# 아키텍처 개요

ClickHouse는 진정한 컬럼 지향 DBMS입니다. 데이터는 컬럼별로 저장되며, 배열(컬럼 벡터 또는 청크)의 실행 중에 처리됩니다. 가능한 경우, 작업은 개별 값이 아닌 배열에서 파생되어 수행됩니다. 이를 "벡터화된 쿼리 실행"이라고 하며, 실제 데이터 처리의 비용을 낮추는 데 도움을 줍니다.

이 아이디어는 새롭지 않습니다. 이는 `APL`(A programming language, 1957)과 그 후손인 `A +`(APL 방언), `J`(1990), `K`(1993) 및 `Q`(Kx Systems의 프로그래밍 언어, 2003)로 거슬러 올라갑니다. 배열 프로그래밍은 과학 데이터 처리에 사용됩니다. 관계형 데이터베이스에서도 이 아이디어는 낯선 것이 아닙니다. 예를 들어, `VectorWise` 시스템(Actian Corporation의 Actian Vector Analytic Database라고도 알려짐)에서 사용됩니다.

쿼리 처리를 가속화하는 두 가지 접근 방식이 있습니다: 벡터화된 쿼리 실행과 런타임 코드 생성. 후자는 모든 간접 참조와 동적 배치를 제거합니다. 이 두 접근 방식 중 어느 하나가 다른 것보다 우수하다고 할 수는 없습니다. 런타임 코드 생성은 많은 작업을 융합하여 CPU 실행 장치와 파이프라인을 완전히 활용할 수 있을 때 더 나은 경우가 있습니다. 벡터화된 쿼리 실행은 일시적인 벡터가 캐시에 쓰여지고 다시 읽혀야 하므로 덜 실용적일 수 있습니다. 만약 임시 데이터가 L2 캐시에 맞지 않으면 문제가 발생합니다. 그러나 벡터화된 쿼리 실행은 CPU의 SIMD 기능을 더 쉽게 활용합니다. 우리 친구들이 쓴 [연구 논문](http://15721.courses.cs.cmu.edu/spring2016/papers/p5-sompolski.pdf)은 두 접근 방식을 결합하는 것이 더 낫다는 것을 보여줍니다. ClickHouse는 벡터화된 쿼리 실행을 사용하며 런타임 코드 생성을 위한 초기 지원이 제한적입니다.

## 컬럼 {#columns}

`IColumn` 인터페이스는 메모리 내 컬럼(사실상 컬럼 청크)을 나타내는 데 사용됩니다. 이 인터페이스는 다양한 관계형 연산자의 구현을 위한 도우미 메서드를 제공합니다. 거의 모든 작업은 불변입니다: 원래 컬럼을 수정하는 것이 아니라 수정된 새로운 컬럼을 생성합니다. 예를 들어 `IColumn :: filter` 메서드는 필터 바이트 마스크를 수용합니다. 이는 `WHERE` 및 `HAVING` 관계형 연산자에 사용됩니다. 추가 예로는 `ORDER BY`를 지원하기 위한 `IColumn :: permute` 메서드와 `LIMIT`을 지원하기 위한 `IColumn :: cut` 메서드가 있습니다.

다양한 `IColumn` 구현(`ColumnUInt8`, `ColumnString` 등)은 컬럼의 메모리 레이아웃을 담당합니다. 메모리 레이아웃은 보통 연속 배열입니다. 정수형 타입의 컬럼에 대해서는 `std :: vector`와 같은 하나의 연속 배열입니다. `String` 및 `Array` 컬럼의 경우, 모든 배열 요소를 연속적으로 배치한 하나의 벡터와 각 배열의 시작에 대한 오프셋을 위한 두 번째 벡터로 구성됩니다. 또한 단 하나의 값을 메모리에 저장하지만 컬럼처럼 보이는 `ColumnConst`도 있습니다.

## 필드 {#field}

그럼에도 불구하고 개별 값으로 작업하는 것도 가능합니다. 개별 값을 나타내기 위해 `Field`가 사용됩니다. `Field`는 `UInt64`, `Int64`, `Float64`, `String` 및 `Array`의 차별화된 합집합입니다. `IColumn`은 n번째 값을 `Field`로 가져오기 위한 `operator []` 메서드와 `Field`를 컬럼 끝에 추가하기 위한 `insert` 메서드를 가지고 있습니다. 이러한 메서드는 개별 값을 나타내는 임시 `Field` 객체를 처리해야 하므로 매우 효율적이지 않습니다. 더 효율적인 방법으로는 `insertFrom`, `insertRangeFrom` 등이 있습니다.

`Field`는 특정 데이터 타입에 대한 충분한 정보를 저장하지 않습니다. 예를 들어, `UInt8`, `UInt16`, `UInt32`, `UInt64`는 모두 `Field`에서 `UInt64`로 표현됩니다.

## 누수 추상화 {#leaky-abstractions}

`IColumn`은 데이터에 대한 공통적인 관계형 변환을 위한 메서드를 가지고 있지만, 모든 요구를 충족하지는 않습니다. 예를 들어, `ColumnUInt64`는 두 컬럼의 합을 계산하는 메서드를 가지지 않으며, `ColumnString`은 부분 문자열 검색을 실행하는 메서드를 가지지 않습니다. 이러한 수많은 루틴은 `IColumn` 외부에서 구현됩니다.

컬럼에 대한 다양한 함수는 `IColumn` 메서드를 사용하여 `Field` 값을 추출하거나, 특정 `IColumn` 구현에서 데이터를 내부 메모리 레이아웃을 알고 전문화된 방법으로 구현할 수 있습니다. 이는 특정 `IColumn` 타입으로 캐스팅된 함수에 의해 구현되며, 내부 표현과 직접적으로 상호작용합니다. 예를 들어 `ColumnUInt64`에는 내부 배열에 대한 참조를 반환하는 `getData` 메서드가 있으며, 이후 별도의 루틴이 그 배열을 직접 읽거나 채웁니다. 우리는 다양한 루틴의 효율적인 특화를 허용하는 "누수 추상화"가 있습니다.

## 데이터 타입 {#data_types}

`IDataType`는 직렬화 및 역직렬화에 책임이 있습니다: 이진 또는 텍스트 형태로 컬럼 청크 또는 개별 값을 읽고 쓰기 위해. `IDataType`는 테이블의 데이터 타입과 직접적으로 대응합니다. 예를 들어, `DataTypeUInt32`, `DataTypeDateTime`, `DataTypeString` 등이 있습니다.

`IDataType`와 `IColumn`은 서로 느슨하게 연관되어 있습니다. 서로 다른 데이터 타입은 동일한 `IColumn` 구현에 의해 메모리에서 표현될 수 있습니다. 예를 들어 `DataTypeUInt32`와 `DataTypeDateTime`은 모두 `ColumnUInt32` 또는 `ColumnConstUInt32`로 표현됩니다. 게다가, 동일한 데이터 타입은 서로 다른 `IColumn` 구현으로 표현될 수 있습니다. 예를 들어 `DataTypeUInt8`는 `ColumnUInt8` 또는 `ColumnConstUInt8`로 표현될 수 있습니다.

`IDataType`는 메타데이터만 저장합니다. 예를 들어 `DataTypeUInt8`는 아무것도 저장하지 않으며(가상 포인터 `vptr` 제외), `DataTypeFixedString`은 고정 크기 문자열의 크기인 `N`만 저장합니다.

`IDataType`는 다양한 데이터 형식에 대한 도우미 메서드를 가지고 있습니다. 예를 들어, 쿼팅이 가능한 값 직렬화, JSON 형식으로 값 직렬화 및 XML 형식의 일부로 값 직렬화하는 메서드가 있습니다. 데이터 형식과의 직접적인 대응은 없습니다. 예를 들어, 서로 다른 데이터 형식인 `Pretty`와 `TabSeparated`는 `IDataType` 인터페이스의 `serializeTextEscaped` 도우미 메서드를 사용할 수 있습니다.

## 블록 {#block}

`Block`은 메모리 내 테이블의 부분 집합(청크)을 나타내는 컨테이너입니다. 이는 단순히 `(IColumn, IDataType, 컬럼 이름)`의 세트입니다. 쿼리 실행 중 데이터는 `Block`을 통해 처리됩니다. `Block`이 있으면, 데이터가 있으며(`IColumn` 객체에서), 해당 컬럼을 처리하는 방법을 나타내는 타입 정보가 있습니다(`IDataType` 내) 및 우리가 가진 컬럼 이름이 있습니다. 이는 테이블의 원래 컬럼 이름일 수도 있고, 계산의 임시 결과를 얻기 위해 할당된 인위적인 이름일 수도 있습니다.

우리가 블록 내의 컬럼에 대한 함수 일부를 계산할 때, 그 결과와 함께 블록에 다른 컬럼을 추가하며, 함수의 인수를 위한 컬럼은 수정되지 않기 때문에 작업은 불변적입니다. 나중에 불필요한 컬럼은 블록에서 제거될 수 있지만 수정되지는 않습니다. 이는 공통 하위 표현식을 제거하는 데 편리합니다.

블록은 처리된 데이터 청크마다 생성됩니다. 동일한 계산 유형에 대해 다른 블록에 대한 컬럼 이름 및 타입은 동일하게 유지되며, 단지 컬럼 데이터만 변경됩니다. 블록의 데이터는 블록 헤더와 분리하는 것이 좋습니다. 작은 블록 크기는 shared_ptrs 및 컬럼 이름을 복사하기 위해 임시 문자열의 높은 오버헤드를 발생시킵니다.

## 프로세서 {#processors}

[https://github.com/ClickHouse/ClickHouse/blob/master/src/Processors/IProcessor.h](https://github.com/ClickHouse/ClickHouse/blob/master/src/Processors/IProcessor.h)에서 설명을 참조하십시오.

## 형식 {#formats}

데이터 형식은 프로세서로 구현됩니다.

## I/O {#io}

바이트 지향 입력/출력을 위해 `ReadBuffer` 및 `WriteBuffer` 추상 클래스가 있습니다. 이들은 C++ `iostream` 대신 사용됩니다. 걱정 마세요: 모든 성숙한 C++ 프로젝트는 좋은 이유로 `iostream`이 아닌 다른 무언가를 사용하고 있습니다.

`ReadBuffer` 및 `WriteBuffer`는 연속 버퍼와 그 버퍼 내의 위치를 가리키는 커서입니다. 구현은 버퍼에 대한 메모리를 소유하거나 소유하지 않을 수 있습니다. 다음 데이터를 버퍼로 채우거나(`ReadBuffer`의 경우) 버퍼를 어딘가로 비우는(WriteBuffer의 경우) 가상 메서드가 있습니다. 이 가상 메서드는 거의 호출되지 않습니다.

`ReadBuffer`/`WriteBuffer`의 구현은 파일, 파일 디스크립터 및 네트워크 소켓과 작업하는 데 사용되며, 압축을 구현하기 위해(`CompressedWriteBuffer`는 다른 WriteBuffer로 초기화되며 데이터 작성을 수행하기 전에 압축을 수행함), 기타 목적을 위해 사용됩니다 – `ConcatReadBuffer`, `LimitReadBuffer`, `HashingWriteBuffer`라는 이름은 그 자체로 충분합니다.

Read/WriteBuffers는 바이트만 처리합니다. 입력/출력을 포맷팅하는 데 도움이 되는 `ReadHelpers` 및 `WriteHelpers` 헤더 파일의 함수가 있습니다. 예를 들어, 10진수 형식으로 숫자를 작성하는 도우미가 있습니다.

이제 `JSON` 형식으로 결과 집합을 stdout에 작성하려고 할 때 발생하는 일을 살펴보겠습니다. 
당신은 풀링 `QueryPipeline`에서 가져올 준비가 된 결과 집합이 있습니다. 
먼저, `WriteBufferFromFileDescriptor(STDOUT_FILENO)`를 생성하여 stdout에 바이트를 작성합니다. 
다음으로, 그 `WriteBuffer`로 초기화된 `JSONRowOutputFormat`에 쿼리 파이프라인의 결과를 연결하여 JSON 형식으로 stdout에 행을 작성합니다. 
이는 `complete` 메서드를 통해 수행될 수 있으며, 이를 통해 풀링 `QueryPipeline`이 완료된 `QueryPipeline`으로 전환됩니다.
내부적으로 `JSONRowOutputFormat`는 여러 JSON 구분자를 작성하고 `IDataType::serializeTextJSON` 메서드를 `IColumn`에 대한 참조 및 행 번호를 인수로 호출합니다. 결과적으로, `IDataType::serializeTextJSON`은 `WriteHelpers.h`의 메서드를 호출합니다: 예를 들어 숫자 유형에 대해서는 `writeText`, `DataTypeString`에 대해서는 `writeJSONString`을 호출합니다.

## 테이블 {#tables}

`IStorage` 인터페이스는 테이블을 나타냅니다. 해당 인터페이스의 다른 구현은 다양한 테이블 엔진입니다. 예를 들어 `StorageMergeTree`, `StorageMemory` 등이 있습니다. 이러한 클래스의 인스턴스는 단순히 테이블입니다.

`IStorage`의 핵심 메서드는 `read` 및 `write`이며, `alter`, `rename`, `drop` 등의 메서드도 있습니다. `read` 메서드는 다음 인수를 수용합니다: 테이블에서 읽을 컬럼 집합, 고려할 `AST` 쿼리 및 원하는 스트림 수. 이는 `Pipe`를 반환합니다.

대부분의 경우, 읽기 메서드는 지정된 컬럼을 테이블에서 읽는 것만 책임지며, 다른 데이터 처리는 더 이상 처리하지 않습니다.
모든 후속 데이터 처리는 파이프라인의 다른 부분에서 처리됩니다.

하지만 주목할 만한 예외가 있습니다:

- AST 쿼리는 `read` 메서드에 전달되며, 테이블 엔진은 이를 사용하여 인덱스 사용을 유도하고 테이블에서 적은 데이터를 읽을 수 있습니다.
- 때때로 테이블 엔진은 특정 단계까지 데이터를 처리할 수 있습니다. 예를 들어 `StorageDistributed`는 원격 서버에 쿼리를 보내고, 그 서버들로부터 받은 데이터를 병합할 수 있는 단계까지 데이터 처리를 요청한 후, 그 전처리된 데이터를 반환할 수 있습니다. 쿼리 해석기는 이후 데이터 처리를 완료합니다.

테이블의 `read` 메서드는 여러 `Processors`로 구성된 `Pipe`를 반환할 수 있습니다. 이러한 `Processors`는 테이블에서 병렬로 읽을 수 있습니다.
이후 다양한 다른 변환(예: 표현식 평가 또는 필터링)과 연결할 수 있으며, 이들은 독립적으로 계산될 수 있습니다.
그리고 그 위에 `QueryPipeline`을 만들어 실행할 수 있습니다.

또한 `TableFunction`이 있습니다. 이는 쿼리의 `FROM` 절에서 사용하기 위해 임시 `IStorage` 객체를 반환하는 함수입니다.

자신의 테이블 엔진을 구현하는 방법을 빠르게 이해하려면, `StorageMemory`나 `StorageTinyLog`와 같은 간단한 것을 참고하십시오.

> `read` 메서드의 결과로 `IStorage`는 `QueryProcessingStage`를 반환합니다 – 저장소 내에서 이미 계산된 쿼리 부분에 대한 정보입니다.

## 파서 {#parsers}

수작업으로 작성된 재귀적 하강 파서는 쿼리를 분석합니다. 예를 들어, `ParserSelectQuery`는 단순히 쿼리의 다양한 부분에 대한 기본 파서를 재귀적으로 호출합니다. 파서는 `AST`를 생성합니다. `AST`는 `IAST`의 인스턴스인 노드를 통해 표현됩니다.

> 역사적인 이유로 파서 생성기는 사용되지 않습니다.

## 인터프리터 {#interpreters}

인터프리터는 AST로부터 쿼리 실행 파이프라인을 생성하는 역할을 합니다. `InterpreterExistsQuery`, `InterpreterDropQuery`와 같은 간단한 인터프리터와 더 정교한 `InterpreterSelectQuery`가 있습니다.

쿼리 실행 파이프라인은 청크(특정 타입의 컬럼 집합)를 소비하고 생성할 수 있는 프로세서의 조합입니다.
프로세서는 포트를 통해 통신하며, 여러 입력 포트와 여러 출력 포트를 가질 수 있습니다.
더 자세한 설명은 [src/Processors/IProcessor.h](https://github.com/ClickHouse/ClickHouse/blob/master/src/Processors/IProcessor.h)에서 확인할 수 있습니다.

예를 들어 `SELECT` 쿼리를 해석한 결과는 결과 집합을 읽기 위한 특별한 출력 포트를 가진 "풀링" `QueryPipeline`입니다.
`INSERT` 쿼리의 결과는 데이터를 삽입하기 위해 작성하는 입력 포트를 가진 "푸시" `QueryPipeline`입니다.
그리고 `INSERT SELECT` 쿼리를 해석한 결과는 입력 및 출력이 없는 "완료된" `QueryPipeline`입니다.

## Merge tree {#merge-tree}

`MergeTree`는 기본 키로 인덱싱을 지원하는 스토리지 엔진 패밀리입니다. 기본 키는 임의의 컬럼 또는 표현의 튜플일 수 있습니다. `MergeTree` 테이블의 데이터는 "파트"에 저장됩니다. 각 파트는 기본 키 순서로 데이터를 저장하며, 따라서 데이터는 기본 키 튜플에 따라 사전식으로 정렬됩니다. 모든 테이블 컬럼은 이러한 파트의 별도의 `column.bin` 파일에 저장됩니다. 파일은 압축된 블록으로 구성됩니다. 각 블록은 평균 값 크기에 따라 보통 64 KB에서 1 MB의 압축되지 않은 데이터로 구성됩니다. 블록은 컬럼 값이 서로 붙어 있는 상태로 배치됩니다. 각각의 컬럼에 대해 컬럼 값은 동일한 순서로 존재하므로 (기본 키가 순서를 정의), 여러 컬럼을 반복하면 해당 행에 대한 값을 얻을 수 있습니다.

기본 키 자체는 "스파스"입니다. 모든 단일 행을 다루는 것이 아니라 일부 데이터 범위만 다룹니다. 별도의 `primary.idx` 파일에는 N 번째 행마다 기본 키의 값이 저장되어 있으며, 여기서 N은 `index_granularity`로 호출됩니다 (보통, N = 8192). 또한 각 컬럼에 대해 `column.mrk` 파일이 있으며, 여기에는 데이터 파일의 각 N 번째 행에 대한 오프셋인 "마크"가 포함됩니다. 각 마크는 압축 블록의 시작으로의 파일 내 오프셋과 압축 해제된 블록의 데이터 시작으로의 오프셋을 포함하는 쌍입니다. 보통, 압축 블록은 마크에 의해 정렬되며, 압축 해제된 블록의 오프셋은 0입니다. `primary.idx`의 데이터는 항상 메모리에 존재하며, `column.mrk` 파일의 데이터는 캐시됩니다.

`MergeTree`에서 파트의 내용을 읽으려고 할 때, 우리는 `primary.idx` 데이터를 보고 요청된 데이터가 포함될 수 있는 범위를 찾은 다음 `column.mrk` 데이터를 살펴보며 해당 범위를 읽기 시작할 위치의 오프셋을 계산합니다. 스파스성 때문에 불필요한 데이터가 읽힐 수 있습니다. ClickHouse는 단순한 포인트 쿼리에 높은 부하가 적합하지 않으며, 각 키마다 `index_granularity` 행의 전체 범위를 읽어야 하고 각 컬럼마다 전체 압축 블록을 압축 해제해야 합니다. 우리는 인덱스에 대해 눈에 띄는 메모리 소모 없이 단일 서버당 수조 개의 행을 유지할 수 있어야 하므로 인덱스를 스파스로 만들었습니다. 또한, 기본 키가 스파스하기 때문에 유일하지 않습니다: INSERT 시점에 테이블에서 키의 존재를 확인할 수 없습니다. 테이블에 동일한 키를 가진 여러 행이 있을 수 있습니다.

`MergeTree`에 데이터 묶음을 `INSERT`하면, 해당 묶음은 기본 키 순서에 따라 정렬되어 새로운 파트를 형성합니다. 주기적으로 일부 파트를 선택하여 단일 정렬된 파트로 병합하는 백그라운드 스레드가 있습니다. 그래서 이것을 `MergeTree`라고 부릅니다. 물론 병합은 "쓰기 증폭"으로 이어집니다. 모든 파트는 불변입니다: 생성되거나 삭제될 뿐 수정되지 않습니다. SELECT가 실행될 때, 테이블의 스냅샷(파트 집합)을 보유합니다. 병합 후, 실패 복구를 쉽게 하기 위해 일정 시간 동안 이전 파트를 유지하므로, 병합된 파트가 손상된 것으로 보일 경우 원본 파트로 교체할 수 있습니다.

`MergeTree`는 LSM 트리가 아닙니다. 왜냐하면 MEMTABLE과 LOG가 포함되어 있지 않기 때문입니다: 삽입된 데이터는 파일 시스템에 직접 기록됩니다. 이 동작 때문에 MergeTree는 배치로 데이터를 삽입하는 데 훨씬 더 적합합니다. 따라서 소량의 행을 자주 삽입하는 것은 MergeTree에 이상적이지 않습니다. 예를 들어, 초당 몇 개의 행 삽입은 괜찮지만, 초당 1000번 하는 것은 MergeTree에 최적이 아닙니다. 그러나 이 제한을 극복하기 위해 소량 삽입을 위한 비동기 삽입 모드가 있습니다. 우리는 간단함을 위해 이 방식을 채택했으며, 이미 우리 애플리케이션에서 배치로 데이터를 삽입하고 있기 때문입니다.

백그라운드 병합 중 추가 작업을 수행하는 MergeTree 엔진도 있습니다. 예로는 `CollapsingMergeTree`와 `AggregatingMergeTree`가 있습니다. 이는 업데이트에 대한 특별한 지원으로 간주될 수 있습니다. 이러한 것은 실제 업데이트가 아닙니다. 왜냐하면 사용자가 보통 백그라운드 병합이 실행되는 시간을 제어할 수 없고, `MergeTree` 테이블의 데이터는 거의 항상 여러 파트에 저장되기 때문입니다.

## Replication {#replication}

ClickHouse의 복제는 테이블별로 구성할 수 있습니다. 같은 서버에서 일부 테이블은 복제되고 일부는 복제되지 않을 수 있습니다. 또한, 두 개의 팩터 복제 및 세 개의 팩터 복제로 복제되는 서로 다른 방식의 테이블을 가질 수 있습니다.

복제는 `ReplicatedMergeTree` 스토리지 엔진에서 구현됩니다. `ZooKeeper`의 경로는 스토리지 엔진의 매개변수로 지정됩니다. `ZooKeeper`에서 동일한 경로를 가진 모든 테이블은 서로의 복제본이 되어 데이터를 동기화하고 일관성을 유지합니다. 복제본은 테이블을 생성하거나 삭제하여 동적으로 추가 및 제거할 수 있습니다.

복제는 비동기 다중 마스터 방식으로 구현됩니다. `ZooKeeper`와 세션이 있는 모든 복제본에 데이터를 삽입할 수 있으며, 데이터는 비동기적으로 모든 다른 복제본에 복제됩니다. ClickHouse는 UPDATE를 지원하지 않으므로 복제는 충돌이 없습니다. 기본적으로 삽입에 대한 쿼럼 인지는 없으므로 한 노드가 실패할 경우 방금 삽입된 데이터가 손실될 수 있습니다. `insert_quorum` 설정을 사용하여 삽입 쿼럼을 활성화할 수 있습니다.

복제를 위한 메타데이터는 ZooKeeper에 저장됩니다. 어떤 작업을 수행할지 나열하는 복제 로그가 있습니다. 작업은: 파트 가져오기; 파트 병합; 파티션 삭제 등입니다. 각 복제본은 복제 로그를 자신의 대기열에 복사한 후 대기열에서 작업을 실행합니다. 예를 들어, 삽입 시 "파트 가져오기" 작업이 로그에 생성되고, 모든 복제본이 해당 파트를 다운로드합니다. 병합은 바이트 동일한 결과를 얻기 위해 복제본 간에 조정됩니다. 모든 파트는 모든 복제본에서 동일한 방식으로 병합됩니다. 리더 중 하나가 먼저 새 병합을 시작하고 "부품 병합" 작업을 로그에 기록합니다. 여러 복제본(또는 모두)이 동시에 리더가 될 수 있습니다. 복제본이 리더가 되는 것을 방지하려면 `merge_tree` 설정 `replicated_can_become_leader`를 사용할 수 있습니다. 리더는 백그라운드 병합 일정을 계획하는 책임이 있습니다.

복제는 물리적입니다: 쿼리가 아닌 압축된 파트만 노드 간에 전송됩니다. 대다수의 경우 병합은 각 복제본에서 독립적으로 처리되어 네트워크 증폭을 피함으로써 네트워크 비용을 줄입니다. 대규모 병합된 파트는 의미 있는 복제 지연이 있는 경우에만 네트워크를 통해 전송됩니다.

또한, 각 복제본은 ZooKeeper에 파트 집합과 그 체크섬으로 자신의 상태를 저장합니다. 로컬 파일 시스템의 상태가 ZooKeeper의 참조 상태와 다를 경우, 복제본은 다른 복제본에서 누락되거나 손상된 파트를 다운로드하여 일관성을 복원합니다. 로컬 파일 시스템에 예기치 않은 데이터나 손상된 데이터가 있을 경우, ClickHouse는 이를 제거하지 않고 별도의 디렉토리로 이동하여 잊어버립니다.

:::note
ClickHouse 클러스터는 독립적인 샤드로 구성되며, 각 샤드는 복제본으로 구성됩니다. 클러스터는 **탄력적이지 않으므로**, 새 샤드를 추가한 후 데이터가 자동으로 샤드 간에 재조정되지 않습니다. 대신 클러스터의 부하는 고르게 조정되지 않는 것으로 설정됩니다. 이 구현은 더 많은 제어를 제공하며, 몇 개의 노드와 같은 상대적으로 작은 클러스터에서는 괜찮습니다. 그러나 우리가 프로덕션에서 사용하는 수백 개의 노드가 있는 클러스터에는 이 접근 방식이 심각한 단점이 됩니다. 우리는 클러스터 전역에 걸쳐 동적으로 복제된 영역으로 자동으로 분할 및 균형을 맞출 수 있는 테이블 엔진을 구현해야 합니다.
:::
