---
'slug': '/integrations/data-ingestion-overview'
'keywords':
- 'Airbyte'
- 'Apache Spark'
- 'Spark'
- 'Azure Synapse'
- 'Amazon Glue'
- 'Apache Beam'
- 'dbt'
- 'Fivetran'
- 'NiFi'
- 'dlt'
- 'Vector'
'title': '데이터 수집'
'description': '데이터 수집 섹션의 랜딩 페이지'
'doc_type': 'landing-page'
---


# 데이터 수집

ClickHouse는 데이터 통합 및 변환을 위한 여러 솔루션과 통합됩니다. 
자세한 내용은 아래 페이지를 확인해 주세요:

| 데이터 수집 도구                                              | 설명                                                                                                                                                                                                                           |
|------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Airbyte](/integrations/airbyte)                                 | 오픈 소스 데이터 통합 플랫폼입니다. ELT 데이터 파이프라인을 생성할 수 있으며, 140개 이상의 즉시 사용 가능한 커넥터가 포함되어 있습니다.                                                                                   |
| [Apache Spark](/integrations/apache-spark)                       | 단일 노드 머신 또는 클러스터에서 데이터 엔지니어링, 데이터 과학, 기계 학습을 실행하기 위한 다국어 엔진입니다.                                                                                                        |
| [Apache Flink](https://github.com/ClickHouse/flink-connector-clickhouse)                       | Flink의 DataStream API를 통한 ClickHouse로의 실시간 데이터 수집 및 처리로, 배치 쓰기를 지원합니다.                                                                                                        |
| [Amazon Glue](/integrations/glue)                                | Amazon Web Services(AWS)에서 제공하는 완전 관리형 서버리스 데이터 통합 서비스로, 분석, 기계 학습 및 애플리케이션 개발을 위한 데이터 탐색, 준비 및 변환 프로세스를 간소화합니다.                                     |
| [Azure Synapse](/integrations/azure-synapse)                     | Microsoft Azure에서 제공하는 완전 관리형 클라우드 기반 분석 서비스로, SQL, Apache Spark 및 데이터 파이프라인을 사용하여 대규모 데이터 통합, 변환 및 분석을 간소화합니다. |
| [Azure Data Factory](/integrations/azure-data-factory)           | 대규모 데이터 워크플로우를 생성, 예약 및 조율할 수 있는 클라우드 기반 데이터 통합 서비스입니다. |
| [Apache Beam](/integrations/apache-beam)                         | 배치 및 스트림(연속) 데이터 처리 파이프라인을 정의하고 실행할 수 있는 오픈 소스 통합 프로그래밍 모델입니다.                                                                                 |
| [BladePipe](/integrations/bladepipe)                             | 초단위 지연으로 플랫폼 간 원활한 데이터 흐름을 촉진하는 실시간 엔드투엔드 데이터 통합 도구입니다.                                                                                |
| [dbt](/integrations/dbt)                                         | 분석 엔지니어가 선택 구문을 작성하여 데이터 웨어하우스의 데이터를 변환할 수 있도록 합니다.                                                                                                                                |
| [dlt](/integrations/data-ingestion/etl-tools/dlt-and-clickhouse) | 다양한 종종 엉망인 데이터 소스에서 잘 구조화되고 실시간 데이터 세트로 데이터를 로드하기 위해 Python 스크립트에 추가할 수 있는 오픈 소스 라이브러리입니다.                                                                            |
| [Fivetran](/integrations/fivetran)                               | 클라우드 데이터 플랫폼 사이에서 데이터의 이동을 자동화하는 데이터 이동 플랫폼입니다.                                                                                                                                    |
| [NiFi](/integrations/nifi)                                       | 소프트웨어 시스템 간 데이터 흐름을 자동화하기 위해 설계된 오픈 소스 워크플로우 관리 소프트웨어입니다.                                                                                                                                  |
| [Vector](/integrations/vector)                                   | 조직이 관찰 가능성 데이터를 제어할 수 있도록 하는 고성능 관찰 가능성 데이터 파이프라인입니다.                                                                                                                        |
