---
'title': '세션 설정'
'sidebar_label': '세션 설정'
'slug': '/operations/settings/settings'
'toc_max_heading_level': 2
'description': '``system.settings`` 테이블에 있는 설정.'
'doc_type': 'reference'
---

import ExperimentalBadge from '@theme/badges/ExperimentalBadge';
import BetaBadge from '@theme/badges/BetaBadge';
import CloudOnlyBadge from '@theme/badges/CloudOnlyBadge';
import SettingsInfoBlock from '@theme/SettingsInfoBlock/SettingsInfoBlock';
import VersionHistory from '@theme/VersionHistory/VersionHistory';

<!-- Autogenerated -->
모든 아래 설정은 테이블 [system.settings](/docs/operations/system-tables/settings)에서도 사용할 수 있습니다. 이러한 설정은 [source](https://github.com/ClickHouse/ClickHouse/blob/master/src/Core/Settings.cpp)에서 자동 생성되었습니다.

## add_http_cors_header {#add_http_cors_header} 

<SettingsInfoBlock type="Bool" default_value="0" />

HTTP CORS 헤더를 추가합니다.
## additional_result_filter {#additional_result_filter} 

`SELECT` 쿼리의 결과에 적용할 추가 필터 표현식입니다.
이 설정은 어떠한 서브쿼리에도 적용되지 않습니다.

**예제**

```sql
INSERT INTO table_1 VALUES (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');
SElECT * FROM table_1;
```
```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 2 │ bb   │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```
```sql
SELECT *
FROM table_1
SETTINGS additional_result_filter = 'x != 2'
```
```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```
## additional_table_filters {#additional_table_filters} 

<SettingsInfoBlock type="Map" default_value="{}" />

지정된 테이블에서 읽은 후에 적용되는 추가 필터 표현식입니다.

**예제**

```sql
INSERT INTO table_1 VALUES (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');
SELECT * FROM table_1;
```
```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 2 │ bb   │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```
```sql
SELECT *
FROM table_1
SETTINGS additional_table_filters = {'table_1': 'x != 2'}
```
```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```
## aggregate_functions_null_for_empty {#aggregate_functions_null_for_empty} 

<SettingsInfoBlock type="Bool" default_value="0" />

쿼리에서 모든 집계 함수를 재작성하고 [-OrNull](/sql-reference/aggregate-functions/combinators#-ornull) 접미사를 추가하는 기능을 활성화하거나 비활성화합니다. SQL 표준 호환성을 위해 이 기능을 활성화합니다.
이는 일관된 결과를 얻기 위해 쿼리 재작성 방식으로 구현됩니다 (분산 쿼리에 대한 [count_distinct_implementation](#count_distinct_implementation) 설정과 유사).

가능한 값:

- 0 — 비활성화됨.
- 1 — 활성화됨.

**예제**

다음의 집계 함수가 포함된 쿼리를 고려해 보십시오:
```sql
SELECT SUM(-1), MAX(0) FROM system.one WHERE 0;
```

`aggregate_functions_null_for_empty = 0`일 경우 생성된 결과는 다음과 같습니다:
```text
┌─SUM(-1)─┬─MAX(0)─┐
│       0 │      0 │
└─────────┴────────┘
```

`aggregate_functions_null_for_empty = 1`일 경우 결과는 다음과 같습니다:
```text
┌─SUMOrNull(-1)─┬─MAXOrNull(0)─┐
│          NULL │         NULL │
└───────────────┴──────────────┘
```
## aggregation_in_order_max_block_bytes {#aggregation_in_order_max_block_bytes} 

<SettingsInfoBlock type="UInt64" default_value="50000000" />

기본 키 순서로 집계 중 수집된 블록의 최대 바이트 크기입니다. 블록 크기가 작을수록 집계의 최종 병합 단계를 더 병렬화할 수 있습니다.
## aggregation_memory_efficient_merge_threads {#aggregation_memory_efficient_merge_threads} 

<SettingsInfoBlock type="UInt64" default_value="0" />

메모리 효율적인 모드에서 병합된 중간 집계 결과에 사용할 스레드 수입니다. 더 크면 더 많은 메모리를 소비합니다. 0은 'max_threads'와 동일합니다.
## allow_aggregate_partitions_independently {#allow_aggregate_partitions_independently} 

<SettingsInfoBlock type="Bool" default_value="0" />

파티션 키가 그룹화 키에 적합할 때 서로 다른 스레드에서 파티션의 독립적인 집계를 활성화합니다. 파티션 수가 코어 수에 가까워지고 파티션의 크기가 대략 동일할 때 유리합니다.
## allow_archive_path_syntax {#allow_archive_path_syntax} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "1"},{"label": "Added new setting to allow disabling archive path syntax."}]}, {"id": "row-2","items": [{"label": "24.5"},{"label": "1"},{"label": "Added new setting to allow disabling archive path syntax."}]}]}/>

파일/S3 엔진/테이블 함수는 아카이브가 올바른 확장자를 가진 경우, `::`로 경로를 `<archive>::<file>`로 파싱합니다.
## allow_asynchronous_read_from_io_pool_for_merge_tree {#allow_asynchronous_read_from_io_pool_for_merge_tree} 

<SettingsInfoBlock type="Bool" default_value="0" />

배경 I/O 풀을 사용하여 MergeTree 테이블에서 읽습니다. 이 설정은 I/O 바운드 쿼리의 성능을 높일 수 있습니다.
## allow_changing_replica_until_first_data_packet {#allow_changing_replica_until_first_data_packet} 

<SettingsInfoBlock type="Bool" default_value="0" />

활성화된 경우, 헤지 요청에서 이미 존재하는 연결을 시작하여 첫 번째 데이터 패킷을 수신할 때까지 새로운 연결을 시작할 수 있습니다 (하지만 진행 상태가 `receive_data_timeout` 제한으로 업데이트되지 않은 경우). 그렇지 않으면, 진행 상황을 처음으로 이룬 후 첫 번째 시간에 복제를 변경하는 것을 비활성화합니다.
## allow_create_index_without_type {#allow_create_index_without_type} 

<SettingsInfoBlock type="Bool" default_value="0" />

TYPE 없이 CREATE INDEX 쿼리를 허용합니다. 쿼리는 무시됩니다. SQL 호환성 테스트를 위해 만들어졌습니다.
## allow_custom_error_code_in_throwif {#allow_custom_error_code_in_throwif} 

<SettingsInfoBlock type="Bool" default_value="0" />

throwIf() 함수에서 사용자 정의 오류 코드를 활성화합니다. true로 설정하면 발생한 예외는 예상치 못한 오류 코드를 가질 수 있습니다.
## allow_ddl {#allow_ddl} 

<SettingsInfoBlock type="Bool" default_value="1" />

true로 설정하면 사용자가 DDL 쿼리를 실행할 수 있습니다.
## allow_deprecated_database_ordinary {#allow_deprecated_database_ordinary} 

<SettingsInfoBlock type="Bool" default_value="0" />

구식 Ordinary 엔진으로 데이터베이스 생성을 허용합니다.
## allow_deprecated_error_prone_window_functions {#allow_deprecated_error_prone_window_functions} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "0"},{"label": "Allow usage of deprecated error prone window functions (neighbor, runningAccumulate, runningDifferenceStartingWithFirstValue, runningDifference)"}]}]}/>

오류가 발생하기 쉬운 구식 윈도우 함수를 사용할 수 있도록 허용합니다 (neighbor, runningAccumulate, runningDifferenceStartingWithFirstValue, runningDifference).
## allow_deprecated_snowflake_conversion_functions {#allow_deprecated_snowflake_conversion_functions} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "Disabled deprecated functions snowflakeToDateTime[64] and dateTime[64]ToSnowflake."}]}]}/>

`snowflakeToDateTime`, `snowflakeToDateTime64`, `dateTimeToSnowflake`, 그리고 `dateTime64ToSnowflake` 함수는 구식이며 기본적으로 비활성화되어 있습니다.
전환 기간 동안 이러한 구식 함수를 다시 활성화하려면 이 설정을 `true`로 설정하십시오.
## allow_deprecated_syntax_for_merge_tree {#allow_deprecated_syntax_for_merge_tree} 

<SettingsInfoBlock type="Bool" default_value="0" />

구식 엔진 정의 구문으로 *MergeTree 테이블을 생성할 수 있도록 허용합니다.
## allow_distributed_ddl {#allow_distributed_ddl} 

<SettingsInfoBlock type="Bool" default_value="1" />

true로 설정하면 사용자가 분산 DDL 쿼리를 실행할 수 있습니다.
## allow_drop_detached {#allow_drop_detached} 

<SettingsInfoBlock type="Bool" default_value="0" />

ALTER TABLE ... DROP DETACHED PART[ITION] ... 쿼리를 허용합니다.
## allow_dynamic_type_in_join_keys {#allow_dynamic_type_in_join_keys} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "0"},{"label": "Disallow using Dynamic type in JOIN keys by default"}]}]}/>

JOIN 키에서 동적 유형을 사용할 수 있도록 허용합니다. 호환성을 위해 추가되었습니다. 동적 유형은 다른 유형과의 비교에서 예상치 못한 결과를 초래할 수 있기 때문에 JOIN 키에서 사용하는 것은 권장되지 않습니다.
## allow_execute_multiif_columnar {#allow_execute_multiif_columnar} 

<SettingsInfoBlock type="Bool" default_value="1" />

multiIf 함수를 컬럼형으로 실행할 수 있도록 허용합니다.
## allow_experimental_alias_table_engine {#allow_experimental_alias_table_engine} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.11"},{"label": "0"},{"label": "New setting"}]}]}/>

Alias 엔진으로 테이블을 생성할 수 있도록 허용합니다.
## allow_experimental_analyzer {#allow_experimental_analyzer} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "Enable analyzer and planner by default."}]}]}/>

새 쿼리 분석기를 사용할 수 있도록 허용합니다.
## allow_experimental_codecs {#allow_experimental_codecs} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

true로 설정하면 실험적 압축 코덱을 지정할 수 있도록 허용합니다 (그러나 현재 그런 것은 없습니다. 이 옵션은 아무런 효과가 없습니다).
## allow_experimental_correlated_subqueries {#allow_experimental_correlated_subqueries} 

<BetaBadge/>

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "1"},{"label": "Mark correlated subqueries support as Beta."}]}, {"id": "row-2","items": [{"label": "25.4"},{"label": "0"},{"label": "Added new setting to allow correlated subqueries execution."}]}]}/>

상관 서브쿼리를 실행할 수 있도록 허용합니다.
## allow_experimental_database_glue_catalog {#allow_experimental_database_glue_catalog} 

<BetaBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "0"},{"label": "Allow experimental database engine DataLakeCatalog with catalog_type = 'glue'"}]}]}/>

catalog_type = 'glue'인 실험적 데이터베이스 엔진 DataLakeCatalog를 사용할 수 있도록 허용합니다.
## allow_experimental_database_hms_catalog {#allow_experimental_database_hms_catalog} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "Allow experimental database engine DataLakeCatalog with catalog_type = 'hive'"}]}]}/>

catalog_type = 'hms'인 실험적 데이터베이스 엔진 DataLakeCatalog를 사용할 수 있도록 허용합니다.
## allow_experimental_database_iceberg {#allow_experimental_database_iceberg} 

<BetaBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "0"},{"label": "New setting."}]}]}/>

catalog_type = 'iceberg'인 실험적 데이터베이스 엔진 DataLakeCatalog를 사용할 수 있도록 허용합니다.
## allow_experimental_database_materialized_postgresql {#allow_experimental_database_materialized_postgresql} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

Engine=MaterializedPostgreSQL(...)로 데이터베이스 생성을 허용합니다.
## allow_experimental_database_unity_catalog {#allow_experimental_database_unity_catalog} 

<BetaBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "0"},{"label": "Allow experimental database engine DataLakeCatalog with catalog_type = 'unity'"}]}]}/>

catalog_type = 'unity'인 실험적 데이터베이스 엔진 DataLakeCatalog를 사용할 수 있도록 허용합니다.
## allow_experimental_delta_kernel_rs {#allow_experimental_delta_kernel_rs} 

<BetaBadge/>

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "New setting"}]}]}/>

실험적 delta-kernel-rs 구현을 사용할 수 있도록 허용합니다.
## allow_experimental_delta_lake_writes {#allow_experimental_delta_lake_writes} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

델타 커널 쓰기 기능을 활성화합니다.
## allow_experimental_full_text_index {#allow_experimental_full_text_index} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

실험적 텍스트 인텍스를 사용할 수 있도록 허용합니다.
## allow_experimental_funnel_functions {#allow_experimental_funnel_functions} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

퍼널 분석을 위한 실험적 함수를 활성화합니다.
## allow_experimental_hash_functions {#allow_experimental_hash_functions} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

실험적 해시 함수를 활성화합니다.
## allow_experimental_iceberg_compaction {#allow_experimental_iceberg_compaction} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting "}]}]}/>

아이스버그 테이블에 대해 'OPTIMIZE'를 명시적으로 사용하도록 허용합니다.
## allow_experimental_insert_into_iceberg {#allow_experimental_insert_into_iceberg} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

Iceberg로 `insert` 쿼리를 실행할 수 있도록 허용합니다.
## allow_experimental_join_right_table_sorting {#allow_experimental_join_right_table_sorting} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

true로 설정되면 `join_to_sort_minimum_perkey_rows` 및 `join_to_sort_maximum_table_rows` 조건이 충족될 때 키에 따라 오른쪽 테이블을 재정렬하여 왼쪽 또는 내부 해시 조인의 성능을 향상시킵니다.
## allow_experimental_kafka_offsets_storage_in_keeper {#allow_experimental_kafka_offsets_storage_in_keeper} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

ClickHouse Keeper에 Kafka 관련 오프셋을 저장하는 실험적 기능을 허용합니다. 활성화되면 Kafka 테이블 엔진에 ClickHouse Keeper 경로와 복제본 이름을 지정할 수 있습니다. 결과적으로 정규 Kafka 엔진 대신 ClickHouse Keeper에 커밋된 오프셋을 주로 저장하는 새로운 유형의 스토리지 엔진이 사용됩니다.
## allow_experimental_kusto_dialect {#allow_experimental_kusto_dialect} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

Kusto 쿼리 언어(KQL)를 활성화합니다 - SQL의 대안입니다.
## allow_experimental_materialized_postgresql_table {#allow_experimental_materialized_postgresql_table} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

MaterializedPostgreSQL 테이블 엔진을 사용할 수 있도록 허용합니다. 기본적으로 비활성화되어 있습니다. 이 기능은 실험적입니다.
## allow_experimental_nlp_functions {#allow_experimental_nlp_functions} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

자연어 처리를 위한 실험적 함수를 활성화합니다.
## allow_experimental_parallel_reading_from_replicas {#allow_experimental_parallel_reading_from_replicas} 

<BetaBadge/>

<SettingsInfoBlock type="UInt64" default_value="0" />

SELECT 쿼리 실행을 위해 각 샤드에서 최대 `max_parallel_replicas`의 복제본 수를 사용합니다. 읽기가 병렬화되고 동적으로 조정됩니다. 0 - 비활성화, 1 - 활성화, 실패할 경우 조용히 비활성화, 2 - 활성화, 실패할 경우 예외를 발생시킵니다.
## allow_experimental_prql_dialect {#allow_experimental_prql_dialect} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

PRQL을 활성화합니다 - SQL의 대안입니다.
## allow_experimental_qbit_type {#allow_experimental_qbit_type} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

[QBit](../../sql-reference/data-types/qbit.md) 데이터 유형을 생성할 수 있습니다.
## allow_experimental_query_deduplication {#allow_experimental_query_deduplication} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

파트 UUID를 기반으로 SELECT 쿼리에 대한 실험적 데이터 중복 제거 기능을 활성화합니다.
## allow_experimental_statistics {#allow_experimental_statistics} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

[통계](../../engines/table-engines/mergetree-family/mergetree.md/#table_engine-mergetree-creating-a-table)와 [통계 조작](../../engines/table-engines/mergetree-family/mergetree.md/#column-statistics)으로 정의된 컬럼을 정의할 수 있도록 허용합니다.
## allow_experimental_time_series_aggregate_functions {#allow_experimental_time_series_aggregate_functions} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

Prometheus와 유사한 시계열 리샘플링, 비율, 델타 계산을 위한 실험적 timeSeries* 집계 함수를 활성화합니다.
## allow_experimental_time_series_table {#allow_experimental_time_series_table} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

[TimeSeries](../../engines/table-engines/integrations/time-series.md) 테이블 엔진으로 테이블을 생성할 수 있도록 허용합니다. 가능한 값:
- 0 — [TimeSeries](../../engines/table-engines/integrations/time-series.md) 테이블 엔진이 비활성화됩니다.
- 1 — [TimeSeries](../../engines/table-engines/integrations/time-series.md) 테이블 엔진이 활성화됩니다.
## allow_experimental_time_time64_type {#allow_experimental_time_time64_type} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

[Time](../../sql-reference/data-types/time.md) 및 [Time64](../../sql-reference/data-types/time64.md) 데이터 유형을 생성할 수 있도록 허용합니다.
## allow_experimental_window_view {#allow_experimental_window_view} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

WINDOW VIEW를 활성화합니다. 충분히 성숙하지 않았습니다.
## allow_experimental_ytsaurus_dictionary_source {#allow_experimental_ytsaurus_dictionary_source} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

YTsaurus와의 통합을 위한 실험적 딕셔너리 소스입니다.
## allow_experimental_ytsaurus_table_engine {#allow_experimental_ytsaurus_table_engine} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

YTsaurus와의 통합을 위한 실험적 테이블 엔진입니다.
## allow_experimental_ytsaurus_table_function {#allow_experimental_ytsaurus_table_function} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

YTsaurus와의 통합을 위한 실험적 테이블 엔진입니다.
## allow_general_join_planning {#allow_general_join_planning} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "Allow more general join planning algorithm when hash join algorithm is enabled."}]}]}/>

보다 복잡한 조건을 처리할 수 있는 보다 일반적인 조인 계획 알고리즘을 허용합니다. 그러나 해시 조인에서만 작동합니다. 해시 조인이 활성화되지 않은 경우에는 이 설정의 값과 상관없이 일반 조인 계획 알고리즘이 사용됩니다.
## allow_get_client_http_header {#allow_get_client_http_header} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "Introduced a new function."}]}]}/>

현재 HTTP 요청 헤더의 값을 가져오는 `getClientHTTPHeader` 함수를 사용할 수 있도록 허용합니다. 보안상의 이유로 기본적으로 활성화되어 있지 않으며, `Cookie`와 같은 일부 헤더는 민감한 정보를 포함할 수 있기 때문입니다. `X-ClickHouse-*` 및 `Authentication` 헤더는 항상 제한되며 이 함수로 가져올 수 없습니다.
## allow_hyperscan {#allow_hyperscan} 

<SettingsInfoBlock type="Bool" default_value="1" />

Hyperscan 라이브러리를 사용하는 함수를 사용할 수 있도록 허용합니다. 잠재적인 긴 컴파일 시간과 과도한 리소스 사용을 피하기 위해 비활성화하십시오.
## allow_introspection_functions {#allow_introspection_functions} 

<SettingsInfoBlock type="Bool" default_value="0" />

쿼리 프로파일링을 위한 [내부 조사 함수](../../sql-reference/functions/introspection.md)를 활성화하거나 비활성화합니다.

가능한 값:

- 1 — 내부 조사 함수가 활성화되었습니다.
- 0 — 내부 조사 함수가 비활성화되었습니다.

**참조**

- [샘플링 쿼리 프로파일러](../../operations/optimizing-performance/sampling-query-profiler.md)
- 시스템 테이블 [trace_log](/operations/system-tables/trace_log)
## allow_materialized_view_with_bad_select {#allow_materialized_view_with_bad_select} 

<SettingsInfoBlock type="Bool" default_value="0" />

존재하지 않는 테이블이나 컬럼을 참조하는 SELECT 쿼리로 CREATE MATERIALIZED VIEW를 허용합니다. 여전히 구문적으로 유효해야 합니다. 갱신 가능한 MV에는 적용되지 않습니다. MV 스키마가 SELECT 쿼리에서 유추되어야 하는 경우(즉, CREATE에 컬럼 목록과 TO 테이블이 없을 경우)에는 적용되지 않습니다. 소스 테이블이 생성되지 않은 경우 MV를 만들 때 사용할 수 있습니다.
## allow_named_collection_override_by_default {#allow_named_collection_override_by_default} 

<SettingsInfoBlock type="Bool" default_value="1" />

기본적으로 명명된 컬렉션의 필드 재정의를 허용합니다.
## allow_non_metadata_alters {#allow_non_metadata_alters} 

<SettingsInfoBlock type="Bool" default_value="1" />

테이블 메타데이터뿐만 아니라 디스크의 데이터에 영향을 미치는 ALTER를 실행할 수 있도록 허용합니다.
## allow_nonconst_timezone_arguments {#allow_nonconst_timezone_arguments} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "0"},{"label": "Allow non-const timezone arguments in certain time-related functions like toTimeZone(), fromUnixTimestamp*(), snowflakeToDateTime*()."}]}]}/>

toTimeZone(), fromUnixTimestamp*(), snowflakeToDateTime*()과 같은 특정 시간 관련 함수에서 비상수 시간대 인수를 허용합니다.
이 설정은 호환성상의 이유로만 존재합니다. ClickHouse에서 시간대는 데이터 유형의 속성이므로 해당 컬럼의 속성입니다.
이 설정을 활성화하면 컬럼 내에서 서로 다른 값이 다른 시간대를 가질 수 있다는 잘못된 인상을 줄 수 있습니다.
따라서 이 설정을 활성화하지 마십시오.
## allow_nondeterministic_mutations {#allow_nondeterministic_mutations} 

사용자 수준 설정으로, 복제 테이블에서 `dictGet`과 같은 비결정적 함수를 사용할 수 있도록 허용합니다.

예를 들어, 사전이 노드 간에 동기화되지 않을 수 있으므로, 사전에서 값을 가져오는 변형은 기본적으로 복제 테이블에서 허용되지 않습니다. 이 설정을 활성화하면 사용자는 모든 노드에서 사용되는 데이터가 동기화되도록 보장해야 합니다.

**예제**

```xml
<profiles>
    <default>
        <allow_nondeterministic_mutations>1</allow_nondeterministic_mutations>

        <!-- ... -->
    </default>

    <!-- ... -->

</profiles>
```
## allow_nondeterministic_optimize_skip_unused_shards {#allow_nondeterministic_optimize_skip_unused_shards} 

<SettingsInfoBlock type="Bool" default_value="0" />

샤딩 키에서 비결정적(예: `rand` 또는 `dictGet`, 후자는 업데이트에 대한 몇 가지 주의 사항이 있음) 함수를 허용합니다.

가능한 값:

- 0 — 비허용.
- 1 — 허용.
## allow_not_comparable_types_in_comparison_functions {#allow_not_comparable_types_in_comparison_functions} 

<SettingsInfoBlock type="Bool" default_value="0" />

비교 함수 `equal/less/greater/etc`에서 비교할 수 없는 유형(예: JSON/AggregateFunction)의 사용을 허용하거나 제한합니다.
## allow_not_comparable_types_in_order_by {#allow_not_comparable_types_in_order_by} 

<SettingsInfoBlock type="Bool" default_value="0" />

ORDER BY 키에서 비교할 수 없는 유형(예: JSON/AggregateFunction)의 사용을 허용하거나 제한합니다.
## allow_prefetched_read_pool_for_local_filesystem {#allow_prefetched_read_pool_for_local_filesystem} 

<SettingsInfoBlock type="Bool" default_value="0" />

모든 파트가 로컬 파일 시스템에 있는 경우 미리 가져온 스레드 풀을 선호합니다.
## allow_prefetched_read_pool_for_remote_filesystem {#allow_prefetched_read_pool_for_remote_filesystem} 

<SettingsInfoBlock type="Bool" default_value="1" />

모든 파트가 원격 파일 시스템에 있는 경우 미리 가져온 스레드 풀을 선호합니다.
## allow_push_predicate_ast_for_distributed_subqueries {#allow_push_predicate_ast_for_distributed_subqueries} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "A new setting"}]}]}/>

분산 서브쿼리에 대해 활성화된 분석기가 있는 경우 AST 수준에서 조건을 푸시할 수 있도록 허용합니다.
## allow_push_predicate_when_subquery_contains_with {#allow_push_predicate_when_subquery_contains_with} 

<SettingsInfoBlock type="Bool" default_value="1" />

서브쿼리에 WITH 절이 포함된 경우 조건을 푸시할 수 있도록 허용합니다.
## allow_reorder_prewhere_conditions {#allow_reorder_prewhere_conditions} 

<SettingsInfoBlock type="Bool" default_value="1" />

WHERE에서 PREWHERE로 조건을 이동할 때 최적화를 위해 조건의 순서를 변경할 수 있도록 허용합니다.
## allow_settings_after_format_in_insert {#allow_settings_after_format_in_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

INSERT 쿼리에서 FORMAT 이후 `SETTINGS`이 허용되는지 제어합니다. 값 해석 부분을 잘못 해석할 수 있으므로 이를 사용하는 것은 권장되지 않습니다.

예제:

```sql
INSERT INTO FUNCTION null('foo String') SETTINGS max_threads=1 VALUES ('bar');
```

다음 쿼리는 `allow_settings_after_format_in_insert`와 함께만 작동합니다:

```sql
SET allow_settings_after_format_in_insert=1;
INSERT INTO FUNCTION null('foo String') VALUES ('bar') SETTINGS max_threads=1;
```

가능한 값:

- 0 — 허용하지 않음.
- 1 — 허용.

:::note
이 설정은 이전 구문에 의존하는 사용 사례가 있는 경우에만 하위 호환성을 위해 사용하십시오.
:::
## allow_simdjson {#allow_simdjson} 

<SettingsInfoBlock type="Bool" default_value="1" />

AVX2 명령어가 있는 경우 'JSON*' 함수에서 simdjson 라이브러리를 사용하는 것을 허용합니다. 비활성화되면 rapidjson이 사용됩니다.
## allow_special_serialization_kinds_in_output_formats {#allow_special_serialization_kinds_in_output_formats} 

<SettingsInfoBlock type="Bool" default_value="1" />

Sparse 및 Replicated와 같은 특별한 직렬화 종류의 컬럼을 완전 컬럼 표현으로 변환하지 않고 출력할 수 있도록 허용합니다.
형식화 중에 불필요한 데이터 복사를 피하는 데 도움이 됩니다.
## allow_statistics_optimize {#allow_statistics_optimize} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

쿼리 최적화를 위해 통계를 사용할 수 있도록 허용합니다.
## allow_suspicious_codecs {#allow_suspicious_codecs} 

<SettingsInfoBlock type="Bool" default_value="0" />

true로 설정되면 의미 없는 압축 코덱을 지정할 수 있도록 허용합니다.
## allow_suspicious_fixed_string_types {#allow_suspicious_fixed_string_types} 

<SettingsInfoBlock type="Bool" default_value="0" />

CREATE TABLE 문에서 n > 256인 FixedString(n) 유형의 컬럼을 생성할 수 있도록 허용합니다. 길이가 >= 256인 FixedString은 의심스러우며 대부분 잘못 사용된 것으로 보입니다.
## allow_suspicious_indices {#allow_suspicious_indices} 

<SettingsInfoBlock type="Bool" default_value="0" />

동일한 표현식을 가진 기본/보조 인덱스 및 정렬 키를 거부합니다.
## allow_suspicious_low_cardinality_types {#allow_suspicious_low_cardinality_types} 

<SettingsInfoBlock type="Bool" default_value="0" />

8바이트 이하의 고정 크기 데이터 유형과 함께 [LowCardinality](../../sql-reference/data-types/lowcardinality.md)의 사용을 허용하거나 제한합니다: 숫자 데이터 유형 및 `FixedString(8_bytes_or_less)`.

소형 고정 값에 대해 `LowCardinality`의 사용은 일반적으로 비효율적입니다. ClickHouse는 각 행에 대한 숫자 인덱스를 저장합니다. 그 결과:

- 디스크 공간 사용량이 증가할 수 있습니다.
- 경우에 따라 RAM 소비가 더 높을 수 있으며, 이는 사전 크기에 따라 다릅니다.
- 추가 코딩/디코딩 작업으로 인해 일부 함수가 더 느릴 수 있습니다.

위에서 설명한 모든 이유로 인해 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)-엔진 테이블의 병합 시간이 증가할 수 있습니다.

가능한 값:

- 1 — `LowCardinality` 사용이 제한되지 않음.
- 0 — `LowCardinality` 사용이 제한됨.
## allow_suspicious_primary_key {#allow_suspicious_primary_key} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "Forbid suspicious PRIMARY KEY/ORDER BY for MergeTree (i.e. SimpleAggregateFunction)"}]}]}/>

MergeTree에 대해 의심스러운 `PRIMARY KEY`/`ORDER BY`를 허용합니다 (예: SimpleAggregateFunction).
## allow_suspicious_ttl_expressions {#allow_suspicious_ttl_expressions} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.12"},{"label": "0"},{"label": "It is a new setting, and in previous versions the behavior was equivalent to allowing."}]}]}/>

테이블의 어떤 컬럼에도 의존하지 않는 TTL 표현식을 거부합니다. 이는 대다수의 경우 사용자 오류를 나타냅니다.
## allow_suspicious_types_in_group_by {#allow_suspicious_types_in_group_by} 

<SettingsInfoBlock type="Bool" default_value="0" />

[Variant](../../sql-reference/data-types/variant.md) 및 [Dynamic](../../sql-reference/data-types/dynamic.md) 타입을 GROUP BY 키에서 사용하도록 허용하거나 제한합니다.
## allow_suspicious_types_in_order_by {#allow_suspicious_types_in_order_by} 

<SettingsInfoBlock type="Bool" default_value="0" />

[Variant](../../sql-reference/data-types/variant.md) 및 [Dynamic](../../sql-reference/data-types/dynamic.md) 타입을 ORDER BY 키에서 사용하도록 허용하거나 제한합니다.
## allow_suspicious_variant_types {#allow_suspicious_variant_types} 

<SettingsInfoBlock type="Bool" default_value="0" />

CREATE TABLE 문에서 유사한 변형 유형(예: 서로 다른 숫자 또는 날짜 타입)으로 Variant 유형을 지정할 수 있도록 허용합니다. 이 설정을 활성화하면 유사한 유형을 가진 값 작업 시 약간의 모호성이 생길 수 있습니다.
## allow_unrestricted_reads_from_keeper {#allow_unrestricted_reads_from_keeper} 

<SettingsInfoBlock type="Bool" default_value="0" />

조건 없이 시스템.zookeeper 테이블에서 읽기를 허용합니다. 유용할 수 있지만 zookeeper에 대한 안전하지 않은 접근입니다.
## alter_move_to_space_execute_async {#alter_move_to_space_execute_async} 

<SettingsInfoBlock type="Bool" default_value="0" />

ALTER TABLE MOVE ... TO [DISK|VOLUME]를 비동기로 실행합니다.
## alter_partition_verbose_result {#alter_partition_verbose_result} 

<SettingsInfoBlock type="Bool" default_value="0" />

파티션 및 파트에 대한 조작 작업이 성공적으로 적용된 정보를 표시하는 기능을 활성화 또는 비활성화합니다.
[ATTACH PARTITION|PART](/sql-reference/statements/alter/partition#attach-partitionpart) 및 [FREEZE PARTITION](/sql-reference/statements/alter/partition#freeze-partition)에 적용됩니다.

가능한 값:

- 0 — 자세한 정보를 비활성화합니다.
- 1 — 자세한 정보를 활성화합니다.

**예제**

```sql
CREATE TABLE test(a Int64, d Date, s String) ENGINE = MergeTree PARTITION BY toYYYYMDECLARE(d) ORDER BY a;
INSERT INTO test VALUES(1, '2021-01-01', '');
INSERT INTO test VALUES(1, '2021-01-01', '');
ALTER TABLE test DETACH PARTITION ID '202101';

ALTER TABLE test ATTACH PARTITION ID '202101' SETTINGS alter_partition_verbose_result = 1;

┌─command_type─────┬─partition_id─┬─part_name────┬─old_part_name─┐
│ ATTACH PARTITION │ 202101       │ 202101_7_7_0 │ 202101_5_5_0  │
│ ATTACH PARTITION │ 202101       │ 202101_8_8_0 │ 202101_6_6_0  │
└──────────────────┴──────────────┴──────────────┴───────────────┘

ALTER TABLE test FREEZE SETTINGS alter_partition_verbose_result = 1;

┌─command_type─┬─partition_id─┬─part_name────┬─backup_name─┬─backup_path───────────────────┬─part_backup_path────────────────────────────────────────────┐
│ FREEZE ALL   │ 202101       │ 202101_7_7_0 │ 8           │ /var/lib/clickhouse/shadow/8/ │ /var/lib/clickhouse/shadow/8/data/default/test/202101_7_7_0 │
│ FREEZE ALL   │ 202101       │ 202101_8_8_0 │ 8           │ /var/lib/clickhouse/shadow/8/ │ /var/lib/clickhouse/shadow/8/data/default/test/202101_8_8_0 │
└──────────────┴──────────────┴──────────────┴─────────────┴───────────────────────────────┴─────────────────────────────────────────────────────────────┘
```
## alter_sync {#alter_sync} 

<SettingsInfoBlock type="UInt64" default_value="1" />

[ALTER](../../sql-reference/statements/alter/index.md), [OPTIMIZE](../../sql-reference/statements/optimize.md) 또는 [TRUNCATE](../../sql-reference/statements/truncate.md) 쿼리에 대해 복제본에서 실행된 작업을 기다리도록 설정할 수 있습니다.

가능한 값:

- `0` — 기다리지 않음.
- `1` — 자신의 실행을 기다림.
- `2` — 모두 기다림.

클라우드의 기본값: `1`.

:::note
`alter_sync`는 `Replicated` 테이블에만 적용됩니다. 비복제 테이블의 ALTER에는 아무 효과가 없습니다.
:::
## alter_update_mode {#alter_update_mode} 

<SettingsInfoBlock type="AlterUpdateMode" default_value="heavy" />

UPDATE 명령이 포함된 `ALTER` 쿼리의 모드입니다.

가능한 값:
- `heavy` - 일반 변환 실행.
- `lightweight` - 가능한 경우 경량 업데이트 실행, 그렇지 않으면 일반 변환 실행.
- `lightweight_force` - 가능한 경우 경량 업데이트 실행, 그렇지 않으면 예외 발생.
## analyze_index_with_space_filling_curves {#analyze_index_with_space_filling_curves} 

<SettingsInfoBlock type="Bool" default_value="1" />

테이블의 인덱스에 공간 채우기 곡선(예: `ORDER BY mortonEncode(x, y)` 또는 `ORDER BY hilbertEncode(x, y)`)이 있는 경우, 쿼리에 그 인수에 대한 조건이 있는 경우(예: `x >= 10 AND x <= 20 AND y >= 20 AND y <= 30`), 인덱스 분석을 위해 공간 채우기 곡선을 사용합니다.
## analyzer_compatibility_allow_compound_identifiers_in_unflatten_nested {#analyzer_compatibility_allow_compound_identifiers_in_unflatten_nested} 

<SettingsInfoBlock type="Bool" default_value="1" />

중첩에서 복합 식별자를 추가할 수 있도록 허용합니다. 이는 쿼리 결과를 변경하는 호환성 설정입니다. 비활성화되면 `SELECT a.b.c FROM table ARRAY JOIN a`는 작동하지 않으며, `SELECT a FROM table`은 `Nested a` 결과에 `a.b.c` 컬럼을 포함하지 않습니다.
## analyzer_compatibility_join_using_top_level_identifier {#analyzer_compatibility_join_using_top_level_identifier} 

<SettingsInfoBlock type="Bool" default_value="0" />

프로젝션에서 JOIN USING으로 식별자를 해결하도록 강제합니다 (예를 들어, `SELECT a + 1 AS b FROM t1 JOIN t2 USING (b)`에서 조인은 `t1.a + 1 = t2.b`로 수행되며, `t1.b = t2.b`는 사용되지 않습니다).
## any_join_distinct_right_table_keys {#any_join_distinct_right_table_keys} 

<SettingsInfoBlock type="Bool" default_value="0" />

`ANY INNER|LEFT JOIN` 연산에서 레거시 ClickHouse 서버 동작을 활성화합니다.

:::note
이 설정은 레거시 `JOIN` 동작에 의존하는 사용 사례가 있는 경우에만 이전 호환성을 위해 사용하십시오.
:::

레거시 동작이 활성화되면:

- `t1 ANY LEFT JOIN t2` 및 `t2 ANY RIGHT JOIN t1` 연산의 결과는 서로 같지 않습니다. ClickHouse는 왼쪽에서 오른쪽으로의 여러 대 일 테이블 키 매핑 방식을 사용합니다.
- `ANY INNER JOIN` 연산의 결과는 왼쪽 테이블의 모든 행을 포함합니다. 이는 `SEMI LEFT JOIN` 연산과 유사합니다.

레거시 동작이 비활성화되면:

- `t1 ANY LEFT JOIN t2` 및 `t2 ANY RIGHT JOIN t1` 연산의 결과는 서로 같아집니다. ClickHouse는 `ANY RIGHT JOIN` 연산에서 여러 대 일 키 매핑을 제공하는 방식을 사용합니다.
- `ANY INNER JOIN` 연산의 결과는 왼쪽 및 오른쪽 테이블에서 각 키 당 하나의 행을 포함합니다.

가능한 값:

- 0 — 레거시 동작이 비활성화됩니다.
- 1 — 레거시 동작이 활성화됩니다.

참조:

- [JOIN 엄격성](/sql-reference/statements/select/join#settings)
## apply_deleted_mask {#apply_deleted_mask} 

<SettingsInfoBlock type="Bool" default_value="1" />

경량 DELETE로 삭제된 행을 필터링하는 기능을 활성화합니다. 비활성화되면 쿼리는 해당 행을 읽을 수 있습니다. 디버깅 및 "복원" 시나리오에 유용합니다.
## apply_mutations_on_fly {#apply_mutations_on_fly} 

참 true로 설정하면 데이터 부분에 물리적으로 적용되지 않은 변형(UPDATE 및 DELETE)이 SELECT에 적용됩니다.
## apply_patch_parts {#apply_patch_parts} 

<SettingsInfoBlock type="Bool" default_value="1" />

참 true로 설정하면 선택에서 경량 업데이트를 나타내는 패치 파트가 적용됩니다.
## apply_patch_parts_join_cache_buckets {#apply_patch_parts_join_cache_buckets} 

<SettingsInfoBlock type="NonZeroUInt64" default_value="8" />

조인 모드에서 패치 파트를 적용하기 위한 임시 캐시에서 사용되는 버킷 수입니다.
## apply_settings_from_server {#apply_settings_from_server} 

<SettingsInfoBlock type="Bool" default_value="1" />

클라이언트가 서버에서 설정을 수락해야 하는지 여부입니다.

이는 클라이언트 측에서 수행된 작업에만 영향을 미치며, 특히 INSERT 입력 데이터 구문 분석 및 쿼리 결과 형식화에 영향을 미칩니다. 대부분의 쿼리 실행은 서버에서 이루어지며 이 설정의 영향을 받지 않습니다.

이 설정은 일반적으로 사용자 프로필(사용자.xml 또는 `ALTER USER`와 같은 쿼리)에서 설정되어야 하며 클라이언트(클라이언트 명령줄 인수, `SET` 쿼리 또는 `SELECT` 쿼리의 `SETTINGS` 섹션)에서 설정할 수 없습니다. 클라이언트에서 false로 변경할 수는 있지만 true로는 변경할 수 없습니다 (사용자 프로필에 `apply_settings_from_server = false`가 설정되어 있으면 서버가 설정을 전송하지 않기 때문입니다).

최초(24.12)에는 서버 설정이 있었지만(`send_settings_to_client`), 이후 더 나은 사용을 위해 이 클라이언트 설정으로 대체되었습니다.
## arrow_flight_request_descriptor_type {#arrow_flight_request_descriptor_type} 

<SettingsInfoBlock type="ArrowFlightDescriptorType" default_value="path" />

Arrow Flight 요청에 사용할 설명자 유형입니다. 'path'는 데이터 세트 이름을 경로 설명자로 보냅니다. 'command'는 SQL 쿼리를 명령 설명자로 보냅니다(이것은 Dremio에 필요합니다).

가능한 값:
- 'path' — FlightDescriptor::Path 사용(기본값, 대부분의 Arrow Flight 서버에서 작동)
- 'command' — SELECT 쿼리가 있는 FlightDescriptor::Command 사용(これは Dremio に必要です)
## asterisk_include_alias_columns {#asterisk_include_alias_columns} 

<SettingsInfoBlock type="Bool" default_value="0" />

와일드카드 쿼리(`SELECT *`)에 대한 [ALIAS](../../sql-reference/statements/create/table.md/#alias) 컬럼을 포함합니다.

가능한 값:

- 0 - 비활성화
- 1 - 활성화
## asterisk_include_materialized_columns {#asterisk_include_materialized_columns} 

<SettingsInfoBlock type="Bool" default_value="0" />

와일드카드 쿼리(`SELECT *`)에 대한 [MATERIALIZED](/sql-reference/statements/create/view#materialized-view) 컬럼을 포함합니다.

가능한 값:

- 0 - 비활성화
- 1 - 활성화
## async_insert {#async_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

true로 설정하면 INSERT 쿼리의 데이터가 큐에 저장되고 나중에 백그라운드에서 테이블로 플러시됩니다. wait_for_async_insert가 false인 경우 INSERT 쿼리는 거의 즉시 처리되지만, 그렇지 않으면 클라이언트는 데이터가 테이블에 플러시될 때까지 기다립니다.
## async_insert_busy_timeout_decrease_rate {#async_insert_busy_timeout_decrease_rate} 



<SettingsInfoBlock type="Double" default_value="0.2" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "0.2"},{"label": "The exponential growth rate at which the adaptive asynchronous insert timeout decreases"}]}]}/>

적응형 비동기 삽입 타임아웃이 감소하는 지수 성장률
## async_insert_busy_timeout_increase_rate {#async_insert_busy_timeout_increase_rate} 



<SettingsInfoBlock type="Double" default_value="0.2" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "0.2"},{"label": "The exponential growth rate at which the adaptive asynchronous insert timeout increases"}]}]}/>

적응형 비동기 삽입 타임아웃이 증가하는 지수 성장률
## async_insert_busy_timeout_max_ms {#async_insert_busy_timeout_max_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="200" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "200"},{"label": "The minimum value of the asynchronous insert timeout in milliseconds; async_insert_busy_timeout_ms is aliased to async_insert_busy_timeout_max_ms"}]}]}/>

첫 번째 데이터가 나타난 이후 쿼리당 수집된 데이터를 덤프하기 전에 기다리는 최대 시간.
## async_insert_busy_timeout_min_ms {#async_insert_busy_timeout_min_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="50" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "50"},{"label": "The minimum value of the asynchronous insert timeout in milliseconds; it also serves as the initial value, which may be increased later by the adaptive algorithm"}]}]}/>

async_insert_use_adaptive_busy_timeout를 통해 자동 조정이 활성화된 경우, 첫 번째 데이터가 나타난 이후 쿼리당 수집된 데이터를 덤프하기 전에 기다리는 최소 시간. 이것은 또한 적응 알고리즘의 초기 값으로 사용됩니다.
## async_insert_deduplicate {#async_insert_deduplicate} 



<SettingsInfoBlock type="Bool" default_value="0" />

복제된 테이블에서 비동기 INSERT 쿼리에 대해 삽입 블록의 중복 제거를 수행해야 함을 지정합니다.
## async_insert_max_data_size {#async_insert_max_data_size} 



<SettingsInfoBlock type="UInt64" default_value="10485760" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "10485760"},{"label": "The previous value appeared to be too small."}]}]}/>

삽입되기 전에 쿼리당 수집된 구문 분석되지 않은 데이터의 최대 크기(바이트).
## async_insert_max_query_number {#async_insert_max_query_number} 



<SettingsInfoBlock type="UInt64" default_value="450" />

삽입되기 전에 최대 INSERT 쿼리 수.
설정 [`async_insert_deduplicate`](#async_insert_deduplicate)가 1일 경우에만 효과가 있습니다.
## async_insert_poll_timeout_ms {#async_insert_poll_timeout_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="10" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "10"},{"label": "Timeout in milliseconds for polling data from asynchronous insert queue"}]}]}/>

비동기 삽입 큐에서 데이터를 폴링하기 위한 타임아웃
## async_insert_use_adaptive_busy_timeout {#async_insert_use_adaptive_busy_timeout} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "Use adaptive asynchronous insert timeout"}]}]}/>

true로 설정하면 비동기 삽입에 대한 적응형 바쁜 타임아웃을 사용합니다.
## async_query_sending_for_remote {#async_query_sending_for_remote} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.3"},{"label": "1"},{"label": "Create connections and send query async across shards"}]}]}/>

원격 쿼리를 실행하는 동안 비동기 연결 생성 및 쿼리 전송을 가능하게 합니다.

기본적으로 활성화되어 있습니다.
## async_socket_for_remote {#async_socket_for_remote} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.5"},{"label": "1"},{"label": "Fix all problems and turn on asynchronous reads from socket for remote queries by default again"}]}, {"id": "row-2","items": [{"label": "21.3"},{"label": "0"},{"label": "Turn off asynchronous reads from socket for remote queries because of some problems"}]}]}/>

원격 쿼리를 실행하는 동안 소켓에서 비동기 읽기를 가능하게 합니다.

기본적으로 활성화되어 있습니다.
## azure_allow_parallel_part_upload {#azure_allow_parallel_part_upload} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "true"},{"label": "Use multiple threads for azure multipart upload."}]}]}/>

azure multipart upload에 여러 스레드를 사용합니다.
## azure_check_objects_after_upload {#azure_check_objects_after_upload} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "Check each uploaded object in azure blob storage to be sure that upload was successful"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "0"},{"label": "Check each uploaded object in azure blob storage to be sure that upload was successful"}]}]}/>

업로드가 성공했는지 확인하기 위해 Azure Blob 스토리지에서 업로드된 각 객체를 확인합니다.
## azure_connect_timeout_ms {#azure_connect_timeout_ms} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "1000"},{"label": "New setting"}]}]}/>

Azure 디스크의 호스트에 대한 연결 타임아웃.
## azure_create_new_file_on_insert {#azure_create_new_file_on_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

Azure 엔진 테이블에서 각 삽입 시 새 파일을 생성할지를 활성화하거나 비활성화합니다.
## azure_ignore_file_doesnt_exist {#azure_ignore_file_doesnt_exist} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "Allow to return 0 rows when the requested files don't exist instead of throwing an exception in AzureBlobStorage table engine"}]}]}/>

특정 키를 읽을 때 파일이 존재하지 않으면 부재를 무시합니다.

가능한 값:
- 1 — `SELECT`가 빈 결과를 반환합니다.
- 0 — `SELECT`가 예외를 발생시킵니다.
## azure_list_object_keys_size {#azure_list_object_keys_size} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

ListObject 요청에 의해 배치로 반환될 수 있는 최대 파일 수
## azure_max_blocks_in_multipart_upload {#azure_max_blocks_in_multipart_upload} 



<SettingsInfoBlock type="UInt64" default_value="50000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "50000"},{"label": "Maximum number of blocks in multipart upload for Azure."}]}]}/>

Azure의 multipart upload에서 최대 파트 수.
## azure_max_get_burst {#azure_max_get_burst} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting"}]}]}/>

초 당 요청 한도에 도달하기 전에 동시에 발행할 수 있는 최대 요청 수. 기본값(0)은 `azure_max_get_rps`와 같습니다.
## azure_max_get_rps {#azure_max_get_rps} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting"}]}]}/>

스로틀링 전에 Azure GET 요청 초당 비율에 대한 제한. 0은 무제한을 의미합니다.
## azure_max_inflight_parts_for_one_file {#azure_max_inflight_parts_for_one_file} 



<SettingsInfoBlock type="UInt64" default_value="20" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "20"},{"label": "The maximum number of a concurrent loaded parts in multipart upload request. 0 means unlimited."}]}]}/>

multipart upload 요청에서 동시에 로드된 파트의 최대 수. 0은 무제한을 의미합니다.
## azure_max_put_burst {#azure_max_put_burst} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting"}]}]}/>

초 당 요청 한도에 도달하기 전에 동시에 발행할 수 있는 최대 요청 수. 기본값(0)은 `azure_max_put_rps`와 같습니다.
## azure_max_put_rps {#azure_max_put_rps} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting"}]}]}/>

스로틀링 전에 Azure PUT 요청 초당 비율에 대한 제한. 0은 무제한을 의미합니다.
## azure_max_redirects {#azure_max_redirects} 



<SettingsInfoBlock type="UInt64" default_value="10" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "10"},{"label": "New setting"}]}]}/>

허용된 최대 Azure 리디렉션 홉 수.
## azure_max_single_part_copy_size {#azure_max_single_part_copy_size} 



<SettingsInfoBlock type="UInt64" default_value="268435456" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "268435456"},{"label": "The maximum size of object to copy using single part copy to Azure blob storage."}]}]}/>

Azure Blob 스토리지에 단일 파트 복사를 사용하여 복사할 수 있는 객체의 최대 크기.
## azure_max_single_part_upload_size {#azure_max_single_part_upload_size} 



<SettingsInfoBlock type="UInt64" default_value="33554432" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "33554432"},{"label": "Align with S3"}]}]}/>

Azure Blob 스토리지에 단일 파트 업로드를 사용하여 업로드할 수 있는 객체의 최대 크기.
## azure_max_single_read_retries {#azure_max_single_read_retries} 



<SettingsInfoBlock type="UInt64" default_value="4" />

단일 Azure Blob 스토리지 읽기 중 최대 재시도 수.
## azure_max_unexpected_write_error_retries {#azure_max_unexpected_write_error_retries} 



<SettingsInfoBlock type="UInt64" default_value="4" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "4"},{"label": "The maximum number of retries in case of unexpected errors during Azure blob storage write"}]}]}/>

Azure Blob 스토리지 쓰기 중 예기치 않은 오류 발생 시 최대 재시도 수.
## azure_max_upload_part_size {#azure_max_upload_part_size} 



<SettingsInfoBlock type="UInt64" default_value="5368709120" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "5368709120"},{"label": "The maximum size of part to upload during multipart upload to Azure blob storage."}]}]}/>

Azure Blob 스토리지에 multipart 업로드 중 업로드할 수 있는 파트의 최대 크기.
## azure_min_upload_part_size {#azure_min_upload_part_size} 



<SettingsInfoBlock type="UInt64" default_value="16777216" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "16777216"},{"label": "The minimum size of part to upload during multipart upload to Azure blob storage."}]}]}/>

Azure Blob 스토리지에 multipart 업로드 중 업로드할 수 있는 파트의 최소 크기.
## azure_request_timeout_ms {#azure_request_timeout_ms} 



<SettingsInfoBlock type="UInt64" default_value="30000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "30000"},{"label": "New setting"}]}]}/>

Azure로 데이터 송수신 시 유휴 타임아웃. 단일 TCP 읽기 또는 쓰기 호출이 이만큼 차단되면 실패합니다.
## azure_sdk_max_retries {#azure_sdk_max_retries} 



<SettingsInfoBlock type="UInt64" default_value="10" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "10"},{"label": "Maximum number of retries in azure sdk"}]}]}/>

Azure SDK의 최대 재시도 수
## azure_sdk_retry_initial_backoff_ms {#azure_sdk_retry_initial_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="10" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "10"},{"label": "Minimal backoff between retries in azure sdk"}]}]}/>

Azure SDK에서 재시도 중 최소 백오프
## azure_sdk_retry_max_backoff_ms {#azure_sdk_retry_max_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "1000"},{"label": "Maximal backoff between retries in azure sdk"}]}]}/>

Azure SDK에서 재시도 중 최대 백오프
## azure_skip_empty_files {#azure_skip_empty_files} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "Allow to skip empty files in azure table engine"}]}]}/>

S3 엔진에서 빈 파일을 건너뛸 수 있도록 활성화하거나 비활성화합니다.

가능한 값:
- 0 — 빈 파일이 요청된 형식과 호환되지 않으면 `SELECT`가 예외를 발생시킵니다.
- 1 — 빈 파일에 대해 `SELECT`가 빈 결과를 반환합니다.
## azure_strict_upload_part_size {#azure_strict_upload_part_size} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "The exact size of part to upload during multipart upload to Azure blob storage."}]}]}/>

Azure Blob 스토리지에 multipart 업로드 중 업로드할 파트의 정확한 크기.
## azure_throw_on_zero_files_match {#azure_throw_on_zero_files_match} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "Allow to throw an error when ListObjects request cannot match any files in AzureBlobStorage engine instead of empty query result"}]}]}/>

glob 확장 규칙에 따라 일치하는 파일이 없으면 오류를 발생시킵니다.

가능한 값:
- 1 — `SELECT`가 예외를 발생시킵니다.
- 0 — `SELECT`가 빈 결과를 반환합니다.
## azure_truncate_on_insert {#azure_truncate_on_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

Azure 엔진 테이블에 삽입하기 전에 잘라내기를 활성화하거나 비활성화합니다.
## azure_upload_part_size_multiply_factor {#azure_upload_part_size_multiply_factor} 



<SettingsInfoBlock type="UInt64" default_value="2" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "2"},{"label": "Multiply azure_min_upload_part_size by this factor each time azure_multiply_parts_count_threshold parts were uploaded from a single write to Azure blob storage."}]}]}/>

Azure Blob 스토리지에 한 번의 쓰기에서 azure_multiply_parts_count_threshold 파트가 업로드될 때마다 azure_min_upload_part_size를 이 계수만큼 곱합니다.
## azure_upload_part_size_multiply_parts_count_threshold {#azure_upload_part_size_multiply_parts_count_threshold} 



<SettingsInfoBlock type="UInt64" default_value="500" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "500"},{"label": "Each time this number of parts was uploaded to Azure blob storage, azure_min_upload_part_size is multiplied by azure_upload_part_size_multiply_factor."}]}]}/>

이 수의 파트가 Azure Blob 스토리지에 업로드될 때마다 azure_min_upload_part_size가 azure_upload_part_size_multiply_factor에 의해 곱해집니다.
## azure_use_adaptive_timeouts {#azure_use_adaptive_timeouts} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "1"},{"label": "New setting"}]}]}/>

true로 설정되면 모든 Azure 요청에 대해 첫 두 번의 시도가 낮은 송수신 타임아웃으로 이루어집니다.
false로 설정되면 모든 시도가 동일한 타임아웃으로 이루어집니다.
## backup_restore_batch_size_for_keeper_multi {#backup_restore_batch_size_for_keeper_multi} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

백업 또는 복원 중 [Zoo]Keeper에 대한 다중 요청의 최대 배치 크기
## backup_restore_batch_size_for_keeper_multiread {#backup_restore_batch_size_for_keeper_multiread} 



<SettingsInfoBlock type="UInt64" default_value="10000" />

백업 또는 복원 중 [Zoo]Keeper에 대한 다중 읽기 요청의 최대 배치 크기
## backup_restore_failure_after_host_disconnected_for_seconds {#backup_restore_failure_after_host_disconnected_for_seconds} 



<SettingsInfoBlock type="UInt64" default_value="3600" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "3600"},{"label": "New setting."}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "3600"},{"label": "New setting."}]}]}/>

BACKUP ON CLUSTER 또는 RESTORE ON CLUSTER 작업 중 호스트가 ZooKeeper에서 이 시간만큼의 시간 동안 'alive' 임시 노드를 재생성하지 않으면 전체 백업 또는 복원이 실패한 것으로 간주됩니다.
이 값은 호스트가 실패 후 ZooKeeper에 다시 연결되는 데 필요한 합리적인 시간보다 커야 합니다.
제로는 무제한을 의미합니다.
## backup_restore_finish_timeout_after_error_sec {#backup_restore_finish_timeout_after_error_sec} 



<SettingsInfoBlock type="UInt64" default_value="180" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "180"},{"label": "New setting."}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "180"},{"label": "New setting."}]}]}/>

시작자가 다른 호스트가 'error' 노드에 반응하고 현재 BACKUP ON CLUSTER 또는 RESTORE ON CLUSTER 작업을 중단할 때까지 기다려야 하는 시간.
## backup_restore_keeper_fault_injection_probability {#backup_restore_keeper_fault_injection_probability} 



<SettingsInfoBlock type="Float" default_value="0" />

백업 또는 복원 중 keeper 요청의 실패 확률. 유효한 값은 [0.0f, 1.0f]의 범위에 있습니다.
## backup_restore_keeper_fault_injection_seed {#backup_restore_keeper_fault_injection_seed} 



<SettingsInfoBlock type="UInt64" default_value="0" />

0 - 임의의 시드, 그렇지 않으면 설정 값
## backup_restore_keeper_max_retries {#backup_restore_keeper_max_retries} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1000"},{"label": "Should be big enough so the whole operation BACKUP or RESTORE operation won't fail because of a temporary [Zoo]Keeper failure in the middle of it."}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "1000"},{"label": "Should be big enough so the whole operation BACKUP or RESTORE operation won't fail because of a temporary [Zoo]Keeper failure in the middle of it."}]}]}/>

BACKUP 또는 RESTORE 작업 중 [Zoo]Keeper 작업의 최대 재시도 수.
전체 작업이 임시 [Zoo]Keeper 오류로 인해 실패하지 않도록 충분히 크게 설정해야 합니다.
## backup_restore_keeper_max_retries_while_handling_error {#backup_restore_keeper_max_retries_while_handling_error} 



<SettingsInfoBlock type="UInt64" default_value="20" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "20"},{"label": "New setting."}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "20"},{"label": "New setting."}]}]}/>

BACKUP ON CLUSTER 또는 RESTORE ON CLUSTER 작업 중 오류를 처리하는 동안 [Zoo]Keeper 작업의 최대 재시도 수.
## backup_restore_keeper_max_retries_while_initializing {#backup_restore_keeper_max_retries_while_initializing} 



<SettingsInfoBlock type="UInt64" default_value="20" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "20"},{"label": "New setting."}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "20"},{"label": "New setting."}]}]}/>

BACKUP ON CLUSTER 또는 RESTORE ON CLUSTER 작업 초기화 중 [Zoo]Keeper 작업의 최대 재시도 수.
## backup_restore_keeper_retry_initial_backoff_ms {#backup_restore_keeper_retry_initial_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="100" />

백업 또는 복원 중 [Zoo]Keeper 작업의 초기 백오프 타임아웃
## backup_restore_keeper_retry_max_backoff_ms {#backup_restore_keeper_retry_max_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="5000" />

백업 또는 복원 중 [Zoo]Keeper 작업의 최대 백오프 타임아웃
## backup_restore_keeper_value_max_size {#backup_restore_keeper_value_max_size} 



<SettingsInfoBlock type="UInt64" default_value="1048576" />

백업 중 [Zoo]Keeper의 노드 데이터를 최대 크기
## backup_restore_s3_retry_attempts {#backup_restore_s3_retry_attempts} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "1000"},{"label": "Setting for Aws::Client::RetryStrategy, Aws::Client does retries itself, 0 means no retries. It takes place only for backup/restore."}]}]}/>

Aws::Client::RetryStrategy에 대한 설정으로, Aws::Client가 자체적으로 재시도를 수행하며, 0은 재시도가 없음을 의미합니다. 백업/복원 시에만 적용됩니다.
## backup_restore_s3_retry_initial_backoff_ms {#backup_restore_s3_retry_initial_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="25" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "25"},{"label": "New setting"}]}]}/>

    백업 및 복원 중 첫 번째 재시도 시도 전에 밀리초로 초기 백오프 지연. 이후 각 재시도는 지정된 `backup_restore_s3_retry_max_backoff_ms`까지 지연을 지수적으로 증가시킵니다.
## backup_restore_s3_retry_jitter_factor {#backup_restore_s3_retry_jitter_factor} 



<SettingsInfoBlock type="Float" default_value="0.1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0.1"},{"label": "New setting"}]}]}/>

    백업 및 복원 작업 중 Aws::Client::RetryStrategy에서 재시도 백오프 지연에 적용되는 지터 계수. 계산된 백오프 지연은 [1.0, 1.0 + jitter] 범위의 임의 계수에 의해 곱해지며, 최대 `backup_restore_s3_retry_max_backoff_ms`까지 늘어납니다. [0.0, 1.0] 범위 내에 있어야 합니다.
## backup_restore_s3_retry_max_backoff_ms {#backup_restore_s3_retry_max_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="5000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "5000"},{"label": "New setting"}]}]}/>

    백업 및 복원 작업 중 재시도 간의 최대 지연(밀리초).
## backup_slow_all_threads_after_retryable_s3_error {#backup_slow_all_threads_after_retryable_s3_error} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting"}]}, {"id": "row-2","items": [{"label": "25.6"},{"label": "0"},{"label": "New setting"}]}, {"id": "row-3","items": [{"label": "25.10"},{"label": "0"},{"label": "Disable the setting by default"}]}]}/>

true로 설정되면, 동일한 백업 엔드포인트에 대한 S3 요청을 실행하는 모든 스레드가 단일 S3 요청이 재시도 가능한 S3 오류를 만나면 느려집니다. 'Slow Down' 등의 오류가 이에 해당합니다. false로 설정되면 각 스레드가 다른 스레드와 독립적으로 S3 요청 백오프를 처리합니다.
## cache_warmer_threads {#cache_warmer_threads} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="4" />

ClickHouse Cloud에서만 효과가 있습니다. [cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch)가 활성화되었을 때 파일 캐시에 새로운 데이터 파트를 추측적으로 다운로드하기 위한 백그라운드 스레드 수. 비활성화 시 0으로 설정합니다.
## calculate_text_stack_trace {#calculate_text_stack_trace} 



<SettingsInfoBlock type="Bool" default_value="1" />

쿼리 실행 중 예외가 발생한 경우 텍스트 스택 추적을 계산합니다. 이것은 기본값입니다. 많은 잘못된 쿼리가 실행될 때 기호 조회가 이루어져 퍼징 테스트 속도가 느려질 수 있습니다. 일반적인 경우, 이 옵션을 비활성화하지 않아야 합니다.
## cancel_http_readonly_queries_on_client_close {#cancel_http_readonly_queries_on_client_close} 



<SettingsInfoBlock type="Bool" default_value="0" />

클라이언트가 응답을 기다리지 않고 연결을 닫으면 HTTP 읽기 전용 쿼리(예: SELECT)를 취소합니다.

클라우드 기본값: `0`.
## cast_ipv4_ipv6_default_on_conversion_error {#cast_ipv4_ipv6_default_on_conversion_error} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.3"},{"label": "0"},{"label": "Make functions cast(value, 'IPv4') and cast(value, 'IPv6') behave same as toIPv4 and toIPv6 functions"}]}]}/>

CAST 연산자를 IPv4로 변환하고, CAST 연산자를 IPV6 형식으로 변환하며, toIPv4 및 toIPv6 함수는 변환 오류 시 예외를 발생시키는 대신 기본값을 반환합니다.
## cast_keep_nullable {#cast_keep_nullable} 



<SettingsInfoBlock type="Bool" default_value="0" />

[CAST](/sql-reference/functions/type-conversion-functions#cast) 작업에서 `Nullable` 데이터 유형을 유지할지를 활성화하거나 비활성화합니다.

설정이 활성화된 경우 `CAST` 함수의 인수가 `Nullable`이면 결과도 `Nullable` 형식으로 변환됩니다. 설정이 비활성화된 경우 결과는 항상 정확한 목적지 유형을 가집니다.

가능한 값:

- 0 — `CAST` 결과가 지정된 목적지 유형과 정확히 일치합니다.
- 1 — 인수 유형이 `Nullable`인 경우 `CAST` 결과가 `Nullable(DestinationDataType)`로 변환됩니다.

**예시**

다음 쿼리는 목적지 데이터 유형이 정확히 일치합니다:

```sql
SET cast_keep_nullable = 0;
SELECT CAST(toNullable(toInt32(0)) AS Int32) as x, toTypeName(x);
```

결과:

```text
┌─x─┬─toTypeName(CAST(toNullable(toInt32(0)), 'Int32'))─┐
│ 0 │ Int32                                             │
└───┴───────────────────────────────────────────────────┘
```

다음 쿼리는 목적지 데이터 유형에 대한 `Nullable` 수정을 결과로 냅니다:

```sql
SET cast_keep_nullable = 1;
SELECT CAST(toNullable(toInt32(0)) AS Int32) as x, toTypeName(x);
```

결과:

```text
┌─x─┬─toTypeName(CAST(toNullable(toInt32(0)), 'Int32'))─┐
│ 0 │ Nullable(Int32)                                   │
└───┴───────────────────────────────────────────────────┘
```

**참조**

- [CAST](/sql-reference/functions/type-conversion-functions#cast) 함수
## cast_string_to_date_time_mode {#cast_string_to_date_time_mode} 



<SettingsInfoBlock type="DateTimeInputFormat" default_value="basic" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.6"},{"label": "basic"},{"label": "Allow to use different DateTime parsing mode in String to DateTime cast"}]}]}/>

String에서 날짜 및 시간으로 변환할 때 텍스트 표현 파서를 선택할 수 있습니다.

가능한 값:

- `'best_effort'` — 확장된 파싱을 가능하게 합니다.

    ClickHouse는 기본 `YYYY-MM-DD HH:MM:SS` 형식과 모든 [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601) 날짜 및 시간 형식을 파싱할 수 있습니다. 예: `'2018-06-08T01:02:03.000Z'`.

- `'best_effort_us'` — `best_effort`와 유사합니다(자세한 내용은 [parseDateTimeBestEffortUS](../../sql-reference/functions/type-conversion-functions#parsedatetimebesteffortus) 참조).

- `'basic'` — 기본 파서를 사용합니다.

    ClickHouse는 기본적으로 `YYYY-MM-DD HH:MM:SS` 또는 `YYYY-MM-DD` 형식만 파싱할 수 있습니다. 예: `2019-08-20 10:18:56` 또는 `2019-08-20`.

참조:

- [DateTime 데이터 유형.](../../sql-reference/data-types/datetime.md)
- [날짜 및 시간 작업을 위한 함수.](../../sql-reference/functions/date-time-functions.md)
## cast_string_to_dynamic_use_inference {#cast_string_to_dynamic_use_inference} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "0"},{"label": "Add setting to allow converting String to Dynamic through parsing"}]}]}/>

String을 Dynamic으로 변환하는 동안 유형 추론을 사용합니다.
## cast_string_to_variant_use_inference {#cast_string_to_variant_use_inference} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "New setting to enable/disable types inference during CAST from String to Variant"}]}]}/>

String을 Variant로 변환하는 동안 유형 추론을 사용합니다.
## check_query_single_value_result {#check_query_single_value_result} 



<SettingsInfoBlock type="Bool" default_value="1" />

`MergeTree` 계열 엔진에 대한 [CHECK TABLE](/sql-reference/statements/check-table) 쿼리 결과의 세부 수준을 정의합니다.

가능한 값:

- 0 — 쿼리가 테이블의 각 개별 데이터 파트에 대한 체크 상태를 표시합니다.
- 1 — 쿼리가 일반 테이블 체크 상태를 표시합니다.
## check_referential_table_dependencies {#check_referential_table_dependencies} 



<SettingsInfoBlock type="Bool" default_value="0" />

DDL 쿼리(DROP TABLE 또는 RENAME 등)가 참조 종속성을 손상시키지 않는지 확인합니다.
## check_table_dependencies {#check_table_dependencies} 



<SettingsInfoBlock type="Bool" default_value="1" />

DDL 쿼리(DROP TABLE 또는 RENAME 등)가 종속성을 손상시키지 않는지 확인합니다.
## checksum_on_read {#checksum_on_read} 



<SettingsInfoBlock type="Bool" default_value="1" />

읽기 시 체크섬을 검증합니다. 기본적으로 활성화되어 있으며, 프로덕션에서는 항상 활성화되어야 합니다. 이 설정을 비활성화한다고 이익을 기대하지 마십시오. 이 설정은 실험 및 벤치마크에만 사용되어야 합니다. 이 설정은 MergeTree 계열의 테이블에만 적용됩니다. 다른 테이블 엔진에 대해 또는 네트워크를 통해 데이터를 받을 때는 항상 체크섬이 검증됩니다.
## cloud_mode {#cloud_mode} 



<SettingsInfoBlock type="Bool" default_value="0" />

클라우드 모드
## cloud_mode_database_engine {#cloud_mode_database_engine} 



<SettingsInfoBlock type="UInt64" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

클라우드에서 허용되는 데이터베이스 엔진. 1 - DDL을 Replicated 데이터베이스를 사용하도록 수정, 2 - DDL을 Shared 데이터베이스를 사용하도록 수정
## cloud_mode_engine {#cloud_mode_engine} 



<SettingsInfoBlock type="UInt64" default_value="1" />

클라우드에서 허용되는 엔진 계열.

- 0 - 모든 것을 허용합니다.
- 1 - DDL을 *ReplicatedMergeTree를 사용하도록 수정합니다.
- 2 - DDL을 SharedMergeTree를 사용하도록 수정합니다.
- 3 - 명시적으로 원격 디스크를 지정하지 않은 경우 SharedMergeTree를 사용하도록 수정합니다.

공개 부분을 최소화하는 UInt64입니다.
## cluster_for_parallel_replicas {#cluster_for_parallel_replicas} 

<BetaBadge/>

현재 서버가 위치한 샤드의 클러스터
## cluster_function_process_archive_on_multiple_nodes {#cluster_function_process_archive_on_multiple_nodes} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.7"},{"label": "1"},{"label": "New setting"}]}]}/>

true로 설정되면 클러스터 함수에서 아카이브를 처리하는 성능이 향상됩니다. 이전 버전에서 아카이브와 함께 클러스터 함수를 사용하고 있는 경우 25.7 이상으로 업그레이드 중에 호환성을 위해 false로 설정해야 합니다.
## cluster_table_function_buckets_batch_size {#cluster_table_function_buckets_batch_size} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.11"},{"label": "0"},{"label": "New setting."}]}]}/>

버킷 분할 세분도 있으며 클러스터 테이블 함수에서 작업을 분산 처리할 때 사용되는 대략적인 배치 크기(바이트 단위)를 정의합니다. 시스템은 이 양이 도달될 때까지 데이터를 축적합니다. 실제 크기는 데이터 경계와 맞추기 위해 약간 더 클 수 있습니다.
## cluster_table_function_split_granularity {#cluster_table_function_split_granularity} 



<SettingsInfoBlock type="ObjectStorageGranularityLevel" default_value="file" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.11"},{"label": "file"},{"label": "New setting."}]}]}/>

클러스터 테이블 함수 실행 시 데이터가 작업으로 분할되는 방식을 제어합니다.

이 설정은 클러스터의 작업 배분 세분성을 정의합니다:
- `file` — 각 작업이 전체 파일을 처리합니다.
- `bucket` — 파일 내 내부 데이터 블록마다 작업이 생성됩니다(예: Parquet 행 그룹).

세분성을 더 세밀하게 선택(예: `bucket`)하면 적은 수의 대형 파일 작업 시 병렬성을 향상시킬 수 있습니다.
예를 들어, Parquet 파일이 여러 행 그룹을 포함하는 경우, `bucket` 세분성을 활성화하면 각 그룹이 서로 다른 작업자에 의해 독립적으로 처리될 수 있습니다.
## collect_hash_table_stats_during_aggregation {#collect_hash_table_stats_during_aggregation} 



<SettingsInfoBlock type="Bool" default_value="1" />

메모리 할당 최적화를 위해 해시 테이블 통계를 수집하는 것을 활성화합니다.
## collect_hash_table_stats_during_joins {#collect_hash_table_stats_during_joins} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "1"},{"label": "New setting."}]}]}/>

메모리 할당 최적화를 위해 해시 테이블 통계를 수집하는 것을 활성화합니다.
## compatibility {#compatibility} 

`compatibility` 설정은 ClickHouse가 이전 버전의 ClickHouse의 기본 설정을 사용하게 합니다. 이전 버전은 설정으로 제공됩니다.

설정이 기본값이 아닌 값으로 설정될 경우, 해당 설정이 유지됩니다(수정되지 않은 설정만 `compatibility` 설정의 영향을 받습니다).

이 설정은 ClickHouse 버전 번호를 문자열로 입력하며, 예: `22.3`, `22.8`입니다. 비어 있는 값은 이 설정이 비활성화되었음을 의미합니다.

기본적으로 비활성화되어 있습니다.

:::note
ClickHouse Cloud에서 서비스 수준의 기본 호환성 설정은 ClickHouse Cloud 지원팀이 설정해야 합니다. 이를 설정하려면 [케이스를 열어주십시오](https://clickhouse.cloud/support).
그러나 호환성 설정은 사용자가 세션에서 `SET compatibility = '22.3'` 또는 쿼리에서 `SETTINGS compatibility = '22.3'`와 같은 표준 ClickHouse 설정 메커니즘을 사용하여 사용자, 역할, 프로필, 쿼리 또는 세션 수준에서 재정의할 수 있습니다.
:::
## compatibility_ignore_auto_increment_in_create_table {#compatibility_ignore_auto_increment_in_create_table} 



<SettingsInfoBlock type="Bool" default_value="0" />

true이면 열 선언에서 AUTO_INCREMENT 키워드를 무시합니다. 그렇지 않으면 오류를 반환합니다. MySQL에서 마이그레이션을 단순화합니다.
## compatibility_ignore_collation_in_create_table {#compatibility_ignore_collation_in_create_table} 



<SettingsInfoBlock type="Bool" default_value="1" />

테이블 생성 시 정렬을 무시하도록 호환성 설정
## compile_aggregate_expressions {#compile_aggregate_expressions} 



<SettingsInfoBlock type="Bool" default_value="1" />

집계 함수를 네이티브 코드로 JIT 컴파일하는 기능을 활성화하거나 비활성화합니다. 이 설정을 활성화하면 성능이 향상될 수 있습니다.

가능한 값:

- 0 — JIT 컴파일 없이 집계가 수행됩니다.
- 1 — JIT 컴파일을 사용하여 집계가 수행됩니다.

**참조**

- [min_count_to_compile_aggregate_expression](#min_count_to_compile_aggregate_expression)
## compile_expressions {#compile_expressions} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "We believe that the LLVM infrastructure behind the JIT compiler is stable enough to enable this setting by default."}]}]}/>

일부 스칼라 함수 및 연산자를 네이티브 코드로 컴파일합니다.
## compile_sort_description {#compile_sort_description} 



<SettingsInfoBlock type="Bool" default_value="1" />

정렬 설명을 네이티브 코드로 컴파일합니다.
## connect_timeout {#connect_timeout} 



<SettingsInfoBlock type="Seconds" default_value="10" />

복제본이 없는 경우 연결 타임아웃.
## connect_timeout_with_failover_ms {#connect_timeout_with_failover_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "1000"},{"label": "Increase default connect timeout because of async connect"}]}]}/>

클러스터 정의에서 'shard' 및 'replica' 섹션이 사용될 경우, 분산 테이블 엔진의 원격 서버와 연결하기 위한 밀리초 단위의 타임아웃입니다.
연결이 실패할 경우 여러 복제본에 연결하기 위한 시도가 이루어집니다.
## connect_timeout_with_failover_secure_ms {#connect_timeout_with_failover_secure_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "1000"},{"label": "Increase default secure connect timeout because of async connect"}]}]}/>

첫 번째 건강한 복제본을 선택하기 위한 연결 타임아웃(보안 연결용).
## connection_pool_max_wait_ms {#connection_pool_max_wait_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="0" />

연결 풀이 가득 찼을 때 연결을 위해 대기하는 시간(밀리초 단위).

가능한 값:

- 양의 정수.
- 0 — 무한 대기.
## connections_with_failover_max_tries {#connections_with_failover_max_tries} 



<SettingsInfoBlock type="UInt64" default_value="3" />

Distributed 테이블 엔진으로 각 복제본과의 최대 연결 시도 수.
## convert_query_to_cnf {#convert_query_to_cnf} 



<SettingsInfoBlock type="Bool" default_value="0" />

`true`로 설정되면 `SELECT` 쿼리가 합성 정상형(CNF)으로 변환됩니다. CNF로 쿼리를 다시 쓰는 것이 더 빠르게 실행되는 경우가 있습니다(설명에 대한 [Github 문제](https://github.com/ClickHouse/ClickHouse/issues/11749)를 참조).

예를 들어, 다음 `SELECT` 쿼리가 수정되지 않음을 알 수 있습니다(기본 동작):

```sql
EXPLAIN SYNTAX
SELECT *
FROM
(
    SELECT number AS x
    FROM numbers(20)
) AS a
WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))
SETTINGS convert_query_to_cnf = false;
```

결과는:

```response
┌─explain────────────────────────────────────────────────────────┐
│ SELECT x                                                       │
│ FROM                                                           │
│ (                                                              │
│     SELECT number AS x                                         │
│     FROM numbers(20)                                           │
│     WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15)) │
│ ) AS a                                                         │
│ WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))     │
│ SETTINGS convert_query_to_cnf = 0                              │
└────────────────────────────────────────────────────────────────┘
```

`convert_query_to_cnf`를 `true`로 설정하고 어떤 변화가 있는지 살펴보겠습니다:

```sql
EXPLAIN SYNTAX
SELECT *
FROM
(
    SELECT number AS x
    FROM numbers(20)
) AS a
WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))
SETTINGS convert_query_to_cnf = true;
```

`WHERE` 절이 CNF로 다시 작성되는 것을 알 수 있지만, 결과 집합은 동일합니다 - 불리언 논리는 변경되지 않습니다:

```response
┌─explain───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SELECT x                                                                                                              │
│ FROM                                                                                                                  │
│ (                                                                                                                     │
│     SELECT number AS x                                                                                                │
│     FROM numbers(20)                                                                                                  │
│     WHERE ((x <= 15) OR (x <= 5)) AND ((x <= 15) OR (x >= 1)) AND ((x >= 10) OR (x <= 5)) AND ((x >= 10) OR (x >= 1)) │
│ ) AS a                                                                                                                │
│ WHERE ((x >= 10) OR (x >= 1)) AND ((x >= 10) OR (x <= 5)) AND ((x <= 15) OR (x >= 1)) AND ((x <= 15) OR (x <= 5))     │
│ SETTINGS convert_query_to_cnf = 1                                                                                     │
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

가능한 값: true, false
## correlated_subqueries_default_join_kind {#correlated_subqueries_default_join_kind} 



<SettingsInfoBlock type="DecorrelationJoinKind" default_value="right" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.11"},{"label": "right"},{"label": "New setting. Default join kind for decorrelated query plan."}]}, {"id": "row-2","items": [{"label": "25.10"},{"label": "right"},{"label": "New setting. Default join kind for decorrelated query plan."}]}]}/>

비교없이는 쿼리 계획에서 어떤 종류의 조인을 제어합니다. 기본값은 `right`로, 이는 비연관 계획에 RIGHT JOIN이 포함된다는 것을 의미합니다.

가능한 값:

- `left` - 비연관 프로세스는 LEFT JOIN을 생성하고 입력 테이블은 왼쪽에 나타납니다.
- `right` - 비연관 프로세스는 RIGHT JOIN을 생성하고 입력 테이블은 오른쪽에 나타납니다.
## correlated_subqueries_substitute_equivalent_expressions {#correlated_subqueries_substitute_equivalent_expressions} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.7"},{"label": "1"},{"label": "New setting to correlated subquery planning optimization."}]}]}/>

필터 표현식을 사용하여 동등한 표현식을 추론하고 이를 CROSS JOIN 생성 대신에 대체합니다.
## count_distinct_implementation {#count_distinct_implementation} 



<SettingsInfoBlock type="String" default_value="uniqExact" />

[COUNT(DISTINCT ...)](/sql-reference/aggregate-functions/reference/count) 구문을 수행하는 데 사용할 `uniq*` 함수 중 어떤 것을 사용할지 지정합니다.

가능한 값:

- [uniq](/sql-reference/aggregate-functions/reference/uniq)
- [uniqCombined](/sql-reference/aggregate-functions/reference/uniqcombined)
- [uniqCombined64](/sql-reference/aggregate-functions/reference/uniqcombined64)
- [uniqHLL12](/sql-reference/aggregate-functions/reference/uniqhll12)
- [uniqExact](/sql-reference/aggregate-functions/reference/uniqexact)
## count_distinct_optimization {#count_distinct_optimization} 



<SettingsInfoBlock type="Bool" default_value="0" />

중복 수를 세기 위해 GROUP BY의 하위 쿼리로 다시 작성합니다.
## count_matches_stop_at_empty_match {#count_matches_stop_at_empty_match} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.6"},{"label": "0"},{"label": "New setting."}]}]}/>

`countMatches` 함수에서 패턴이 0 길이와 일치하면 계산을 중지합니다.
## create_if_not_exists {#create_if_not_exists} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "New setting."}]}]}/>

기본적으로 `CREATE` 문에 대해 `IF NOT EXISTS`를 활성화합니다. 이 설정이나 `IF NOT EXISTS`가 지정되고 제공된 이름의 테이블이 이미 존재하는 경우 예외가 발생하지 않습니다.
## create_index_ignore_unique {#create_index_ignore_unique} 



<SettingsInfoBlock type="Bool" default_value="0" />

CREATE UNIQUE INDEX에서 UNIQUE 키워드를 무시합니다. SQL 호환성 테스트를 위해 만들어졌습니다.
## create_replicated_merge_tree_fault_injection_probability {#create_replicated_merge_tree_fault_injection_probability} 



<SettingsInfoBlock type="Float" default_value="0" />

ZooKeeper에서 메타데이터를 생성한 후 테이블 생성 중 오류 삽입 확률
## create_table_empty_primary_key_by_default {#create_table_empty_primary_key_by_default} 



<SettingsInfoBlock type="Bool" default_value="0" />

ORDER BY 및 PRIMARY KEY가 지정되지 않은 경우 빈 기본 키를 가진 *MergeTree 테이블 생성을 허용합니다.
## cross_join_min_bytes_to_compress {#cross_join_min_bytes_to_compress} 



<SettingsInfoBlock type="UInt64" default_value="1073741824" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "1073741824"},{"label": "Minimal size of block to compress in CROSS JOIN. Zero value means - disable this threshold. This block is compressed when any of the two thresholds (by rows or by bytes) are reached."}]}]}/>

CROSS JOIN에서 압축할 최소 블록 크기. 제로 값은 이 임계값을 비활성화함을 의미합니다. 이 블록은 두 임계값(행 수 또는 바이트 수) 중 하나가 도달되면 압축됩니다.
## cross_join_min_rows_to_compress {#cross_join_min_rows_to_compress} 



<SettingsInfoBlock type="UInt64" default_value="10000000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "10000000"},{"label": "Minimal count of rows to compress block in CROSS JOIN. Zero value means - disable this threshold. This block is compressed when any of the two thresholds (by rows or by bytes) are reached."}]}]}/>

CROSS JOIN에서 블록을 압축할 최소 행 수. 제로 값은 이 임계값을 비활성화함을 의미합니다. 이 블록은 두 임계값(행 수 또는 바이트 수) 중 하나가 도달되면 압축됩니다.
## data_type_default_nullable {#data_type_default_nullable} 



<SettingsInfoBlock type="Bool" default_value="0" />

명시적 수정자 [NULL 또는 NOT NULL](/sql-reference/statements/create/table#null-or-not-null-modifiers) 없이 데이터 유형이 있는 경우, 컬럼 정의는 [Nullable](/sql-reference/data-types/nullable)로 설정됩니다.

가능한 값:

- 1 — 컬럼 정의의 데이터 유형이 기본적으로 `Nullable`로 설정됩니다.
- 0 — 컬럼 정의의 데이터 유형이 기본적으로 `Nullable`가 아닌 것으로 설정됩니다.
## database_atomic_wait_for_drop_and_detach_synchronously {#database_atomic_wait_for_drop_and_detach_synchronously} 



<SettingsInfoBlock type="Bool" default_value="0" />

모든 `DROP` 및 `DETACH` 쿼리에 `SYNC` 수식어를 추가합니다.

가능한 값:

- 0 — 쿼리가 지연되어 실행됩니다.
- 1 — 쿼리가 지연 없이 실행됩니다.
## database_replicated_allow_explicit_uuid {#database_replicated_allow_explicit_uuid} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "Added a new setting to disallow explicitly specifying table UUID"}]}]}/>

0 - 복제된 데이터베이스의 테이블에 대해 UUID를 명시적으로 지정하는 것을 허용하지 않습니다. 1 - 허용합니다. 2 - 허용하나, 지정된 UUID를 무시하고 대신 무작위 UUID를 생성합니다.
## database_replicated_allow_heavy_create {#database_replicated_allow_heavy_create} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "Long-running DDL queries (CREATE AS SELECT and POPULATE) for Replicated database engine was forbidden"}]}]}/>

복제된 데이터베이스 엔진에서 장기 실행 DDL 쿼리(예: CREATE AS SELECT 및 POPULATE)를 허용합니다. 이는 DDL 대기열을 오랜 시간 동안 차단할 수 있습니다.
## database_replicated_allow_only_replicated_engine {#database_replicated_allow_only_replicated_engine} 



<SettingsInfoBlock type="Bool" default_value="0" />

복제된 엔진으로 데이터베이스에 복제된 테이블만 생성할 수 있도록 허용합니다.
## database_replicated_allow_replicated_engine_arguments {#database_replicated_allow_replicated_engine_arguments} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "Don't allow explicit arguments by default"}]}]}/>

0 - 복제된 데이터베이스의 *MergeTree 테이블에 대해 ZooKeeper 경로와 복제본 이름을 명시적으로 지정하는 것을 허용하지 않습니다. 1 - 허용합니다. 2 - 허용하나, 지정된 경로를 무시하고 기본 경로를 사용합니다. 3 - 허용하고 경고를 기록하지 않습니다.
## database_replicated_always_detach_permanently {#database_replicated_always_detach_permanently} 



<SettingsInfoBlock type="Bool" default_value="0" />

데이터베이스 엔진이 Replicated인 경우, DETACH TABLE을 DETACH TABLE PERMANENTLY로 실행합니다.
## database_replicated_enforce_synchronous_settings {#database_replicated_enforce_synchronous_settings} 



<SettingsInfoBlock type="Bool" default_value="0" />

일부 쿼리에 대해 동기 대기를 강제합니다(데이터베이스의 database_atomic_wait_for_drop_and_detach_synchronously, mutations_sync, alter_sync 참조). 이러한 설정을 활성화하는 것은 권장되지 않습니다.
## database_replicated_initial_query_timeout_sec {#database_replicated_initial_query_timeout_sec} 



<SettingsInfoBlock type="UInt64" default_value="300" />

Replicated 데이터베이스가 이전 DDL 큐 항목을 처리하기 위해 초기 DDL 쿼리가 대기해야 하는 시간을 초 단위로 설정합니다.

가능한 값:

- 양의 정수.
- 0 — 무제한.
## database_shared_drop_table_delay_seconds {#database_shared_drop_table_delay_seconds} 



<SettingsInfoBlock type="UInt64" default_value="28800" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.11"},{"label": "28800"},{"label": "New setting."}]}]}/>

Shared 데이터베이스에서 삭제된 테이블이 실제로 제거되기 전에 대기하는 시간(초)입니다. 이 시간을 사용하여 `UNDROP TABLE` 쿼리로 테이블을 복구할 수 있습니다.
## decimal_check_overflow {#decimal_check_overflow} 



<SettingsInfoBlock type="Bool" default_value="1" />

십진수 산술/비교 작업의 오버플로우를 확인합니다.
## deduplicate_blocks_in_dependent_materialized_views {#deduplicate_blocks_in_dependent_materialized_views} 



<SettingsInfoBlock type="Bool" default_value="0" />

Replicated\* 테이블에서 데이터를 수신하는 물리화된 뷰에 대한 중복 확인을 활성화하거나 비활성화합니다.

가능한 값:

      0 — 비활성화.
      1 — 활성화.

활성화되면 ClickHouse는 Replicated\* 테이블에 의존하는 물리화된 뷰 블록의 중복을 수행합니다. 이 설정은 삽입 작업이 실패로 인해 다시 시도될 때 물리화된 뷰에 중복 데이터가 포함되지 않도록 하는 데 유용합니다.

**참고**

- [NULL 처리가 IN 연산자에서](/guides/developer/deduplicating-inserts-on-retries#insert-deduplication-with-materialized-views)
## default_materialized_view_sql_security {#default_materialized_view_sql_security} 



<SettingsInfoBlock type="SQLSecurityType" default_value="DEFINER" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "DEFINER"},{"label": "Allows to set a default value for SQL SECURITY option when creating a materialized view"}]}]}/>

물리화된 뷰를 생성할 때 SQL SECURITY 옵션의 기본값을 설정할 수 있습니다. [SQL 보안에 대한 자세한 내용](../../sql-reference/statements/create/view.md/#sql_security).

기본값은 `DEFINER`입니다.
## default_max_bytes_in_join {#default_max_bytes_in_join} 



<SettingsInfoBlock type="UInt64" default_value="1000000000" />

`max_bytes_in_join`이 설정되지 않은 경우 오른쪽 테이블의 최대 크기.
## default_normal_view_sql_security {#default_normal_view_sql_security} 



<SettingsInfoBlock type="SQLSecurityType" default_value="INVOKER" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "INVOKER"},{"label": "Allows to set default `SQL SECURITY` option while creating a normal view"}]}]}/>

정상 뷰를 생성하는 동안 기본 `SQL SECURITY` 옵션을 설정할 수 있습니다. [SQL 보안에 대한 자세한 내용](../../sql-reference/statements/create/view.md/#sql_security).

기본값은 `INVOKER`입니다.
## default_table_engine {#default_table_engine} 



<SettingsInfoBlock type="DefaultTableEngine" default_value="MergeTree" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "MergeTree"},{"label": "Set default table engine to MergeTree for better usability"}]}]}/>

`CREATE` 문에 `ENGINE`이 설정되지 않았을 때 사용할 기본 테이블 엔진입니다.

가능한 값:

- 유효한 테이블 엔진 이름을 나타내는 문자열

클라우드 기본값: `SharedMergeTree`.

**예시**

쿼리:

```sql
SET default_table_engine = 'Log';

SELECT name, value, changed FROM system.settings WHERE name = 'default_table_engine';
```

결과:

```response
┌─name─────────────────┬─value─┬─changed─┐
│ default_table_engine │ Log   │       1 │
└──────────────────────┴───────┴─────────┘
```

이 예시에서는 `Engine`이 지정되지 않은 모든 새 테이블이 `Log` 테이블 엔진을 사용합니다.

쿼리:

```sql
CREATE TABLE my_table (
    x UInt32,
    y UInt32
);

SHOW CREATE TABLE my_table;
```

결과:

```response
┌─statement────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.my_table
(
    `x` UInt32,
    `y` UInt32
)
ENGINE = Log
└──────────────────────────────────────────────────────────────────────────┘
```
## default_temporary_table_engine {#default_temporary_table_engine} 



<SettingsInfoBlock type="DefaultTableEngine" default_value="Memory" />

임시 테이블에 대한 [default_table_engine](#default_table_engine)과 동일합니다.

이 예시에서는 `Engine`이 지정되지 않은 모든 새 임시 테이블이 `Log` 테이블 엔진을 사용합니다.

쿼리:

```sql
SET default_temporary_table_engine = 'Log';

CREATE TEMPORARY TABLE my_table (
    x UInt32,
    y UInt32
);

SHOW CREATE TEMPORARY TABLE my_table;
```

결과:

```response
┌─statement────────────────────────────────────────────────────────────────┐
│ CREATE TEMPORARY TABLE default.my_table
(
    `x` UInt32,
    `y` UInt32
)
ENGINE = Log
└──────────────────────────────────────────────────────────────────────────┘
```
## default_view_definer {#default_view_definer} 



<SettingsInfoBlock type="String" default_value="CURRENT_USER" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "CURRENT_USER"},{"label": "Allows to set default `DEFINER` option while creating a view"}]}]}/>

뷰를 생성할 때 기본 `DEFINER` 옵션을 설정할 수 있습니다. [SQL 보안에 대한 자세한 내용](../../sql-reference/statements/create/view.md/#sql_security).

기본값은 `CURRENT_USER`입니다.
## delta_lake_enable_engine_predicate {#delta_lake_enable_engine_predicate} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "1"},{"label": "New setting"}]}]}/>

delta-kernel 내부 데이터 정리를 활성화합니다.
## delta_lake_enable_expression_visitor_logging {#delta_lake_enable_expression_visitor_logging} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting"}]}]}/>

DeltaLake 표현식 방문자에 대한 테스트 수준 로그를 활성화합니다. 이 로그는 테스트 로깅에도 너무 자세할 수 있습니다.
## delta_lake_insert_max_bytes_in_data_file {#delta_lake_insert_max_bytes_in_data_file} 



<SettingsInfoBlock type="NonZeroUInt64" default_value="1073741824" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.9"},{"label": "1073741824"},{"label": "New setting."}]}]}/>

delta lake에 단일 삽입 데이터 파일에 대한 바이트 한도를 정의합니다.
## delta_lake_insert_max_rows_in_data_file {#delta_lake_insert_max_rows_in_data_file} 



<SettingsInfoBlock type="NonZeroUInt64" default_value="1000000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.9"},{"label": "1000000"},{"label": "New setting."}]}]}/>

delta lake에 단일 삽입 데이터 파일에 대한 행 한도를 정의합니다.
## delta_lake_log_metadata {#delta_lake_log_metadata} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "0"},{"label": "New setting."}]}]}/>

시스템 테이블에 delta lake 메타데이터 파일을 로그로 기록합니다.
## delta_lake_snapshot_version {#delta_lake_snapshot_version} 



<SettingsInfoBlock type="Int64" default_value="-1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "-1"},{"label": "New setting"}]}]}/>

읽을 delta lake 스냅샷의 버전입니다. 값 -1은 최신 버전을 읽는 것을 의미합니다 (값 0은 유효한 스냅샷 버전입니다).
## delta_lake_throw_on_engine_predicate_error {#delta_lake_throw_on_engine_predicate_error} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting"}]}]}/>

delta-kernel에서 스캔 조건 분석 중 오류가 발생할 경우 예외를 발생시키도록 설정합니다.
## describe_compact_output {#describe_compact_output} 



<SettingsInfoBlock type="Bool" default_value="0" />

true인 경우, DESCRIBE 쿼리의 결과에 열 이름과 유형만 포함됩니다.
## describe_include_subcolumns {#describe_include_subcolumns} 



<SettingsInfoBlock type="Bool" default_value="0" />

[DESCRIBE](../../sql-reference/statements/describe-table.md) 쿼리에 대한 서브컬럼 설명을 활성화합니다. 예를 들어, [Tuple](../../sql-reference/data-types/tuple.md)의 구성원 또는 [Map](/sql-reference/data-types/map#reading-subcolumns-of-map), [Nullable](../../sql-reference/data-types/nullable.md/#finding-null) 또는 [Array](../../sql-reference/data-types/array.md/#array-size) 데이터 타입의 서브컬럼.

가능한 값:

- 0 — 서브컬럼이 `DESCRIBE` 쿼리에 포함되지 않습니다.
- 1 — 서브컬럼이 `DESCRIBE` 쿼리에 포함됩니다.

**예시**

[DESCRIBE](../../sql-reference/statements/describe-table.md) 문에 대한 예시를 참조하세요.
## describe_include_virtual_columns {#describe_include_virtual_columns} 



<SettingsInfoBlock type="Bool" default_value="0" />

true인 경우, 테이블의 가상 컬럼이 DESCRIBE 쿼리의 결과에 포함됩니다.
## dialect {#dialect} 



<SettingsInfoBlock type="Dialect" default_value="clickhouse" />

쿼리를 파싱하는 데 사용되는 방언입니다.
## dictionary_validate_primary_key_type {#dictionary_validate_primary_key_type} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "Validate primary key type for dictionaries. By default id type for simple layouts will be implicitly converted to UInt64."}]}]}/>

딕셔너리에 대한 기본 키 유형을 검증합니다. 기본적으로 단순 레이아웃의 ID 유형은 UInt64로 암묵적으로 변환됩니다.
## distinct_overflow_mode {#distinct_overflow_mode} 



<SettingsInfoBlock type="OverflowMode" default_value="throw" />

데이터 양이 한계 중 하나를 초과했을 때 발생하는 작업을 설정합니다.

가능한 값:
- `throw`: 예외를 발생시킵니다 (기본값).
- `break`: 쿼리 실행을 중단하고 소스 데이터가 부족한 것처럼 부분 결과를 반환합니다.
## distributed_aggregation_memory_efficient {#distributed_aggregation_memory_efficient} 



<SettingsInfoBlock type="Bool" default_value="1" />

메모리를 절약하는 분산 집계 모드가 활성화되었습니다.
## distributed_background_insert_batch {#distributed_background_insert_batch} 



<SettingsInfoBlock type="Bool" default_value="0" />

데이터 삽입을 배치로 보낼 수 있도록 활성화/비활성화합니다.

배치 발송이 활성화되면, [Distributed](../../engines/table-engines/special/distributed.md) 테이블 엔진은 여러 삽입 데이터 파일을 한 번의 작업으로 전송하려고 합니다. 배치 발송은 서버 및 네트워크 리소스를 더 잘 활용하여 클러스터 성능을 향상시킵니다.

가능한 값:

- 1 — 활성화.
- 0 — 비활성화.
## distributed_background_insert_max_sleep_time_ms {#distributed_background_insert_max_sleep_time_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="30000" />

Distributed 테이블 엔진이 데이터를 전송하는 최대 간격입니다. [distributed_background_insert_sleep_time_ms](#distributed_background_insert_sleep_time_ms) 설정에서 설정된 간격의 기하급수적 성장을 제한합니다.

가능한 값:

- 양의 정수 밀리초 숫자.
## distributed_background_insert_sleep_time_ms {#distributed_background_insert_sleep_time_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="100" />

Distributed 테이블 엔진이 데이터를 보내기 위해 사용할 기본 간격입니다. 오류가 발생할 경우 실제 간격이 기하급수적으로 증가합니다.

가능한 값:

- 양의 정수 밀리초 숫자.
## distributed_background_insert_split_batch_on_failure {#distributed_background_insert_split_batch_on_failure} 



<SettingsInfoBlock type="Bool" default_value="0" />

오류 발생 시 배치를 분할할 수 있도록 활성화/비활성화합니다.

가끔 원격 샤드에 특정 배치를 보내는 데 실패할 수 있습니다. 이 경우 재시도가 도움이 되지 않으며, 해당 배치의 파일을 하나씩 보내는 것이 INSERT를 성공시키는 데 도움이 될 수 있습니다.

따라서 이 설정을 `1`로 설치하면 실패한 배치에 대해 배치 전송을 비활성화합니다 (즉, 실패한 배치에 대해 `distributed_background_insert_batch`를 일시적으로 비활성화합니다).

가능한 값:

- 1 — 활성화.
- 0 — 비활성화.

:::note
이 설정은 비정상 서버 종료로 인해 발생할 수 있는 손상된 배치에도 영향을 미칩니다 (이 경우 `fsync_after_insert`/`fsync_directories`가 필요합니다).
:::

:::note
자동 배치 분할에 의존해서는 안 되며, 이는 성능에 영향을 줄 수 있습니다.
:::
## distributed_background_insert_timeout {#distributed_background_insert_timeout} 



<SettingsInfoBlock type="UInt64" default_value="0" />

분산에 대한 삽입 쿼리의 타임아웃입니다. 이 설정은 `insert_distributed_sync`가 활성화된 경우에만 사용됩니다. 값이 0이면 타임아웃이 없습니다.
## distributed_cache_alignment {#distributed_cache_alignment} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.7"},{"label": "0"},{"label": "Rename of distributed_cache_read_alignment"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 테스트 목적의 설정이며 변경하지 마십시오.
## distributed_cache_bypass_connection_pool {#distributed_cache_bypass_connection_pool} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 분산 캐시 연결 풀을 우회하도록 허용합니다.
## distributed_cache_connect_backoff_max_ms {#distributed_cache_connect_backoff_max_ms} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="50" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "50"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 분산 캐시 연결 생성을 위한 최대 백오프 밀리초.
## distributed_cache_connect_backoff_min_ms {#distributed_cache_connect_backoff_min_ms} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 분산 캐시 연결 생성을 위한 최소 백오프 밀리초.
## distributed_cache_connect_max_tries {#distributed_cache_connect_max_tries} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="5" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "5"},{"label": "Changed setting value"}]}, {"id": "row-2","items": [{"label": "25.1"},{"label": "20"},{"label": "Cloud only"}]}, {"id": "row-3","items": [{"label": "24.10"},{"label": "20"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 실패할 경우 분산 캐시에 연결하기 위한 시도 횟수.
## distributed_cache_connect_timeout_ms {#distributed_cache_connect_timeout_ms} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="50" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "50"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 분산 캐시 서버에 연결할 때의 타임아웃.
## distributed_cache_credentials_refresh_period_seconds {#distributed_cache_credentials_refresh_period_seconds} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="5" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.6"},{"label": "5"},{"label": "New private setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 자격 증명 갱신 기간.
## distributed_cache_data_packet_ack_window {#distributed_cache_data_packet_ack_window} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="5" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "5"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 단일 분산 캐시 읽기 요청에서 DataPacket 시퀀스에 대한 ACK를 전송하는 창입니다.
## distributed_cache_discard_connection_if_unread_data {#distributed_cache_discard_connection_if_unread_data} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "New setting"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "1"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 일부 데이터가 읽히지 않은 경우 연결을 폐기합니다.
## distributed_cache_fetch_metrics_only_from_current_az {#distributed_cache_fetch_metrics_only_from_current_az} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 시스템의 분산 캐시 메트릭 및 이벤트에서 현재 가용 영역에서만 메트릭을 가져옵니다.
## distributed_cache_log_mode {#distributed_cache_log_mode} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="DistributedCacheLogMode" default_value="on_error" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "on_error"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. system.distributed_cache_log에 쓰기 위한 모드입니다.
## distributed_cache_max_unacked_inflight_packets {#distributed_cache_max_unacked_inflight_packets} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="10" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "10"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 단일 분산 캐시 읽기 요청에서 미확인 비행 패킷의 최대 수.
## distributed_cache_min_bytes_for_seek {#distributed_cache_min_bytes_for_seek} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "New private setting."}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 분산 캐시에서 탐색을 수행하기 위해 필요한 최소 바이트 수입니다.
## distributed_cache_pool_behaviour_on_limit {#distributed_cache_pool_behaviour_on_limit} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="DistributedCachePoolBehaviourOnLimit" default_value="wait" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "wait"},{"label": "Cloud only"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "allocate_bypassing_pool"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 풀 제한에 도달했을 때의 분산 캐시 연결 동작을 식별합니다.
## distributed_cache_prefer_bigger_buffer_size {#distributed_cache_prefer_bigger_buffer_size} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "0"},{"label": "New setting."}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. filesystem_cache_prefer_bigger_buffer_size와 동일하지만 분산 캐시에 해당됩니다.
## distributed_cache_read_only_from_current_az {#distributed_cache_read_only_from_current_az} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 현재 가용 영역에서만 읽도록 허용합니다. 비활성화된 경우, 모든 가용 영역의 모든 캐시 서버에서 읽습니다.
## distributed_cache_read_request_max_tries {#distributed_cache_read_request_max_tries} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="10" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "10"},{"label": "Changed setting value"}]}, {"id": "row-2","items": [{"label": "25.4"},{"label": "20"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 실패할 경우 분산 캐시 요청을 시도하는 횟수입니다.
## distributed_cache_receive_response_wait_milliseconds {#distributed_cache_receive_response_wait_milliseconds} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="60000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "60000"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 분산 캐시에서 요청에 대한 데이터를 수신하기 위한 대기 시간(밀리초)입니다.
## distributed_cache_receive_timeout_milliseconds {#distributed_cache_receive_timeout_milliseconds} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="10000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "10000"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 분산 캐시에서 모든 종류의 응답을 수신하기 위한 대기 시간(밀리초)입니다.
## distributed_cache_receive_timeout_ms {#distributed_cache_receive_timeout_ms} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="3000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "3000"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 분산 캐시 서버에서 데이터를 수신하기 위한 타임아웃(밀리초)입니다. 이 간격 내에 바이트가 수신되지 않으면 예외가 발생합니다.
## distributed_cache_send_timeout_ms {#distributed_cache_send_timeout_ms} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="3000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "3000"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 분산 캐시 서버에 데이터를 전송하는 타임아웃(밀리초)입니다. 클라이언트가 일부 데이터를 보내야 하지만 이 간격 내에 바이트를 보내지 못하면 예외가 발생합니다.
## distributed_cache_tcp_keep_alive_timeout_ms {#distributed_cache_tcp_keep_alive_timeout_ms} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="2900" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "2900"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. TCP가 keepalive 프로브를 전송하기 전에 분산 캐시 서버에 대한 연결이 유휴 상태를 유지해야 하는 시간(밀리초)입니다.
## distributed_cache_throw_on_error {#distributed_cache_throw_on_error} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 분산 캐시와의 통신 중 발생한 예외를 다시 발생시킵니다. 그렇지 않으면 오류가 발생할 경우 분산 캐시를 건너뜁니다.
## distributed_cache_wait_connection_from_pool_milliseconds {#distributed_cache_wait_connection_from_pool_milliseconds} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="100" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "100"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. distributed_cache_pool_behaviour_on_limit이 대기인 경우 연결 풀에서 연결을 수신하기 위한 대기 시간(밀리초)입니다.
## distributed_connections_pool_size {#distributed_connections_pool_size} 



<SettingsInfoBlock type="UInt64" default_value="1024" />

단일 Distributed 테이블에 대한 모든 쿼리를 분산 처리하기 위해 원격 서버와 동시에 연결할 수 있는 최대 연결 수입니다. 클러스터의 서버 수 이상으로 값을 설정하는 것이 좋습니다.
## distributed_ddl_entry_format_version {#distributed_ddl_entry_format_version} 



<SettingsInfoBlock type="UInt64" default_value="5" />

분산 DDL (ON CLUSTER) 쿼리의 호환성 버전입니다.
## distributed_ddl_output_mode {#distributed_ddl_output_mode} 



<SettingsInfoBlock type="DistributedDDLOutputMode" default_value="throw" />

분산 DDL 쿼리 결과의 형식을 설정합니다.

가능한 값:

- `throw` — 쿼리가 완료된 모든 호스트의 쿼리 실행 상태와 함께 결과 집합을 반환합니다. 쿼리가 일부 호스트에서 실패한 경우 첫 번째 예외를 다시 발생시킵니다. 일부 호스트에서 쿼리가 아직 완료되지 않았고 [distributed_ddl_task_timeout](#distributed_ddl_task_timeout)를 초과한 경우 `TIMEOUT_EXCEEDED` 예외를 발생시킵니다.
- `none` — throw와 유사하지만 분산 DDL 쿼리는 결과 집합을 반환하지 않습니다.
- `null_status_on_timeout` — 결과 집합의 일부 행에서 실행 상태를 `NULL`로 반환하며, 해당 호스트에서 쿼리가 완료되지 않으면 `TIMEOUT_EXCEEDED`를 발생시키지 않습니다.
- `never_throw` — 쿼리가 일부 호스트에서 실패한 경우 `TIMEOUT_EXCEEDED`를 발생시키지 않고 예외를 다시 발생시키지 않습니다.
- `none_only_active` — `none`과 유사하지만 `Replicated` 데이터베이스의 비활성 복제본을 기다리지 않습니다. 참고: 이 모드에서는 일부 복제본에서 쿼리가 실행되지 않았음을 확인할 수 없습니다.
- `null_status_on_timeout_only_active` — `null_status_on_timeout`과 유사하지만 `Replicated` 데이터베이스의 비활성 복제본을 기다리지 않습니다.
- `throw_only_active` — `throw`와 유사하지만 `Replicated` 데이터베이스의 비활성 복제본을 기다리지 않습니다.

클라우드 기본값: `throw`.
## distributed_ddl_task_timeout {#distributed_ddl_task_timeout} 



<SettingsInfoBlock type="Int64" default_value="180" />

클러스터의 모든 호스트에서 DDL 쿼리 응답을 위한 타임아웃을 설정합니다. 모든 호스트에서 DDL 요청이 수행되지 않은 경우 응답에는 타임아웃 오류가 포함되며 요청은 비동기 모드로 실행됩니다. 음수 값은 무한을 의미합니다.

가능한 값:

- 양의 정수.
- 0 — 비동기 모드.
- 음의 정수 — 무한 타임아웃.
## distributed_foreground_insert {#distributed_foreground_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

[Distributed](/engines/table-engines/special/distributed) 테이블에 동기식 데이터 삽입을 활성화하거나 비활성화합니다.

기본적으로 Distributed 테이블에 데이터를 삽입할 때 ClickHouse 서버는 데이터를 백그라운드 모드로 클러스터 노드에 전송합니다. `distributed_foreground_insert=1` 일 경우 데이터는 동기식으로 처리되며, `INSERT` 작업은 모든 샤드에 데이터가 저장된 후에만 성공합니다(각 샤드에 대해 최소 한 개의 복제본이 있어야 한다면 `internal_replication`이 true일 때).

가능한 값:

- `0` — 데이터가 백그라운드 모드로 삽입됩니다.
- `1` — 데이터가 동기식 모드로 삽입됩니다.

클라우드 기본값: `0`.

**참고**

- [Distributed 테이블 엔진](/engines/table-engines/special/distributed)
- [분산 테이블 관리](/sql-reference/statements/system#managing-distributed-tables)
## distributed_group_by_no_merge {#distributed_group_by_no_merge} 



<SettingsInfoBlock type="UInt64" default_value="0" />

분산 쿼리 처리를 위해 서로 다른 서버의 집계 상태를 병합하지 않도록 설정합니다. 서로 다른 샤드에 서로 다른 키가 있는 경우에 사용할 수 있습니다.

가능한 값:

- `0` — 비활성화 (최종 쿼리 처리는 시작 노드에서 수행됨).
- `1` - 서로 다른 서버에서 집계 상태를 병합하지 않도록 하여 분산 쿼리를 처리합니다(쿼리는 샤드에서 완전히 처리되며 시작 노드는 단지 데이터를 프록시).
- `2` - `1`과 같지만 `ORDER BY` 및 `LIMIT` 적용 (원격 노드에서 쿼리가 완전히 처리될 경우 적용할 수 없음).

**예시**

```sql
SELECT *
FROM remote('127.0.0.{2,3}', system.one)
GROUP BY dummy
LIMIT 1
SETTINGS distributed_group_by_no_merge = 1
FORMAT PrettyCompactMonoBlock

┌─dummy─┐
│     0 │
│     0 │
└───────┘
```

```sql
SELECT *
FROM remote('127.0.0.{2,3}', system.one)
GROUP BY dummy
LIMIT 1
SETTINGS distributed_group_by_no_merge = 2
FORMAT PrettyCompactMonoBlock

┌─dummy─┐
│     0 │
└───────┘
```
## distributed_insert_skip_read_only_replicas {#distributed_insert_skip_read_only_replicas} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "If true, INSERT into Distributed will skip read-only replicas"}]}]}/>

Distributed에 대한 INSERT 쿼리에서 읽기 전용 복제본을 건너뛰도록 활성화합니다.

가능한 값:

- 0 — INSERT가 일반적으로 수행되며 읽기 전용 복제본으로 가면 실패합니다.
- 1 — 시작자는 샤드에 데이터를 보내기 전에 읽기 전용 복제본을 건너뜁니다.
## distributed_plan_default_reader_bucket_count {#distributed_plan_default_reader_bucket_count} 

<ExperimentalBadge/>



<SettingsInfoBlock type="UInt64" default_value="8" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "8"},{"label": "New experimental setting."}]}]}/>

분산 쿼리에서 병렬 읽기를 위한 기본 작업 수입니다. 작업이 복제본 간에 분산됩니다.
## distributed_plan_default_shuffle_join_bucket_count {#distributed_plan_default_shuffle_join_bucket_count} 

<ExperimentalBadge/>



<SettingsInfoBlock type="UInt64" default_value="8" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "8"},{"label": "New experimental setting."}]}]}/>

분산 셔플 해시 조인의 기본 버킷 수입니다.
## distributed_plan_execute_locally {#distributed_plan_execute_locally} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "New experimental setting."}]}]}/>

분산 쿼리 계획의 모든 작업을 로컬에서 실행합니다. 테스트 및 디버깅에 유용합니다.
## distributed_plan_force_exchange_kind {#distributed_plan_force_exchange_kind} 

<ExperimentalBadge/>



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": ""},{"label": "New experimental setting."}]}]}/>

분산 쿼리 단계 간에 지정된 종류의 교환 연산자를 강제합니다.

가능한 값:

 - '' - 어떤 종류의 교환 연산자도 강제하지 않으며, 최적화 프로그램이 선택하도록 허용합니다.
 - 'Persisted' - 객체 저장소에 임시 파일을 사용합니다.
 - 'Streaming' - 네트워크를 통한 데이터 교환입니다.
## distributed_plan_force_shuffle_aggregation {#distributed_plan_force_shuffle_aggregation} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.7"},{"label": "0"},{"label": "New experimental setting"}]}]}/>

분산 쿼리 계획에서 부분 집계 + 병합 대신 셔플 집계 전략을 사용합니다.
## distributed_plan_max_rows_to_broadcast {#distributed_plan_max_rows_to_broadcast} 

<ExperimentalBadge/>



<SettingsInfoBlock type="UInt64" default_value="20000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.7"},{"label": "20000"},{"label": "New experimental setting."}]}]}/>

분산 쿼리 계획에서 셔플 조인 대신 방송 조인을 사용하기 위한 최대 행 수입니다.
## distributed_plan_optimize_exchanges {#distributed_plan_optimize_exchanges} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "New experimental setting."}]}]}/>

분산 쿼리 계획에서 불필요한 교환을 제거합니다. 디버깅을 위해 비활성화하십시오.
## distributed_product_mode {#distributed_product_mode} 



<SettingsInfoBlock type="DistributedProductMode" default_value="deny" />

[분산 서브쿼리](../../sql-reference/operators/in.md)의 동작을 변경합니다.

ClickHouse는 쿼리에 분산 테이블의 곱이 포함된 경우 이 설정을 적용합니다. 즉, 분산 테이블에 대한 쿼리에 분산 테이블을 위한 비전역 서브쿼리가 포함되어 있을 때입니다.

제한 사항:

- IN 및 JOIN 서브쿼리에 대해서만 적용됩니다.
- FROM 섹션이 1개 이상의 샤드를 포함하는 분산 테이블을 사용하는 경우에 한합니다.
- 서브쿼리가 1개 이상의 샤드를 포함하는 분산 테이블과 관련이 있을 경우에만 적용됩니다.
- 테이블 값으로 [원격](../../sql-reference/table-functions/remote.md) 함수를 사용할 때는 적용되지 않습니다.

가능한 값:

- `deny` — 기본값. 이 유형의 서브쿼리 사용을 금지합니다 ( "Double-distributed in/JOIN subqueries is denied" 예외 반납).
- `local` — 목적지 서버(샤드)의 서브쿼리에서 데이터베이스와 테이블을 로컬 것으로 바꿉니다 (정상적인 `IN`/`JOIN`은 유지합니다).
- `global` — `IN`/`JOIN` 쿼리를 `GLOBAL IN`/`GLOBAL JOIN`으로 바꿉니다.
- `allow` — 이 유형의 서브쿼리 사용을 허용합니다.
## distributed_push_down_limit {#distributed_push_down_limit} 



<SettingsInfoBlock type="UInt64" default_value="1" />

각 샤드에서 [LIMIT](#limit)를 적용하는 것을 활성화하거나 비활성화합니다.

이렇게 하면 다음을 피할 수 있습니다:
- 네트워크를 통해 추가 행 전송;
- 시작 노드에서 제한보다 뒤의 행을 처리.

21.9 버전부터는 부정확한 결과를 더 이상 얻을 수 없습니다. `distributed_push_down_limit`는 다음 중 하나의 조건이 충족될 경우에만 쿼리 실행을 변경합니다:
- [distributed_group_by_no_merge](#distributed_group_by_no_merge) > 0.
- 쿼리에 `GROUP BY`/`DISTINCT`/`LIMIT BY`가 **없고**, `ORDER BY`/`LIMIT`이 있는 경우.
- 쿼리에 `GROUP BY`/`DISTINCT`/`LIMIT BY`가 **있고**, `ORDER BY`/`LIMIT`가 있으며:
    - [optimize_skip_unused_shards](#optimize_skip_unused_shards)가 활성화됨.
    - [optimize_distributed_group_by_sharding_key](#optimize_distributed_group_by_sharding_key)가 활성화됨.

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.

추가 참고:

- [distributed_group_by_no_merge](#distributed_group_by_no_merge)
- [optimize_skip_unused_shards](#optimize_skip_unused_shards)
- [optimize_distributed_group_by_sharding_key](#optimize_distributed_group_by_sharding_key)
## distributed_replica_error_cap {#distributed_replica_error_cap} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

- 유형: unsigned int
- 기본값: 1000

각 복제본의 오류 수는 이 값으로 제한되며, 단일 복제본이 너무 많은 오류를 축적하는 것을 방지합니다.

추가 참고:

- [load_balancing](#load_balancing-round_robin)
- [Distributed 테이블 엔진](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_half_life](#distributed_replica_error_half_life)
- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)
## distributed_replica_error_half_life {#distributed_replica_error_half_life} 



<SettingsInfoBlock type="Seconds" default_value="60" />

- 유형: 초
- 기본값: 60초

분산 테이블의 오류가 제로로 돌아가는 속도를 제어합니다. 복제본이 일정 시간 동안 사용할 수 없으며 5개의 오류를 축적하고 distributed_replica_error_half_life가 1초로 설정된 경우, 마지막 오류 발생 3초 후 복제본은 정상 상태로 간주됩니다.

추가 참고:

- [load_balancing](#load_balancing-round_robin)
- [Distributed 테이블 엔진](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_cap](#distributed_replica_error_cap)
- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)
## distributed_replica_max_ignored_errors {#distributed_replica_max_ignored_errors} 



<SettingsInfoBlock type="UInt64" default_value="0" />

- 유형: unsigned int
- 기본값: 0

복제본을 선택할 때 ( `load_balancing` 알고리즘에 따라) 무시될 오류 수입니다.

추가 참고:

- [load_balancing](#load_balancing-round_robin)
- [Distributed 테이블 엔진](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_cap](#distributed_replica_error_cap)
- [distributed_replica_error_half_life](#distributed_replica_error_half_life)
## do_not_merge_across_partitions_select_final {#do_not_merge_across_partitions_select_final} 



<SettingsInfoBlock type="Bool" default_value="0" />

select final에서 한 파티션 내에서만 파트를 병합합니다.
## empty_result_for_aggregation_by_constant_keys_on_empty_set {#empty_result_for_aggregation_by_constant_keys_on_empty_set} 



<SettingsInfoBlock type="Bool" default_value="1" />

빈 집합에서 상수 키로 집계할 때 빈 결과를 반환합니다.
## empty_result_for_aggregation_by_empty_set {#empty_result_for_aggregation_by_empty_set} 



<SettingsInfoBlock type="Bool" default_value="0" />

빈 집합에서 키 없이 집계할 때 빈 결과를 반환합니다.
## enable_adaptive_memory_spill_scheduler {#enable_adaptive_memory_spill_scheduler} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "0"},{"label": "New setting. Enable spill memory data into external storage adaptively."}]}]}/>

데이터를 외부 스토리지에 적응적으로 쏟아내는 트리거 프로세서를 활성화합니다. 현재는 조인에 대해 grace를 지원합니다.
## enable_add_distinct_to_in_subqueries {#enable_add_distinct_to_in_subqueries} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting to reduce the size of temporary tables transferred for distributed IN subqueries."}]}]}/>

`IN` 서브쿼리에서 `DISTINCT`를 활성화합니다. 이는 트레이드오프 설정입니다: 이를 활성화하면 전송되는 임시 테이블의 크기를 크게 줄이고 샤드 간 데이터 전송 속도를 상당히 높일 수 있습니다. 그러나 이 설정을 활성화하면 각 노드에서 추가 병합 작업이 발생하므로 중복 제거(DISTINCT)를 수행해야 합니다. 네트워크 전송이 병목 현상인 경우 이 설정을 사용하고 추가 병합 비용이 허용 가능한 경우에 사용하십시오.
## enable_blob_storage_log {#enable_blob_storage_log} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "Write information about blob storage operations to system.blob_storage_log table"}]}]}/>

blob 스토리지 작업에 대한 정보를 system.blob_storage_log 테이블에 기록합니다.
## enable_deflate_qpl_codec {#enable_deflate_qpl_codec} 



<SettingsInfoBlock type="Bool" default_value="0" />

켤 경우, DEFLATE_QPL 코덱을 사용하여 컬럼을 압축할 수 있습니다.
## enable_early_constant_folding {#enable_early_constant_folding} 



<SettingsInfoBlock type="Bool" default_value="1" />

쿼리의 함수 및 서브쿼리 결과를 분석하고 상수가 있는 경우 쿼리를 다시 작성하는 쿼리 최적화를 활성화합니다.
## enable_extended_results_for_datetime_functions {#enable_extended_results_for_datetime_functions} 



<SettingsInfoBlock type="Bool" default_value="0" />

`Date` 타입보다 확장된 범위를 가진 `Date32` 또는 `DateTime` 타입보다 확장된 범위를 가진 `DateTime64`의 결과를 반환하는 기능을 활성화 또는 비활성화합니다.

가능한 값:

- `0` — 모든 유형의 인수에 대해 함수가 `Date` 또는 `DateTime`을 반환합니다.
- `1` — 함수가 `Date32` 또는 `DateTime64` 인수에 대해 `Date32` 또는 `DateTime64`를 반환하고, 그렇지 않으면 `Date` 또는 `DateTime`을 반환합니다.

아래 표는 다양한 날짜-시간 함수에 대한 이 설정의 동작을 보여줍니다.

| 함수 | `enable_extended_results_for_datetime_functions = 0` | `enable_extended_results_for_datetime_functions = 1` |
|----------|---------------------------------------------------|---------------------------------------------------|
| `toStartOfYear` | `Date` 또는 `DateTime` 반환 | `Date`/`DateTime` 입력에 대해 `Date`/`DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `Date32`/`DateTime64` 반환 |
| `toStartOfISOYear` | `Date` 또는 `DateTime` 반환 | `Date`/`DateTime` 입력에 대해 `Date`/`DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `Date32`/`DateTime64` 반환 |
| `toStartOfQuarter` | `Date` 또는 `DateTime` 반환 | `Date`/`DateTime` 입력에 대해 `Date`/`DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `Date32`/`DateTime64` 반환 |
| `toStartOfMonth` | `Date` 또는 `DateTime` 반환 | `Date`/`DateTime` 입력에 대해 `Date`/`DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `Date32`/`DateTime64` 반환 |
| `toStartOfWeek` | `Date` 또는 `DateTime` 반환 | `Date`/`DateTime` 입력에 대해 `Date`/`DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `Date32`/`DateTime64` 반환 |
| `toLastDayOfWeek` | `Date` 또는 `DateTime` 반환 | `Date`/`DateTime` 입력에 대해 `Date`/`DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `Date32`/`DateTime64` 반환 |
| `toLastDayOfMonth` | `Date` 또는 `DateTime` 반환 | `Date`/`DateTime` 입력에 대해 `Date`/`DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `Date32`/`DateTime64` 반환 |
| `toMonday` | `Date` 또는 `DateTime` 반환 | `Date`/`DateTime` 입력에 대해 `Date`/`DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `Date32`/`DateTime64` 반환 |
| `toStartOfDay` | `DateTime` 반환<br/>*참고: 1970-2149 범위를 벗어난 값에 대해 잘못된 결과* | `Date`/`DateTime` 입력에 대해 `DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `DateTime64` 반환 |
| `toStartOfHour` | `DateTime` 반환<br/>*참고: 1970-2149 범위를 벗어난 값에 대해 잘못된 결과* | `Date`/`DateTime` 입력에 대해 `DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `DateTime64` 반환 |
| `toStartOfFifteenMinutes` | `DateTime` 반환<br/>*참고: 1970-2149 범위를 벗어난 값에 대해 잘못된 결과* | `Date`/`DateTime` 입력에 대해 `DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `DateTime64` 반환 |
| `toStartOfTenMinutes` | `DateTime` 반환<br/>*참고: 1970-2149 범위를 벗어난 값에 대해 잘못된 결과* | `Date`/`DateTime` 입력에 대해 `DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `DateTime64` 반환 |
| `toStartOfFiveMinutes` | `DateTime` 반환<br/>*참고: 1970-2149 범위를 벗어난 값에 대해 잘못된 결과* | `Date`/`DateTime` 입력에 대해 `DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `DateTime64` 반환 |
| `toStartOfMinute` | `DateTime` 반환<br/>*참고: 1970-2149 범위를 벗어난 값에 대해 잘못된 결과* | `Date`/`DateTime` 입력에 대해 `DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `DateTime64` 반환 |
| `timeSlot` | `DateTime` 반환<br/>*참고: 1970-2149 범위를 벗어난 값에 대해 잘못된 결과* | `Date`/`DateTime` 입력에 대해 `DateTime` 반환<br/>`Date32`/`DateTime64` 입력에 대해 `DateTime64` 반환 |
## enable_filesystem_cache {#enable_filesystem_cache} 



<SettingsInfoBlock type="Bool" default_value="1" />

원격 파일 시스템에 대한 캐시를 사용합니다. 이 설정은 디스크에 대한 캐시를 켜거나 끄지 않지만, 의도된 경우 일부 쿼리에 대해 캐시를 우회할 수 있습니다.
## enable_filesystem_cache_log {#enable_filesystem_cache_log} 



<SettingsInfoBlock type="Bool" default_value="0" />

각 쿼리에 대해 파일 시스템 캐시 로그를 기록할 수 있습니다.
## enable_filesystem_cache_on_write_operations {#enable_filesystem_cache_on_write_operations} 



<SettingsInfoBlock type="Bool" default_value="0" />

`write-through` 캐시의 활성화 또는 비활성화를 설정합니다. `false`로 설정하면 쓰기 작업에 대한 `write-through` 캐시가 비활성화됩니다. `true`로 설정하면 서버 구성의 캐시 디스크 구성 섹션에서 `cache_on_write_operations`가 켜져 있는 한 `write-through` 캐시가 활성화됩니다.
자세한 내용은 ["로컬 캐시 사용"](/operations/storing-data#using-local-cache)를 참조하세요.
## enable_filesystem_read_prefetches_log {#enable_filesystem_read_prefetches_log} 



<SettingsInfoBlock type="Bool" default_value="0" />

쿼리 중에 system.filesystem prefetch_log에 기록합니다. 테스트 또는 디버깅 용도로만 사용해야 하며, 기본적으로 활성화하는 것은 권장되지 않습니다.
## enable_global_with_statement {#enable_global_with_statement} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.2"},{"label": "1"},{"label": "Propagate WITH statements to UNION queries and all subqueries by default"}]}]}/>

WITH 문을 UNION 쿼리 및 모든 하위 쿼리에 전파합니다.
## enable_hdfs_pread {#enable_hdfs_pread} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "New setting."}]}]}/>

HDFS 파일에 대한 pread를 활성화하거나 비활성화합니다. 기본적으로 `hdfsPread`가 사용됩니다. 비활성화하면 `hdfsRead` 및 `hdfsSeek`가 HDFS 파일을 읽는 데 사용됩니다.
## enable_http_compression {#enable_http_compression} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "1"},{"label": "It should be beneficial in general"}]}]}/>

HTTP 요청에 대한 응답에서 데이터 압축을 활성화하거나 비활성화합니다.

자세한 정보는 [HTTP 인터페이스 설명](../../interfaces/http.md)를 참조하세요.

가능한 값:

- 0 — 비활성화됨.
- 1 — 활성화됨.
## enable_job_stack_trace {#enable_job_stack_trace} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.6"},{"label": "0"},{"label": "The setting was disabled by default to avoid performance overhead."}]}, {"id": "row-2","items": [{"label": "24.11"},{"label": "0"},{"label": "Enables collecting stack traces from job's scheduling. Disabled by default to avoid performance overhead."}]}]}/>

작업 결과가 예외로 발생할 때 작업 생성자의 스택 추적을 출력합니다. 성능 오버헤드를 피하기 위해 기본적으로 비활성화되어 있습니다.
## enable_join_runtime_filters {#enable_join_runtime_filters} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "0"},{"label": "New setting"}]}]}/>

실행 시간에 오른쪽에서 수집된 JOIN 키 집합에 의해 왼쪽을 필터링합니다.
## enable_lazy_columns_replication {#enable_lazy_columns_replication} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.11"},{"label": "1"},{"label": "Enable lazy columns replication in JOIN and ARRAY JOIN by default"}]}, {"id": "row-2","items": [{"label": "25.10"},{"label": "0"},{"label": "Add a setting to enable lazy columns replication in JOIN and ARRAY JOIN"}]}]}/>

JOIN 및 ARRAY JOIN에서 Lazy 컬럼 복제를 활성화합니다. 이렇게 하면 같은 행을 메모리에 여러 번 불필요하게 복사하는 것을 피할 수 있습니다.
## enable_lightweight_delete {#enable_lightweight_delete} 



<SettingsInfoBlock type="Bool" default_value="1" />

MergeTree 테이블에 대한 경량 DELETE 변형을 활성화합니다.
## enable_lightweight_update {#enable_lightweight_update} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "1"},{"label": "Lightweight updates were moved to Beta. Added an alias for setting 'allow_experimental_lightweight_update'."}]}]}/>

경량 업데이트를 사용할 수 있도록 허용합니다.
## enable_memory_bound_merging_of_aggregation_results {#enable_memory_bound_merging_of_aggregation_results} 



<SettingsInfoBlock type="Bool" default_value="1" />

집계에 대한 메모리 경계 병합 전략을 활성화합니다.
## enable_multiple_prewhere_read_steps {#enable_multiple_prewhere_read_steps} 



<SettingsInfoBlock type="Bool" default_value="1" />

여러 조건이 AND로 결합된 경우 WHERE에서 PREWHERE로 더 많은 조건을 이동하고 디스크에서 읽고 필터링을 여러 단계로 수행합니다.
## enable_named_columns_in_function_tuple {#enable_named_columns_in_function_tuple} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "Generate named tuples in function tuple() when all names are unique and can be treated as unquoted identifiers."}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "0"},{"label": "Disabled pending usability improvements"}]}]}/>

모든 이름이 고유하고 따옴표 없는 식별자로 취급될 수 있을 때 함수 tuple()에 명명된 튜플을 생성합니다.
## enable_optimize_predicate_expression {#enable_optimize_predicate_expression} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "18.12.17"},{"label": "1"},{"label": "Optimize predicates to subqueries by default"}]}]}/>

`SELECT` 쿼리에서 프레디케이트 푸시다운을 활성화합니다.

프레디케이트 푸시다운은 분산 쿼리에 대한 네트워크 트래픽을 크게 줄일 수 있습니다.

가능한 값:

- 0 — 비활성화됨.
- 1 — 활성화됨.

사용법

다음 쿼리를 고려하십시오:

1.  `SELECT count() FROM test_table WHERE date = '2018-10-10'`
2.  `SELECT count() FROM (SELECT * FROM test_table) WHERE date = '2018-10-10'`

`enable_optimize_predicate_expression = 1`인 경우, ClickHouse는 하위 쿼리 처리 시 `WHERE`를 하위 쿼리에 적용하므로 이러한 쿼리의 실행 시간이 동일합니다.

`enable_optimize_predicate_expression = 0`인 경우, 두 번째 쿼리의 실행 시간이 훨씬 길어집니다. 왜냐하면 `WHERE` 절이 하위 쿼리가 완료된 후에 모든 데이터에 적용되기 때문입니다.
## enable_optimize_predicate_expression_to_final_subquery {#enable_optimize_predicate_expression_to_final_subquery} 



<SettingsInfoBlock type="Bool" default_value="1" />

최종 하위 쿼리에 프레디케이트 푸시를 허용합니다.
## enable_order_by_all {#enable_order_by_all} 



<SettingsInfoBlock type="Bool" default_value="1" />

`ORDER BY ALL` 구문으로 정렬을 활성화 또는 비활성화합니다. [ORDER BY](../../sql-reference/statements/select/order-by.md)를 참조하세요.

가능한 값:

- 0 — ORDER BY ALL 비활성화.
- 1 — ORDER BY ALL 활성화.

**예시**

쿼리:

```sql
CREATE TABLE TAB(C1 Int, C2 Int, ALL Int) ENGINE=Memory();

INSERT INTO TAB VALUES (10, 20, 30), (20, 20, 10), (30, 10, 20);

SELECT * FROM TAB ORDER BY ALL; -- returns an error that ALL is ambiguous

SELECT * FROM TAB ORDER BY ALL SETTINGS enable_order_by_all = 0;
```

결과:

```text
┌─C1─┬─C2─┬─ALL─┐
│ 20 │ 20 │  10 │
│ 30 │ 10 │  20 │
│ 10 │ 20 │  30 │
└────┴────┴─────┘
```
## enable_parallel_blocks_marshalling {#enable_parallel_blocks_marshalling} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.6"},{"label": "true"},{"label": "A new setting"}]}]}/>

분산 쿼리에서만 영향을 미칩니다. 활성화되면 블록이 파이프라인 스레드에서 (비직렬화) 및 (비압축)되고 나서/전송됩니다.
## enable_parsing_to_custom_serialization {#enable_parsing_to_custom_serialization} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1"},{"label": "New setting"}]}]}/>

참이면 사용자 정의 직렬화(예: Sparse)로 직접 열로 파싱할 수 있습니다. 
## enable_positional_arguments {#enable_positional_arguments} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.7"},{"label": "1"},{"label": "Enable positional arguments feature by default"}]}]}/>

[GROUP BY](/sql-reference/statements/select/group-by), [LIMIT BY](../../sql-reference/statements/select/limit-by.md), [ORDER BY](../../sql-reference/statements/select/order-by.md) 문에 대한 위치 지정 인수를 활성화하거나 비활성화합니다.

가능한 값:

- 0 — 위치 지정 인수가 지원되지 않음.
- 1 — 위치 지정 인수가 지원됩니다: 컬럼 번호를 컬럼 이름 대신 사용할 수 있습니다.

**예시**

쿼리:

```sql
CREATE TABLE positional_arguments(one Int, two Int, three Int) ENGINE=Memory();

INSERT INTO positional_arguments VALUES (10, 20, 30), (20, 20, 10), (30, 10, 20);

SELECT * FROM positional_arguments ORDER BY 2,3;
```

결과:

```text
┌─one─┬─two─┬─three─┐
│  30 │  10 │   20  │
│  20 │  20 │   10  │
│  10 │  20 │   30  │
└─────┴─────┴───────┘
```
## enable_producing_buckets_out_of_order_in_aggregation {#enable_producing_buckets_out_of_order_in_aggregation} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.9"},{"label": "1"},{"label": "New setting"}]}]}/>

메모리 효율적인 집계를 허용합니다(예: `distributed_aggregation_memory_efficient`) 루프에서 순서가 다른 집계를 생성합니다. 이를 통해 집계 버킷 크기가 불균형할 때 성능을 개선할 수 있습니다. 복제본이 여전히 낮은 ID의 일부 무거운 버킷을 처리하는 동안 높은 ID의 버킷을 발신자로 보낼 수 있으므로 더 나은 성능을 발휘할 수 있습니다.
단점은 잠재적으로 메모리 사용량이 증가할 수 있습니다.
## enable_reads_from_query_cache {#enable_reads_from_query_cache} 



<SettingsInfoBlock type="Bool" default_value="1" />

활성화되면 `SELECT` 쿼리의 결과가 [쿼리 캐시](../query-cache.md)에서 검색됩니다.

가능한 값:

- 0 - 비활성화됨
- 1 - 활성화됨
## enable_s3_requests_logging {#enable_s3_requests_logging} 



<SettingsInfoBlock type="Bool" default_value="0" />

S3 요청에 대한 매우 명시적인 로깅을 활성화합니다. 디버그 용도로 적합합니다.
## enable_scalar_subquery_optimization {#enable_scalar_subquery_optimization} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "19.18"},{"label": "1"},{"label": "Prevent scalar subqueries from (de)serializing large scalar values and possibly avoid running the same subquery more than once"}]}]}/>

참으로 설정하면 스칼라 하위 쿼리가 큰 스칼라 값을 (비)직렬화하는 것을 방지하고 동일한 하위 쿼리를 한 번 이상 실행하는 것을 피할 수 있습니다.
## enable_scopes_for_with_statement {#enable_scopes_for_with_statement} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.7"},{"label": "1"},{"label": "New setting for backward compatibility with the old analyzer."}]}, {"id": "row-2","items": [{"label": "25.6"},{"label": "1"},{"label": "New setting for backward compatibility with the old analyzer."}]}, {"id": "row-3","items": [{"label": "25.5"},{"label": "1"},{"label": "New setting for backward compatibility with the old analyzer."}]}, {"id": "row-4","items": [{"label": "25.4"},{"label": "1"},{"label": "New setting for backward compatibility with the old analyzer."}]}]}/>

비활성화하면 부모 WITH 절의 선언이 현재 범위에 선언된 것과 동일한 범위에서 작동합니다.

이것은 이전 분석기가 실행할 수 있었던 일부 잘못된 쿼리를 실행할 수 있도록 하는 새 분석기 호환성 설정임을 유의하십시오.
## enable_shared_storage_snapshot_in_query {#enable_shared_storage_snapshot_in_query} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.6"},{"label": "0"},{"label": "A new setting to share storage snapshot in query"}]}]}/>

활성화되면 단일 쿼리 내의 모든 하위 쿼리는 각 테이블에 대해 동일한 StorageSnapshot을 공유합니다.
이는 쿼리 전체에 걸쳐 데이터의 일관된 뷰를 보장합니다. 동일한 테이블이 여러 번 액세스되는 경우에도 마찬가지입니다.

데이터 부분의 내부 일관성이 중요한 쿼리에 필요합니다. 예시:

```sql
SELECT
    count()
FROM events
WHERE (_part, _part_offset) IN (
    SELECT _part, _part_offset
    FROM events
    WHERE user_id = 42
)
```

이 설정이 없으면 외부 및 내부 쿼리가 서로 다른 데이터 스냅샷에서 작동하여 잘못된 결과를 초래할 수 있습니다.

:::note
이 설정을 활성화하면 최적화가 비활성화되어 계획 단계가 완료되면 스냅샷에서 불필요한 데이터 부분이 제거됩니다.
결과적으로 장기 실행 쿼리는 전체 실행 기간 동안 구식 부품을 보유할 수 있어 부분 정리를 지연시키고 저장소 압력을 증가시킬 수 있습니다.

이 설정은 현재 MergeTree 패밀리의 테이블에만 적용됩니다.
:::

가능한 값:

- 0 - 비활성화됨
- 1 - 활성화됨
## enable_sharing_sets_for_mutations {#enable_sharing_sets_for_mutations} 



<SettingsInfoBlock type="Bool" default_value="1" />

IN 하위 쿼리에 대해 빌드된 공유 집합 개체를 동일한 변형의 서로 다른 작업 간에 공유할 수 있습니다. 이렇게 하면 메모리 사용량과 CPU 소모를 줄일 수 있습니다.
## enable_software_prefetch_in_aggregation {#enable_software_prefetch_in_aggregation} 



<SettingsInfoBlock type="Bool" default_value="1" />

집계에서 소프트웨어 프리패치 사용을 활성화합니다.
## enable_unaligned_array_join {#enable_unaligned_array_join} 



<SettingsInfoBlock type="Bool" default_value="0" />

크기가 다른 여러 배열로 ARRAY JOIN을 허용합니다. 이 설정이 활성화되면 배열은 가장 긴 배열로 크기가 조정됩니다.
## enable_url_encoding {#enable_url_encoding} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "Changed existing setting's default value"}]}]}/>

[URL](../../engines/table-engines/special/url.md) 엔진 테이블에서 URI의 경로를 디코딩/인코딩할 수 있도록 활성화/비활성화합니다.

기본적으로 비활성화되어 있습니다.
## enable_vertical_final {#enable_vertical_final} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "Enable vertical final by default again after fixing bug"}]}, {"id": "row-2","items": [{"label": "24.1"},{"label": "1"},{"label": "Use vertical final by default"}]}]}/>

활성화되면 FINAL 중 중복된 행을 제거하여 행을 삭제된 것으로 표시하고 나중에 필터링합니다. 병합하는 대신에.
## enable_writes_to_query_cache {#enable_writes_to_query_cache} 



<SettingsInfoBlock type="Bool" default_value="1" />

활성화되면 `SELECT` 쿼리의 결과가 [쿼리 캐시](../query-cache.md)에 저장됩니다.

가능한 값:

- 0 - 비활성화됨
- 1 - 활성화됨
## enable_zstd_qat_codec {#enable_zstd_qat_codec} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "Add new ZSTD_QAT codec"}]}]}/>

활성화되면 ZSTD_QAT 코덱을 사용하여 열을 압축할 수 있습니다.
## enforce_strict_identifier_format {#enforce_strict_identifier_format} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "New setting."}]}]}/>

활성화되면 알파벳 문자와 언더스코어만 포함된 식별자만 허용합니다.
## engine_file_allow_create_multiple_files {#engine_file_allow_create_multiple_files} 



<SettingsInfoBlock type="Bool" default_value="0" />

파일 엔진 테이블에서 각 삽입 시 새 파일을 생성할 수 있도록 활성화하거나 비활성화합니다. 형식에 접미사(`JSON`, `ORC`, `Parquet` 등)가 있는 경우. 활성화되면 각 삽입 시 다음과 같은 패턴의 이름으로 새 파일이 생성됩니다:

`data.Parquet` -> `data.1.Parquet` -> `data.2.Parquet` 등.

가능한 값:
- 0 — `INSERT` 쿼리가 파일 끝에 새로운 데이터를 추가합니다.
- 1 — `INSERT` 쿼리가 새 파일을 생성합니다.
## engine_file_empty_if_not_exists {#engine_file_empty_if_not_exists} 



<SettingsInfoBlock type="Bool" default_value="0" />

파일이 없는 상태에서 파일 엔진 테이블에서 데이터를 선택할 수 있도록 합니다.

가능한 값:
- 0 — `SELECT`가 예외를 발생시킵니다.
- 1 — `SELECT`가 빈 결과를 반환합니다.
## engine_file_skip_empty_files {#engine_file_skip_empty_files} 



<SettingsInfoBlock type="Bool" default_value="0" />

[File](../../engines/table-engines/special/file.md) 엔진 테이블에서 빈 파일을 스킵하는 기능을 활성화하거나 비활성화합니다.

가능한 값:
- 0 — 빈 파일이 요청된 형식과 호환되지 않는 경우 `SELECT`가 예외를 발생시킵니다.
- 1 — 빈 파일에 대해 `SELECT`가 빈 결과를 반환합니다.
## engine_file_truncate_on_insert {#engine_file_truncate_on_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

[File](../../engines/table-engines/special/file.md) 엔진 테이블에서 삽입 전에 잘라내는 기능을 활성화하거나 비활성화합니다.

가능한 값:
- 0 — `INSERT` 쿼리가 파일 끝에 새로운 데이터를 추가합니다.
- 1 — `INSERT` 쿼리가 파일의 기존 콘텐츠를 새 데이터로 교체합니다.
## engine_url_skip_empty_files {#engine_url_skip_empty_files} 



<SettingsInfoBlock type="Bool" default_value="0" />

[URL](../../engines/table-engines/special/url.md) 엔진 테이블에서 빈 파일을 스킵하는 기능을 활성화하거나 비활성화합니다.

가능한 값:
- 0 — 빈 파일이 요청된 형식과 호환되지 않는 경우 `SELECT`가 예외를 발생시킵니다.
- 1 — 빈 파일에 대해 `SELECT`가 빈 결과를 반환합니다.
## except_default_mode {#except_default_mode} 



<SettingsInfoBlock type="SetOperationMode" default_value="ALL" />

EXCEPT 쿼리의 기본 모드를 설정합니다. 가능한 값: 빈 문자열, 'ALL', 'DISTINCT'. 비어 있을 경우 모드 없이 쿼리를 실행하면 예외가 발생합니다.
## exclude_materialize_skip_indexes_on_insert {#exclude_materialize_skip_indexes_on_insert} 



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": ""},{"label": "New setting."}]}]}/>

INSERT 중에 특정 스킵 인덱스를 작성 및 저장하지 않도록 제외합니다. 제외된 스킵 인덱스는 여전히 [병합 중](merge-tree-settings.md/#materialize_skip_indexes_on_merge) 작성 및 저장되거나 명시적인
[MATERIALIZE INDEX](/sql-reference/statements/alter/skipping-index.md/#materialize-index) 쿼리로 작성됩니다.

[materialize_skip_indexes_on_insert](#materialize_skip_indexes_on_insert)가 false인 경우에는 영향을 미치지 않습니다.

예시:

```sql
CREATE TABLE tab
(
    a UInt64,
    b UInt64,
    INDEX idx_a a TYPE minmax,
    INDEX idx_b b TYPE set(3)
)
ENGINE = MergeTree ORDER BY tuple();

SET exclude_materialize_skip_indexes_on_insert='idx_a'; -- idx_a will be not be updated upon insert
--SET exclude_materialize_skip_indexes_on_insert='idx_a, idx_b'; -- neither index would be updated on insert

INSERT INTO tab SELECT number, number / 50 FROM numbers(100); -- only idx_b is updated

-- since it is a session setting it can be set on a per-query level
INSERT INTO tab SELECT number, number / 50 FROM numbers(100, 100) SETTINGS exclude_materialize_skip_indexes_on_insert='idx_b';

ALTER TABLE tab MATERIALIZE INDEX idx_a; -- this query can be used to explicitly materialize the index

SET exclude_materialize_skip_indexes_on_insert = DEFAULT; -- reset setting to default
```
## execute_exists_as_scalar_subquery {#execute_exists_as_scalar_subquery} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "1"},{"label": "New setting"}]}]}/>

비상관 하위 쿼리로 EXISTS를 스칼라 하위 쿼리로 실행합니다. 스칼라 하위 쿼리에 대해 캐시가 사용되며 결과에 대해 상수 접기가 적용됩니다.
## external_storage_connect_timeout_sec {#external_storage_connect_timeout_sec} 



<SettingsInfoBlock type="UInt64" default_value="10" />

연결 시간 초과(초)입니다. 현재 MySQL에 대해서만 지원됩니다.
## external_storage_max_read_bytes {#external_storage_max_read_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

외부 엔진을 가진 테이블이 이력 데이터를 플러시할 때 최대 바이트 수를 제한합니다. 현재 MySQL 테이블 엔진, 데이터베이스 엔진 및 딕셔너리에 대해서만 지원됩니다. 0과 같으면 이 설정이 비활성화됩니다.
## external_storage_max_read_rows {#external_storage_max_read_rows} 



<SettingsInfoBlock type="UInt64" default_value="0" />

외부 엔진을 가진 테이블이 이력 데이터를 플러시할 때 최대 행 수를 제한합니다. 현재 MySQL 테이블 엔진, 데이터베이스 엔진 및 딕셔너리에 대해서만 지원됩니다. 0과 같으면 이 설정이 비활성화됩니다.
## external_storage_rw_timeout_sec {#external_storage_rw_timeout_sec} 



<SettingsInfoBlock type="UInt64" default_value="300" />

읽기/쓰기 시간 초과(초)입니다. 현재 MySQL에 대해서만 지원됩니다.
## external_table_functions_use_nulls {#external_table_functions_use_nulls} 



<SettingsInfoBlock type="Bool" default_value="1" />

[mysql](../../sql-reference/table-functions/mysql.md), [postgresql](../../sql-reference/table-functions/postgresql.md) 및 [odbc](../../sql-reference/table-functions/odbc.md) 테이블 함수가 Nullable 컬럼을 사용하는 방식을 정의합니다.

가능한 값:

- 0 — 테이블 함수가 명시적으로 Nullable 컬럼을 사용합니다.
- 1 — 테이블 함수가 암묵적으로 Nullable 컬럼을 사용합니다.

**사용법**

설정이 `0`으로 설정되면 테이블 함수는 Nullable 컬럼을 만들지 않고 NULL 대신 기본값을 삽입합니다. 이는 배열 내의 NULL 값에도 적용됩니다.
## external_table_strict_query {#external_table_strict_query} 



<SettingsInfoBlock type="Bool" default_value="0" />

참으로 설정되면 외부 테이블 쿼리의 로컬 필터로 변환하는 것이 금지됩니다.
## extract_key_value_pairs_max_pairs_per_row {#extract_key_value_pairs_max_pairs_per_row} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "0"},{"label": "Max number of pairs that can be produced by the `extractKeyValuePairs` function. Used as a safeguard against consuming too much memory."}]}]}/>

`extractKeyValuePairs` 함수에서 생성할 수 있는 최대 쌍 수입니다. 메모리 과다 소비를 방지하기 위한 안전 장치로 사용됩니다.
## extremes {#extremes} 



<SettingsInfoBlock type="Bool" default_value="0" />

쿼리 결과의 컬럼에서 극단값(최소값 및 최대값)을 계산할지 여부입니다. 0 또는 1을 허용합니다. 기본값은 0(비활성화)입니다. 극단값에 대한 자세한 내용은 "극단값" 섹션을 참조하세요.
## fallback_to_stale_replicas_for_distributed_queries {#fallback_to_stale_replicas_for_distributed_queries} 



<SettingsInfoBlock type="Bool" default_value="1" />

업데이트된 데이터가 없는 경우 쿼리를 구식 복제본으로 강제합니다. [복제](../../engines/table-engines/mergetree-family/replication.md)를 참조하세요.

ClickHouse는 표의 구식 복제본 중 가장 관련 있는 것을 선택합니다.

복제된 테이블을 가리키는 분산 테이블에서 `SELECT`를 수행할 때 사용됩니다.

기본적으로 1(활성화됨)입니다.
## filesystem_cache_allow_background_download {#filesystem_cache_allow_background_download} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.11"},{"label": "1"},{"label": "New setting to control background downloads in filesystem cache per query."}]}]}/>

원격 저장소에서 읽은 데이터에 대한 백그라운드 다운로드를 큐에 추가할 수 있도록 파일 시스템 캐시를 허용합니다. 현재 쿼리/세션에 대해 다운로드를 전경으로 유지하려면 비활성화합니다.
## filesystem_cache_boundary_alignment {#filesystem_cache_boundary_alignment} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "New setting"}]}]}/>

파일 시스템 캐시 경계 정렬. 이 설정은 비디스크 읽기(예: 원격 테이블 엔진/테이블 함수 캐시의 경우)에서만 적용됩니다. 값 0은 정렬이 없음을 의미합니다.
## filesystem_cache_enable_background_download_during_fetch {#filesystem_cache_enable_background_download_during_fetch} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 파일 시스템 캐시에서 공간 예약을 위한 캐시 잠금을 위한 대기 시간입니다.
## filesystem_cache_enable_background_download_for_metadata_files_in_packed_storage {#filesystem_cache_enable_background_download_for_metadata_files_in_packed_storage} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 파일 시스템 캐시에서 공간 예약을 위한 캐시 잠금을 위한 대기 시간입니다.
## filesystem_cache_max_download_size {#filesystem_cache_max_download_size} 



<SettingsInfoBlock type="UInt64" default_value="137438953472" />

단일 쿼리로 다운로드할 수 있는 원격 파일 시스템 캐시의 최대 크기입니다.
## filesystem_cache_name {#filesystem_cache_name} 



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": ""},{"label": "Filesystem cache name to use for stateless table engines or data lakes"}]}]}/>

무상태 테이블 엔진 또는 데이터 레이크에 사용할 파일 시스템 캐시 이름입니다.
## filesystem_cache_prefer_bigger_buffer_size {#filesystem_cache_prefer_bigger_buffer_size} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "New setting"}]}]}/>

파일 시스템 캐시가 활성화된 경우 작은 파일 세그먼트의 작성을 피하기 위해 더 큰 버퍼 크기를 선호합니다. 반면 이 설정을 활성화하면 메모리 사용량이 증가할 수 있습니다.
## filesystem_cache_reserve_space_wait_lock_timeout_milliseconds {#filesystem_cache_reserve_space_wait_lock_timeout_milliseconds} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1000"},{"label": "Wait time to lock cache for space reservation in filesystem cache"}]}]}/>

파일 시스템 캐시에서 공간 예약을 위한 캐시 잠금을 위한 대기 시간입니다.
## filesystem_cache_segments_batch_size {#filesystem_cache_segments_batch_size} 



<SettingsInfoBlock type="UInt64" default_value="20" />

읽기 버퍼가 캐시에서 요청할 수 있는 단일 파일 세그먼트 배치의 크기에 대한 제한입니다. 값이 너무 낮으면 캐시에 과도한 요청이 발생하고, 값이 너무 크면 캐시에서 퇴거 속도가 느려질 수 있습니다.
## filesystem_cache_skip_download_if_exceeds_per_query_cache_write_limit {#filesystem_cache_skip_download_if_exceeds_per_query_cache_write_limit} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "Rename of setting skip_download_if_exceeds_query_cache_limit"}]}]}/>

쿼리 캐시 크기를 초과하면 원격 파일 시스템에서 다운로드하지 않습니다.
## filesystem_prefetch_max_memory_usage {#filesystem_prefetch_max_memory_usage} 



<SettingsInfoBlock type="NonZeroUInt64" default_value="1073741824" />

프리패치에 대한 최대 메모리 사용량입니다.
## filesystem_prefetch_step_bytes {#filesystem_prefetch_step_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

프리패치 단계(바이트)입니다. 0은 `auto`를 의미합니다. 가장 좋은 프리패치 단계를 자동으로 유추하지만 100% 최적의 값은 아닐 수 있습니다. 실제 값은 filesystem_prefetch_min_bytes_for_single_read_task 설정에 따라 다를 수 있습니다.
## filesystem_prefetch_step_marks {#filesystem_prefetch_step_marks} 



<SettingsInfoBlock type="UInt64" default_value="0" />

프리패치 단계(마크)입니다. 0은 `auto`를 의미합니다. 가장 좋은 프리패치 단계를 자동으로 유추하지만 100% 최적의 값은 아닐 수 있습니다. 실제 값은 filesystem_prefetch_min_bytes_for_single_read_task 설정에 따라 다를 수 있습니다.
## filesystem_prefetches_limit {#filesystem_prefetches_limit} 



<SettingsInfoBlock type="UInt64" default_value="200" />

최대 프리패치 수입니다. 0은 무제한을 의미합니다. 프리패치 수를 제한하려면 `filesystem_prefetches_max_memory_usage` 설정을 권장합니다.
## final {#final} 



<SettingsInfoBlock type="Bool" default_value="0" />

쿼리의 모든 테이블에 [FINAL](../../sql-reference/statements/select/from.md/#final-modifier) 수정자가 자동으로 적용되며, [FINAL](../../sql-reference/statements/select/from.md/#final-modifier)가 적용되는 테이블, 조인된 테이블 및 하위 쿼리의 테이블 및 분산 테이블을 포함합니다.

가능한 값:

- 0 - 비활성화됨
- 1 - 활성화됨

예시:

```sql
CREATE TABLE test
(
    key Int64,
    some String
)
ENGINE = ReplacingMergeTree
ORDER BY key;

INSERT INTO test FORMAT Values (1, 'first');
INSERT INTO test FORMAT Values (1, 'second');

SELECT * FROM test;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘
┌─key─┬─some──┐
│   1 │ first │
└─────┴───────┘

SELECT * FROM test SETTINGS final = 1;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘

SET final = 1;
SELECT * FROM test;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘
```
## flatten_nested {#flatten_nested} 



<SettingsInfoBlock type="Bool" default_value="1" />

[중첩된](../../sql-reference/data-types/nested-data-structures/index.md) 컬럼의 데이터 형식을 설정합니다.

가능한 값:

- 1 — 중첩된 컬럼이 개별 배열로 평탄화됩니다.
- 0 — 중첩된 컬럼이 튜플의 단일 배열 그대로 유지됩니다.

**사용법**

설정이 `0`으로 설정되면 임의의 수준의 중첩을 사용할 수 있습니다.

**예시**

쿼리:

```sql
SET flatten_nested = 1;
CREATE TABLE t_nest (`n` Nested(a UInt32, b UInt32)) ENGINE = MergeTree ORDER BY tuple();

SHOW CREATE TABLE t_nest;
```

결과:

```text
┌─statement───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.t_nest
(
    `n.a` Array(UInt32),
    `n.b` Array(UInt32)
)
ENGINE = MergeTree
ORDER BY tuple()
SETTINGS index_granularity = 8192 │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

쿼리:

```sql
SET flatten_nested = 0;

CREATE TABLE t_nest (`n` Nested(a UInt32, b UInt32)) ENGINE = MergeTree ORDER BY tuple();

SHOW CREATE TABLE t_nest;
```

결과:

```text
┌─statement──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.t_nest
(
    `n` Nested(a UInt32, b UInt32)
)
ENGINE = MergeTree
ORDER BY tuple()
SETTINGS index_granularity = 8192 │
└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```
## force_aggregate_partitions_independently {#force_aggregate_partitions_independently} 



<SettingsInfoBlock type="Bool" default_value="0" />

최적화를 적용해야 할 때는 강제로 최적화를 사용하도록 합니다. 그러나 휴리스틱적으로 사용하지 않기로 결정된 경우에도 강제합니다.
## force_aggregation_in_order {#force_aggregation_in_order} 



<SettingsInfoBlock type="Bool" default_value="0" />

이 설정은 서버 자체에서 분산 쿼리를 지원하는 데 사용됩니다. 수동으로 변경하지 마십시오. 그렇게 하면 정상적인 작업이 중단됩니다. (분산 집계 중 원격 노드에서 순서대로 집계를 강제로 적용합니다).
## force_data_skipping_indices {#force_data_skipping_indices} 

전달된 데이터 스킵 인덱스가 사용되지 않은 경우 쿼리 실행을 비활성화합니다.

다음 예제를 고려하십시오:

```sql
CREATE TABLE data
(
    key Int,
    d1 Int,
    d1_null Nullable(Int),
    INDEX d1_idx d1 TYPE minmax GRANULARITY 1,
    INDEX d1_null_idx assumeNotNull(d1_null) TYPE minmax GRANULARITY 1
)
Engine=MergeTree()
ORDER BY key;

SELECT * FROM data_01515;
SELECT * FROM data_01515 SETTINGS force_data_skipping_indices=''; -- query will produce CANNOT_PARSE_TEXT error.
SELECT * FROM data_01515 SETTINGS force_data_skipping_indices='d1_idx'; -- query will produce INDEX_NOT_USED error.
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='d1_idx'; -- Ok.
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='`d1_idx`'; -- Ok (example of full featured parser).
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='`d1_idx`, d1_null_idx'; -- query will produce INDEX_NOT_USED error, since d1_null_idx is not used.
SELECT * FROM data_01515 WHERE d1 = 0 AND assumeNotNull(d1_null) = 0 SETTINGS force_data_skipping_indices='`d1_idx`, d1_null_idx'; -- Ok.
```
## force_grouping_standard_compatibility {#force_grouping_standard_compatibility} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.9"},{"label": "1"},{"label": "Make GROUPING function output the same as in SQL standard and other DBMS"}]}]}/>

GROUPING 함수가 인수가 집계 키로 사용되지 않을 때 1을 반환하도록 합니다.
## force_index_by_date {#force_index_by_date} 



<SettingsInfoBlock type="Bool" default_value="0" />

인덱스를 날짜별로 사용할 수 없는 경우 쿼리 실행을 비활성화합니다.

MergeTree 패밀리의 테이블과 함께 작동합니다.

`force_index_by_date=1`인 경우 ClickHouse는 쿼리에 데이터를 제한하기 위해 사용할 수 있는 날짜 키 조건이 있는지 확인합니다. 적절한 조건이 없는 경우 예외가 발생합니다. 그러나 조건이 읽어야 할 데이터 양을 줄이는지 여부는 확인하지 않습니다. 예를 들어, 조건 `Date != ' 2000-01-01 '`은 테이블의 모든 데이터와 일치해도 허용됩니다(즉, 쿼리를 실행하려면 전체 스캔이 필요함). MergeTree 테이블의 데이터 범위에 대한 자세한 내용은 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)를 참조하십시오.
## force_optimize_projection {#force_optimize_projection} 



<SettingsInfoBlock type="Bool" default_value="0" />

`SELECT` 쿼리에서 [프로젝션](../../engines/table-engines/mergetree-family/mergetree.md/#projections)의 필수 사용을 활성화하거나 비활성화합니다. 프로젝션 최적화가 활성화된 경우(설정이 [optimize_use_projections](#optimize_use_projections)).

가능한 값:

- 0 — 프로젝션 최적화가 필수가 아님.
- 1 — 프로젝션 최적화가 필수입니다.
## force_optimize_projection_name {#force_optimize_projection_name} 

비어 있지 않은 문자열로 설정되면 이 프로젝션이 쿼리에서 최소한 한 번 사용되었는지 확인합니다.

가능한 값:

- 문자열: 쿼리에서 사용된 프로젝션의 이름
## force_optimize_skip_unused_shards {#force_optimize_skip_unused_shards} 



<SettingsInfoBlock type="UInt64" default_value="0" />

[optimize_skip_unused_shards](#optimize_skip_unused_shards)가 활성화되고 사용되지 않는 샤드를 건너뛰는 것 불가능할 경우 쿼리 실행을 비활성화하도록 활성화 또는 비활성화합니다. 건너뛰기가 불가능하고 이 설정이 활성화되면 예외가 발생합니다.

가능한 값:

- 0 — 비활성화됨. ClickHouse는 예외를 발생시키지 않습니다.
- 1 — 활성화됨. 테이블에 분할 키가 있는 경우에만 쿼리 실행이 비활성화됩니다.
- 2 — 활성화됨. 테이블에 분할 키가 정의되었든 그렇지 않든 쿼리 실행이 비활성화됩니다.
## force_optimize_skip_unused_shards_nesting {#force_optimize_skip_unused_shards_nesting} 



<SettingsInfoBlock type="UInt64" default_value="0" />

[`force_optimize_skip_unused_shards`](#force_optimize_skip_unused_shards)를 제어합니다(따라서 여전히 [`force_optimize_skip_unused_shards`](#force_optimize_skip_unused_shards)가 필요합니다). 이 설정은 분산 쿼리의 중첩 수준에 따라 다릅니다(예: 하나의 `Distributed` 테이블이 다른 `Distributed` 테이블을 참조하는 경우).

가능한 값:

- 0 - 비활성화됨, `force_optimize_skip_unused_shards`는 항상 작동합니다.
- 1 — 첫 번째 수준에 대해서만 `force_optimize_skip_unused_shards`를 활성화합니다.
- 2 — 두 번째 수준까지 `force_optimize_skip_unused_shards`를 활성화합니다.
## force_primary_key {#force_primary_key} 



<SettingsInfoBlock type="Bool" default_value="0" />

기본 키로 인덱싱할 수 없는 경우 쿼리 실행을 비활성화합니다.

MergeTree 패밀리의 테이블과 함께 작동합니다.

`force_primary_key=1`인 경우 ClickHouse는 쿼리에 데이터 범위를 제한하는 데 사용할 수 있는 기본 키 조건이 있는지 확인합니다. 적절한 조건이 없는 경우 예외가 발생합니다. 그러나 조건이 읽어야 할 데이터 양을 줄이는지 여부는 확인하지 않습니다. MergeTree 테이블의 데이터 범위에 대한 자세한 내용은 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)를 참조하십시오.
## force_remove_data_recursively_on_drop {#force_remove_data_recursively_on_drop} 



<SettingsInfoBlock type="Bool" default_value="0" />

DROP 쿼리에서 데이터를 재귀적으로 제거합니다. '디렉터리가 비어 있지 않음' 오류를 피하지만 분리된 데이터를 조용히 제거할 수 있습니다.
## formatdatetime_e_with_space_padding {#formatdatetime_e_with_space_padding} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "Improved compatibility with MySQL DATE_FORMAT/STR_TO_DATE"}]}]}/>

'formatDateTime' 함수의 포맷터 '%e'는 일 단위를 선행 공백과 함께 인쇄합니다. 예: ' 2' 대신 '2'입니다.
## formatdatetime_f_prints_scale_number_of_digits {#formatdatetime_f_prints_scale_number_of_digits} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "New setting."}]}]}/>

'formatDateTime' 함수의 포맷터 '%f'는 고정된 6자리 대신 DateTime64에 대한 자릿수의 양만 인쇄합니다.
## formatdatetime_f_prints_single_zero {#formatdatetime_f_prints_single_zero} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "0"},{"label": "Improved compatibility with MySQL DATE_FORMAT()/STR_TO_DATE()"}]}]}/>

'formatDateTime' 함수의 포맷터 '%f'는 형식화된 값에 분수 초가 없는 경우 여섯 개의 제로 대신 하나의 제로를 인쇄합니다.
## formatdatetime_format_without_leading_zeros {#formatdatetime_format_without_leading_zeros} 



<SettingsInfoBlock type="Bool" default_value="0" />

'formatDateTime' 함수의 포맷터 '%c', '%l' 및 '%k'는 선행 제로가 없는 형태로 월 및 시간을 인쇄합니다.
## formatdatetime_parsedatetime_m_is_month_name {#formatdatetime_parsedatetime_m_is_month_name} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "1"},{"label": "Improved compatibility with MySQL DATE_FORMAT/STR_TO_DATE"}]}]}/>

'formatDateTime' 및 'parseDateTime' 함수의 포맷터 '%M'는 분 대신 월 이름을 인쇄/구문 분석합니다.
## fsync_metadata {#fsync_metadata} 

<SettingsInfoBlock type="Bool" default_value="1" />

`.sql` 파일을 작성할 때 [fsync](http://pubs.opengroup.org/onlinepubs/9699919799/functions/fsync.html)를 사용 여부를 설정합니다. 기본값은 활성화되어 있습니다.

서버에 수백만 개의 작은 테이블이 지속적으로 생성되고 파괴되는 경우 비활성화하는 것이 합리적입니다.
## function_date_trunc_return_type_behavior {#function_date_trunc_return_type_behavior} 

<SettingsInfoBlock type="UInt64" default_value="0" />

`dateTrunc` 함수의 결과 유형 동작을 변경할 수 있습니다.

 가능한 값:

- 0 - 두 번째 인수가 `DateTime64/Date32`일 경우, 반환 유형은 첫 번째 인수의 시간 단위에 관계없이 `DateTime64/Date32`가 됩니다.
- 1 - `Date32`는 항상 `Date`입니다. `DateTime64`는 시간 단위가 `second` 및 그 이상인 경우 결과가 `DateTime`입니다.
## function_implementation {#function_implementation} 

특정 대상 또는 변형(실험적)의 함수 구현을 선택합니다. 비어 있으면 모든 구현을 활성화합니다.
## function_json_value_return_type_allow_complex {#function_json_value_return_type_allow_complex} 

<SettingsInfoBlock type="Bool" default_value="0" />

`json_value` 함수에 대해 복합형(예: struct, array, map)을 반환하도록 허용할지 제어합니다.

```sql
SELECT JSON_VALUE('{"hello":{"world":"!"}}', '$.hello') settings function_json_value_return_type_allow_complex=true

┌─JSON_VALUE('{"hello":{"world":"!"}}', '$.hello')─┐
│ {"world":"!"}                                    │
└──────────────────────────────────────────────────┘

1 row in set. Elapsed: 0.001 sec.
```

 가능한 값:

- true — 허용.
- false — 비허용.
## function_json_value_return_type_allow_nullable {#function_json_value_return_type_allow_nullable} 

<SettingsInfoBlock type="Bool" default_value="0" />

JSON_VALUE 함수의 값이 존재하지 않을 때 `NULL`을 반환하도록 허용할지 제어합니다.

```sql
SELECT JSON_VALUE('{"hello":"world"}', '$.b') settings function_json_value_return_type_allow_nullable=true;

┌─JSON_VALUE('{"hello":"world"}', '$.b')─┐
│ ᴺᵁᴸᴸ                                   │
└────────────────────────────────────────┘

1 row in set. Elapsed: 0.001 sec.
```

 가능한 값:

- true — 허용.
- false — 비허용.
## function_locate_has_mysql_compatible_argument_order {#function_locate_has_mysql_compatible_argument_order} 

<SettingsInfoBlock type="Bool" default_value="1" />

함수 [locate](../../sql-reference/functions/string-search-functions.md/#locate)의 인수 순서를 제어합니다.

 가능한 값:

- 0 — 함수 `locate`가 인수 `(haystack, needle[, start_pos])`를 허용합니다.
- 1 — 함수 `locate`가 인수 `(needle, haystack, [, start_pos])` (MySQL 호환 동작)를 허용합니다.
## function_range_max_elements_in_block {#function_range_max_elements_in_block} 

<SettingsInfoBlock type="UInt64" default_value="500000000" />

함수 [range](/sql-reference/functions/array-functions#range)로 생성된 데이터 볼륨의 안전 임계값을 설정합니다. 데이터 블록당 함수가 생성할 수 있는 최대 값 수를 정의합니다(블록의 각 행에 대한 배열 크기의 합).

 가능한 값:

- 양의 정수.

**참고**

- [`max_block_size`](#max_block_size)
- [`min_insert_block_size_rows`](#min_insert_block_size_rows)
## function_sleep_max_microseconds_per_block {#function_sleep_max_microseconds_per_block} 

<SettingsInfoBlock type="UInt64" default_value="3000000" />

각 블록에 대해 함수 `sleep`가 잠들 수 있는 최대 마이크로초 수입니다. 사용자가 더 큰 값을 호출하면 예외가 발생합니다. 이는 안전 임계값입니다.
## function_visible_width_behavior {#function_visible_width_behavior} 

<SettingsInfoBlock type="UInt64" default_value="1" />

`visibleWidth` 동작의 버전입니다. 0 - 코드 포인트 수만 계산; 1 - 제로 너비 및 결합 문자를 정확히 계산하고, 전체 폭 문자를 두 개로 계산하며, 탭 너비를 추정하고, 삭제 문자를 계산합니다.
## geo_distance_returns_float64_on_float64_arguments {#geo_distance_returns_float64_on_float64_arguments} 

<SettingsInfoBlock type="Bool" default_value="1" />

`geoDistance`, `greatCircleDistance`, `greatCircleAngle` 함수의 네 인수가 모두 Float64이면 Float64를 반환하고 내부 계산에 대해 배정밀도를 사용합니다. 이전 ClickHouse 버전에서는 함수가 항상 Float32를 반환했습니다.
## geotoh3_argument_order {#geotoh3_argument_order} 

<BetaBadge/>

<SettingsInfoBlock type="GeoToH3ArgumentOrder" default_value="lat_lon" />

함수 'geoToH3'는 'lon_lat'로 설정된 경우 (lon, lat)를 수락하고 'lat_lon'로 설정된 경우 (lat, lon)를 수락합니다.
## glob_expansion_max_elements {#glob_expansion_max_elements} 

허용된 최대 주소 수(외부 저장소, 테이블 함수 등).
## grace_hash_join_initial_buckets {#grace_hash_join_initial_buckets} 

<ExperimentalBadge/>

<SettingsInfoBlock type="NonZeroUInt64" default_value="1" />

그레이스 해시 조인 버킷의 초기 수입니다.
## grace_hash_join_max_buckets {#grace_hash_join_max_buckets} 

<ExperimentalBadge/>

<SettingsInfoBlock type="NonZeroUInt64" default_value="1024" />

그레이스 해시 조인 버킷 수에 대한 제한입니다.
## group_by_overflow_mode {#group_by_overflow_mode} 

고유 키 수가 한계를 초과할 때 발생하는 처리를 설정합니다:
- `throw`: 예외를 발생시킴
- `break`: 쿼리를 실행 중지하고 부분 결과를 반환함
- `any`: 집합에 포함된 키에 대해 집계를 계속하지만 새로운 키를 집합에 추가하지 않음.

'any' 값을 사용하면 GROUP BY의 근사치를 실행할 수 있습니다. 이 근사치의 품질은 데이터의 통계적 성격에 따라 달라집니다.
## group_by_two_level_threshold {#group_by_two_level_threshold} 

몇 개의 키부터 이중 집계가 시작되는지 설정합니다. 0 - 임계값이 설정되지 않음.
## group_by_two_level_threshold_bytes {#group_by_two_level_threshold_bytes} 

바이트로 집계 상태의 크기가 몇 개부터 이중 집계 사용이 시작되는지 설정합니다. 0 - 임계값이 설정되지 않음. 적어도 한 개의 임계값이 발생했을 때 이중 집계가 사용됩니다.
## group_by_use_nulls {#group_by_use_nulls} 

[GROUP BY 절](/sql-reference/statements/select/group-by)이 집계 키의 유형을 처리하는 방식을 변경합니다. `ROLLUP`, `CUBE` 또는 `GROUPING SETS` 지시어를 사용할 때 일부 집계 키는 결과 행을 생성하는 데 사용되지 않을 수 있습니다. 이러한 키에 대한 컬럼은 이 설정에 따라 기본값 또는 `NULL`로 채워집니다.

가능한 값:

- 0 — 집계 키 유형의 기본값이 생략된 값 생성을 위해 사용됩니다.
- 1 — ClickHouse가 SQL 표준에서 정의한 대로 `GROUP BY`를 실행합니다. 집계 키의 유형은 [Nullable](/sql-reference/data-types/nullable)로 변환됩니다. 해당 집계 키에 대한 컬럼은 사용되지 않은 행에 대해 [NULL](/sql-reference/syntax#null)로 채워집니다.

또한 참조:

- [GROUP BY 절](/sql-reference/statements/select/group-by)
## h3togeo_lon_lat_result_order {#h3togeo_lon_lat_result_order} 

<SettingsInfoBlock type="Bool" default_value="0" />

함수 'h3ToGeo'는 true인 경우 (lon, lat)를 반환하고, 그렇지 않은 경우 (lat, lon)을 반환합니다.
## handshake_timeout_ms {#handshake_timeout_ms} 

핸드셰이크 중 복제본에서 Hello 패킷을 수신하기 위한 밀리초 단위의 타임아웃입니다.
## hdfs_create_new_file_on_insert {#hdfs_create_new_file_on_insert} 

HDFS 엔진 테이블에 삽입할 때마다 새 파일 생성을 활성화하거나 비활성화합니다. 활성화되면 각 삽입 시 다음 패턴과 유사한 이름으로 새 HDFS 파일이 생성됩니다:

초기: `data.Parquet.gz` -> `data.1.Parquet.gz` -> `data.2.Parquet.gz`, 등.

가능한 값:
- 0 — `INSERT` 쿼리가 파일 끝에 새 데이터를 추가합니다.
- 1 — `INSERT` 쿼리가 새 파일을 생성합니다.
## hdfs_ignore_file_doesnt_exist {#hdfs_ignore_file_doesnt_exist} 

<SettingsInfoBlock type="Bool" default_value="0" />

특정 키를 읽을 때 파일이 존재하지 않을 경우 무시합니다.

가능한 값:
- 1 — `SELECT`가 빈 결과를 반환합니다.
- 0 — `SELECT`가 예외를 발생시킵니다.
## hdfs_replication {#hdfs_replication} 

hdfs 파일 생성 시 실제 복제 수를 지정할 수 있습니다.
## hdfs_skip_empty_files {#hdfs_skip_empty_files} 

[HDFS](../../engines/table-engines/integrations/hdfs.md) 엔진 테이블에서 빈 파일을 건너뛰는 기능을 활성화합니다.

가능한 값:
- 0 — 빈 파일이 요청된 형식과 호환되지 않을 경우 `SELECT`가 예외를 발생시킵니다.
- 1 — 빈 파일에 대해 `SELECT`가 빈 결과를 반환합니다.
## hdfs_throw_on_zero_files_match {#hdfs_throw_on_zero_files_match} 

제로 파일이 glob 확장 규칙에 따라 일치하지 않을 경우 오류를 발생시킵니다.

가능한 값:
- 1 — `SELECT`가 예외를 발생시킵니다.
- 0 — `SELECT`가 빈 결과를 반환합니다.
## hdfs_truncate_on_insert {#hdfs_truncate_on_insert} 

hdfs 엔진 테이블에서 삽입 전에 잘라내기를 활성화하거나 비활성화합니다. 비활성화된 경우, HDFS에 파일이 이미 존재할 때 삽입을 시도하면 예외가 발생합니다.

가능한 값:
- 0 — `INSERT` 쿼리가 파일 끝에 새 데이터를 추가합니다.
- 1 — `INSERT` 쿼리가 기존 파일의 내용을 새 데이터로 대체합니다.
## hedged_connection_timeout_ms {#hedged_connection_timeout_ms} 

헤지 요청에 대한 복제본과의 연결을 설정할 때의 연결 타임아웃
## hnsw_candidate_list_size_for_search {#hnsw_candidate_list_size_for_search} 

벡터 유사성 인덱스 검색 시 동적 후보 목록의 크기입니다. 'ef_search'라고도 합니다.
## hsts_max_age {#hsts_max_age} 

HSTS의 만료 시간입니다. 0은 HSTS를 비활성화합니다.
## http_connection_timeout {#http_connection_timeout} 

HTTP 연결 타임아웃(초 단위).

 가능한 값:

- 양의 정수.
- 0 - 비활성화됨(무제한 타임아웃).
## http_headers_progress_interval_ms {#http_headers_progress_interval_ms} 

지정된 간격보다 더 빈번하게 HTTP 헤더 X-ClickHouse-Progress를 보내지 않습니다.
## http_make_head_request {#http_make_head_request} 

`http_make_head_request` 설정은 HTTP에서 데이터를 읽을 때 파일의 크기와 같은 정보를 검색하기 위해 `HEAD` 요청을 실행할 수 있도록 합니다. 기본적으로 활성화되어 있으므로 서버가 `HEAD` 요청을 지원하지 않는 경우 이 설정을 비활성화하는 것이 바람직할 수 있습니다.
## http_max_field_name_size {#http_max_field_name_size} 

HTTP 헤더의 필드 이름 최대 길이입니다.
## http_max_field_value_size {#http_max_field_value_size} 

HTTP 헤더의 필드 값 최대 길이입니다.
## http_max_fields {#http_max_fields} 

HTTP 헤더의 최대 필드 수입니다.
## http_max_multipart_form_data_size {#http_max_multipart_form_data_size} 

multipart/form-data 콘텐츠의 크기에 대한 제한입니다. 이 설정은 URL 매개변수에서 구문 분석할 수 없으며 사용자 프로필에서 설정해야 합니다. 콘텐츠는 쿼리 실행 시작 전에 메모리에서 구문 분석되고 외부 테이블이 생성됩니다. 이것은 해당 단계에 영향을 미치는 유일한 제한입니다(최대 메모리 사용량 및 최대 실행 시간에 대한 제한은 HTTP 양식 데이터를 읽는 동안 영향을 미치지 않습니다).
## http_max_request_param_data_size {#http_max_request_param_data_size} 

사전 정의된 HTTP 요청에서 쿼리 매개변수로 사용되는 요청 데이터의 크기에 대한 제한입니다.
## http_max_tries {#http_max_tries} 

HTTP를 통해 읽기 위한 최대 시도 횟수입니다.
## http_max_uri_size {#http_max_uri_size} 

HTTP 요청의 최대 URI 길이를 설정합니다.

 가능한 값:

- 양의 정수.
## http_native_compression_disable_checksumming_on_decompress {#http_native_compression_disable_checksumming_on_decompress} 

클라이언트에서 HTTP POST 데이터를 압축 해제할 때 체크섬 검증을 활성화하거나 비활성화합니다. ClickHouse 기본 압축 형식에만 사용됩니다( `gzip` 또는 `deflate`와는 사용되지 않음).

자세한 내용은 [HTTP 인터페이스 설명](../../interfaces/http.md)를 참조하세요.

 가능한 값:

- 0 — 비활성화됨.
- 1 — 활성화됨.
## http_receive_timeout {#http_receive_timeout} 

HTTP 수신 타임아웃(초 단위).

 가능한 값:

- 양의 정수.
- 0 - 비활성화됨(무제한 타임아웃).
## http_response_buffer_size {#http_response_buffer_size} 

HTTP 응답을 클라이언트에 전송하기 전에 서버 메모리에 버퍼링할 바이트 수입니다.
## http_response_headers {#http_response_headers} 

 성공적인 쿼리 결과와 함께 서버가 응답에 포함할 HTTP 헤더를 추가하거나 덮어쓰도록 허용합니다. 이는 HTTP 인터페이스에만 영향을 미칩니다.

기본적으로 이미 설정된 헤더가 있는 경우 제공된 값이 이를 덮어씁니다. 기본적으로 설정되지 않은 헤더인 경우 헤더 목록에 추가됩니다. 서버가 기본적으로 설정한 헤더는 이 설정에 의해 덮어쓰지 않으며 유지됩니다.

이 설정을 사용하면 헤더를 상수 값으로 설정할 수 있습니다. 현재 동적으로 계산된 값으로 헤더를 설정하는 방법은 없습니다.

사용자가 설정을 수정할 수 있도록 하는 UI 애플리케이션을 구현하는 경우, 반환된 헤더를 기반으로 결정을 내리는 것이 좋습니다. 이 설정을 읽기 전용으로 제한해야 합니다.

예: `SET http_response_headers = '{"Content-Type": "image/png"}'`
## http_retry_initial_backoff_ms {#http_retry_initial_backoff_ms} 

HTTP를 통해 읽기를 재시도할 때의 최소 지연 시간(밀리초)입니다.
## http_retry_max_backoff_ms {#http_retry_max_backoff_ms} 

HTTP를 통해 읽기를 재시도할 때의 최대 지연 시간(밀리초)입니다.
## http_send_timeout {#http_send_timeout} 

HTTP 전송 타임아웃(초 단위).

 가능한 값:

- 양의 정수.
- 0 - 비활성화됨(무제한 타임아웃).

:::note
이 설정은 기본 프로필에만 적용됩니다. 변경 사항이 적용되려면 서버를 재부팅해야 합니다.
:::
## http_skip_not_found_url_for_globs {#http_skip_not_found_url_for_globs} 

HTTP_NOT_FOUND 오류로 glob에 대한 URL을 건너뜁니다.
## http_wait_end_of_query {#http_wait_end_of_query} 

서버 측에서 HTTP 응답 버퍼링을 활성화합니다.
## http_write_exception_in_output_format {#http_write_exception_in_output_format} 

유효한 출력을 생성하기 위해 출력 형식으로 예외를 작성합니다. JSON 및 XML 형식에서 작동합니다.
## http_zlib_compression_level {#http_zlib_compression_level} 

[enable_http_compression = 1](#enable_http_compression)인 경우 HTTP 요청에 대한 응답에서 데이터 압축 수준을 설정합니다.

 가능한 값: 1에서 9까지의 숫자입니다.
## iceberg_delete_data_on_drop {#iceberg_delete_data_on_drop} 

삭제 시 모든 아이스버그 파일을 삭제할지를 설정합니다.
## iceberg_insert_max_bytes_in_data_file {#iceberg_insert_max_bytes_in_data_file} 

삽입 작업 중 아이스버그 파르quet 데이터 파일의 최대 바이트 수입니다.
## iceberg_insert_max_rows_in_data_file {#iceberg_insert_max_rows_in_data_file} 

삽입 작업 중 아이스버그 파르quet 데이터 파일의 최대 행 수입니다.
## iceberg_metadata_compression_method {#iceberg_metadata_compression_method} 

<ExperimentalBadge/>

`.metadata.json` 파일을 압축하는 방법입니다.
## iceberg_metadata_log_level {#iceberg_metadata_log_level} 

시스템.iceberg_metadata_log에 대해 아이스버그 테이블의 메타데이터 로깅 수준을 제어합니다. 일반적으로 이 설정은 디버깅 목적으로 수정할 수 있습니다.

가능한 값:
- none - 메타데이터 로그 없음.
- metadata - 루트 metadata.json 파일.
- manifest_list_metadata - 모든 항목 위 + 스냅샷에 해당하는 avro manifest 목록의 메타데이터.
- manifest_list_entry - 모든 항목 위 + avro manifest 목록 항목.
- manifest_file_metadata - 모든 항목 위 + 탐색된 avro manifest 파일의 메타데이터.
- manifest_file_entry - 모든 항목 위 + 탐색된 avro manifest 파일 항목.
## iceberg_snapshot_id {#iceberg_snapshot_id} 

특정 스냅샷 ID를 사용하여 아이스버그 테이블 쿼리.
## iceberg_timestamp_ms {#iceberg_timestamp_ms} 

특정 타임스탬프에서 현재인 스냅샷을 사용하여 아이스버그 테이블 쿼리.
## idle_connection_timeout {#idle_connection_timeout} 

지정된 초 수 후 유휴 TCP 연결을 닫기 위한 타임아웃입니다.

 가능한 값:

- 양의 정수(0 - 즉시 닫기, 0초 후).
## ignore_cold_parts_seconds {#ignore_cold_parts_seconds} 

<CloudOnlyBadge/>

ClickHouse Cloud에서만 효과가 있습니다. 새로운 데이터 파트를 SELECT 쿼리에서 제외합니다. 새로운 데이터 파트가 미리 로드(pre-warmed)되거나 이 설정만큼 초가 지나야 조회됩니다. Replicated-/SharedMergeTree 전용입니다.
## ignore_data_skipping_indices {#ignore_data_skipping_indices} 

쿼리에서 사용되는 경우 지정된 스킵 인덱스를 무시합니다.

다음 예를 고려하십시오:

```sql
CREATE TABLE data
(
    key Int,
    x Int,
    y Int,
    INDEX x_idx x TYPE minmax GRANULARITY 1,
    INDEX y_idx y TYPE minmax GRANULARITY 1,
    INDEX xy_idx (x,y) TYPE minmax GRANULARITY 1
)
Engine=MergeTree()
ORDER BY key;

INSERT INTO data VALUES (1, 2, 3);

SELECT * FROM data;
SELECT * FROM data SETTINGS ignore_data_skipping_indices=''; -- query will produce CANNOT_PARSE_TEXT error.
SELECT * FROM data SETTINGS ignore_data_skipping_indices='x_idx'; -- Ok.
SELECT * FROM data SETTINGS ignore_data_skipping_indices='na_idx'; -- Ok.

SELECT * FROM data WHERE x = 1 AND y = 1 SETTINGS ignore_data_skipping_indices='xy_idx',force_data_skipping_indices='xy_idx' ; -- query will produce INDEX_NOT_USED error, since xy_idx is explicitly ignored.
SELECT * FROM data WHERE x = 1 AND y = 2 SETTINGS ignore_data_skipping_indices='xy_idx';
```

인덱스를 무시하지 않는 쿼리:
```sql
EXPLAIN indexes = 1 SELECT * FROM data WHERE x = 1 AND y = 2;

Expression ((Projection + Before ORDER BY))
  Filter (WHERE)
    ReadFromMergeTree (default.data)
    Indexes:
      PrimaryKey
        Condition: true
        Parts: 1/1
        Granules: 1/1
      Skip
        Name: x_idx
        Description: minmax GRANULARITY 1
        Parts: 0/1
        Granules: 0/1
      Skip
        Name: y_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
      Skip
        Name: xy_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
```

`xy_idx` 인덱스를 무시하는 쿼리:
```sql
EXPLAIN indexes = 1 SELECT * FROM data WHERE x = 1 AND y = 2 SETTINGS ignore_data_skipping_indices='xy_idx';

Expression ((Projection + Before ORDER BY))
  Filter (WHERE)
    ReadFromMergeTree (default.data)
    Indexes:
      PrimaryKey
        Condition: true
        Parts: 1/1
        Granules: 1/1
      Skip
        Name: x_idx
        Description: minmax GRANULARITY 1
        Parts: 0/1
        Granules: 0/1
      Skip
        Name: y_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
```

MergeTree 계열의 테이블과 함께 작동합니다.
## ignore_drop_queries_probability {#ignore_drop_queries_probability} 

활성화된 경우, 서버는 지정된 확률로 모든 DROP 테이블 쿼리를 무시합니다(메모리 및 JOIN 엔진의 경우 DROP 대신 TRUNCATE로 대체됨). 테스트 목적으로 사용됩니다.
## ignore_materialized_views_with_dropped_target_table {#ignore_materialized_views_with_dropped_target_table} 

뷰로 푸시할 때 삭제된 대상 테이블이 있는 MV를 무시합니다.
## ignore_on_cluster_for_replicated_access_entities_queries {#ignore_on_cluster_for_replicated_access_entities_queries} 

복제된 엑세스 엔티티 관리 쿼리에 대해 ON CLUSTER 절을 무시합니다.
## ignore_on_cluster_for_replicated_named_collections_queries {#ignore_on_cluster_for_replicated_named_collections_queries} 

복제된 명명된 컬렉션 관리 쿼리에 대해 ON CLUSTER 절을 무시합니다.
## ignore_on_cluster_for_replicated_udf_queries {#ignore_on_cluster_for_replicated_udf_queries} 

복제된 UDF 관리 쿼리에 대해 ON CLUSTER 절을 무시합니다.
## implicit_select {#implicit_select} 

선행 SELECT 키워드 없이 간단한 SELECT 쿼리를 작성할 수 있도록 허용합니다. 계산기 스타일의 사용에 간단합니다. 예: `1 + 2`는 유효한 쿼리가 됩니다.

`clickhouse-local`에서는 기본적으로 활성화되어 있으며 명시적으로 비활성화할 수 있습니다.
## implicit_table_at_top_level {#implicit_table_at_top_level} 

비어 있지 않은 경우, 최상위 수준에서 FROM 없이 쿼리가 이 테이블에서 읽습니다. 이는 clickhouse-local에서 입력 데이터 처리에 사용됩니다. 사용자가 명시적으로 설정할 수 있지만 이 유형의 사용에 대해 의도되지 않았습니다.

서브쿼리는 이 설정에 영향을 받지 않습니다(스칼라, FROM 또는 IN 서브쿼리와는 관계 없음). UNION, INTERSECT, EXCEPT 체인의 최상위 SELECT는 균일하게 처리되며 이 설정의 영향을 받습니다. 괄호로 그룹화된 것과는 관계없이 말입니다. 이 설정이 뷰와 분산 쿼리에 미치는 영향은 지정되어 있지 않습니다.

이 설정은 테이블 이름을 허용(현재 데이터베이스에서 테이블을 해결)하거나 'database.table' 형식의 자격 있는 이름입니다. 데이터베이스 및 테이블 이름은 쌍따옴표 없이 명시되어야 하며, 단순 식별자만 허용됩니다.
## implicit_transaction {#implicit_transaction} 

<ExperimentalBadge/>

활성화되면 이미 트랜잭션 내부에 있지 않은 경우 쿼리를 전체 트랜잭션(시작 + 커밋 또는 롤백)으로 래핑합니다.
## inject_random_order_for_select_without_order_by {#inject_random_order_for_select_without_order_by} 

활성화된 경우 ORDER BY 절이 없는 SELECT 쿼리에 'ORDER BY rand()'를 삽입합니다. 서브쿼리 깊이 = 0일 때만 적용됩니다. 서브쿼리와 INSERT INTO ... SELECT에는 영향을 미치지 않습니다. 최상위 구성 요소가 UNION인 경우 'ORDER BY rand()'는 모든 자식에 독립적으로 삽입됩니다. 이는 테스트 및 개발에만 유용합니다(ORDER BY가 누락되면 비결정론적 쿼리 결과의 원인이 됩니다).
## input_format_parallel_parsing {#input_format_parallel_parsing} 

데이터 형식의 순서 보존 분위기 분석을 활성화하거나 비활성화합니다. [TabSeparated (TSV)](/interfaces/formats/TabSeparated), [TSKV](/interfaces/formats/TSKV), [CSV](/interfaces/formats/CSV) 및 [JSONEachRow](/interfaces/formats/JSONEachRow) 형식에 대해서만 지원됩니다.

 가능한 값:

- 1 — 활성화됨.
- 0 — 비활성화됨.
## insert_allow_materialized_columns {#insert_allow_materialized_columns} 

이 설정이 활성화된 경우 INSERT에서 물리화된 컬럼을 허용합니다.
## insert_deduplicate {#insert_deduplicate} 

`INSERT`의 블록 중복 제거 기능을 활성화하거나 비활성화합니다(Replicated* 테이블에 대해).

 가능한 값:

- 0 — 비활성화됨.
- 1 — 활성화됨.

기본적으로 `INSERT` 문에 의해 복제 테이블에 삽입된 블록은 중복 제거됩니다( [Data Replication](../../engines/table-engines/mergetree-family/replication.md) 참조). 복제된 테이블에 대해서는 기본적으로 각 파티션에서 가장 최근의 100개의 블록만 중복 제거됩니다( [replicated_deduplication_window](merge-tree-settings.md/#replicated_deduplication_window), [replicated_deduplication_window_seconds](merge-tree-settings.md/#replicated_deduplication_window_seconds) 참조). 비복제 테이블은 [non_replicated_deduplication_window](merge-tree-settings.md/#non_replicated_deduplication_window) 참조.
## insert_deduplication_token {#insert_deduplication_token} 

이 설정은 MergeTree/ReplicatedMergeTree에서 사용자가 고유한 중복 제거 의미론을 제공할 수 있도록 합니다.
예를 들어, 각 INSERT 문에서 설정에 고유한 값을 제공함으로써 사용자는 동일하게 삽입된 데이터가 중복 제거되는 것을 방지할 수 있습니다.

 가능한 값:

- 모든 문자열

`insert_deduplication_token`은 비어있지 않을 때만 중복 제거에 사용됩니다.

복제된 테이블에 대해서는 기본적으로 각 파티션에서 가장 최근의 100개의 삽입만 중복 제거됩니다( [replicated_deduplication_window](merge-tree-settings.md/#replicated_deduplication_window), [replicated_deduplication_window_seconds](merge-tree-settings.md/#replicated_deduplication_window_seconds) 참조). 비복제 테이블은 [non_replicated_deduplication_window](merge-tree-settings.md/#non_replicated_deduplication_window) 참조.

:::note
`insert_deduplication_token`은 파티션 수준에서 작동합니다( `insert_deduplication` 체크섬과 동일). 여러 파티션이 같은 `insert_deduplication_token`을 가질 수 있습니다.
:::

예시:

```sql
CREATE TABLE test_table
( A Int64 )
ENGINE = MergeTree
ORDER BY A
SETTINGS non_replicated_deduplication_window = 100;

INSERT INTO test_table SETTINGS insert_deduplication_token = 'test' VALUES (1);

-- the next insert won't be deduplicated because insert_deduplication_token is different
INSERT INTO test_table SETTINGS insert_deduplication_token = 'test1' VALUES (1);

-- the next insert will be deduplicated because insert_deduplication_token
-- is the same as one of the previous
INSERT INTO test_table SETTINGS insert_deduplication_token = 'test' VALUES (2);

SELECT * FROM test_table

┌─A─┐
│ 1 │
└───┘
┌─A─┐
│ 1 │
└───┘
```
## insert_keeper_fault_injection_probability {#insert_keeper_fault_injection_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

삽입 중 Keeper 요청에 대한 오류 발생 확률의 근사값입니다. 유효 값은 [0.0f, 1.0f] 구간입니다.
## insert_keeper_fault_injection_seed {#insert_keeper_fault_injection_seed} 

0 - 무작위 시드, 그렇지 않으면 설정 값
## insert_keeper_max_retries {#insert_keeper_max_retries} 

<SettingsInfoBlock type="UInt64" default_value="20" />

이 설정은 복제된 MergeTree에 삽입할 때 ClickHouse Keeper(또는 ZooKeeper) 요청의 최대 재시도 횟수를 설정합니다. 네트워크 오류, Keeper 세션 타임아웃 또는 요청 타임아웃으로 인해 실패한 Keeper 요청만 재시도합니다.

 가능한 값:

- 양의 정수.
- 0 — 재시도가 비활성화됨.

클라우드 기본값: `20`.

Keeper 요청 재시도는 일정한 타임아웃 후에 수행됩니다. 타임아웃은 다음 설정으로 제어됩니다: `insert_keeper_retry_initial_backoff_ms`, `insert_keeper_retry_max_backoff_ms`.
첫 번째 재시도는 `insert_keeper_retry_initial_backoff_ms` 타임아웃 후에 이루어집니다. 이후의 타임아웃은 다음과 같이 계산됩니다:
```
timeout = min(insert_keeper_retry_max_backoff_ms, latest_timeout * 2)
```

예를 들어 `insert_keeper_retry_initial_backoff_ms=100`, `insert_keeper_retry_max_backoff_ms=10000`이고 `insert_keeper_max_retries=8`인 경우 타임아웃은 `100, 200, 400, 800, 1600, 3200, 6400, 10000`이 됩니다.

내성성 외에도, 재시도는 사용자 경험을 개선하기 위한 목적으로도 사용되며, 예를 들어 Keeper가 업그레이드로 재시작되는 경우 INSERT 실행 도중 오류를 반환하지 않도록 합니다.
## insert_keeper_retry_initial_backoff_ms {#insert_keeper_retry_initial_backoff_ms} 

삽입 쿼리 실행 중 실패한 Keeper 요청을 재시도하기 위한 초기 타임아웃(밀리초 단위)

 가능한 값:

- 양의 정수.
- 0 — 타임아웃 없음
## insert_keeper_retry_max_backoff_ms {#insert_keeper_retry_max_backoff_ms} 

INSERT 쿼리 실행 중 실패한 Keeper 요청을 재시도하기 위한 최대 타임아웃(밀리초 단위)

 가능한 값:

- 양의 정수.
- 0 — 최대 타임아웃에 제한 없음
## insert_null_as_default {#insert_null_as_default} 

[nullable](/sql-reference/data-types/nullable) 데이터 유형을 갖는 컬럼에 대해 [NULL](/sql-reference/syntax#null) 대신 [기본값](/sql-reference/statements/create/table#default_values)을 삽입하도록 활성화하거나 비활성화합니다.
컬럼 유형이 nullable이 아니고 이 설정이 비활성화된 경우에는 `NULL`을 삽입하면 예외가 발생합니다. 컬럼 유형이 nullable인 경우, `NULL` 값은 이 설정에 관계없이 원래 그대로 삽입됩니다.

이 설정은 [INSERT ... SELECT](../../sql-reference/statements/insert-into.md/#inserting-the-results-of-select) 쿼리에 적용됩니다. `SELECT` 서브쿼리는 `UNION ALL` 절과 함께 연결할 수 있습니다.

 가능한 값:

- 0 — NULL 값을 비nullable 컬럼에 삽입하면 예외가 발생합니다.
- 1 — NULL 대신 기본 컬럼 값이 삽입됩니다.
## insert_quorum {#insert_quorum} 

:::note
이 설정은 SharedMergeTree에 적용되지 않습니다. 자세한 내용은 [SharedMergeTree consistency](/cloud/reference/shared-merge-tree#consistency)를 참조하세요.
:::

쿼럼 작성을 활성화합니다.

- `insert_quorum < 2`인 경우, 쿼럼 작성이 비활성화됩니다.
- `insert_quorum >= 2`인 경우, 쿼럼 작성이 활성화됩니다.
- `insert_quorum = 'auto'`인 경우, 쿼럼 숫자로 다수(`number_of_replicas / 2 + 1`)를 사용합니다.

쿼럼 작성을 위해

`INSERT`가 성공하려면 ClickHouse가 `insert_quorum`의 복제본에 데이터를 올바르게 작성해야 합니다. 어떤 이유로 `insert_quorum` 내에서 정상적으로 쓴 복제본 수가 `insert_quorum`에 도달하지 않으면 쓰기가 실패로 간주되고 ClickHouse는 이미 데이터를 쓴 모든 복제본에서 삽입한 블록을 삭제합니다.

`insert_quorum_parallel`이 비활성화되어 있는 경우 쿼럼의 모든 복제본은 일관성 있게 유지됩니다 즉, 모든 이전 `INSERT` 쿼리에서 데이터를 포함하고 있습니다(`INSERT` 순서는 선형화됩니다). `insert_quorum` 및 `insert_quorum_parallel`이 비활성화된 상태에서 작성된 데이터를 읽을 때 [select_sequential_consistency](#select_sequential_consistency)를 사용하여 SELECT 쿼리에 대한 순차적 일관성을 켤 수 있습니다.

ClickHouse는 예외를 생성합니다:

- 쿼리 시 사용할 수 있는 복제본 수가 `insert_quorum`보다 적을 경우.
- `insert_quorum_parallel`이 비활성화되어 있으며 이전 블록이 복제본의 `insert_quorum`에 삽입되기 전에 데이터를 작성하면 실패한 경우. 이는 사용자가 직전의 `insert_quorum`으로 완료되기 전에 동일한 테이블에 대한 또 다른 `INSERT` 쿼리를 실행하려고 하는 경우 발생할 수 있습니다.

참조:

- [insert_quorum_timeout](#insert_quorum_timeout)
- [insert_quorum_parallel](#insert_quorum_parallel)
- [select_sequential_consistency](#select_sequential_consistency)
## insert_quorum_parallel {#insert_quorum_parallel} 

<SettingsInfoBlock type="Bool" default_value="1" />

:::note
이 설정은 SharedMergeTree에 적용되지 않습니다. 자세한 내용은 [SharedMergeTree consistency](/cloud/reference/shared-merge-tree#consistency)를 참조하세요.
:::

쿼럼 `INSERT` 쿼리에 대해 병렬성을 활성화하거나 비활성화합니다. 활성화되면 이전 쿼리가 아직 완료되지 않았을 때 추가 `INSERT` 쿼리를 보낼 수 있습니다. 비활성화되면 같은 테이블에 대한 추가 쓰기가 거부됩니다.

 가능한 값:

- 0 — 비활성화됨.
- 1 — 활성화됨.

또한 참조:

- [insert_quorum](#insert_quorum)
- [insert_quorum_timeout](#insert_quorum_timeout)
- [select_sequential_consistency](#select_sequential_consistency)
## insert_quorum_timeout {#insert_quorum_timeout} 

쿼럼에 쓰기 타임아웃(밀리초 단위). 타임아웃이 지나고도 쓰기가 발생하지 않으면 ClickHouse는 예외를 생성하며 클라이언트는 동일한 블록을 동일한 또는 다른 복제본에 쓰기 위한 쿼리를 반복해야 합니다.

또한 참조:

- [insert_quorum](#insert_quorum)
- [insert_quorum_parallel](#insert_quorum_parallel)
- [select_sequential_consistency](#select_sequential_consistency)
## insert_shard_id {#insert_shard_id} 

0이 아니면 데이터가 동기적으로 삽입될 [Distributed](/engines/table-engines/special/distributed) 테이블의 샤드를 지정합니다.

잘못된 `insert_shard_id` 값이 있을 경우 서버는 예외를 발생시킵니다.

`requested_cluster`의 샤드 수를 얻으려면 서버 설정을 확인하거나 다음 쿼리를 사용할 수 있습니다:

```sql
SELECT uniq(shard_num) FROM system.clusters WHERE cluster = 'requested_cluster';
```

 가능한 값:

- 0 — 비활성화됨.
- 해당 [Distributed](/engines/table-engines/special/distributed) 테이블의 `1`에서 `shards_num`까지의 모든 숫자.
  
**예시**

쿼리:

```sql
CREATE TABLE x AS system.numbers ENGINE = MergeTree ORDER BY number;
CREATE TABLE x_dist AS x ENGINE = Distributed('test_cluster_two_shards_localhost', currentDatabase(), x);
INSERT INTO x_dist SELECT * FROM numbers(5) SETTINGS insert_shard_id = 1;
SELECT * FROM x_dist ORDER BY number ASC;
```

결과:

```text
┌─number─┐
│      0 │
│      0 │
│      1 │
│      1 │
│      2 │
│      2 │
│      3 │
│      3 │
│      4 │
│      4 │
└────────┘
```
## interactive_delay {#interactive_delay} 

요청 실행이 취소되었는지 확인하고 진행 상황을 전송하는 간격(마이크로초 단위)입니다.
## intersect_default_mode {#intersect_default_mode} 

INTERSECT 쿼리에서 기본 모드를 설정합니다. 가능한 값: 빈 문자열, 'ALL', 'DISTINCT'. 비어 있으면 모드가 없는 쿼리에서 예외를 발생시킵니다.
## jemalloc_collect_profile_samples_in_trace_log {#jemalloc_collect_profile_samples_in_trace_log} 

트레이스 로그에서 jemalloc 할당 및 해제 샘플을 수집합니다.
## jemalloc_enable_profiler {#jemalloc_enable_profiler} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.9"},{"label": "0"},{"label": "New setting"}]}]}/>

쿼리를 위한 jemalloc 프로파일러를 활성화합니다. Jemalloc은 샘플링된 할당에 대해 할당 및 모든 해제를 샘플링합니다. 프로파일은 SYSTEM JEMALLOC FLUSH PROFILE을 사용하여 플러시할 수 있으며, 이는 할당 분석에 사용될 수 있습니다. 샘플은 config jemalloc_collect_global_profile_samples_in_trace_log 또는 쿼리 설정 jemalloc_collect_profile_samples_in_trace_log를 사용하여 system.trace_log에 저장될 수도 있습니다. [Allocation Profiling](/operations/allocation-profiling)을 참조하세요.

## join_algorithm {#join_algorithm} 

<SettingsInfoBlock type="JoinAlgorithm" default_value="direct,parallel_hash,hash" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "direct,parallel_hash,hash"},{"label": "'default' was deprecated in favor of explicitly specified join algorithms, also parallel_hash is now preferred over hash"}]}]}/>

어떤 [JOIN](../../sql-reference/statements/select/join.md) 알고리즘이 사용되는지를 지정합니다.

여러 알고리즘을 지정할 수 있으며, 특정 쿼리에 대해 사용 가능한 알고리즘이 선택됩니다. 선택은 종류/엄격성과 테이블 엔진에 따라 다릅니다.

가능한 값:

- grace_hash

 [그레이스 해시 조인](https://en.wikipedia.org/wiki/Hash_join#Grace_hash_join)이 사용됩니다. Grace 해시는 메모리 사용을 제한하면서 성능이 우수한 복잡한 조인을 제공하는 알고리즘 옵션을 제공합니다.

 그레이스 조인의 첫 번째 단계는 오른쪽 테이블을 읽고 키 열의 해시 값에 따라 N 버킷으로 나누는 것입니다 (초기적으로 N은 `grace_hash_join_initial_buckets`입니다). 각 버킷이 독립적으로 처리가 가능하도록 하기 위해 이러한 방식으로 수행됩니다. 첫 번째 버킷의 행은 메모리 내 해시 테이블에 추가되며, 나머지는 디스크에 저장됩니다. 해시 테이블이 메모리 한도를 초과하면 (예: [`max_bytes_in_join`](/operations/settings/settings#max_bytes_in_join)으로 설정됨), 버킷 수를 늘리고 각 행에 대한 버킷을 재배정합니다. 현재 버킷에 속하지 않는 모든 행은 플러시되고 재배정됩니다.

 `INNER/LEFT/RIGHT/FULL ALL/ANY JOIN`을 지원합니다.

- hash

 [해시 조인 알고리즘](https://en.wikipedia.org/wiki/Hash_join)이 사용됩니다. 종류 및 엄격성과 여러 조인 키의 모든 조합을 지원하는 가장 일반적인 구현입니다. 이들은 `JOIN ON` 섹션에서 `OR`로 결합됩니다.

 `hash` 알고리즘을 사용할 때, `JOIN`의 오른쪽 부분은 RAM으로 업로드됩니다.

- parallel_hash

 데이터를 버킷으로 나누고 동시에 여러 해시 테이블을 구축하는 해시 조인의 변형입니다.

 `parallel_hash` 알고리즘을 사용할 때, `JOIN`의 오른쪽 부분은 RAM으로 업로드됩니다.

- partial_merge

 [정렬-병합 알고리즘](https://en.wikipedia.org/wiki/Sort-merge_join)의 변형으로, 오른쪽 테이블만 완전히 정렬됩니다.

 `RIGHT JOIN` 및 `FULL JOIN`은 `ALL` 엄격성에서만 지원됩니다 (`SEMI`, `ANTI`, `ANY`, 및 `ASOF`는 지원되지 않음).

 `partial_merge` 알고리즘을 사용할 때, ClickHouse는 데이터를 정렬하고 디스크에 덤프합니다. ClickHouse의 `partial_merge` 알고리즘은 고전적인 실현과 약간 다릅니다. 먼저 ClickHouse는 조인 키에 따라 오른쪽 테이블을 블록으로 정렬하고 정렬된 블록의 최소-최대 인덱스를 생성합니다. 그런 다음 왼쪽 테이블의 부분을 `join key`에 따라 정렬하고 오른쪽 테이블에 대해 조인합니다. 최소-최대 인덱스는 필요하지 않은 오른쪽 테이블 블록을 스킵하는 데에도 사용됩니다.

- direct

 이 알고리즘은 오른쪽 테이블이 키-값 요청을 지원하는 저장소에 적용될 수 있습니다.

 `direct` 알고리즘은 왼쪽 테이블의 행을 키로 사용하여 오른쪽 테이블에서 조회를 수행합니다. 이는 [Dictionary](/engines/table-engines/special/dictionary) 또는 [EmbeddedRocksDB](../../engines/table-engines/integrations/embedded-rocksdb.md)와 같은 특별한 저장소에만 지원되며 `LEFT` 및 `INNER` JOIN에만 해당됩니다.

- auto

 `auto`로 설정하면 먼저 `hash` 조인을 시도하고, 메모리 한도가 위배되면 알고리즘이 자동으로 다른 알고리즘으로 전환됩니다.

- full_sorting_merge

 [정렬-병합 알고리즘](https://en.wikipedia.org/wiki/Sort-merge_join)으로 조인 이전에 스트블레이팅된 테이블을 완전 정렬합니다.

- prefer_partial_merge

 ClickHouse는 가능할 경우 항상 `partial_merge` 조인을 사용하려고 시도하며, 그렇지 않으면 `hash`를 사용합니다. *Deprecated*, `partial_merge`, `hash`와 동일합니다.

- default (deprecated)

 구식 값, 더 이상 사용하지 마십시오. `direct, hash`와 동일하여 즉, 직접 조인과 해시 조인을 이 순서대로 시도합니다.

## join_any_take_last_row {#join_any_take_last_row} 

<SettingsInfoBlock type="Bool" default_value="0" />

`ANY` 엄격성의 조인 작업의 동작을 변경합니다.

:::note
이 설정은 [Join](../../engines/table-engines/special/join.md) 엔진 테이블과 함께 사용하는 `JOIN` 작업에만 적용됩니다.
:::

가능한 값:

- 0 — 오른쪽 테이블에 일치하는 행이 두 개 이상 있을 경우, 찾은 첫 번째 것만 조인됩니다.
- 1 — 오른쪽 테이블에 일치하는 행이 두 개 이상 있을 경우, 찾은 마지막 것만 조인됩니다.

참고하세요:

- [JOIN 절](/sql-reference/statements/select/join)
- [Join 테이블 엔진](../../engines/table-engines/special/join.md)
- [join_default_strictness](#join_default_strictness)

## join_default_strictness {#join_default_strictness} 

<SettingsInfoBlock type="JoinStrictness" default_value="ALL" />

[JOIN 절](/sql-reference/statements/select/join)에 대한 기본 엄격성을 설정합니다.

가능한 값:

- `ALL` — 오른쪽 테이블에 여러 개의 일치하는 행이 있는 경우 ClickHouse는 일치하는 행에서 [카르테시안 곱](https://en.wikipedia.org/wiki/Cartesian_product)을 생성합니다. 이는 표준 SQL에서의 일반적인 `JOIN` 동작입니다.
- `ANY` — 오른쪽 테이블에 여러 개의 일치하는 행이 있는 경우, 찾은 첫 번째 것만 조인됩니다. 오른쪽 테이블에 일치하는 행이 하나만 있는 경우 결과는 `ANY`와 `ALL`이 같습니다.
- `ASOF` — 불확실한 일치로 시퀀스를 연결하기 위해 사용됩니다.
- `빈 문자열` — 쿼리에서 `ALL` 또는 `ANY`가 지정되지 않은 경우 ClickHouse는 예외를 발생시킵니다.

## join_on_disk_max_files_to_merge {#join_on_disk_max_files_to_merge} 

<SettingsInfoBlock type="UInt64" default_value="64" />

디스크에서 실행될 MergeJoin 작업의 병렬 정렬을 위해 허용되는 파일 수의 한계를 설정합니다.

설정 값이 클수록 RAM이 더 많이 사용되고 디스크 I/O가 적게 필요합니다.

가능한 값:

- 2 이상의 모든 양의 정수.

## join_output_by_rowlist_perkey_rows_threshold {#join_output_by_rowlist_perkey_rows_threshold} 

<SettingsInfoBlock type="UInt64" default_value="5" />

해시 조인에서 행 목록으로 출력할지를 결정하기 위해 오른쪽 테이블의 평균 행 수에 대한 하한입니다.

## join_overflow_mode {#join_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

다음 조인 한계 중 하나에 도달했을 때 ClickHouse가 수행하는 작업을 정의합니다:

- [max_bytes_in_join](/operations/settings/settings#max_bytes_in_join)
- [max_rows_in_join](/operations/settings/settings#max_rows_in_join)

가능한 값:

- `THROW` — ClickHouse는 예외를 발생시키고 작업을 중단합니다.
- `BREAK` — ClickHouse는 작업을 중단하고 예외를 발생시키지 않습니다.

기본값: `THROW`.

**참고하세요**

- [JOIN 절](/sql-reference/statements/select/join)
- [Join 테이블 엔진](/engines/table-engines/special/join)

## join_runtime_bloom_filter_bytes {#join_runtime_bloom_filter_bytes} 

<ExperimentalBadge/>

<SettingsInfoBlock type="UInt64" default_value="524288" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "524288"},{"label": "New setting"}]}]}/>

JOIN 런타임 필터로 사용되는 블룸 필터의 크기(바이트 단위)입니다 (enable_join_runtime_filters 설정 참조).

## join_runtime_bloom_filter_hash_functions {#join_runtime_bloom_filter_hash_functions} 

<ExperimentalBadge/>

<SettingsInfoBlock type="UInt64" default_value="3" />

JOIN 런타임 필터로 사용되는 블룸 필터의 해시 함수 수 (enable_join_runtime_filters 설정 참조).

## join_runtime_filter_exact_values_limit {#join_runtime_filter_exact_values_limit} 

<ExperimentalBadge/>

<SettingsInfoBlock type="UInt64" default_value="10000" />

runtime 필터에 저장되는 요소의 최대 수, 이 임계값이 초과되면 블룸 필터로 전환됩니다.

## join_to_sort_maximum_table_rows {#join_to_sort_maximum_table_rows} 

<ExperimentalBadge/>

<SettingsInfoBlock type="UInt64" default_value="10000" />

왼쪽 또는 내부 조인에서 키별로 오른쪽 테이블을 재정렬할지를 결정하기 위한 오른쪽 테이블의 최대 행 수입니다.

## join_to_sort_minimum_perkey_rows {#join_to_sort_minimum_perkey_rows} 

<ExperimentalBadge/>

<SettingsInfoBlock type="UInt64" default_value="40" />

왼쪽 또는 내부 조인에서 키별로 오른쪽 테이블을 재정렬할지를 결정하기 위한 오른쪽 테이블의 평균 행 수에 대한 하한입니다. 이 설정은 스파스 테이블 키에 대해 최적화가 적용되지 않도록 보장합니다.

## join_use_nulls {#join_use_nulls} 

<SettingsInfoBlock type="Bool" default_value="0" />

[JOIN](../../sql-reference/statements/select/join.md) 동작의 유형을 설정합니다. 테이블 병합 시 빈 셀가 나타날 수 있습니다. ClickHouse는 이 설정에 따라 다르게 채웁니다.

가능한 값:

- 0 — 빈 셀은 해당 필드 유형의 기본 값으로 채워집니다.
- 1 — `JOIN`은 표준 SQL과 동일하게 동작합니다. 해당 필드의 유형은 [Nullable](/sql-reference/data-types/nullable)로 변환되며, 빈 셀은 [NULL](/sql-reference/syntax)로 채워집니다.

## joined_block_split_single_row {#joined_block_split_single_row} 

<SettingsInfoBlock type="Bool" default_value="0" />

왼쪽 테이블의 단일 행과 일치하는 행을 기준으로 해시 조인 결과를 청크로 나눕니다. 이는 오른쪽 테이블에서 많은 일치를 가진 행의 경우 메모리 사용을 줄일 수 있지만 CPU 사용량이 증가할 수 있습니다. `max_joined_block_size_rows != 0`가 이 설정이 효과를 가지기 위해 필수입니다. `max_joined_block_size_bytes`와 이 설정을 함께 사용하면 오른쪽 테이블에서 많은 일치가 있는 일부 큰 행의 경우 과도한 메모리 사용을 피하는 데 도움이 됩니다.

## joined_subquery_requires_alias {#joined_subquery_requires_alias} 

<SettingsInfoBlock type="Bool" default_value="1" />

정확한 이름 자격을 위해 조인된 서브쿼리 및 테이블 함수에 별칭을 부여하도록 강제합니다.

## kafka_disable_num_consumers_limit {#kafka_disable_num_consumers_limit} 

CPU 코어 수에 따라 kafka_num_consumers에 대한 한계를 비활성화합니다.

## kafka_max_wait_ms {#kafka_max_wait_ms} 

재시도를 하기 전에 [Kafka](/engines/table-engines/integrations/kafka)에서 메시지를 읽기 위한 대기 시간(밀리초)입니다.

가능한 값:

- 양의 정수.
- 0 — 무한 타임아웃.

추가 정보:

- [Apache Kafka](https://kafka.apache.org/)

## keeper_map_strict_mode {#keeper_map_strict_mode} 

KeeperMap에서 작업을 수행할 때 추가 확인을 시행합니다. 예를 들어, 이미 존재하는 키에 대한 삽입 시 예외를 발생시킵니다.

## keeper_max_retries {#keeper_max_retries} 

<SettingsInfoBlock type="UInt64" default_value="10" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "10"},{"label": "Max retries for general keeper operations"}]}]}/>

일반 케어작업에 대한 최대 재시도 횟수입니다.

## keeper_retry_initial_backoff_ms {#keeper_retry_initial_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="100" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "100"},{"label": "Initial backoff timeout for general keeper operations"}]}]}/>

일반 케어작업에 대한 초기 대기 시간입니다.

## keeper_retry_max_backoff_ms {#keeper_retry_max_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="5000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "5000"},{"label": "Max backoff timeout for general keeper operations"}]}]}/>

일반 케어작업에 대한 최대 대기 시간입니다.

## least_greatest_legacy_null_behavior {#least_greatest_legacy_null_behavior} 

<SettingsInfoBlock type="Bool" default_value="0" />

이 설정이 활성화되면, 함수 'least' 및 'greatest'는 인수 중 하나가 NULL일 경우 NULL을 반환합니다.

## legacy_column_name_of_tuple_literal {#legacy_column_name_of_tuple_literal} 

<SettingsInfoBlock type="Bool" default_value="0" />

해시 대신 컬럼 이름으로 큰 튜플 리터럴의 모든 요소 이름을 나열합니다. 이 설정은 호환성 이유로만 존재합니다. 21.7 미만의 버전에서 더 높은 버전으로 클러스터를 롤링 업데이트할 때 'true'로 설정하는 것이 의미가 있습니다.

## lightweight_delete_mode {#lightweight_delete_mode} 

<SettingsInfoBlock type="LightweightDeleteMode" default_value="alter_update" />

경량 삭제의 일환으로 실행되는 내부 업데이트 쿼리의 모드입니다.

가능한 값:
- `alter_update` - 무거운 변형을 만드는 `ALTER UPDATE` 쿼리를 실행합니다.
- `lightweight_update` - 가능하다면 경량 업데이트를 실행하고, 그렇지 않으면 `ALTER UPDATE`를 실행합니다.
- `lightweight_update_force` - 가능하다면 경량 업데이트를 실행하고, 그렇지 않으면 예외를 발생시킵니다.

## lightweight_deletes_sync {#lightweight_deletes_sync} 

<SettingsInfoBlock type="UInt64" default_value="2" />

[`mutations_sync`](#mutations_sync)와 동일하지만 경량 삭제 실행만 제어합니다.

가능한 값:

| 값 | 설명                                                                                                                                           |
|----|--------------------------------------------------------------------------------------------------------------------------------------------------|
| `0`  | 변형은 비동기적으로 실행됩니다.                                                                                                                 |
| `1`  | 쿼리는 현재 서버에서 경량 삭제가 완료될 때까지 대기합니다.                                                                                           |
| `2`  | 쿼리는 모든 복제본이 완성될 때까지 대기합니다(존재하는 경우).                                                                                          |
| `3`  | 쿼리는 활성 복제본에 대해서만 대기합니다. `SharedMergeTree`에 대해서만 지원됩니다. `ReplicatedMergeTree`에 대해서는 `mutations_sync = 2`와 동일하게 동작합니다. |

**참고하세요**

- [ALTER 쿼리의 동시성](../../sql-reference/statements/alter/index.md/#synchronicity-of-alter-queries)
- [변형](../../sql-reference/statements/alter/index.md/#mutations)

## limit {#limit} 

<SettingsInfoBlock type="UInt64" default_value="0" />

쿼리 결과에서 가져올 최대 행 수를 설정합니다. 이는 [LIMIT](/sql-reference/statements/select/limit) 절에 설정된 값을 조정하여, 쿼리에서 지정된 한도가 이 설정에 의해 설정된 한도를 초과할 수 없도록 합니다.

가능한 값:

- 0 — 행 수가 제한되지 않습니다.
- 양의 정수.

## load_balancing {#load_balancing} 

<SettingsInfoBlock type="LoadBalancing" default_value="random" />

분산 쿼리 처리를 위한 복제본 선택 알고리즘을 지정합니다.

ClickHouse는 다음과 같은 복제본 선택 알고리즘을 지원합니다:

- [무작위](#load_balancing-random) (기본값)
- [가장 가까운 호스트명](#load_balancing-nearest_hostname)
- [호스트명 레벤슈타인 거리](#load_balancing-hostname_levenshtein_distance)
- [순차](#load_balancing-in_order)
- [첫 번째 또는 무작위](#load_balancing-first_or_random)
- [라운드 로빈](#load_balancing-round_robin)

추가 정보:

- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)

### 무작위 (기본값) {#load_balancing-random}

```sql
load_balancing = random
```

오류 수는 각 복제본에 대해 계산됩니다. 쿼리는 가장 적은 오류가 있는 복제본에 전송되며, 이러한 복제본이 여러 개 있을 경우 임의의 복제본으로 전송됩니다.
단점: 서버 근접성이 고려되지 않으며, 복제본에 서로 다른 데이터가 있는 경우 서로 다른 데이터가 반환됩니다.

### 가장 가까운 호스트명 {#load_balancing-nearest_hostname}

```sql
load_balancing = nearest_hostname
```

오류 수는 각 복제본에 대해 계산됩니다. 5분마다 오류 수가 전체적으로 2로 나누어집니다. 따라서 최근 데이터에 대해 지수 평활법으로 계산됩니다. 최소 오류 수를 가진 복제본이 하나 있다면(즉 최근에 다른 복제본에서 오류가 발생), 쿼리를 해당 복제본으로 전송합니다. 동일한 최소 오류 수를 가진 여러 복제본이 있는 경우, 쿼리는 구성 파일의 서버의 호스트명과 가장 유사한 호스트명을 가진 복제본으로 전송됩니다(동일한 위치의 문자 수만큼 다를 경우, 두 호스트명의 최소 길이를 기준으로).

예를 들어, example01-01-1과 example01-01-2는 한 위치에서 다르며, example01-01-1과 example01-02-2는 두 위치에서 다릅니다.
이 방법은 원시적일 수 있지만, 네트워크 토폴로지에 대한 외부 데이터가 필요하지 않으며, IP 주소를 비교하지 않으므로 우리의 IPv6 주소에 대해 복잡해질 수 있습니다.

따라서, 동등한 복제본이 있을 경우, 이름에 따라 가장 가까운 것이 선호됩니다.
같은 서버에 쿼리를 보낼 때 실패가 없을 경우, 분산 쿼리도 동일한 서버로 전송될 것이라고 가정할 수 있습니다. 따라서 복제본에 서로 다른 데이터가 저장되어 있더라도, 쿼리는 대부분 동일한 결과를 반환합니다.

### 호스트명 레벤슈타인 거리 {#load_balancing-hostname_levenshtein_distance}

```sql
load_balancing = hostname_levenshtein_distance
```

`nearest_hostname`와 유사하지만, 레벤슈타인 거리 [levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) 방식으로 호스트명을 비교합니다. 예를 들어:

```text
example-clickhouse-0-0 ample-clickhouse-0-0
1

example-clickhouse-0-0 example-clickhouse-1-10
2

example-clickhouse-0-0 example-clickhouse-12-0
3
```

### 순차 {#load_balancing-in_order}

```sql
load_balancing = in_order
```

동일한 오류 수를 가진 복제본은 구성에서 지정된 순서대로 접근됩니다. 이 방법은 어떤 복제본이 선호되는지 명확할 경우 적합합니다.

### 첫 번째 또는 무작위 {#load_balancing-first_or_random}

```sql
load_balancing = first_or_random
```

이 알고리즘은 세트의 첫 번째 복제본을 선택하거나 첫 번째 복제본이 사용할 수 없는 경우 무작위 복제본을 선택합니다. 크로스 복제 토폴로지 설정에서 효과적이지만 다른 구성에서는 쓸모가 없습니다.

`first_or_random` 알고리즘은 `in_order` 알고리즘의 문제를 해결합니다. `in_order`는 한 복제본이 다운되면, 다음 복제본이 이중 하중을 받아 나머지 복제본은 일반적인 트래픽을 처리하게 됩니다. `first_or_random` 알고리즘을 사용할 때 로드는 여전히 가용한 복제본 사이에 균등하게 분배됩니다. `load_balancing_first_offset` 설정을 사용하여 첫 번째 복제본이 무엇인지 명시적으로 정의할 수 있습니다. 이로 인해 복제본 간 쿼리 작업 부하를 재조정할 수 있습니다.

### 라운드 로빈 {#load_balancing-round_robin}

```sql
load_balancing = round_robin
```

이 알고리즘은 동일한 오류 수를 가진 복제본에 대해 라운드 로빈 정책을 사용합니다 (오직 `round_robin` 정책의 쿼리만 계산됨).

## load_balancing_first_offset {#load_balancing_first_offset} 

<SettingsInfoBlock type="UInt64" default_value="0" />

FIRST_OR_RANDOM 로드 밸런싱 전략이 사용될 때 쿼리를 주로 어디로 보낼지를 지정합니다.

## load_marks_asynchronously {#load_marks_asynchronously} 

<SettingsInfoBlock type="Bool" default_value="0" />

MergeTree 마크를 비동기로 로드합니다.

## local_filesystem_read_method {#local_filesystem_read_method} 

<SettingsInfoBlock type="String" default_value="pread_threadpool" />

로컬 파일 시스템에서 데이터를 읽는 방법으로, read, pread, mmap, io_uring, pread_threadpool 중 하나입니다.

'io_uring' 방법은 실험적이며 Log, TinyLog, StripeLog, File, Set 및 조인, 동시 읽기 및 쓰기에서 추가 가능한 파일이 있는 테이블에 대해 작동하지 않습니다. 인터넷에서 'io_uring'에 관한 다양한 기사를 읽는다면, 이들에 의해 맹목적으로 되지 마십시오. 이는 작은 IO 요청의 양이 많을 경우에만 더 나은 파일 읽기 방법이지만, ClickHouse에서는 이런 경우가 아닙니다. 'io_uring'을 활성화할 이유가 없습니다.

## local_filesystem_read_prefetch {#local_filesystem_read_prefetch} 

<SettingsInfoBlock type="Bool" default_value="0" />

로컬 파일 시스템에서 데이터를 읽을 때 미리 가져오기 사용 여부입니다.

## lock_acquire_timeout {#lock_acquire_timeout} 

<SettingsInfoBlock type="Seconds" default_value="120" />

잠금 요청이 실패하기 전에 대기하는 시간을 초 단위로 정의합니다.

잠금 시간 초과는 테이블과 함께 읽기/쓰기 작업을 수행할 때 데드락을 방지하기 위해 사용됩니다. 시간 초과가 만료되고 잠금 요청이 실패하는 경우 ClickHouse 서버는 "Locking attempt timed out! Possible deadlock avoided. Client should retry."라는 예외를 발생시키며, 오류 코드는 `DEADLOCK_AVOIDED`입니다.

가능한 값:

- 양의 정수(초 단위).
- 0 — 잠금 시간 초과 없음.

## log_comment {#log_comment} 

[system.query_log](../system-tables/query_log.md) 테이블의 `log_comment` 필드의 값을 지정하고 서버 로그의 주석 텍스트를 지정합니다.

이는 서버 로그의 가독성을 향상시키기 위해 사용될 수 있습니다. 또한, [clickhouse-test](../../development/tests.md)를 실행한 후 `system.query_log`에서 테스트와 관련된 쿼리를 선택하는 데 도움이 됩니다.

가능한 값:

- [max_query_size](#max_query_size)보다 길지 않은 모든 문자열. max_query_size를 초과하면 서버가 예외를 발생시킵니다.

**예시**

쿼리:

```sql
SET log_comment = 'log_comment test', log_queries = 1;
SELECT 1;
SYSTEM FLUSH LOGS;
SELECT type, query FROM system.query_log WHERE log_comment = 'log_comment test' AND event_date >= yesterday() ORDER BY event_time DESC LIMIT 2;
```

결과:

```text
┌─type────────┬─query─────┐
│ QueryStart  │ SELECT 1; │
│ QueryFinish │ SELECT 1; │
└─────────────┴───────────┘
```

## log_formatted_queries {#log_formatted_queries} 

<SettingsInfoBlock type="Bool" default_value="0" />

형식화된 쿼리를 [system.query_log](../../operations/system-tables/query_log.md) 시스템 테이블에 기록할 수 있습니다 (형식화된 쿼리는 [system.query_log](../../operations/system-tables/query_log.md)의 `formatted_query` 열을 채울 것입니다).

가능한 값:

- 0 — 형식화된 쿼리는 시스템 테이블에 기록되지 않습니다.
- 1 — 형식화된 쿼리가 시스템 테이블에 기록됩니다.

## log_processors_profiles {#log_processors_profiles} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "Enable by default"}]}]}/>

프로세서가 실행/데이터 대기 중에 소요한 시간을 `system.processors_profile_log` 테이블에 기록합니다.

추가 정보:

- [`system.processors_profile_log`](../../operations/system-tables/processors_profile_log.md)
- [`EXPLAIN PIPELINE`](../../sql-reference/statements/explain.md/#explain-pipeline)

## log_profile_events {#log_profile_events} 

쿼리 성능 통계를 query_log, query_thread_log 및 query_views_log에 기록합니다.

## log_queries {#log_queries} 

쿼리 로깅 설정입니다.

이 설정이 활성화된 상태에서 ClickHouse에 전송된 쿼리는 [query_log](../../operations/server-configuration-parameters/settings.md/#query_log) 서버 구성 매개변수의 규칙에 따라 기록됩니다.

예시:

```text
log_queries=1
```

## log_queries_cut_to_length {#log_queries_cut_to_length} 

쿼리 길이가 지정된 임계값(바이트 단위)을 초과하는 경우, 쿼리를 쿼리 로그에 기록할 때 자릅니다. 일반 텍스트 로그에 인쇄되는 쿼리의 길이도 제한합니다.

## log_queries_min_query_duration_ms {#log_queries_min_query_duration_ms} 

이 설정이 활성화된 경우(0이 아닐 때), 이 설정의 값보다 빠른 쿼리는 로그되지 않습니다 (이것은 [MySQL 느린 쿼리 로그](https://dev.mysql.com/doc/refman/5.7/slow-query-log.html)의 `long_query_time`과 유사하게 생각할 수 있습니다). 이는 다음 테이블에서 쿼리를 찾을 수 없음을 의미합니다:

- `system.query_log`
- `system.query_thread_log`

로그에는 다음과 같은 유형의 쿼리만 기록됩니다:

- `QUERY_FINISH`
- `EXCEPTION_WHILE_PROCESSING`

- 유형: 밀리초
- 기본값: 0 (모든 쿼리)

## log_queries_min_type {#log_queries_min_type} 

`query_log`에 기록할 최소 유형입니다.

가능한 값:
- `QUERY_START` (`=1`)
- `QUERY_FINISH` (`=2`)
- `EXCEPTION_BEFORE_START` (`=3`)
- `EXCEPTION_WHILE_PROCESSING` (`=4`)

`query_log`로 들어갈 엔티티를 제한하는 데 사용할 수 있습니다. 예를 들어, 오류만 관심 있는 경우 `EXCEPTION_WHILE_PROCESSING`를 사용할 수 있습니다:

```text
log_queries_min_type='EXCEPTION_WHILE_PROCESSING'
```

## log_queries_probability {#log_queries_probability} 

사용자가 [query_log](../../operations/system-tables/query_log.md), [query_thread_log](../../operations/system-tables/query_thread_log.md), 및 [query_views_log](../../operations/system-tables/query_views_log.md) 시스템 테이블에 대해 지정된 확률로 임의로 선택된 쿼리 샘플만 기록할 수 있습니다. 이는 초당 많은 양의 쿼리 부하를 줄이는 데 도움이 됩니다.

가능한 값:

- 0 — 쿼리는 시스템 테이블에 기록되지 않습니다.
- [0..1] 범위의 양의 실수. 예를 들어, 설정 값이 `0.5`이면 약 절반의 쿼리가 시스템 테이블에 기록됩니다.
- 1 — 모든 쿼리가 시스템 테이블에 기록됩니다.

## log_query_settings {#log_query_settings} 

쿼리 설정을 query_log 및 OpenTelemetry 스팬 로그에 기록합니다.

## log_query_threads {#log_query_threads} 

쿼리 스레드 로깅 설정입니다.

쿼리 스레드는 [system.query_thread_log](../../operations/system-tables/query_thread_log.md) 테이블에 기록됩니다. 이 설정은 [log_queries](#log_queries)가 true일 때만 효과가 있습니다. ClickHouse에 의해 실행된 쿼리 스레드가 이 설정이 활성화된 경우 [query_thread_log](/operations/server-configuration-parameters/settings#query_thread_log) 서버 구성 매개변수의 규칙에 따라 기록됩니다.

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.

**예시**

```text
log_query_threads=1
```

## log_query_views {#log_query_views} 

쿼리 뷰 로깅 설정입니다.

이 설정이 활성화되면 ClickHouse에서 실행된 쿼리에 연결된 뷰(물리화된 뷰 또는 라이브 뷰)가 [query_views_log](/operations/server-configuration-parameters/settings#query_views_log) 서버 구성 매개변수에 기록됩니다.

예시:

```text
log_query_views=1
```

## low_cardinality_allow_in_native_format {#low_cardinality_allow_in_native_format} 

[LowCardinality](../../sql-reference/data-types/lowcardinality.md) 데이터 유형을 [Native](/interfaces/formats/Native) 형식과 함께 사용하는 것을 허용하거나 제한합니다.

`LowCardinality`의 사용이 제한되는 경우, ClickHouse 서버는 `SELECT` 쿼리에서 `LowCardinality` 컬럼을 일반 컬럼으로 변환하고, `INSERT` 쿼리에서 일반 컬럼을 `LowCardinality` 컬럼으로 변환합니다.

이 설정은 `LowCardinality` 데이터 유형을 지원하지 않는 서드 파티 클라이언트를 위해 주로 필요합니다.

가능한 값:

- 1 — `LowCardinality`의 사용이 제한되지 않습니다.
- 0 — `LowCardinality`의 사용이 제한됩니다.

## low_cardinality_max_dictionary_size {#low_cardinality_max_dictionary_size} 

[LowCardinality](../../sql-reference/data-types/lowcardinality.md) 데이터 유형에 대한 공유 전역 딕셔너리의 최대 크기를 행 수 단위로 설정하며, 스토리지 파일 시스템에 쓸 수 있습니다. 이 설정은 무제한 딕셔너리 성장으로 인한 RAM 문제를 방지합니다. 최대 딕셔너리 크기 제한으로 인해 인코딩할 수 없는 모든 데이터는 ClickHouse가 일반 방법으로 기록합니다.

가능한 값:

- 모든 양의 정수.

## low_cardinality_use_single_dictionary_for_part {#low_cardinality_use_single_dictionary_for_part} 

데이터 파트에 대해 단일 딕셔너리를 사용하는 것을 켜거나 끕니다.

기본적으로 ClickHouse 서버는 딕셔너리 크기를 모니터링하며, 딕셔너리가 오버플로우되면 서버는 다음 것을 기록하기 시작합니다. 여러 딕셔너리를 생성하는 것을 금지하려면 `low_cardinality_use_single_dictionary_for_part = 1`을 설정하세요.

가능한 값:

- 1 — 데이터 파트에 대해 여러 딕셔너리 생성이 금지됩니다.
- 0 — 데이터 파트에 대해 여러 딕셔너리 생성이 금지되지 않습니다.

## low_priority_query_wait_time_ms {#low_priority_query_wait_time_ms} 

<BetaBadge/>

<SettingsInfoBlock type="Milliseconds" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1000"},{"label": "New setting."}]}]}/>

쿼리 우선 순위 메커니즘이 사용될 경우(설정 `priority` 참고), 저우선 순위 쿼리는 고우선 순위 쿼리가 완료될 때까지 대기합니다. 이 설정은 대기 시간을 지정합니다.

## make_distributed_plan {#make_distributed_plan} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

분산 쿼리 계획을 만듭니다.

## materialize_skip_indexes_on_insert {#materialize_skip_indexes_on_insert} 

INSERT가 스킵 인덱스를 빌드하고 저장할지 여부입니다. 비활성화되면 스킵 인덱스는 [병합 중](/merge-tree-settings.md/#materialize_skip_indexes_on_merge)만 빌드되고 저장되거나 명시적인 [MATERIALIZE INDEX](/sql-reference/statements/alter/skipping-index.md/#materialize-index)에 의해 생성됩니다.

[exclude_materialize_skip_indexes_on_insert](#exclude_materialize_skip_indexes_on_insert)도 참조하세요.

## materialize_statistics_on_insert {#materialize_statistics_on_insert} 

INSERT가 통계를 빌드하고 삽입할지 여부입니다. 비활성화되면 통계는 병합 중에 빌드되거나 명시적 MATERIALIZE STATISTICS에 의해 저장됩니다.

## materialize_ttl_after_modify {#materialize_ttl_after_modify} 

ALTER MODIFY TTL 쿼리 후 구식 데이터에 대해 TTL을 적용합니다.

## materialized_views_ignore_errors {#materialized_views_ignore_errors} 

MATERIALIZED VIEW에 대한 오류를 무시하고 MVs와 상관없이 원본 블록을 테이블에 전달할 수 있습니다.

## materialized_views_squash_parallel_inserts {#materialized_views_squash_parallel_inserts} 

병렬 삽입으로부터 단일 INSERT 쿼리에 대한 물리화된 뷰의 대상 테이블에 대해 삽입을 압축하여 생성된 파트 수를 줄입니다. false로 설정하고 `parallel_view_processing`이 활성화된 경우, INSERT 쿼리는 각 `max_insert_thread`에 대해 대상 테이블에서 파트를 생성합니다.

## max_analyze_depth {#max_analyze_depth} 

인터프리터에 의해 수행되는 최대 분석 수입니다.

## max_ast_depth {#max_ast_depth} 

쿼리 구문 트리의 최대 중첩 깊이입니다. 초과 시 예외가 발생합니다.

:::note
현재 이 체크는 파싱 중에 확인되지 않고, 쿼리를 파싱한 후에만 확인됩니다.
즉, 파싱 중에 너무 깊은 구문 트리가 생성되더라도 쿼리가 실패할 수 있습니다.
:::

## max_ast_elements {#max_ast_elements} 

쿼리 구문 트리의 최대 요소 수입니다. 초과 시 예외가 발생합니다.

:::note
현재 이 체크는 파싱 중에 확인되지 않고, 쿼리를 파싱한 후에만 확인됩니다.
즉, 파싱 중에 너무 깊은 구문 트리가 생성되더라도 쿼리가 실패할 수 있습니다.
:::

## max_autoincrement_series {#max_autoincrement_series} 

`generateSerialID` 함수로 생성된 시리즈 수에 대한 제한입니다.

각 시리즈는 Keeper의 노드를 나타내므로, 수가 몇 백만을 초과하지 않도록 하는 것이 좋습니다.

## max_backup_bandwidth {#max_backup_bandwidth} 

특정 백업의 서버에 대한 최대 읽기 속도(바이트 단위)입니다. 0은 무제한을 의미합니다.

## max_block_size {#max_block_size} 

ClickHouse에서 데이터는 컬럼 파트 집합으로 처리되는 블록 단위로 처리됩니다. 단일 블록의 내부 처리 주기는 효율적이지만 각 블록을 처리할 때는 눈에 띄는 비용이 발생합니다.

`max_block_size` 설정은 테이블에서 데이터 로드 시 단일 블록에 포함될 최대 행 수를 권장합니다. `max_block_size` 크기의 블록이 항상 테이블에서 로드되는 것은 아닙니다: ClickHouse가 더 적은 데이터를 검색해야 한다고 판단하는 경우 더 작은 블록을 처리합니다.

블록 크기는 너무 작지 않아야 각 블록을 처리할 때 눈에 띄는 비용이 발생하지 않도록 해야 합니다. 또한 첫 번째 블록을 처리한 후 LIMIT 절이 있는 쿼리가 빠르게 실행되도록 하기 위해 크기가 너무 커서도 안 됩니다. `max_block_size`를 설정할 때, 목표는 많은 수의 컬럼을 여러 스레드에서 추출할 때 지나치게 많은 메모리를 소비하지 않도록 하고, 최소한 일부 캐시 지역성을 보존하는 것입니다.

## max_bytes_before_external_group_by {#max_bytes_before_external_group_by} 



<SettingsInfoBlock type="UInt64" default_value="0" />

클라우드 기본값: 복제본당 메모리 양의 절반입니다.

외부 메모리에서 `GROUP BY` 절의 실행을 활성화하거나 비활성화합니다.
(외부 메모리에서의 [GROUP BY](/sql-reference/statements/select/group-by#group-by-in-external-memory) 참고)

가능한 값:

- 단일 [GROUP BY](/sql-reference/statements/select/group-by) 작업에 사용할 수 있는 최대 RAM 용량(바이트 단위).
- `0` — 외부 메모리에서의 `GROUP BY` 비활성화.

:::note
GROUP BY 작업 중 메모리 사용량이 이 바이트 임계값을 초과하면,
‘외부 집계’ 모드를 활성화하여 (데이터를 디스크로 쏟아내기) 진행합니다.

권장 값은 사용 가능한 시스템 메모리의 절반입니다.
:::
## max_bytes_before_external_sort {#max_bytes_before_external_sort} 



<SettingsInfoBlock type="UInt64" default_value="0" />

클라우드 기본값: 복제본당 메모리 양의 절반입니다.

외부 메모리에서 `ORDER BY` 절 실행을 활성화하거나 비활성화합니다. [ORDER BY 구현 세부 정보](../../sql-reference/statements/select/order-by.md#implementation-details) 참조
ORDER BY 작업 중 메모리 사용량이 이 임계값을 초과하면 ‘외부 정렬’ 모드가 활성화되어 (데이터를 디스크로 쏟아냄) 진행됩니다.

가능한 값:

- 단일 [ORDER BY](../../sql-reference/statements/select/order-by.md) 작업에 사용할 수 있는 최대 RAM 용량(바이트 단위).
  권장 값은 사용 가능한 시스템 메모리의 절반입니다.
- `0` — 외부 메모리에서의 `ORDER BY` 비활성화.
## max_bytes_before_remerge_sort {#max_bytes_before_remerge_sort} 



<SettingsInfoBlock type="UInt64" default_value="1000000000" />

LIMIT가 있는 ORDER BY의 경우, 메모리 사용량이 지정된 임계값보다 높을 경우 최종 병합 전에 블록 병합의 추가 단계를 수행하여 상위 LIMIT 행만 유지합니다.
## max_bytes_in_distinct {#max_bytes_in_distinct} 



<SettingsInfoBlock type="UInt64" default_value="0" />

DISTINCT를 사용할 때 해시 테이블이 소비하는 상태의 최대 바이트 수(압축되지 않은 바이트 기준).
## max_bytes_in_join {#max_bytes_in_join} 



<SettingsInfoBlock type="UInt64" default_value="0" />

테이블 조인 시 사용하는 해시 테이블의 최대 크기(바이트 수).

이 설정은 [SELECT ... JOIN](/sql-reference/statements/select/join) 작업과 [Join 테이블 엔진](/engines/table-engines/special/join)에 적용됩니다.

쿼리에 조인이 포함되어 있을 때, ClickHouse는 각 중간 결과에 대해 이 설정을 확인합니다.

ClickHouse는 제한에 도달했을 때 다른 작업을 진행할 수 있습니다. [`join_overflow_mode`](/operations/settings/settings#join_overflow_mode) 설정을 사용하여 작업을 선택하십시오.

가능한 값:

- 양의 정수.
- 0 — 메모리 제어 비활성화.
## max_bytes_in_set {#max_bytes_in_set} 



<SettingsInfoBlock type="UInt64" default_value="0" />

하위 쿼리에서 생성된 IN 절의 집합에서 사용하는 최대 바이트 수(압축되지 않은 데이터 수).
## max_bytes_ratio_before_external_group_by {#max_bytes_ratio_before_external_group_by} 



<SettingsInfoBlock type="Double" default_value="0.5" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0.5"},{"label": "Enable automatic spilling to disk by default."}]}, {"id": "row-2","items": [{"label": "24.12"},{"label": "0"},{"label": "New setting."}]}]}/>

`GROUP BY`에 허용되는 가용 메모리의 비율입니다. 이 비율에 도달하면 집계에 외부 메모리를 사용합니다.

예를 들어, `0.6`으로 설정하면 `GROUP BY`는 실행 시작 시 가용 메모리의 60%를 사용할 수 있습니다(서버/사용자/병합에 대해), 이후에는 외부 집계를 사용하기 시작합니다.
## max_bytes_ratio_before_external_sort {#max_bytes_ratio_before_external_sort} 



<SettingsInfoBlock type="Double" default_value="0.5" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0.5"},{"label": "Enable automatic spilling to disk by default."}]}, {"id": "row-2","items": [{"label": "24.12"},{"label": "0"},{"label": "New setting."}]}]}/>

`ORDER BY`에 허용되는 가용 메모리의 비율입니다. 이 비율에 도달하면 외부 정렬이 사용됩니다.

예를 들어, `0.6`으로 설정하면 `ORDER BY`는 실행 시작 시 가용 메모리의 `60%`를 사용할 수 있습니다(서버/사용자/병합에 대해), 이후에는 외부 정렬을 사용하기 시작합니다.

참고로, `max_bytes_before_external_sort`는 여전히 유지되며 정렬 블록이 `max_bytes_before_external_sort`보다 클 경우에만 디스크로 쏟아내기가 수행됩니다.
## max_bytes_to_read {#max_bytes_to_read} 



<SettingsInfoBlock type="UInt64" default_value="0" />

쿼리를 실행할 때 테이블에서 읽을 수 있는 최대 바이트 수(압축되지 않은 데이터).
제한은 처리되는 데이터 청크마다 확인되며, 가장 깊은 테이블 표현식에 대해서만 적용되고 원격 서버에서 읽을 때는 원격 서버에서만 확인됩니다.
## max_bytes_to_read_leaf {#max_bytes_to_read_leaf} 



<SettingsInfoBlock type="UInt64" default_value="0" />

분산 쿼리를 수행할 때 리프 노드의 로컬 테이블에서 읽을 수 있는 최대 바이트 수(압축되지 않은 데이터). 분산 쿼리는 각 샤드(리프)에 여러 하위 쿼리를 실행할 수 있지만, 이 제한은 읽기 단계에서만 레프 노드에서 확인되며 결과 병합 단계에서는 무시됩니다.

예를 들어, 클러스터에 2개의 샤드가 있고 각 샤드에 100바이트의 데이터가 있는 테이블이 포함되어 있습니다. `max_bytes_to_read=150` 설정으로 두 테이블의 모든 데이터를 읽으려는 분산 쿼리는 총 200바이트가 될 것이므로 실패합니다. `max_bytes_to_read_leaf=150`을 사용한 쿼리는 리프 노드에서 최대 100바이트만 읽기 때문에 성공합니다.

제한은 처리되는 데이터 청크마다 확인됩니다.

:::note
이 설정은 `prefer_localhost_replica=1`과 함께 사용할 때 안정성이 떨어집니다.
:::
## max_bytes_to_sort {#max_bytes_to_sort} 



<SettingsInfoBlock type="UInt64" default_value="0" />

정렬 전에 처리해야 하는 최대 바이트 수입니다. ORDER BY 작업에 대해 지정된 바이트 수가 초과되면, 동작은 기본적으로 `throw`로 설정된 `sort_overflow_mode`에 따라 결정됩니다.
## max_bytes_to_transfer {#max_bytes_to_transfer} 



<SettingsInfoBlock type="UInt64" default_value="0" />

GLOBAL IN/JOIN 섹션이 실행될 때 원격 서버에 전송되거나 임시 테이블에 저장될 수 있는 최대 바이트 수(압축되지 않은 데이터).
## max_columns_to_read {#max_columns_to_read} 



<SettingsInfoBlock type="UInt64" default_value="0" />

단일 쿼리에서 테이블에서 읽을 수 있는 최대 컬럼 수입니다.
쿼리가 지정된 수의 컬럼을 초과하여 읽어야 하는 경우 예외가 발생합니다.

:::tip
이 설정은 지나치게 복잡한 쿼리를 방지하는 데 유용합니다.
:::

`0` 값은 무제한을 의미합니다.
## max_compress_block_size {#max_compress_block_size} 



<SettingsInfoBlock type="UInt64" default_value="1048576" />

테이블에 쓰기 위해 압축하기 전에 압축되지 않은 데이터 블록의 최대 크기입니다. 기본값은 1,048,576 (1 MiB)입니다. 더 작은 블록 크기를 지정하면 일반적으로 압축 비율이 약간 감소하며, 압축 및 압축 해제 속도가 약간 증가하고 메모리 소비가 줄어듭니다.

:::note
이 설정은 전문가 수준의 설정이며, ClickHouse를 처음 사용하는 경우 변경하지 않아야 합니다.
:::

압축을 위한 블록(바이트로 구성된 메모리 청크)과 쿼리 처리 블록(테이블의 행 집합)을 혼동하지 마십시오.
## max_concurrent_queries_for_all_users {#max_concurrent_queries_for_all_users} 



<SettingsInfoBlock type="UInt64" default_value="0" />

동시에 처리되는 쿼리 수가 현재 처리되는 쿼리 수보다 작거나 같은 경우 예외를 발생시킵니다.

예: `max_concurrent_queries_for_all_users`는 모든 사용자에 대해 99로 설정할 수 있으며, 데이터베이스 관리자는 이를 100으로 설정하여 서버가 과중된 경우에도 조사를 위해 쿼리를 실행할 수 있도록 합니다.

하나의 쿼리 또는 사용자에 대해 설정을 수정하면 다른 쿼리에 영향을 미치지 않습니다.

가능한 값:

- 양의 정수.
- 0 — 제한 없음.

**예제**

```xml
<max_concurrent_queries_for_all_users>99</max_concurrent_queries_for_all_users>
```

**참고 사항**

- [max_concurrent_queries](/operations/server-configuration-parameters/settings#max_concurrent_queries)
## max_concurrent_queries_for_user {#max_concurrent_queries_for_user} 



<SettingsInfoBlock type="UInt64" default_value="0" />

사용자당 동시에 처리되는 쿼리 수의 최대 수입니다.

가능한 값:

- 양의 정수.
- 0 — 제한 없음.

**예제**

```xml
<max_concurrent_queries_for_user>5</max_concurrent_queries_for_user>
```
## max_distributed_connections {#max_distributed_connections} 



<SettingsInfoBlock type="UInt64" default_value="1024" />

단일 분산 테이블의 단일 쿼리에 대한 원격 서버와의 동시 연결 수의 최대 수입니다. 클러스터의 서버 수보다 적지 않도록 설정하는 것이 좋습니다.

다음 매개변수는 분산 테이블을 생성할 때와 서버를 시작할 때만 사용되므로 런타임 중에 변경할 이유가 없습니다.
## max_distributed_depth {#max_distributed_depth} 



<SettingsInfoBlock type="UInt64" default_value="5" />

[Distributed](../../engines/table-engines/special/distributed.md) 테이블에 대한 재귀 쿼리의 최대 깊이를 제한합니다.

값이 초과될 경우 서버가 예외를 발생시킵니다.

가능한 값:

- 양의 정수.
- 0 — 무제한 깊이.
## max_download_buffer_size {#max_download_buffer_size} 



<SettingsInfoBlock type="UInt64" default_value="10485760" />

각 스레드에 대해 병렬 다운로드(예: URL 엔진)의 최대 버퍼 크기입니다.
## max_download_threads {#max_download_threads} 



<SettingsInfoBlock type="MaxThreads" default_value="4" />

데이터를 다운로드하기 위한 최대 스레드 수(예: URL 엔진).
## max_estimated_execution_time {#max_estimated_execution_time} 



<SettingsInfoBlock type="Seconds" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "Separate max_execution_time and max_estimated_execution_time"}]}]}/>

쿼리의 최대 예상 실행 시간(초). [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 만료 시 데이터 블록마다 확인됩니다.
## max_execution_speed {#max_execution_speed} 



<SettingsInfoBlock type="UInt64" default_value="0" />

초당 최대 실행 행 수입니다. [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 만료 시 데이터 블록마다 확인됩니다. 실행 속도가 높으면 실행 속도가 감소합니다.
## max_execution_speed_bytes {#max_execution_speed_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

초당 최대 실행 바이트 수입니다. [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 만료 시 데이터 블록마다 확인됩니다. 실행 속도가 높으면 실행 속도가 감소합니다.
## max_execution_time {#max_execution_time} 



<SettingsInfoBlock type="Seconds" default_value="0" />

최대 쿼리 실행 시간(초).

`max_execution_time` 매개변수는 약간 이해하기 어려울 수 있습니다.
현재 쿼리 실행 속도에 대한 보간을 기반으로 작동합니다
(이 동작은 [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)에 의해 제어됨).

ClickHouse는 예상 실행 시간이 지정된 `max_execution_time`을 초과하면 쿼리를 중단합니다. 기본적으로 `timeout_before_checking_execution_speed`는 10초로 설정되어 있습니다. 이는 쿼리 실행 후 10초가 지나면 ClickHouse가 총 실행 시간을 추정하기 시작함을 의미합니다. 예를 들어, `max_execution_time`이 3600초(1시간)로 설정되어 있으면, ClickHouse는 예상 시간(3600초 제한)을 초과하면 쿼리를 종료합니다. `timeout_before_checking_execution_speed`를 0으로 설정하면 ClickHouse는 `max_execution_time`의 기준으로 시계 시간을 사용합니다.

쿼리 실행 시간이 지정된 초수를 초과하면, 동작은 기본적으로 `throw`로 설정된 'timeout_overflow_mode'에 의해 결정됩니다.

:::note
타임아웃은 확인되며 쿼리는 데이터 처리 중 지정된 장소에서만 중단할 수 있습니다.
현재 집계 상태 병합 또는 쿼리 분석 중에는 중단할 수 없으며, 실제 실행 시간은 이 설정의 값보다 높을 것입니다.
:::
## max_execution_time_leaf {#max_execution_time_leaf} 



<SettingsInfoBlock type="Seconds" default_value="0" />

[`max_execution_time`](#max_execution_time)와 의미가 유사하지만 분산 또는 원격 쿼리에 대해 리프 노드에만 적용됩니다.

예를 들어, 리프 노드에서 실행 시간을 `10초`로 제한하고 초기 노드에는 제한이 없는 경우 중첩된 하위 쿼리 설정에 `max_execution_time`을 사용하는 대신 다음과 같이 사용할 수 있습니다:

```sql
SELECT count()
FROM cluster(cluster, view(SELECT * FROM t SETTINGS max_execution_time = 10));
```

쿼리 설정으로 `max_execution_time_leaf`를 사용할 수 있습니다:

```sql
SELECT count()
FROM cluster(cluster, view(SELECT * FROM t)) SETTINGS max_execution_time_leaf = 10;
```
## max_expanded_ast_elements {#max_expanded_ast_elements} 



<SettingsInfoBlock type="UInt64" default_value="500000" />

별칭과 별표 확장이 수행된 후 쿼리 구문 트리의 최대 크기(노드 수).
## max_fetch_partition_retries_count {#max_fetch_partition_retries_count} 



<SettingsInfoBlock type="UInt64" default_value="5" />

다른 호스트에서 파티션을 가져오는 동안 재시도 횟수입니다.
## max_final_threads {#max_final_threads} 



<SettingsInfoBlock type="MaxThreads" default_value="'auto(N)'" />

[FINAL](/sql-reference/statements/select/from#final-modifier) 수정자를 사용하여 `SELECT` 쿼리 데이터 읽기 단계에서 최대 병렬 스레드 수를 설정합니다.

가능한 값:

- 양의 정수.
- 0 또는 1 — 비활성화. `SELECT` 쿼리는 단일 스레드로 실행됩니다.
## max_http_get_redirects {#max_http_get_redirects} 



<SettingsInfoBlock type="UInt64" default_value="0" />

허용되는 최대 HTTP GET 리디렉션 홉 수입니다. 악의적인 서버가 요청을 예기치 않은 서비스로 리디렉션하지 않도록 추가적인 보안 조치를 보장합니다.\n\n외부 서버가 다른 주소로 리디렉션되지만 해당 주소가 회사 인프라에 내부로 보이는 경우, 내부 서버에 HTTP 요청을 보내면 내부 네트워크의 내부 API를 요청하거나 심지어 Redis 또는 Memcached와 같은 다른 서비스를 쿼리할 수 있습니다. 내부 인프라(로컬 호스트에서 실행되는 것 포함)가 없거나 서버를 신뢰하는 경우 리디렉션을 허용하는 것이 안전합니다. URL이 HTTPS 대신 HTTP를 사용하는 경우, 원격 서버뿐만 아니라 ISP 및 중간 네트워크를 신뢰해야 합니다.
## max_hyperscan_regexp_length {#max_hyperscan_regexp_length} 



<SettingsInfoBlock type="UInt64" default_value="0" />

[hyperscan 다중 매치 함수](/sql-reference/functions/string-search-functions#multiMatchAny)에서 각 정규 표현식의 최대 길이를 정의합니다.

가능한 값:

- 양의 정수.
- 0 - 길이 제한 없음.

**예제**

쿼리:

```sql
SELECT multiMatchAny('abcd', ['ab','bcd','c','d']) SETTINGS max_hyperscan_regexp_length = 3;
```

결과:

```text
┌─multiMatchAny('abcd', ['ab', 'bcd', 'c', 'd'])─┐
│                                              1 │
└────────────────────────────────────────────────┘
```

쿼리:

```sql
SELECT multiMatchAny('abcd', ['ab','bcd','c','d']) SETTINGS max_hyperscan_regexp_length = 2;
```

결과:

```text
Exception: Regexp length too large.
```

**참고 사항**

- [max_hyperscan_regexp_total_length](#max_hyperscan_regexp_total_length)
## max_hyperscan_regexp_total_length {#max_hyperscan_regexp_total_length} 



<SettingsInfoBlock type="UInt64" default_value="0" />

각 [hyperscan 다중 매치 함수](/sql-reference/functions/string-search-functions#multiMatchAny)에서 모든 정규 표현식의 최대 길이 총합을 설정합니다.

가능한 값:

- 양의 정수.
- 0 - 길이 제한 없음.

**예제**

쿼리:

```sql
SELECT multiMatchAny('abcd', ['a','b','c','d']) SETTINGS max_hyperscan_regexp_total_length = 5;
```

결과:

```text
┌─multiMatchAny('abcd', ['a', 'b', 'c', 'd'])─┐
│                                           1 │
└─────────────────────────────────────────────┘
```

쿼리:

```sql
SELECT multiMatchAny('abcd', ['ab','bc','c','d']) SETTINGS max_hyperscan_regexp_total_length = 5;
```

결과:

```text
Exception: Total regexp lengths too large.
```

**참고 사항**

- [max_hyperscan_regexp_length](#max_hyperscan_regexp_length)
## max_insert_block_size {#max_insert_block_size} 



<SettingsInfoBlock type="NonZeroUInt64" default_value="1048449" />

테이블에 삽입하기 위해 형성할 블록의 크기(행 수 기준)입니다.
이 설정은 서버가 블록을 형성하는 경우에만 적용됩니다.
예를 들어, HTTP 인터페이스를 통한 INSERT의 경우 서버가 데이터 형식을 파싱하고 지정된 크기의 블록을 형성합니다.
그러나 clickhouse-client를 사용할 때, 클라이언트가 데이터를 자체적으로 파싱하므로 서버의 'max_insert_block_size' 설정은 삽입된 블록의 크기에 영향을 미치지 않습니다.
INSERT SELECT를 사용할 때는 선택 후 형성된 동일한 블록을 사용하여 데이터가 삽입되므로 이 설정은 효용이 없습니다.

기본값은 `max_block_size`보다 약간 더 큽니다. 이 이유는 특정 테이블 엔진(`*MergeTree`)이 각 삽입된 블록에 대해 디스크에 데이터 파트를 형성하기 때문입니다. 유사하게, `*MergeTree` 테이블은 삽입 중 데이터를 정렬하며, 충분히 큰 블록 크기는 RAM에서 더 많은 데이터를 정렬할 수 있게 해줍니다.
## max_insert_delayed_streams_for_parallel_write {#max_insert_delayed_streams_for_parallel_write} 



<SettingsInfoBlock type="UInt64" default_value="0" />

최종 파트 플러시를 지연할 최대 스트림(컬럼) 수입니다. 기본값 - 자동(병렬 쓰기를 지원하는 하위 저장소의 경우는 100, 그렇지 않은 경우에는 비활성화)
## max_insert_threads {#max_insert_threads} 



<SettingsInfoBlock type="UInt64" default_value="0" />

`INSERT SELECT` 쿼리를 실행하는 최대 스레드 수입니다.

가능한 값:

- 0 (또는 1) — `INSERT SELECT` 병렬 실행 없이.
- 양의 정수. 1보다 큼.

클라우드 기본값:
- 8 GiB 메모리 있는 노드의 경우 `1`
- 16 GiB 메모리 있는 노드의 경우 `2`
- 더 큰 노드의 경우 `4`

병렬 `INSERT SELECT`는 `SELECT` 부분이 병렬로 실행되는 경우에만 효과가 있습니다. [`max_threads`](#max_threads) 설정을 참조하십시오.
더 높은 값은 더 높은 메모리 사용량으로 이어집니다.
## max_joined_block_size_bytes {#max_joined_block_size_bytes} 



<SettingsInfoBlock type="UInt64" default_value="4194304" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "4194304"},{"label": "New setting"}]}]}/>

JOIN 결과의 최대 블록 크기(조인 알고리즘이 지원하는 경우). 0은 무제한을 의미합니다.
## max_joined_block_size_rows {#max_joined_block_size_rows} 



<SettingsInfoBlock type="UInt64" default_value="65409" />

JOIN 결과의 최대 블록 크기(조인 알고리즘이 지원하는 경우). 0은 무제한을 의미합니다.
## max_limit_for_vector_search_queries {#max_limit_for_vector_search_queries} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1000"},{"label": "New setting"}]}]}/>

LIMIT보다 큰 SELECT 쿼리는 벡터 유사성 인덱스를 사용할 수 없습니다. 벡터 유사성 인덱스의 메모리 오버플로를 방지하는 데 도움이 됩니다.
## max_local_read_bandwidth {#max_local_read_bandwidth} 



<SettingsInfoBlock type="UInt64" default_value="0" />

초당 최대 로컬 읽기 속도(바이트 수).
## max_local_write_bandwidth {#max_local_write_bandwidth} 



<SettingsInfoBlock type="UInt64" default_value="0" />

초당 최대 로컬 쓰기 속도(바이트 수).
## max_memory_usage {#max_memory_usage} 



<SettingsInfoBlock type="UInt64" default_value="0" />

클라우드 기본값: 복제본의 RAM 양에 따라 다릅니다.

단일 서버에서 쿼리 실행에 사용할 최대 RAM 양입니다.
`0` 값은 무제한을 의미합니다.

이 설정은 사용 가능한 메모리의 양이나 머신의 총 메모리 볼륨을 고려하지 않습니다. 이 제한은 단일 서버 내에서 단일 쿼리에 적용됩니다.

각 쿼리에 대한 현재 메모리 소비량을 보려면 `SHOW PROCESSLIST` 명령을 사용할 수 있습니다.
각 쿼리의 피크 메모리 소비량은 추적되어 로그에 기록됩니다.

다음 집계 함수의 상태에 대한 메모리 사용량은 완전히 추적되지 않습니다:
- `min`
- `max`
- `any`
- `anyLast`
- `argMin`
- `argMax`

메모리 소비량은 [`max_memory_usage_for_user`](/operations/settings/settings#max_memory_usage_for_user)
및 [`max_server_memory_usage`](/operations/server-configuration-parameters/settings#max_server_memory_usage) 매개변수에 의해 제한됩니다.
## max_memory_usage_for_user {#max_memory_usage_for_user} 



<SettingsInfoBlock type="UInt64" default_value="0" />

단일 서버에서 사용자의 쿼리 실행에 사용할 최대 RAM 양입니다. 0은 무제한을 의미합니다.

기본적으로는 양이 제한되지 않습니다(`max_memory_usage_for_user = 0`).

[`max_memory_usage`](/operations/settings/settings#max_memory_usage)에 대한 설명도 참조하십시오.

예를 들어, 사용자인 `clickhouse_read`에 대해 `max_memory_usage_for_user`를 1000바이트로 설정하려면 다음 문을 사용할 수 있습니다.

```sql
ALTER USER clickhouse_read SETTINGS max_memory_usage_for_user = 1000;
```

클라이언트에서 로그아웃한 후 다시 로그인하여 다음과 같이 `getSetting` 함수를 사용하여 설정이 작동했는지 확인할 수 있습니다:

```sql
SELECT getSetting('max_memory_usage_for_user');
```
## max_network_bandwidth {#max_network_bandwidth} 



<SettingsInfoBlock type="UInt64" default_value="0" />

초당 네트워크를 통해 데이터 교환 속도(바이트 수)를 제한합니다. 이 설정은 모든 쿼리에 적용됩니다.

가능한 값:

- 양의 정수.
- 0 — 대역폭 제어 비활성화.
## max_network_bandwidth_for_all_users {#max_network_bandwidth_for_all_users} 



<SettingsInfoBlock type="UInt64" default_value="0" />

초당 네트워크에서의 데이터 교환 속도를 제한합니다(바이트 수). 이 설정은 서버에서 동시에 실행되는 모든 쿼리에 적용됩니다.

가능한 값:

- 양의 정수.
- 0 — 데이터 속도 제어 비활성화.
## max_network_bandwidth_for_user {#max_network_bandwidth_for_user} 



<SettingsInfoBlock type="UInt64" default_value="0" />

사용자가 수행하는 모든 동시 실행 쿼리에 대해 네트워크에서 데이터 교환 속도(바이트 수)를 제한합니다.

가능한 값:

- 양의 정수.
- 0 — 데이터 속도 제어 비활성화.
## max_network_bytes {#max_network_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

쿼리를 실행할 때 네트워크를 통해 수신되거나 전송되는 데이터 볼륨(바이트)을 제한합니다. 이 설정은 각 개별 쿼리에 적용됩니다.

가능한 값:

- 양의 정수.
- 0 — 데이터 볼륨 제어 비활성화.
## max_number_of_partitions_for_independent_aggregation {#max_number_of_partitions_for_independent_aggregation} 



<SettingsInfoBlock type="UInt64" default_value="128" />

최대 최적화 적용을 위한 테이블의 파티션 수입니다.
## max_os_cpu_wait_time_ratio_to_throw {#max_os_cpu_wait_time_ratio_to_throw} 



<SettingsInfoBlock type="Float" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "Setting values were changed and backported to 25.4"}]}, {"id": "row-2","items": [{"label": "25.4"},{"label": "0"},{"label": "New setting"}]}]}/>

쿼리를 거부하는 것으로 간주할 OS CPU 대기(OSCPUWaitMicroseconds 메트릭)와 바쁜(OSCPUVirtualTimeMicroseconds 메트릭) 시간 간의 최대 비율입니다. 최소 및 최대 비율 간의 선형 보간이 사용되어 확률을 계산하며, 이 시점에서 확률은 1입니다.
## max_parallel_replicas {#max_parallel_replicas} 



<SettingsInfoBlock type="NonZeroUInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1000"},{"label": "Use up to 1000 parallel replicas by default."}]}]}/>

쿼리를 실행할 때 각 샤드에 대해 최대 복제본 수입니다.

가능한 값:

- 양의 정수.

**추가 정보**

이 옵션은 사용되는 설정에 따라 다른 결과를 생성합니다.

:::note
이 설정은 조인 또는 하위 쿼리가 포함된 경우 잘못된 결과를 생성하며, 모든 테이블이 특정 요구 사항을 충족하지 않으면 정확하지 않을 수 있습니다. 자세한 내용은 [Distributed Subqueries and max_parallel_replicas](/operations/settings/settings#max_parallel_replicas)를 참고하십시오.
:::
### `SAMPLE` 키를 사용한 병렬 처리

여러 서버에서 병렬로 실행하면 쿼리 처리가 더 빨라질 수 있습니다. 그러나 다음 경우에 쿼리 성능이 저하될 수 있습니다:

- 샘플링 키의 위치가 파티셔닝 키에 있어 효율적인 범위 스캔을 허용하지 않습니다.
- 테이블에 샘플링 키가 추가되면 다른 컬럼별 필터링이 비효율적이 됩니다.
- 샘플링 키가 계산 비용이 많이 드는 표현식입니다.
- 클러스터 지연 분포에 긴 꼬리가 있어 더 많은 서버에 쿼리하면 전체 쿼리 지연이 증가합니다.
### [parallel_replicas_custom_key](#parallel_replicas_custom_key)를 사용한 병렬 처리

이 설정은 모든 복제테이블에 유용합니다.
## max_parser_backtracks {#max_parser_backtracks} 



<SettingsInfoBlock type="UInt64" default_value="1000000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1000000"},{"label": "Limiting the complexity of parsing"}]}]}/>

최대 파서 백트래킹(재귀적 하향 파싱 프로세스에서 다양한 대안을 시도하는 횟수).
## max_parser_depth {#max_parser_depth} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

재귀 하향 파서에서 최대 재귀 깊이를 제한합니다. 스택 크기를 제어할 수 있습니다.

가능한 값:

- 양의 정수.
- 0 — 재귀 깊이 무제한.
## max_parsing_threads {#max_parsing_threads} 



<SettingsInfoBlock type="MaxThreads" default_value="'auto(N)'" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "0"},{"label": "Add a separate setting to control number of threads in parallel parsing from files"}]}]}/>

병렬 파싱을 지원하는 입력 형식에서 데이터를 구문 분석하기 위한 최대 스레드 수입니다. 기본적으로 자동으로 결정됩니다.
## max_partition_size_to_drop {#max_partition_size_to_drop} 



<SettingsInfoBlock type="UInt64" default_value="50000000000" />

쿼리 시간에 파티션을 제거하는 제약입니다. 값 `0`은 어떤 제약 없이 파티션을 제거할 수 있음을 의미합니다.

클라우드 기본값: 1TB.

:::note
이 쿼리 설정은 서버 설정의 등가물을 덮어씁니다. [max_partition_size_to_drop](/operations/server-configuration-parameters/settings#max_partition_size_to_drop) 참조
:::
## max_partitions_per_insert_block {#max_partitions_per_insert_block} 



<SettingsInfoBlock type="UInt64" default_value="100" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "19.5"},{"label": "100"},{"label": "Add a limit for the number of partitions in one block"}]}]}/>

단일 삽입 블록의 최대 파티션 수를 제한하며, 블록에 너무 많은 파티션이 포함되어 있을 경우 예외가 발생합니다.

- 양의 정수.
- `0` — 파티션 수 무제한.

**세부 사항**

데이터를 삽입할 때 ClickHouse는 삽입된 블록에서 파티션 수를 계산합니다. 파티션 수가 `max_partitions_per_insert_block`를 초과하면 ClickHouse는 경고를 기록하거나 `throw_on_max_partitions_per_insert_block`에 따라 예외를 던집니다. 예외는 다음과 같은 내용을 포함합니다:

> "단일 INSERT 블록에 대한 파티션 수가 너무 많습니다(`partitions_count` 개의 파티션, 제한은 " + toString(max_partitions) + ").
  이 제한은 'max_partitions_per_insert_block' 설정에 의해 제어됩니다.
  너무 많은 파티션은 일반적인 오해입니다. 이는 심각한 부정적인 성능 영향을 초래하며, 서버 시작 지연, 느린 INSERT 쿼리 및 느린 SELECT 쿼리를 포함합니다. 테이블에 대한 권장 총 파티션 수는 1000..10000 이하입니다. SELECT 쿼리 속도를 개선할 의도로 파티셔닝이 고안된 것이 아니며, (ORDER BY 키로 충분히 빠른 범위 쿼리를 수행할 수 있습니다). 파티션은 데이터 조작을 위한 것입니다(파티션 제거 등)."

:::note
이 설정은 위에서 언급한 것처럼 많은 파티션을 사용하는 것이 일반적인 오해로 발생하는 안전 기준입니다.
:::
## max_partitions_to_read {#max_partitions_to_read} 



<SettingsInfoBlock type="Int64" default_value="-1" />

단일 쿼리에서 액세스할 수 있는 최대 파티션 수를 제한합니다.

테이블 생성 시 지정된 설정 값은 쿼리 수준에서 설정을 통해 재정의할 수 있습니다.

가능한 값:

- 양의 정수
- `-1` - 무제한 (기본값)

:::note
테이블 설정에서 MergeTree 설정 [`max_partitions_to_read`](/operations/settings/settings#max_partitions_to_read)를 지정할 수도 있습니다.
:::
## max_parts_to_move {#max_parts_to_move} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1000"},{"label": "New setting"}]}]}/>

한 쿼리에서 이동할 수 있는 파트 수를 제한합니다. 0은 무제한을 의미합니다.
## max_projection_rows_to_use_projection_index {#max_projection_rows_to_use_projection_index} 



<SettingsInfoBlock type="UInt64" default_value="1000000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.11"},{"label": "1000000"},{"label": "New setting"}]}]}/>

프로젝션 인덱스에서 읽을 행 수가 이 임계값 이하인 경우 ClickHouse는 쿼리 실행 중에 프로젝션 인덱스를 적용하려고 합니다.
## max_query_size {#max_query_size} 



<SettingsInfoBlock type="UInt64" default_value="262144" />

SQL 파서에 의해 파싱되는 쿼리 문자열의 최대 바이트 수입니다.
INSERT 쿼리의 VALUES 절에 있는 데이터는 별도의 스트림 파서에 의해 처리되며(메모리 소비량 O(1)) 이 제한의 영향을 받지 않습니다.

:::note
`max_query_size`는 SQL 쿼리 내에서 설정할 수 없습니다(예: `SELECT now() SETTINGS max_query_size=10000`). ClickHouse는 쿼리를 파싱하기 위한 버퍼를 할당해야 하며, 이 버퍼 크기는 쿼리 실행 전에 구성해야 하는 `max_query_size` 설정에 의해 결정됩니다.
:::
## max_read_buffer_size {#max_read_buffer_size} 



<SettingsInfoBlock type="NonZeroUInt64" default_value="1048576" />

파일 시스템에서 읽기 위한 버퍼의 최대 크기입니다.
## max_read_buffer_size_local_fs {#max_read_buffer_size_local_fs} 



<SettingsInfoBlock type="UInt64" default_value="131072" />

로컬 파일 시스템에서 읽기 위한 버퍼의 최대 크기입니다. 0으로 설정할 경우 max_read_buffer_size가 사용됩니다.
## max_read_buffer_size_remote_fs {#max_read_buffer_size_remote_fs} 



<SettingsInfoBlock type="UInt64" default_value="0" />

원격 파일 시스템에서 읽기 위한 버퍼의 최대 크기입니다. 0으로 설정할 경우 max_read_buffer_size가 사용됩니다.
## max_recursive_cte_evaluation_depth {#max_recursive_cte_evaluation_depth} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "1000"},{"label": "Maximum limit on recursive CTE evaluation depth"}]}]}/>

재귀적 CTE 평가 깊이에 대한 최대 한계입니다.
## max_remote_read_network_bandwidth {#max_remote_read_network_bandwidth} 



<SettingsInfoBlock type="UInt64" default_value="0" />

읽기 위한 초당 네트워크 데이터 교환 속도의 최대 속도(바이트 수).
## max_remote_write_network_bandwidth {#max_remote_write_network_bandwidth} 



<SettingsInfoBlock type="UInt64" default_value="0" />

쓰기 위한 초당 네트워크 데이터 교환 속도의 최대 속도(바이트 수).
## max_replica_delay_for_distributed_queries {#max_replica_delay_for_distributed_queries} 



<SettingsInfoBlock type="UInt64" default_value="300" />

분산 쿼리를 위한 지연 복제본을 비활성화합니다. [복제](../../engines/table-engines/mergetree-family/replication.md)를 참조하십시오.

초 단위의 시간을 설정합니다. 복제본의 지연이 설정된 값보다 크거나 같으면 이 복제본은 사용되지 않습니다.

가능한 값:

- 양의 정수.
- 0 — 복제본 지연이 확인되지 않음.

지연이 0이 아닌 복제본의 사용을 방지하려면 이 매개변수를 1로 설정하십시오.

복제된 테이블을 가리키는 분산 테이블에서 `SELECT`를 수행할 때 사용됩니다.
## max_result_bytes {#max_result_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

결과 크기를 바이트 단위(압축되지 않음)로 제한합니다. 임계값이 충족된 후 데이터 블록을 처리한 후 쿼리가 중지되지만 마지막 결과 블록은 잘리지 않으므로 결과 크기가 임계값보다 클 수 있습니다.

**주의 사항**

결과 메모리에서의 크기가 이 임계값에 영향을 미칩니다.
결과 크기가 작더라도 메모리 내에서 더 큰 데이터 구조를 참조할 수 있으며,
LowCardinality 열의 딕셔너리 및 AggregateFunction 열의 Arena를 나타낼 수 있으므로,
작은 결과 크기임에도 불구하고 임계값이 초과될 수 있습니다.

:::warning
이 설정은 매우 저수준이며 주의해서 사용해야 합니다.
:::
## max_result_rows {#max_result_rows} 



<SettingsInfoBlock type="UInt64" default_value="0" />

클라우드 기본값: `0`.

결과의 행 수를 제한합니다. 서브쿼리에 대해서도 확인되며, 분산 쿼리의 일부를 실행할 때 원격 서버에서 확인됩니다.
값이 `0`일 때는 제한이 적용되지 않습니다.

임계값이 충족된 후 데이터 블록을 처리한 후 쿼리가 중지되지만,
마지막 결과 블록은 잘리지 않으므로 결과 크기가 임계값보다 클 수 있습니다.
## max_rows_in_distinct {#max_rows_in_distinct} 



<SettingsInfoBlock type="UInt64" default_value="0" />

DISTINCT를 사용할 때 최대 다른 행 수입니다.
## max_rows_in_join {#max_rows_in_join} 



<SettingsInfoBlock type="UInt64" default_value="0" />

테이블 조인 시 사용하는 해시 테이블에서의 최대 행 수를 제한합니다.

이 설정은 [SELECT ... JOIN](/sql-reference/statements/select/join) 작업과
[Join](/engines/table-engines/special/join) 테이블 엔진에 적용됩니다.

쿼리에 여러 조인이 포함되어 있는 경우, ClickHouse는 각 중간 결과 대해 이 설정을 확인합니다.

ClickHouse는 제한에 도달했을 때 다른 작업을 진행할 수 있습니다. [`join_overflow_mode`](/operations/settings/settings#join_overflow_mode) 설정을 사용하여 작업을 선택하십시오.

가능한 값:

- 양의 정수.
- `0` — 무제한 행 수.
## max_rows_in_set {#max_rows_in_set} 



<SettingsInfoBlock type="UInt64" default_value="0" />

하위 쿼리에서 생성된 IN 절의 데이터 집합에 대한 최대 행 수입니다.
## max_rows_in_set_to_optimize_join {#max_rows_in_set_to_optimize_join} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "Disable join optimization as it prevents from read in order optimization"}]}]}/>

조인된 테이블의 각 행 집합을 사용하여 조인 전에 필터링할 집합의 최대 크기입니다.

가능한 값:

- 0 — 비활성화.
- 양의 정수.

## max_rows_to_group_by {#max_rows_to_group_by} 



<SettingsInfoBlock type="UInt64" default_value="0" />

집계에서 수신된 고유 키의 최대 수. 이 설정은 집계할 때 메모리 사용량을 제한할 수 있도록 합니다.

GROUP BY 동안 집계가 지정된 수의 행(고유 GROUP BY 키)보다 많아지는 경우 동작은 기본값이 `throw`인 'group_by_overflow_mode'에 의해 결정되지만 근사 GROUP BY 모드로 전환할 수도 있습니다.
## max_rows_to_read {#max_rows_to_read} 



<SettingsInfoBlock type="UInt64" default_value="0" />

쿼리를 실행할 때 테이블에서 읽을 수 있는 최대 행 수.
제한은 처리되는 각 데이터 청크에 대해 확인되며, 가장 깊은 테이블 표현에만 적용되고 원격 서버에서 읽을 때는 원격 서버에서만 확인됩니다.
## max_rows_to_read_leaf {#max_rows_to_read_leaf} 



<SettingsInfoBlock type="UInt64" default_value="0" />

분산 쿼리를 실행할 때 리프 노드의 로컬 테이블에서 읽을 수 있는 최대 행 수. 분산 쿼리는 각 샤드(리프)에 여러 서브 쿼리를 발행할 수 있지만, 이 제한은 리프 노드에서 읽기 단계에서만 확인되고 루트 노드에서 결과 병합 단계에서는 무시됩니다.

예를 들어, 클러스터가 2개의 샤드로 구성되어 있고 각 샤드에 100행이 포함된 테이블이 있다고 가정합니다. `max_rows_to_read=150` 설정을 가진 분산 쿼리는 두 테이블의 모든 데이터를 읽도록 되어 있으므로 실패합니다. 총 200행이 있기 때문입니다. `max_rows_to_read_leaf=150`을 가진 쿼리는 성공할 것이며, 리프 노드는 최대 100행을 읽습니다.

제한은 처리되는 각 데이터 청크에 대해 확인됩니다.

:::note
이 설정은 `prefer_localhost_replica=1`과 함께 불안정합니다.
:::
## max_rows_to_sort {#max_rows_to_sort} 



<SettingsInfoBlock type="UInt64" default_value="0" />

정렬 전 최대 행 수. 이 설정은 정렬 시 메모리 사용량을 제한할 수 있도록 합니다.
지정된 수의 레코드가 ORDER BY 연산을 위해 처리되어야 하는 경우 동작은 기본적으로 `throw`로 설정된 `sort_overflow_mode`에 따라 결정됩니다.
## max_rows_to_transfer {#max_rows_to_transfer} 



<SettingsInfoBlock type="UInt64" default_value="0" />

GLOBAL IN/JOIN 섹션이 실행될 때 원격 서버로 전달되거나 임시 테이블에 저장될 수 있는 최대 크기(행 수).
## max_sessions_for_user {#max_sessions_for_user} 



<SettingsInfoBlock type="UInt64" default_value="0" />

인증된 사용자당 ClickHouse 서버에 대한 동시에 활성화된 최대 세션 수.

예시:

```xml
<profiles>
    <single_session_profile>
        <max_sessions_for_user>1</max_sessions_for_user>
    </single_session_profile>
    <two_sessions_profile>
        <max_sessions_for_user>2</max_sessions_for_user>
    </two_sessions_profile>
    <unlimited_sessions_profile>
        <max_sessions_for_user>0</max_sessions_for_user>
    </unlimited_sessions_profile>
</profiles>
<users>
    <!-- User Alice can connect to a ClickHouse server no more than once at a time. -->
    <Alice>
        <profile>single_session_user</profile>
    </Alice>
    <!-- User Bob can use 2 simultaneous sessions. -->
    <Bob>
        <profile>two_sessions_profile</profile>
    </Bob>
    <!-- User Charles can use arbitrarily many of simultaneous sessions. -->
    <Charles>
        <profile>unlimited_sessions_profile</profile>
    </Charles>
</users>
```

가능한 값들:
- 양의 정수
- `0` - 무제한 동시 세션 수 (기본값)
## max_size_to_preallocate_for_aggregation {#max_size_to_preallocate_for_aggregation} 



<SettingsInfoBlock type="UInt64" default_value="1000000000000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "1000000000000"},{"label": "Enable optimisation for bigger tables."}]}, {"id": "row-2","items": [{"label": "22.12"},{"label": "100000000"},{"label": "This optimizes performance"}]}]}/>

집계 전에 모든 해시 테이블에서 미리 할당할 수 있는 요소 수
## max_size_to_preallocate_for_joins {#max_size_to_preallocate_for_joins} 



<SettingsInfoBlock type="UInt64" default_value="1000000000000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "100000000"},{"label": "New setting."}]}, {"id": "row-2","items": [{"label": "24.12"},{"label": "1000000000000"},{"label": "Enable optimisation for bigger tables."}]}]}/>

조인 전 모든 해시 테이블에서 미리 할당할 수 있는 요소 수
## max_streams_for_merge_tree_reading {#max_streams_for_merge_tree_reading} 



<SettingsInfoBlock type="UInt64" default_value="0" />

0이 아닐 경우, MergeTree 테이블의 읽기 스트림 수를 제한합니다.
## max_streams_multiplier_for_merge_tables {#max_streams_multiplier_for_merge_tables} 



<SettingsInfoBlock type="Float" default_value="5" />

Merge 테이블에서 읽을 때 더 많은 스트림을 요청합니다. 스트림은 Merge 테이블이 사용할 테이블 간에 분산됩니다. 이렇게 하면 스레드 간 작업을 더 균등하게 분배할 수 있으며 특히 병합된 테이블의 크기가 다를 때 유용합니다.
## max_streams_to_max_threads_ratio {#max_streams_to_max_threads_ratio} 



<SettingsInfoBlock type="Float" default_value="1" />

작업을 스레드 간에 더 균등하게 분배할 수 있도록 스레드 수보다 더 많은 소스를 사용할 수 있게 해줍니다. 이는 잠정적인 해결책으로 가정되며, 미래에는 소스 수와 스레드 수가 일치하고 각 소스가 동적으로 사용 가능한 작업을 선택할 수 있게 될 것입니다.
## max_subquery_depth {#max_subquery_depth} 



<SettingsInfoBlock type="UInt64" default_value="100" />

쿼리에 지정된 수의 중첩 서브쿼리가 초과되는 경우 예외가 발생합니다.

:::tip
이는 클러스터의 사용자가 지나치게 복잡한 쿼리를 작성하지 못하도록 방지하기 위한 건강 검진을 허용합니다.
:::
## max_table_size_to_drop {#max_table_size_to_drop} 



<SettingsInfoBlock type="UInt64" default_value="50000000000" />

쿼리 시간에 테이블 삭제에 대한 제한. 값 `0`은 모든 테이블을 제한 없이 삭제할 수 있음을 의미합니다.

클라우드 기본값: 1 TB.

:::note
이 쿼리 설정은 서버 설정에서 동일한 설정을 덮어씁니다. 자세한 내용은 [max_table_size_to_drop](/operations/server-configuration-parameters/settings#max_table_size_to_drop)을 참조하십시오.
:::
## max_temporary_columns {#max_temporary_columns} 



<SettingsInfoBlock type="UInt64" default_value="0" />

쿼리를 실행할 때 RAM에 동시에 유지해야 하는 임시 컬럼의 최대 수, 상수 컬럼 포함. 쿼리의 중간 계산 결과로 메모리에 지정된 수의 임시 컬럼이 생성되면 예외가 발생합니다.

:::tip
이 설정은 지나치게 복잡한 쿼리를 방지하는 데 유용합니다.
:::

`0`값은 무제한을 의미합니다.
## max_temporary_data_on_disk_size_for_query {#max_temporary_data_on_disk_size_for_query} 



<SettingsInfoBlock type="UInt64" default_value="0" />

동시에 실행되는 모든 쿼리에 대해 디스크의 임시 파일이 소비하는 최대 데이터 양(바이트).

가능한 값:

- 양의 정수.
- `0` — 무제한 (기본값)
## max_temporary_data_on_disk_size_for_user {#max_temporary_data_on_disk_size_for_user} 



<SettingsInfoBlock type="UInt64" default_value="0" />

동시에 실행되는 모든 사용자 쿼리에 대한 디스크의 임시 파일이 소비하는 최대 데이터 양(바이트).

가능한 값:

- 양의 정수.
- `0` — 무제한 (기본값)
## max_temporary_non_const_columns {#max_temporary_non_const_columns} 



<SettingsInfoBlock type="UInt64" default_value="0" />

`max_temporary_columns`와 마찬가지로 쿼리를 실행할 때 RAM에 동시에 유지해야 하는 임시 컬럼의 최대 수로, 상수 컬럼 수는 포함하지 않습니다.

:::note
상수 컬럼은 쿼리를 실행할 때 상당히 자주 형성되지만, 대략 0에 가까운 컴퓨팅 리소스가 필요합니다.
:::
## max_threads {#max_threads} 



<SettingsInfoBlock type="MaxThreads" default_value="'auto(N)'" />

원격 서버에서 데이터를 검색하는 데 사용하는 스레드를 제외한 쿼리 처리 스레드의 최대 수(‘max_distributed_connections’ 매개변수 참조).

이 매개변수는 쿼리 처리 파이프라인의 동일한 단계에서 병렬로 실행되는 스레드에 적용됩니다.
예를 들어, 테이블에서 읽을 때 함수와 함께 표현식을 평가하고, WHERE로 필터링하고, GROUP BY를 위해 사전 집계하는 것이 가능하다면 'max_threads' 수 이상의 스레드를 사용하게 됩니다.

LIMIT 때문에 쿼리가 빨리 완료되는 경우 'max_threads'를 더 낮게 설정할 수 있습니다. 예를 들어, 필요한 수의 항목이 모든 블록에 위치하고 max_threads = 8인 경우, 8 블록이 검색됩니다. 비록 하나만 읽으면 충분했을 것입니다.

`max_threads` 값이 작을수록 메모리 사용량이 줄어듭니다.

클라우드 기본값: `auto(3)`
## max_threads_for_indexes {#max_threads_for_indexes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

인덱스를 처리하는 최대 스레드 수.
## max_untracked_memory {#max_untracked_memory} 



<SettingsInfoBlock type="UInt64" default_value="4194304" />

작은 할당 및 해제는 스레드 지역 변수에 그룹화되며, 지정된 값보다 커질 때만 추적되거나 프로파일링됩니다. 값이 'memory_profiler_step'보다 높으면 효과적으로 'memory_profiler_step'으로 낮아집니다.
## memory_overcommit_ratio_denominator {#memory_overcommit_ratio_denominator} 



<SettingsInfoBlock type="UInt64" default_value="1073741824" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.5"},{"label": "1073741824"},{"label": "Enable memory overcommit feature by default"}]}]}/>

전역 수준에서 하드 한계를 초과했을 때 소프트 메모리 한계를 나타냅니다. 이 값은 쿼리에 대한 오버 커밋 비율을 계산하는 데 사용됩니다. 0은 쿼리를 건너뛰는 것을 의미합니다. [메모리 오버 커밋](/memory-overcommit.md)에 대해 자세히 알아보십시오.
## memory_overcommit_ratio_denominator_for_user {#memory_overcommit_ratio_denominator_for_user} 



<SettingsInfoBlock type="UInt64" default_value="1073741824" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.5"},{"label": "1073741824"},{"label": "Enable memory overcommit feature by default"}]}]}/>

사용자 수준에서 하드 한계를 초과했을 때 소프트 메모리 한계를 나타냅니다. 이 값은 쿼리에 대한 오버 커밋 비율을 계산하는 데 사용됩니다. 0은 쿼리를 건너뛰는 것을 의미합니다. [메모리 오버 커밋](/memory-overcommit.md)에 대해 자세히 알아보십시오.
## memory_profiler_sample_max_allocation_size {#memory_profiler_sample_max_allocation_size} 



<SettingsInfoBlock type="UInt64" default_value="0" />

지정된 값 이하의 크기에서 무작위 할당을 수집합니다. 확률은 `memory_profiler_sample_probability`와 같습니다. 0은 비활성화됩니다. 이 임계값이 예상대로 작동하도록 하려면 'max_untracked_memory'를 0으로 설정해야 할 수도 있습니다.
## memory_profiler_sample_min_allocation_size {#memory_profiler_sample_min_allocation_size} 



<SettingsInfoBlock type="UInt64" default_value="0" />

지정된 값 이상의 크기에서 무작위 할당을 수집합니다. 확률은 `memory_profiler_sample_probability`와 같습니다. 0은 비활성화됩니다. 이 임계값이 예상대로 작동하도록 하려면 'max_untracked_memory'를 0으로 설정해야 할 수도 있습니다.
## memory_profiler_sample_probability {#memory_profiler_sample_probability} 



<SettingsInfoBlock type="Float" default_value="0" />

무작위 할당 및 해제를 수집하고 'MemorySample' trace_type으로 system.trace_log에 기록합니다. 이 확률은 할당 크기에 관계없이 모든 할당/해제에 대해 적용됩니다(크기는 `memory_profiler_sample_min_allocation_size` 및 `memory_profiler_sample_max_allocation_size`로 변경할 수 있음). 추적되지 않은 메모리 양이 'max_untracked_memory'를 초과할 때만 샘플링이 발생합니다. 추가 세부 샘플링을 위해 'max_untracked_memory'를 0으로 설정하는 것이 좋습니다.
## memory_profiler_step {#memory_profiler_step} 



<SettingsInfoBlock type="UInt64" default_value="4194304" />

메모리 프로파일러의 단계를 설정합니다. 쿼리 메모리 사용량이 바이트 수에서 다음 단계보다 커지면 메모리 프로파일러는 할당 스택 트레이스를 수집하고 이를 [trace_log](/operations/system-tables/trace_log)에 기록합니다.

가능한 값:

- 양의 정수 바이트 수입니다.

- 메모리 프로파일러를 끄기 위해 0 사용.
## memory_tracker_fault_probability {#memory_tracker_fault_probability} 



<SettingsInfoBlock type="Float" default_value="0" />

`예외 안전성` 테스트를 위해 지정된 확률로 메모리를 할당할 때마다 예외를 발생시킵니다.
## memory_usage_overcommit_max_wait_microseconds {#memory_usage_overcommit_max_wait_microseconds} 



<SettingsInfoBlock type="UInt64" default_value="5000000" />

사용자 수준에서 메모리 오버 커밋의 경우 스레드가 메모리가 해제될 때까지 최대 대기 시간(마이크로초).
타임아웃에 도달하고 메모리가 해제되지 않으면 예외가 발생합니다. [메모리 오버 커밋](/memory-overcommit.md)에 대해 자세히 알아보십시오.
## merge_table_max_tables_to_look_for_schema_inference {#merge_table_max_tables_to_look_for_schema_inference} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1000"},{"label": "A new setting"}]}]}/>

명시적인 스키마 없이 `Merge` 테이블을 생성하거나 `merge` 테이블 함수 사용 시, 지정된 수의 일치하는 테이블의 집합으로 스키마를 유추합니다.
테이블 수가 더 많으면 스키마는 첫 번째 지정된 수의 테이블에서 유추됩니다.
## merge_tree_coarse_index_granularity {#merge_tree_coarse_index_granularity} 



<SettingsInfoBlock type="UInt64" default_value="8" />

데이터를 검색할 때 ClickHouse는 인덱스 파일의 데이터 마크를 검사합니다. ClickHouse가 필요한 키가 어느 범위에 있는지 찾으면 이 범위를 `merge_tree_coarse_index_granularity` 하위 범위로 나누고 그 안에서 필요한 키를 재귀적으로 검색합니다.

가능한 값:

- 모든 양의 짝수 정수.
## merge_tree_compact_parts_min_granules_to_multibuffer_read {#merge_tree_compact_parts_min_granules_to_multibuffer_read} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="16" />

ClickHouse Cloud에서만 효과가 있습니다. MergeTree 테이블의 압축된 파트의 스트라이프에서 멀티버퍼 리더를 사용하여 병렬 읽기 및 미리 가져오기를 지원하는 그라뉼의 수입니다. 원격 fs에서 읽을 때 멀티버퍼 리더를 사용할 경우 읽기 요청의 수가 증가합니다.
## merge_tree_determine_task_size_by_prewhere_columns {#merge_tree_determine_task_size_by_prewhere_columns} 



<SettingsInfoBlock type="Bool" default_value="1" />

읽기 작업 크기를 결정할 때 오직 prewhere 열의 크기만 사용할지 여부를 나타냅니다.
## merge_tree_max_bytes_to_use_cache {#merge_tree_max_bytes_to_use_cache} 



<SettingsInfoBlock type="UInt64" default_value="2013265920" />

ClickHouse가 한 쿼리에서 `merge_tree_max_bytes_to_use_cache` 바이트보다 많은 데이터를 읽어야 하는 경우 압축 해제된 블록의 캐시를 사용하지 않습니다.

압축 해제된 블록의 캐시는 쿼리를 위해 추출된 데이터를 저장합니다. ClickHouse는 이 캐시를 사용하여 반복적인 작은 쿼리에 대한 응답 속도를 증가시킵니다. 이 설정은 많은 양의 데이터를 읽는 쿼리로 인한 캐시의 소모를 방지합니다. 서버 설정인 [uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size)는 압축 해제된 블록의 캐시 크기를 정의합니다.

가능한 값:

- 모든 양의 정수.
## merge_tree_max_rows_to_use_cache {#merge_tree_max_rows_to_use_cache} 



<SettingsInfoBlock type="UInt64" default_value="1048576" />

ClickHouse가 한 쿼리에서 `merge_tree_max_rows_to_use_cache` 행보다 많은 데이터를 읽어야 하는 경우 압축 해제된 블록의 캐시를 사용하지 않습니다.

압축 해제된 블록의 캐시는 쿼리를 위해 추출된 데이터를 저장합니다. ClickHouse는 이 캐시를 사용하여 반복적인 작은 쿼리에 대한 응답 속도를 증가시킵니다. 이 설정은 많은 양의 데이터를 읽는 쿼리로 인한 캐시의 소모를 방지합니다. 서버 설정인 [uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size)는 압축 해제된 블록의 캐시 크기를 정의합니다.

가능한 값:

- 모든 양의 정수.
## merge_tree_min_bytes_for_concurrent_read {#merge_tree_min_bytes_for_concurrent_read} 



<SettingsInfoBlock type="UInt64" default_value="251658240" />

[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 엔진 테이블의 한 파일에서 읽어야 하는 바이트 수가 `merge_tree_min_bytes_for_concurrent_read`를 초과할 경우, ClickHouse는 여러 스레드에서 동시 읽기를 시도합니다.

가능한 값:

- 양의 정수.
## merge_tree_min_bytes_for_concurrent_read_for_remote_filesystem {#merge_tree_min_bytes_for_concurrent_read_for_remote_filesystem} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "Setting is deprecated"}]}]}/>

원격 파일 시스템에서 읽을 때 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 엔진이 읽기를 병렬화할 수 있는 최소 바이트 수입니다. 이 설정을 사용하는 것은 권장되지 않습니다.

가능한 값:

- 양의 정수.
## merge_tree_min_bytes_for_seek {#merge_tree_min_bytes_for_seek} 



<SettingsInfoBlock type="UInt64" default_value="0" />

한 파일에서 읽을 두 데이터 블록 사이의 거리가 `merge_tree_min_bytes_for_seek` 바이트보다 짧으면 ClickHouse는 두 블록을 포함하는 파일의 범위를 순차적으로 읽습니다. 별도의 추가 탐색을 피하게 됩니다.

가능한 값:

- 모든 양의 정수.
## merge_tree_min_bytes_per_task_for_remote_reading {#merge_tree_min_bytes_per_task_for_remote_reading} 



<SettingsInfoBlock type="UInt64" default_value="2097152" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "2097152"},{"label": "Value is unified with `filesystem_prefetch_min_bytes_for_single_read_task`"}]}]}/>

원격 읽기를 위한 작업당 최소 바이트 수입니다.
## merge_tree_min_read_task_size {#merge_tree_min_read_task_size} 



<SettingsInfoBlock type="NonZeroUInt64" default_value="8" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "8"},{"label": "New setting"}]}]}/>

작업 크기에 대한 강한 하한(그레누얼 수가 낮고 사용 가능한 스레드 수가 높아도 작은 작업을 할당하지 않습니다).
## merge_tree_min_rows_for_concurrent_read {#merge_tree_min_rows_for_concurrent_read} 



<SettingsInfoBlock type="UInt64" default_value="163840" />

[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 테이블의 한 파일에서 읽어야 하는 행 수가 `merge_tree_min_rows_for_concurrent_read`를 초과하는 경우 ClickHouse는 여러 스레드에서 이 파일에서 동시 읽기를 시도합니다.

가능한 값:

- 양의 정수.
## merge_tree_min_rows_for_concurrent_read_for_remote_filesystem {#merge_tree_min_rows_for_concurrent_read_for_remote_filesystem} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "Setting is deprecated"}]}]}/>

원격 파일 시스템에서 읽을 때 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 엔진이 읽기를 병렬화할 수 있는 최소 행 수입니다. 이 설정을 사용하는 것은 권장되지 않습니다.

가능한 값:

- 양의 정수.
## merge_tree_min_rows_for_seek {#merge_tree_min_rows_for_seek} 



<SettingsInfoBlock type="UInt64" default_value="0" />

한 파일에서 읽을 두 데이터 블록 사이의 거리가 `merge_tree_min_rows_for_seek` 행보다 짧으면 ClickHouse는 파일을 탐색하지 않고 데이터를 순차적으로 읽습니다.

가능한 값:

- 모든 양의 정수.
## merge_tree_read_split_ranges_into_intersecting_and_non_intersecting_injection_probability {#merge_tree_read_split_ranges_into_intersecting_and_non_intersecting_injection_probability} 



<SettingsInfoBlock type="Float" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "For testing of `PartsSplitter` - split read ranges into intersecting and non intersecting every time you read from MergeTree with the specified probability."}]}]}/>

`PartsSplitter` 테스트용 - MergeTree에서 읽을 때 지정된 확률로 읽기 범위를 교차하는 것과 교차하지 않는 것으로 나눔.
## merge_tree_storage_snapshot_sleep_ms {#merge_tree_storage_snapshot_sleep_ms} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.6"},{"label": "0"},{"label": "A new setting to debug storage snapshot consistency in query"}]}]}/>

MergeTree 테이블에 대한 스토리지 스냅샷을 생성할 때 인위적인 지연(밀리초)을 주입합니다. 오직 테스트 및 디버깅 목적으로 사용됩니다.

가능한 값:
- 0 - 지연 없음 (기본값)
- N - 밀리초 단위의 지연
## merge_tree_use_const_size_tasks_for_remote_reading {#merge_tree_use_const_size_tasks_for_remote_reading} 



<SettingsInfoBlock type="Bool" default_value="1" />

원격 테이블에서 읽을 때 일정한 크기의 작업을 사용할지 여부.
## merge_tree_use_deserialization_prefixes_cache {#merge_tree_use_deserialization_prefixes_cache} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "A new setting to control the usage of deserialization prefixes cache in MergeTree"}]}]}/>

MergeTree에서 원격 디스크에서 읽을 때 파일 접두사에서 컬럼 메타데이터의 캐싱을 활성화합니다.
## merge_tree_use_prefixes_deserialization_thread_pool {#merge_tree_use_prefixes_deserialization_thread_pool} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "A new setting controlling the usage of the thread pool for parallel prefixes deserialization in MergeTree"}]}]}/>

MergeTree의 Wide 파트에서 병렬 접두사 읽기를 위해 스레드 풀의 사용을 활성화합니다. 이 스레드 풀의 크기는 서버 설정 `max_prefixes_deserialization_thread_pool_size`에 의해 제어됩니다.
## merge_tree_use_v1_object_and_dynamic_serialization {#merge_tree_use_v1_object_and_dynamic_serialization} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "Add new serialization V2 version for JSON and Dynamic types"}]}]}/>

활성화되면 MergeTree에서 JSON 및 Dynamic 타입의 V1 직렬화 버전이 V2 대신 사용됩니다. 이 설정을 변경하면 서버를 재시작해야 적용됩니다.
## metrics_perf_events_enabled {#metrics_perf_events_enabled} 



<SettingsInfoBlock type="Bool" default_value="0" />

활성화되면 쿼리 실행 중 몇 가지 성능 이벤트가 측정됩니다.
## metrics_perf_events_list {#metrics_perf_events_list} 

쿼리 실행 중 측정될 성능 메트릭의 쉼표로 구분된 목록입니다. 비어 있으면 모든 이벤트를 의미합니다. 사용 가능한 이벤트에 대한 정보는 소스의 PerfEventInfo를 참조하십시오.
## min_bytes_to_use_direct_io {#min_bytes_to_use_direct_io} 



<SettingsInfoBlock type="UInt64" default_value="0" />

저장 디스크에 대한 직접 I/O 접근을 사용하는 데 필요한 최소 데이터 볼륨입니다.

ClickHouse는 테이블에서 데이터를 읽을 때 이 설정을 사용합니다. 읽어야 할 모든 데이터의 총 저장 용량이 `min_bytes_to_use_direct_io` 바이트를 초과하면 ClickHouse는 `O_DIRECT` 옵션으로 저장 디스크에서 데이터를 읽습니다.

가능한 값:

- 0 — 직접 I/O 비활성화.
- 양의 정수.
## min_bytes_to_use_mmap_io {#min_bytes_to_use_mmap_io} 



<SettingsInfoBlock type="UInt64" default_value="0" />

실험적인 설정입니다. 커널에서 사용자 공간으로 데이터를 복사하지 않고 큰 파일을 읽기 위해 필요한 최소 메모리 양을 설정합니다. 권장 임계값은 약 64MB입니다. [mmap/munmap](https://en.wikipedia.org/wiki/Mmap)는 느리기 때문에 큰 파일에만 의미가 있습니다. 이는 페이지 캐시에 데이터가 존재하는 경우에만 도움이 됩니다.

가능한 값:

- 양의 정수.
- 0 — 대형 파일은 커널에서 사용자 공간으로 데이터 복사만으로 읽습니다.
## min_chunk_bytes_for_parallel_parsing {#min_chunk_bytes_for_parallel_parsing} 



<SettingsInfoBlock type="NonZeroUInt64" default_value="10485760" />

- 타입: unsigned int
- 기본값: 1 MiB

각 스레드가 병렬로 분석할 최소 청크 크기(바이트)입니다.
## min_compress_block_size {#min_compress_block_size} 



<SettingsInfoBlock type="UInt64" default_value="65536" />

[MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 테이블에 대한 설정입니다. 쿼리 처리 지연을 줄이기 위해 블록은 다음 마크를 쓸 때 그 크기가 `min_compress_block_size` 이상일 경우 압축됩니다. 기본값은 65,536입니다.

압축되지 않은 데이터의 실제 크기가 `max_compress_block_size`보다 작을 경우 블록의 크기는 이 값과 하나의 마크에 대한 데이터 양보다 작지 않도록 합니다.

예를 들어, `index_granularity`가 테이블 생성 시 8192로 설정되었다고 가정합니다.

UInt32 타입의 컬럼(값당 4 바이트)을 쓸 때 8192 행을 쓰면 총 32KB의 데이터가 됩니다. min_compress_block_size = 65,536이므로 각 두 마크에 대해 압축된 블록이 형성됩니다.

문자열형 URL 컬럼(값당 평균 60 바이트)을 쓸 때 8192 행을 쓰면 평균적으로 500KB의 데이터가 약간 넘습니다. 이는 65,536보다 크므로 각 마크에 대해 압축된 블록이 형성됩니다. 이 경우 한 마크의 범위에서 디스크에서 데이터를 읽을 때 추가 데이터는 압축 해제되지 않습니다.

:::note
이 설정은 전문가 수준의 설정으로, ClickHouse를 처음 접하는 경우 변경하지 않는 것이 좋습니다.
:::
## min_count_to_compile_aggregate_expression {#min_count_to_compile_aggregate_expression} 



<SettingsInfoBlock type="UInt64" default_value="3" />

JIT 컴파일을 시작하기 위해 동일한 집계 표현식의 최소 수입니다. [compile_aggregate_expressions](#compile_aggregate_expressions) 설정이 활성화되어 있는 경우에만 작동합니다.

가능한 값:

- 양의 정수.
- 0 — 동일한 집계 표현식은 항상 JIT 컴파일됩니다.
## min_count_to_compile_expression {#min_count_to_compile_expression} 



<SettingsInfoBlock type="UInt64" default_value="3" />

컴파일하기 전에 실행된 동일한 표현식의 최소 수입니다.
## min_count_to_compile_sort_description {#min_count_to_compile_sort_description} 



<SettingsInfoBlock type="UInt64" default_value="3" />

JIT 컴파일되기 전에 동일한 정렬 설명의 수입니다.
## min_execution_speed {#min_execution_speed} 



<SettingsInfoBlock type="UInt64" default_value="0" />

초기 행/초의 최소 실행 속도. [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 시간이 만료될 때마다 각 데이터 블록에서 확인합니다. 실행 속도가 낮은 경우 예외가 발생합니다.
## min_execution_speed_bytes {#min_execution_speed_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

초기 바이트/초의 최소 실행 속도. [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 시간이 만료될 때마다 각 데이터 블록에서 확인합니다. 실행 속도가 낮은 경우 예외가 발생합니다.
## min_external_table_block_size_bytes {#min_external_table_block_size_bytes} 



<SettingsInfoBlock type="UInt64" default_value="268402944" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "268402944"},{"label": "Squash blocks passed to external table to specified size in bytes, if blocks are not big enough."}]}]}/>

외부 테이블에 전달되는 블록을 지정된 크기(바이트)로 압축합니다. 크기가 충분하지 않은 경우.
## min_external_table_block_size_rows {#min_external_table_block_size_rows} 



<SettingsInfoBlock type="UInt64" default_value="1048449" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1048449"},{"label": "Squash blocks passed to external table to specified size in rows, if blocks are not big enough"}]}]}/>

외부 테이블에 전달되는 블록을 지정된 크기(행 수)로 압축합니다. 크기가 충분하지 않은 경우.
## min_free_disk_bytes_to_perform_insert {#min_free_disk_bytes_to_perform_insert} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "Maintain some free disk space bytes from inserts while still allowing for temporary writing."}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "0"},{"label": "New setting."}]}]}/>

삽입 작업을 수행하기 위한 최소 여유 디스크 공간 바이트 수입니다.
## min_free_disk_ratio_to_perform_insert {#min_free_disk_ratio_to_perform_insert} 



<SettingsInfoBlock type="Float" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "Maintain some free disk space bytes expressed as ratio to total disk space from inserts while still allowing for temporary writing."}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "0"},{"label": "New setting."}]}]}/>

삽입 작업을 수행하기 위한 최소 여유 디스크 공간 비율입니다.
## min_free_disk_space_for_temporary_data {#min_free_disk_space_for_temporary_data} 



<SettingsInfoBlock type="UInt64" default_value="0" />

외부 정렬 및 집계에 사용되는 임시 데이터를 작성할 때 유지해야 할 최소 디스크 공간입니다.
## min_hit_rate_to_use_consecutive_keys_optimization {#min_hit_rate_to_use_consecutive_keys_optimization} 



<SettingsInfoBlock type="Float" default_value="0.5" />

집계에서 연속 키 최적화를 유지하기 위해 사용되는 캐시의 최소 적중률입니다.
## min_insert_block_size_bytes {#min_insert_block_size_bytes} 



<SettingsInfoBlock type="UInt64" default_value="268402944" />

`INSERT` 쿼리로 테이블에 삽입할 수 있는 블록에서 바이트 수의 최소값을 설정합니다. 크기가 작은 블록은 대형 블록으로 압축됩니다.

가능한 값:

- 양의 정수.
- 0 — 압축 비활성화.
## min_insert_block_size_bytes_for_materialized_views {#min_insert_block_size_bytes_for_materialized_views} 



<SettingsInfoBlock type="UInt64" default_value="0" />

`INSERT` 쿼리로 테이블에 삽입할 수 있는 블록에서 바이트 수의 최소값을 설정합니다. 크기가 작은 블록은 대형 블록으로 압축됩니다. 이 설정은 [물리화된 뷰](../../sql-reference/statements/create/view.md)에 삽입되는 블록에만 적용됩니다. 이 설정을 조정하여 물리화된 뷰로 밀어넣을 때 블록 압축을 제어하고 과도한 메모리 사용을 피할 수 있습니다.

가능한 값:

- 음이 아닌 정수.
- 0 — 압축 비활성화.

**참고**

- [min_insert_block_size_bytes](#min_insert_block_size_bytes)
## min_insert_block_size_rows {#min_insert_block_size_rows} 



<SettingsInfoBlock type="UInt64" default_value="1048449" />

`INSERT` 쿼리로 테이블에 삽입할 수 있는 블록에서 행 수의 최소값을 설정합니다. 크기가 작은 블록은 대형 블록으로 압축됩니다.

가능한 값:

- 양의 정수.
- 0 — 압축 비활성화.
## min_insert_block_size_rows_for_materialized_views {#min_insert_block_size_rows_for_materialized_views} 



<SettingsInfoBlock type="UInt64" default_value="0" />

`INSERT` 쿼리로 테이블에 삽입할 수 있는 블록에서 행 수의 최소값을 설정합니다. 크기가 작은 블록은 대형 블록으로 압축됩니다. 이 설정은 [물리화된 뷰](../../sql-reference/statements/create/view.md)에 삽입되는 블록에만 적용됩니다. 이 설정을 조정하여 물리화된 뷰로 밀어넣을 때 블록 압축을 제어하고 과도한 메모리 사용을 피할 수 있습니다.

가능한 값:

- 음이 아닌 정수.
- 0 — 압축 비활성화.

**참고**

- [min_insert_block_size_rows](#min_insert_block_size_rows)
## min_joined_block_size_bytes {#min_joined_block_size_bytes} 



<SettingsInfoBlock type="UInt64" default_value="524288" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "524288"},{"label": "New setting."}]}]}/>

JOIN 입력 및 출력 블록에 대한 최소 블록 크기(조인 알고리즘이 이를 지원하는 경우). 작은 블록은 압축됩니다. 0은 무제한을 의미합니다.
## min_joined_block_size_rows {#min_joined_block_size_rows} 



<SettingsInfoBlock type="UInt64" default_value="65409" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.7"},{"label": "65409"},{"label": "New setting."}]}]}/>

JOIN 입력 및 출력 블록에 대한 최소 블록 크기(조인 알고리즘이 이를 지원하는 경우). 작은 블록은 압축됩니다. 0은 무제한을 의미합니다.
## min_os_cpu_wait_time_ratio_to_throw {#min_os_cpu_wait_time_ratio_to_throw} 



<SettingsInfoBlock type="Float" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "Setting values were changed and backported to 25.4"}]}, {"id": "row-2","items": [{"label": "25.4"},{"label": "0"},{"label": "New setting"}]}]}/>

쿼리 거부를 고려하기 위한 OS CPU 대기(OSCPUWaitMicroseconds 메트릭)와 바쁜(OSCPUVirtualTimeMicroseconds 메트릭) 시간 간의 최소 비율입니다. 최소 및 최대 비율 간의 선형 보간이 사용되어 확률을 계산하며, 이 지점에서 확률은 0입니다.
## min_outstreams_per_resize_after_split {#min_outstreams_per_resize_after_split} 



<SettingsInfoBlock type="UInt64" default_value="24" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.6"},{"label": "24"},{"label": "New setting."}]}]}/>

파이프라인 생성 중 분할이 수행된 후 `Resize` 또는 `StrictResize` 프로세서의 출력 스트림 수의 최소값을 지정합니다. 생성된 스트림 수가 이 값을 초과하지 않으면 분할 작업이 발생하지 않습니다.
### Resize 노드란 무엇인가?
`Resize` 노드는 쿼리 파이프라인에서 데이터를 흐르는 스트림 수를 조정하는 프로세서입니다. 여러 스레드 또는 프로세서 간의 작업 부하를 균형 있게 분배하기 위해 스트림 수를 늘리거나 줄일 수 있습니다. 예를 들어, 쿼리에 더 많은 병렬성이 필요할 경우, `Resize` 노드는 단일 스트림을 여러 스트림으로 분할할 수 있습니다. 반대로, 여러 스트림을 병합하여 더 적은 수의 스트림으로 데이터를 통합할 수도 있습니다.

`Resize` 노드는 데이터가 스트림 간에 고르게 분배되도록 하여 데이터 블록의 구조를 유지합니다. 이는 리소스 활용 최적화 및 쿼리 성능 향상에 도움을 줍니다.
### 왜 Resize 노드를 분할해야 하는가?
파이프라인 실행 중, 중앙 집중식 `Resize` 노드의 ExecutingGraph::Node::status_mutex가 많은 데이터를 동시에 처리하는 환경에서 심하게 경합하게 되는 경우가 있으며, 이 때문에:
1. ExecutingGraph::updateNode에 대한 지연이 증가하고, 이는 쿼리 성능에 직접적인 영향을 미칩니다.
2. 스핀 잠금 경합(native_queued_spin_lock_slowpath)에서 많은 CPU 사이클이 낭비되어 효율성 저하가 초래됩니다.
3. CPU 활용도가 감소하여 병렬성과 처리량이 제한됩니다.
### Resize 노드의 분할 방법
1. 출력 스트림 수가 분할이 수행될 수 있는지 확인됩니다: 각 분할 프로세서의 출력 스트림은 `min_outstreams_per_resize_after_split` 한도를 충족해야 하거나 초과해야 합니다.
2. `Resize` 노드는 포트 수가 동일한 더 작은 `Resize` 노드로 나누어지며, 각각은 입력 및 출력 스트림의 하위 집합을 처리합니다.
3. 각 그룹은 독립적으로 처리되어 잠금 경합을 줄입니다.
### 임의의 입력/출력으로 Resize 노드 분할
입력/출력이 분할된 `Resize` 노드의 수로 나눌 수 없는 경우에는 일부 입력이 `NullSource`에 연결되고 일부 출력이 `NullSink`에 연결됩니다. 이는 데이터 흐름에 영향을 주지 않으면서 분할이 발생하도록 허용합니다.
### 설정 목적
`min_outstreams_per_resize_after_split` 설정은 `Resize` 노드의 분할이 의미 있게 이루어지도록 보장하며, 너무 적은 스트림을 생성하여 비효율적인 병렬 처리가 발생하지 않도록 합니다. 최소 출력 스트림 수를 강제함으로써 이 설정은 스트림 분할 및 병합과 관련된 경우에서 병렬성과 오버헤드 간의 균형을 유지하여 쿼리 실행을 최적화하는 데 도움을 줍니다.
### 설정 비활성화
`Resize` 노드의 분할을 비활성화하려면 이 설정을 0으로 설정합니다. 이렇게 하면 파이프라인 생성 중 `Resize` 노드의 분할이 방지되어 더 작은 노드로 나누어지지 않고 원래 구조를 유지하게 됩니다.
## min_table_rows_to_use_projection_index {#min_table_rows_to_use_projection_index} 



<SettingsInfoBlock type="UInt64" default_value="1000000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.11"},{"label": "1000000"},{"label": "New setting"}]}]}/>

테이블에서 읽은 예상 행 수가 이 임계값 이상인 경우 ClickHouse는 쿼리 실행 중 프로젝션 인덱스를 사용하려고 합니다.
## mongodb_throw_on_unsupported_query {#mongodb_throw_on_unsupported_query} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "1"},{"label": "New setting."}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "1"},{"label": "New setting."}]}]}/>

활성화되면 MongoDB 쿼리를 구축할 수 없는 경우 MongoDB 테이블이 오류를 반환합니다. 그렇지 않으면 ClickHouse는 전체 테이블을 읽고 이를 로컬에서 처리합니다. 이 옵션은 'allow_experimental_analyzer=0'일 때는 적용되지 않습니다.
## move_all_conditions_to_prewhere {#move_all_conditions_to_prewhere} 

<SettingsInfoBlock type="Bool" default_value="1" />

WHERE에서 PREWHERE로 모든 유효한 조건 이동
## move_primary_key_columns_to_end_of_prewhere {#move_primary_key_columns_to_end_of_prewhere} 

<SettingsInfoBlock type="Bool" default_value="1" />

기본 키 컬럼을 포함하는 PREWHERE 조건을 AND 체인의 끝으로 이동합니다. 이러한 조건은 기본 키 분석 중에 고려될 가능성이 높으므로 PREWHERE 필터링에 크게 기여하지 않을 것입니다.
## multiple_joins_try_to_keep_original_names {#multiple_joins_try_to_keep_original_names} 

<SettingsInfoBlock type="Bool" default_value="0" />

여러 조인 재작성에서 최상위 표현 목록에 별칭을 추가하지 마십시오.
## mutations_execute_nondeterministic_on_initiator {#mutations_execute_nondeterministic_on_initiator} 

<SettingsInfoBlock type="Bool" default_value="0" />

진정한 상수 비결정적 함수(예: 함수 `now()`)가 이니시에이터에서 실행되고 `UPDATE` 및 `DELETE` 쿼리에서 리터럴로 교체됩니다. 이는 비결정적 함수가 있는 변화를 실행하는 동안 데이터가 복제본에서 동기화되도록 돕습니다. 기본값: `false`.
## mutations_execute_subqueries_on_initiator {#mutations_execute_subqueries_on_initiator} 

<SettingsInfoBlock type="Bool" default_value="0" />

진정한 스칼라 서브쿼리가 이니시에이터에서 실행되고 `UPDATE` 및 `DELETE` 쿼리에서 리터럴로 교체됩니다. 기본값: `false`.
## mutations_max_literal_size_to_replace {#mutations_max_literal_size_to_replace} 

<SettingsInfoBlock type="UInt64" default_value="16384" />

`UPDATE` 및 `DELETE` 쿼리에서 리터럴로 교체할 수 있는 직렬화된 리터럴의 최대 크기(바이트). 위의 두 설정 중 하나가 활성화된 경우에만 적용됩니다. 기본값: 16384 (16 KiB).
## mutations_sync {#mutations_sync} 

<SettingsInfoBlock type="UInt64" default_value="0" />

`ALTER TABLE ... UPDATE|DELETE|MATERIALIZE INDEX|MATERIALIZE PROJECTION|MATERIALIZE COLUMN|MATERIALIZE STATISTICS` 쿼리([mutations](../../sql-reference/statements/alter/index.md/#mutations))를 동기적으로 실행할 수 있도록 허용합니다.

가능한 값:

| 값  | 설명                                                                                                                                          |
|-----|------------------------------------------------------------------------------------------------------------------------------------------------|
| `0` | 변형은 비동기적으로 실행됩니다.                                                                                                                 |
| `1` | 쿼리는 현재 서버에서 모든 변형이 완료될 때까지 대기합니다.                                                                                     |
| `2` | 쿼리는 모든 복제본(존재하는 경우)에서 모든 변형이 완료될 때까지 대기합니다.                                                                   |
| `3` | 쿼리는 활성 복제본에 대해서만 대기합니다. `SharedMergeTree`에 대해서만 지원됩니다. `ReplicatedMergeTree`의 경우 `mutations_sync = 2`와 동일하게 작동합니다. |
## mysql_datatypes_support_level {#mysql_datatypes_support_level} 

MySQL 유형이 해당 ClickHouse 유형으로 변환되는 방식을 정의합니다. 'decimal', 'datetime64', 'date2Date32' 또는 'date2String'의 조합으로 쉼표로 구분된 목록입니다.
- `decimal`: 정밀도가 허용되는 경우 `NUMERIC` 및 `DECIMAL` 유형을 `Decimal`로 변환합니다.
- `datetime64`: 정밀도가 `0`가 아닐 경우 `DATETIME` 및 `TIMESTAMP` 유형을 `DateTime` 대신 `DateTime64`로 변환합니다.
- `date2Date32`: `DATE`를 `Date` 대신 `Date32`로 변환합니다. `date2String`보다 우선합니다.
- `date2String`: `DATE`를 `Date` 대신 `String`으로 변환합니다. `datetime64`에 의해 재정의됩니다.
## mysql_map_fixed_string_to_text_in_show_columns {#mysql_map_fixed_string_to_text_in_show_columns} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "Reduce the configuration effort to connect ClickHouse with BI tools."}]}]}/>

사용하도록 설정되면 [FixedString](../../sql-reference/data-types/fixedstring.md) ClickHouse 데이터 유형이 [SHOW COLUMNS](../../sql-reference/statements/show.md/#show_columns)에서 `TEXT`로 표시됩니다.

MySQL 전송 프로토콜을 통해 연결이 이루어질 때만 효과가 있습니다.

- 0 - `BLOB` 사용.
- 1 - `TEXT` 사용.
## mysql_map_string_to_text_in_show_columns {#mysql_map_string_to_text_in_show_columns} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "Reduce the configuration effort to connect ClickHouse with BI tools."}]}]}/>

사용하도록 설정되면 [String](../../sql-reference/data-types/string.md) ClickHouse 데이터 유형이 [SHOW COLUMNS](../../sql-reference/statements/show.md/#show_columns)에서 `TEXT`로 표시됩니다.

MySQL 전송 프로토콜을 통해 연결이 이루어질 때만 효과가 있습니다.

- 0 - `BLOB` 사용.
- 1 - `TEXT` 사용.
## mysql_max_rows_to_insert {#mysql_max_rows_to_insert} 

<SettingsInfoBlock type="UInt64" default_value="65536" />

MySQL 저장 엔진의 MySQL 일괄 삽입에서 허용되는 최대 행 수
## network_compression_method {#network_compression_method} 

<SettingsInfoBlock type="String" default_value="LZ4" />

클라이언트/서버 및 서버/서버 간 통신을 압축할 코덱입니다.

가능한 값:

- `NONE` — 압축 없음.
- `LZ4` — LZ4 코덱 사용.
- `LZ4HC` — LZ4HC 코덱 사용.
- `ZSTD` — ZSTD 코덱 사용.

**참고**

- [network_zstd_compression_level](#network_zstd_compression_level)
## network_zstd_compression_level {#network_zstd_compression_level} 

<SettingsInfoBlock type="Int64" default_value="1" />

ZSTD 압축 수준을 조정합니다. [network_compression_method](#network_compression_method)가 `ZSTD`로 설정되었을 때만 사용됩니다.

가능한 값:

- 1에서 15까지의 양의 정수.
## normalize_function_names {#normalize_function_names} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.3"},{"label": "1"},{"label": "Normalize function names to their canonical names, this was needed for projection query routing"}]}]}/>

함수 이름을 표준 이름으로 정규화합니다.
## number_of_mutations_to_delay {#number_of_mutations_to_delay} 

<SettingsInfoBlock type="UInt64" default_value="0" />

변경된 테이블에 미완료 변형이 최소한 이만큼 포함된 경우, 테이블 변형 속도를 인위적으로 줄입니다. 0 - 비활성
## number_of_mutations_to_throw {#number_of_mutations_to_throw} 

<SettingsInfoBlock type="UInt64" default_value="0" />

변경된 테이블에 미완료 변형이 최소한 이만큼 포함된 경우, '변형이 너무 많음 ...' 예외를 발생시킵니다. 0 - 비활성
## odbc_bridge_connection_pool_size {#odbc_bridge_connection_pool_size} 

<SettingsInfoBlock type="UInt64" default_value="16" />

ODBC 브리지에서 각 연결 설정 문자열의 연결 풀 크기입니다.
## odbc_bridge_use_connection_pooling {#odbc_bridge_use_connection_pooling} 

<SettingsInfoBlock type="Bool" default_value="1" />

ODBC 브리지에서 연결 풀링을 사용합니다. false로 설정하면 매번 새 연결이 생성됩니다.
## offset {#offset} 

<SettingsInfoBlock type="UInt64" default_value="0" />

쿼리에서 행을 반환하기 시작하기 전에 건너뛸 행 수를 설정합니다. 이는 [OFFSET](/sql-reference/statements/select/offset) 절에 의해 설정된 오프셋을 조정하며, 이 두 값이 요약되도록 합니다.

가능한 값:

- 0 — 건너뛴 행이 없습니다.
- 양의 정수.

**예시**

입력 테이블:

```sql
CREATE TABLE test (i UInt64) ENGINE = MergeTree() ORDER BY i;
INSERT INTO test SELECT number FROM numbers(500);
```

쿼리:

```sql
SET limit = 5;
SET offset = 7;
SELECT * FROM test LIMIT 10 OFFSET 100;
```
결과:

```text
┌───i─┐
│ 107 │
│ 108 │
│ 109 │
└─────┘
```
## opentelemetry_start_trace_probability {#opentelemetry_start_trace_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

쿼리에 대해 ClickHouse가 추적을 시작할 확률을 설정합니다(부모 [추적 컨텍스트](https://www.w3.org/TR/trace-context/)가 제공되지 않은 경우).

가능한 값:

- 0 — 모든 실행 쿼리에 대한 추적이 비활성화됩니다(부모 추적 컨텍스트가 제공되지 않은 경우).
- [0..1] 범위의 양의 부동 소수점 숫자. 예를 들어, 설정 값이 `0.5`인 경우 ClickHouse는 평균적으로 쿼리의 절반에서 추적을 시작할 수 있습니다.
- 1 — 모든 실행 쿼리에 대한 추적이 활성화됩니다.
## opentelemetry_trace_cpu_scheduling {#opentelemetry_trace_cpu_scheduling} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting to trace `cpu_slot_preemption` feature."}]}]}/>

워크로드의 선점 CPU 스케줄링에 대한 OpenTelemetry 범위를 수집합니다.
## opentelemetry_trace_processors {#opentelemetry_trace_processors} 

<SettingsInfoBlock type="Bool" default_value="0" />

프로세서에 대한 OpenTelemetry 범위를 수집합니다.
## optimize_aggregation_in_order {#optimize_aggregation_in_order} 

<SettingsInfoBlock type="Bool" default_value="0" />

해당 순서로 데이터를 집계하기 위한 [SELECT](../../sql-reference/statements/select/index.md) 쿼리에서 [GROUP BY](/sql-reference/statements/select/group-by) 최적화를 활성화합니다. [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 테이블에서 해당 됩니다.

가능한 값:

- 0 — `GROUP BY` 최적화 비활성화.
- 1 — `GROUP BY` 최적화 활성화.

**참고**

- [GROUP BY 최적화](/sql-reference/statements/select/group-by#group-by-optimization-depending-on-table-sorting-key)
## optimize_aggregators_of_group_by_keys {#optimize_aggregators_of_group_by_keys} 

<SettingsInfoBlock type="Bool" default_value="1" />

SELECT 섹션의 GROUP BY 키에서 min/max/any/anyLast 집계기를 제거합니다.
## optimize_and_compare_chain {#optimize_and_compare_chain} 

<SettingsInfoBlock type="Bool" default_value="1" />

필터링 능력을 향상시키기 위해 AND 체인에서 상수 비교를 채웁니다. `<`, `<=`, `>`, `>=`, `=` 및 이들의 조합 연산자를 지원합니다. 예를 들어, `(a < b) AND (b < c) AND (c < 5)`는 `(a < b) AND (b < c) AND (c < 5) AND (b < 5) AND (a < 5)`로 변환될 것입니다.
## optimize_append_index {#optimize_append_index} 

<SettingsInfoBlock type="Bool" default_value="0" />

인덱스 조건을 추가하기 위해 [constraints](../../sql-reference/statements/create/table.md/#constraints)를 사용합니다. 기본값은 `false`입니다.

가능한 값:

- true, false
## optimize_arithmetic_operations_in_aggregate_functions {#optimize_arithmetic_operations_in_aggregate_functions} 

<SettingsInfoBlock type="Bool" default_value="1" />

산술 작업을 집계 함수 외부로 이동합니다.
## optimize_const_name_size {#optimize_const_name_size} 

<SettingsInfoBlock type="Int64" default_value="256" />

스칼라로 대체하고, 큰 상수에 대한 이름으로 해시를 사용합니다(크기는 이름 길이로 추정됨).

가능한 값:

- 양의 정수 - 이름의 최대 길이,
- 0 — 항상,
- 음의 정수 - 절대.
## optimize_count_from_files {#optimize_count_from_files} 

<SettingsInfoBlock type="Bool" default_value="1" />

다양한 입력 형식의 파일에서 행 수를 계산하는 최적화를 활성화하거나 비활성화합니다. 테이블 함수/엔진 `file`/`s3`/`url`/`hdfs`/`azureBlobStorage`에 적용됩니다.

가능한 값:

- 0 — 최적화 비활성화.
- 1 — 최적화 활성화.
## optimize_distinct_in_order {#optimize_distinct_in_order} 

<SettingsInfoBlock type="Bool" default_value="1" />

DISTINCT의 최적화를 활성화합니다. 일부 컬럼이 DISTINCT의 접두사가 됨을 보장합니다. 예를 들어, MergeTree의 정렬 키 접두사 또는 ORDER BY 절.
## optimize_distributed_group_by_sharding_key {#optimize_distributed_group_by_sharding_key} 

<SettingsInfoBlock type="Bool" default_value="1" />

비용이 많이 드는 이니시에이터 서버에서 집계를 피하도록 `GROUP BY sharding_key` 쿼리를 최적화합니다(이로 인해 이니시에이터 서버의 메모리 사용량이 감소합니다).

지원되는 쿼리의 유형(및 이들의 모든 조합):

- `SELECT DISTINCT [..., ]sharding_key[, ...] FROM dist`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...]`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] ORDER BY x`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] LIMIT 1`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] LIMIT 1 BY x`

지원되지 않는 쿼리의 유형(일부는 나중에 지원이 추가될 수 있음):

- `SELECT ... GROUP BY sharding_key[, ...] WITH TOTALS`
- `SELECT ... GROUP BY sharding_key[, ...] WITH ROLLUP`
- `SELECT ... GROUP BY sharding_key[, ...] WITH CUBE`
- `SELECT ... GROUP BY sharding_key[, ...] SETTINGS extremes=1`

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.

참고 사항:

- [distributed_group_by_no_merge](#distributed_group_by_no_merge)
- [distributed_push_down_limit](#distributed_push_down_limit)
- [optimize_skip_unused_shards](#optimize_skip_unused_shards)

:::note
현재는 `optimize_skip_unused_shards`를 요구합니다(이유는 언젠가는 기본적으로 활성화될 수 있으며, 이는 Distributed 테이블을 통해 데이터가 삽입되었을 때만 올바르게 작동하기 때문입니다. 즉, 데이터가 sharding_key에 따라 분산됩니다).
:::
## optimize_empty_string_comparisons {#optimize_empty_string_comparisons} 

<SettingsInfoBlock type="Bool" default_value="1" />

`col = ''` 또는 `'' = col`과 같은 표현을 `empty(col)`로, `col != ''` 또는 `'' != col`을 `notEmpty(col)`으로 변환합니다.
단, `col`이 String 또는 FixedString 유형일 경우에만 적용됩니다.
## optimize_extract_common_expressions {#optimize_extract_common_expressions} 

<SettingsInfoBlock type="Bool" default_value="1" />

WHERE, PREWHERE, ON, HAVING 및 QUALIFY 표현식에서 논리식을 추출할 수 있습니다. `(A AND B) OR (A AND C)`와 같은 논리 표현식은 `A AND (B OR C)`로 재작성될 수 있으며, 이를 통해:
- 간단한 필터링 표현식에서 인덱스를 활용할 수 있음
- 교차 내부 조인 최적화를 도울 수 있습니다.
## optimize_functions_to_subcolumns {#optimize_functions_to_subcolumns} 

<SettingsInfoBlock type="Bool" default_value="1" />

일부 함수를 하위 열 읽기로 변환하는 최적화를 활성화하거나 비활성화합니다. 이를 통해 읽어야 할 데이터 양을 줄일 수 있습니다.

변환할 수 있는 함수:

- [length](/sql-reference/functions/array-functions#length)는 [size0](../../sql-reference/data-types/array.md/#array-size) 하위 열을 읽기 위해.
- [empty](/sql-reference/functions/array-functions#empty)는 [size0](../../sql-reference/data-types/array.md/#array-size) 하위 열을 읽기 위해.
- [notEmpty](/sql-reference/functions/array-functions#notEmpty)는 [size0](../../sql-reference/data-types/array.md/#array-size) 하위 열을 읽기 위해.
- [isNull](/sql-reference/functions/functions-for-nulls#isNull)는 [null](../../sql-reference/data-types/nullable.md/#finding-null) 하위 열을 읽기 위해.
- [isNotNull](/sql-reference/functions/functions-for-nulls#isNotNull)는 [null](../../sql-reference/data-types/nullable.md/#finding-null) 하위 열을 읽기 위해.
- [count](/sql-reference/aggregate-functions/reference/count)는 [null](../../sql-reference/data-types/nullable.md/#finding-null) 하위 열을 읽기 위해.
- [mapKeys](/sql-reference/functions/tuple-map-functions#mapkeys)는 [keys](/sql-reference/data-types/map#reading-subcolumns-of-map) 하위 열을 읽기 위해.
- [mapValues](/sql-reference/functions/tuple-map-functions#mapvalues)는 [values](/sql-reference/data-types/map#reading-subcolumns-of-map) 하위 열을 읽기 위해.

가능한 값:

- 0 — 최적화 비활성화.
- 1 — 최적화 활성화.
## optimize_group_by_constant_keys {#optimize_group_by_constant_keys} 

<SettingsInfoBlock type="Bool" default_value="1" />

블록의 모든 키가 상수일 경우 GROUP BY를 최적화합니다.
## optimize_group_by_function_keys {#optimize_group_by_function_keys} 

<SettingsInfoBlock type="Bool" default_value="1" />

GROUP BY 섹션의 다른 키 함수 제거합니다.
## optimize_if_chain_to_multiif {#optimize_if_chain_to_multiif} 

<SettingsInfoBlock type="Bool" default_value="0" />

`if(cond1, then1, if(cond2, ...))` 체인을 `multiIf`로 교체합니다. 현재 이 기능은 숫자 유형에 이점을 주지 않습니다.
## optimize_if_transform_strings_to_enum {#optimize_if_transform_strings_to_enum} 

<SettingsInfoBlock type="Bool" default_value="0" />

If 및 Transform의 문자열 유형 인수를 enum으로 교체합니다. 이는 분산 쿼리의 일관성을 해칠 수 있으므로 기본적으로 비활성화되어 있습니다.
## optimize_injective_functions_in_group_by {#optimize_injective_functions_in_group_by} 

<SettingsInfoBlock type="Bool" default_value="1" />

GROUP BY 섹션에서 모든 인젝티브 함수를 인수로 교체합니다.
## optimize_injective_functions_inside_uniq {#optimize_injective_functions_inside_uniq} 

<SettingsInfoBlock type="Bool" default_value="1" />

uniq*() 함수 내의 하나의 인수로써 인젝티브 함수를 삭제합니다.
## optimize_min_equality_disjunction_chain_length {#optimize_min_equality_disjunction_chain_length} 

최적화를 위한 표현식 `expr = x1 OR ... expr = xN`의 최소 길이입니다.
## optimize_min_inequality_conjunction_chain_length {#optimize_min_inequality_conjunction_chain_length} 

최적화를 위한 표현식 `expr <> x1 AND ... expr <> xN`의 최소 길이입니다.
## optimize_move_to_prewhere {#optimize_move_to_prewhere} 

<SettingsInfoBlock type="Bool" default_value="1" />

자동 [PREWHERE](../../sql-reference/statements/select/prewhere.md) 최적화를 [SELECT](../../sql-reference/statements/select/index.md) 쿼리에서 활성화하거나 비활성화합니다.

이는 [*MergeTree](../../engines/table-engines/mergetree-family/index.md) 테이블에 대해서만 작동합니다.

가능한 값:

- 0 — 자동 `PREWHERE` 최적화 비활성화.
- 1 — 자동 `PREWHERE` 최적화 활성화.
## optimize_move_to_prewhere_if_final {#optimize_move_to_prewhere_if_final} 

<SettingsInfoBlock type="Bool" default_value="0" />

[FINAL](/sql-reference/statements/select/from#final-modifier) 수정자가 있는 [SELECT](../../sql-reference/statements/select/index.md) 쿼리에서 자동 [PREWHERE](../../sql-reference/statements/select/prewhere.md) 최적화를 활성화하거나 비활성화합니다.

이는 [*MergeTree](../../engines/table-engines/mergetree-family/index.md) 테이블에 대해서만 작동합니다.

가능한 값:

- 0 — `FINAL` 수정자가 있는 `SELECT` 쿼리에서 자동 `PREWHERE` 최적화 비활성화.
- 1 — `FINAL` 수정자가 있는 `SELECT` 쿼리에서 자동 `PREWHERE` 최적화 활성화.

**참고사항**

- [optimize_move_to_prewhere](#optimize_move_to_prewhere) 설정
## optimize_multiif_to_if {#optimize_multiif_to_if} 

<SettingsInfoBlock type="Bool" default_value="1" />

조건이 하나만 있는 'multiIf'를 'if'로 교체합니다.
## optimize_normalize_count_variants {#optimize_normalize_count_variants} 

<SettingsInfoBlock type="Bool" default_value="1" />

count()와 의미적으로 동일한 집계 함수를 count()로 재작성합니다.
## optimize_on_insert {#optimize_on_insert} 

<SettingsInfoBlock type="Bool" default_value="1" />

삽입 전에 데이터를 변환하는 기능을 활성화하거나 비활성화합니다. 마치 이 블록에서 병합이 이루어진 것처럼(테이블 엔진에 따라).

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.

**예시**

활성화된 경우와 비활성화된 경우의 차이:

쿼리:

```sql
SET optimize_on_insert = 1;

CREATE TABLE test1 (`FirstTable` UInt32) ENGINE = ReplacingMergeTree ORDER BY FirstTable;

INSERT INTO test1 SELECT number % 2 FROM numbers(5);

SELECT * FROM test1;

SET optimize_on_insert = 0;

CREATE TABLE test2 (`SecondTable` UInt32) ENGINE = ReplacingMergeTree ORDER BY SecondTable;

INSERT INTO test2 SELECT number % 2 FROM numbers(5);

SELECT * FROM test2;
```

결과:

```text
┌─FirstTable─┐
│          0 │
│          1 │
└────────────┘

┌─SecondTable─┐
│           0 │
│           0 │
│           0 │
│           1 │
│           1 │
└─────────────┘
```

이 설정은 [물리화된 뷰](/sql-reference/statements/create/view#materialized-view) 동작에 영향을 미친다는 점에 유의하세요.
## optimize_or_like_chain {#optimize_or_like_chain} 

여러 OR LIKE를 multiMatchAny로 최적화합니다. 이 최적화는 일부 경우에서 인덱스 분석을 무효화할 수 있으므로 기본적으로 활성화되어서는 안됩니다.
## optimize_qbit_distance_function_reads {#optimize_qbit_distance_function_reads} 

<SettingsInfoBlock type="Bool" default_value="1" />

`QBit` 데이터 유형의 거리 함수에 대해 계산에 필요한 열만 스토리지에서 읽도록 동등한 함수로 교체합니다.
## optimize_read_in_order {#optimize_read_in_order} 

[ORDER BY](/sql-reference/statements/select/order-by#optimization-of-data-reading) 최적화를 [SELECT](../../sql-reference/statements/select/index.md) 쿼리에서 활성화합니다. [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 테이블로부터 데이터를 읽습니다.

가능한 값:

- 0 — `ORDER BY` 최적화 비활성화.
- 1 — `ORDER BY` 최적화 활성화.

**참고사항**

- [ORDER BY 절](/sql-reference/statements/select/order-by#optimization-of-data-reading)
## optimize_read_in_window_order {#optimize_read_in_window_order} 

MergeTree 테이블에서 해당 순서로 데이터를 읽기 위해 창 절에서 ORDER BY 최적화를 활성화합니다.
## optimize_redundant_functions_in_order_by {#optimize_redundant_functions_in_order_by} 

ORDER BY의 인수가 ORDER BY에도 있을 경우 ORDER BY에서 함수를 제거합니다.
## optimize_respect_aliases {#optimize_respect_aliases} 

비활성화된 경우 WHERE/GROUP BY/ORDER BY에서 별칭을 귀찮게 합니다. 이는 파티션 프루닝/2차 인덱스/optimize_aggregation_in_order/optimize_read_in_order/optimize_trivial_count에 도움이 됩니다.
## optimize_rewrite_aggregate_function_with_if {#optimize_rewrite_aggregate_function_with_if} 

논리적으로 동등할 때 인수로 if 표현식을 사용하는 집계 함수를 재작성합니다.
예를 들어, `avg(if(cond, col, null))`는 `avgOrNullIf(cond, col)`로 재작성할 수 있습니다. 이는 성능 개선에 도움을 줄 수 있습니다.

:::note
분석기(`enable_analyzer = 1`)와만 지원됩니다.
:::
## optimize_rewrite_array_exists_to_has {#optimize_rewrite_array_exists_to_has} 

논리적으로 동등할 때 `arrayExists()` 함수를 `has()`로 재작성합니다. 예를 들어, `arrayExists(x -> x = 1, arr)`는 `has(arr, 1)`으로 재작성될 수 있습니다.
## optimize_rewrite_like_perfect_affix {#optimize_rewrite_like_perfect_affix} 

완벽한 전사 또는 접미사가 있는 LIKE 표현을 `startsWith` 또는 `endsWith` 함수로 재작성합니다(예: `col LIKE 'ClickHouse%'`는 `startsWith(col, 'ClickHouse')`로).
## optimize_rewrite_regexp_functions {#optimize_rewrite_regexp_functions} 

정규 표현식 관련 함수를 더 간단하고 효율적인 형식으로 재작성합니다.
## optimize_rewrite_sum_if_to_count_if {#optimize_rewrite_sum_if_to_count_if} 

논리적으로 동등할 때 sumIf() 및 sum(if()) 함수를 countIf() 함수로 재작성합니다.
## optimize_skip_merged_partitions {#optimize_skip_merged_partitions} 

최적화가 불필요한 경우 [OPTIMIZE TABLE ... FINAL](../../sql-reference/statements/optimize.md) 쿼리에 대한 최적화를 활성화하거나 비활성화합니다. 파트가 하나만 있고 레벨이 0보다 크며 만료된 TTL이 없는 경우.

- `OPTIMIZE TABLE ... FINAL SETTINGS optimize_skip_merged_partitions=1`

기본적으로 `OPTIMIZE TABLE ... FINAL` 쿼리는 파트가 하나만 있는 경우에도 해당 파트를 다시 작성합니다.

가능한 값:

- 1 - 최적화 활성화.
- 0 - 최적화 비활성화.
## optimize_skip_unused_shards {#optimize_skip_unused_shards} 

[SELECT](../../sql-reference/statements/select/index.md) 쿼리가 `WHERE/PREWHERE`에서 sharding key 조건을 가진 경우 사용되지 않는 샤드를 건너뛰는 기능을 활성화하거나 비활성화합니다(데이터가 sharding key에 따라 분산된 경우; 그렇지 않으면 쿼리가 잘못된 결과를 가져옵니다).

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.
## optimize_skip_unused_shards_limit {#optimize_skip_unused_shards_limit} 

sharding key 값 수의 제한으로, 제한에 도달하면 `optimize_skip_unused_shards`가 꺼집니다.

너무 많은 값은 처리에 상당한 양을 요구할 수 있으며, 이점은 의심스러우므로 `IN (...)`에 많은 수의 값이 있을 경우, 쿼리가 어차피 모든 샤드로 전달될 것입니다.
## optimize_skip_unused_shards_nesting {#optimize_skip_unused_shards_nesting} 

분산 쿼리의 중첩 수준에 따라 [`optimize_skip_unused_shards`](#optimize_skip_unused_shards) (따라서 [`optimize_skip_unused_shards`](#optimize_skip_unused_shards)를 요구합니다)를 제어합니다(한 `Distributed` 테이블이 다른 `Distributed` 테이블을 검색하는 경우).

가능한 값:

- 0 — 비활성화, `optimize_skip_unused_shards`는 항상 작동합니다.
- 1 — 첫 번째 수준에서만 `optimize_skip_unused_shards`를 활성화합니다.
- 2 — 두 번째 수준까지 `optimize_skip_unused_shards`를 활성화합니다.
## optimize_skip_unused_shards_rewrite_in {#optimize_skip_unused_shards_rewrite_in} 

원격 샤드에서 쿼리의 IN을 재작성하여 샤드에 속하지 않는 값을 제외합니다(최적화된 건너뛰기 사용 필요).

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.
## optimize_sorting_by_input_stream_properties {#optimize_sorting_by_input_stream_properties} 

입력 스트림의 정렬 속성을 기반으로 정렬을 최적화합니다.
## optimize_substitute_columns {#optimize_substitute_columns} 

열 대체를 위해 [constraints](../../sql-reference/statements/create/table.md/#constraints)를 사용합니다. 기본값은 `false`입니다.

가능한 값:

- true, false
## optimize_syntax_fuse_functions {#optimize_syntax_fuse_functions} 

동일한 인수를 가진 집계 함수를 결합할 수 있도록 합니다. 동일한 인수를 가진 집계 함수를 [sum](/sql-reference/aggregate-functions/reference/sum), [count](/sql-reference/aggregate-functions/reference/count) 또는 [avg](/sql-reference/aggregate-functions/reference/avg)를 포함하는 쿼리를 [sumCount](/sql-reference/aggregate-functions/reference/sumcount)로 재작성합니다.

가능한 값:

- 0 — 동일한 인수를 가진 함수는 결합되지 않음.
- 1 — 동일한 인수를 가진 함수는 결합됨.

**예시**

쿼리:

```sql
CREATE TABLE fuse_tbl(a Int8, b Int8) Engine = Log;
SET optimize_syntax_fuse_functions = 1;
EXPLAIN SYNTAX SELECT sum(a), sum(b), count(b), avg(b) from fuse_tbl FORMAT TSV;
```

결과:

```text
SELECT
    sum(a),
    sumCount(b).1,
    sumCount(b).2,
    (sumCount(b).1) / (sumCount(b).2)
FROM fuse_tbl
```
## optimize_throw_if_noop {#optimize_throw_if_noop} 

<SettingsInfoBlock type="Bool" default_value="0" />

쿼리에서 [OPTIMIZE](../../sql-reference/statements/optimize.md) 쿼리가 병합을 수행하지 않았을 경우 예외를 발생시켜야 하는 기능을 활성화하거나 비활성화합니다.

기본적으로 `OPTIMIZE`는 아무 작업도 하지 않았더라도 성공적으로 반환됩니다. 이 설정은 이러한 상황을 구별하고 예외 메시지에서 이유를 알 수 있도록 합니다.

가능한 값:

- 1 — 예외 발생 활성화.
- 0 — 예외 발생 비활성화.
## optimize_time_filter_with_preimage {#optimize_time_filter_with_preimage} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "Date 및 DateTime 절을 최적화하여 변환 없이 등가 비교로 변환합니다 (예: toYear(col) = 2023 -> col >= '2023-01-01' AND col <= '2023-12-31')"}]}]}/>

함수를 변환하여 Date 및 DateTime 절을 최적화합니다. 변환 없이 동일한 비교로 바꿉니다(예: `toYear(col) = 2023 -> col >= '2023-01-01' AND col <= '2023-12-31'`).
## optimize_trivial_approximate_count_query {#optimize_trivial_approximate_count_query} 

<SettingsInfoBlock type="Bool" default_value="0" />

예를 들어, EmbeddedRocksDB와 같이 해당 추정을 지원하는 스토리지에 대한 트리비얼 카운트 최적화를 위해 근사 값을 사용합니다.

가능한 값:

   - 0 — 최적화 비활성화.
   - 1 — 최적화 활성화.
## optimize_trivial_count_query {#optimize_trivial_count_query} 

<SettingsInfoBlock type="Bool" default_value="1" />

메타데이터를 사용하여 `SELECT count() FROM table`의 트리비얼 쿼리에 대한 최적화를 활성화하거나 비활성화합니다. 행 수준 보안을 사용해야 하는 경우 이 설정을 비활성화합니다.

가능한 값:

   - 0 — 최적화 비활성화.
   - 1 — 최적화 활성화.

참고 사항:

- [optimize_functions_to_subcolumns](#optimize_functions_to_subcolumns)
## optimize_trivial_insert_select {#optimize_trivial_insert_select} 

<SettingsInfoBlock type="Bool" default_value="0" />

트리비얼 'INSERT INTO table SELECT ... FROM TABLES' 쿼리를 최적화합니다.
## optimize_uniq_to_count {#optimize_uniq_to_count} 

uniq 및 그 변형(uniqUpTo 제외)을 DISTINCT 또는 GROUP BY 절을 가진 서브쿼리의 count if로 재작성합니다.
## optimize_use_implicit_projections {#optimize_use_implicit_projections} 

SELECT 쿼리를 수행하기 위해 자동으로 암시적 프로젝션을 선택합니다.
## optimize_use_projection_filtering {#optimize_use_projection_filtering} 

<SettingsInfoBlock type="Bool" default_value="1" />

가능한 값:

- true, false
## optimize_use_projections {#optimize_use_projections} 

[SELECT](../../sql-reference/statements/select/index.md) 쿼리를 처리할 때 [projections](../../engines/table-engines/mergetree-family/mergetree.md/#projections) 최적화를 활성화하거나 비활성화합니다.

가능한 값:

- 0 — 프로젝션 최적화 비활성화.
- 1 — 프로젝션 최적화 활성화.
## optimize_using_constraints {#optimize_using_constraints} 

쿼리 최적화를 위해 [constraints](../../sql-reference/statements/create/table.md/#constraints)를 사용합니다. 기본값은 `false`입니다.

가능한 값:

- true, false
## os_threads_nice_value_materialized_view {#os_threads_nice_value_materialized_view} 

<SettingsInfoBlock type="Int32" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.9"},{"label": "0"},{"label": "New setting."}]}]}/>

물리화된 뷰 스레드에 대한 리눅스 nice 값. 낮은 값은 높은 CPU 우선 순위를 의미합니다.

CAP_SYS_NICE 권한이 필요하며, 그렇지 않으면 작동하지 않습니다.

가능한 값: -20에서 19까지.
## os_threads_nice_value_query {#os_threads_nice_value_query} 

<SettingsInfoBlock type="Int32" default_value="0" />

쿼리 처리 스레드에 대한 리눅스 nice 값. 낮은 값은 높은 CPU 우선 순위를 의미합니다.

CAP_SYS_NICE 권한이 필요하며, 그렇지 않으면 작동하지 않습니다.

가능한 값: -20에서 19까지.
## output_format_compression_level {#output_format_compression_level} 

<SettingsInfoBlock type="UInt64" default_value="3" />

쿼리 출력이 압축되는 경우의 기본 압축 수준. 이 설정은 `SELECT` 쿼리에 `INTO OUTFILE`가 있거나 `file`, `url`, `hdfs`, `s3`, 또는 `azureBlobStorage`로 쓸 때 적용됩니다.

가능한 값: `1`에서 `22`까지.
## output_format_compression_zstd_window_log {#output_format_compression_zstd_window_log} 

<SettingsInfoBlock type="UInt64" default_value="0" />

출력 압축 방법이 `zstd`인 경우 사용할 수 있습니다. 값이 0보다 크면 이 설정은 압축 창 크기(2의 거듭제곱)를 명시적으로 설정하고 zstd 압축을 위한 장거리 모드를 활성화합니다. 이는 더 나은 압축 비율을 달성하는 데 도움이 될 수 있습니다.

가능한 값: 음수가 아닌 숫자. 값이 너무 작거나 클 경우 `zstdlib`에서 예외가 발생합니다. 일반적인 값은 `20`(창 크기 = `1MB`)에서 `30`(창 크기 = `1GB`)까지입니다.
## output_format_parallel_formatting {#output_format_parallel_formatting} 

데이터 형식의 병렬 포맷팅을 활성화하거나 비활성화합니다. [TSV](/interfaces/formats/TabSeparated), [TSKV](/interfaces/formats/TSKV), [CSV](/interfaces/formats/CSV) 및 [JSONEachRow](/interfaces/formats/JSONEachRow) 형식만 지원됩니다.

가능한 값:

- 1 — 활성화.
- 0 — 비활성화.
## page_cache_block_size {#page_cache_block_size} 

<SettingsInfoBlock type="UInt64" default_value="1048576" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1048576"},{"label": "Made this setting adjustable on a per-query level."}]}]}/>

사용자 공간 페이지 캐시에 저장할 파일 청크의 크기(바이트). 캐시를 통과하는 모든 읽기는 이 크기의 배수로 올림됩니다.

이 설정은 쿼리 수준에서 조정할 수 있지만, 서로 다른 블록 크기를 가진 캐시 항목은 재사용할 수 없습니다. 이 설정을 변경하면 기존 캐시 항목이 무효화됩니다.

1 MiB와 같은 높은 값은 높은 처리량 쿼리에 좋으며, 64 KiB와 같은 낮은 값은 낮은 지연 시간의 포인트 쿼리에 좋습니다.
## page_cache_inject_eviction {#page_cache_inject_eviction} 

<SettingsInfoBlock type="Bool" default_value="0" />

사용자 공간 페이지 캐시는 때때로 임의로 일부 페이지를 무효화합니다. 테스트 용으로 의도됨.
## page_cache_lookahead_blocks {#page_cache_lookahead_blocks} 

<SettingsInfoBlock type="UInt64" default_value="16" />

사용자 공간 페이지 캐시 미스 시, 기본 스토리지에서 이 많은 연속 블록을 한 번에 읽어옵니다. 이 블록들도 캐시에 없을 경우에는 유효합니다. 각 블록의 크기는 page_cache_block_size 바이트입니다.

높은 값은 높은 처리량 쿼리에 유리하지만, 낮은 지연 시간의 포인트 쿼리는 선읽기 없이 더 잘 작동합니다.
## parallel_distributed_insert_select {#parallel_distributed_insert_select} 

<SettingsInfoBlock type="UInt64" default_value="2" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.7"},{"label": "2"},{"label": "Enable parallel distributed insert select by default"}]}]}/>

병렬 분산 `INSERT ... SELECT` 쿼리를 활성화합니다.

`INSERT INTO distributed_table_a SELECT ... FROM distributed_table_b` 쿼리를 실행할 때, 두 테이블이 동일한 클러스터를 사용하고 두 테이블이 [복제됨](../../engines/table-engines/mergetree-family/replication.md) 또는 비복제 상태인 경우, 이 쿼리는 모든 샤드에서 로컬로 처리됩니다.

가능한 값:

- `0` — 비활성화.
- `1` — `SELECT`가 분산 엔진의 기본 테이블에서 각 샤드에서 실행됩니다.
- `2` — `SELECT`와 `INSERT`가 분산 엔진의 기본 테이블에서 각 샤드에서 실행됩니다.

이 설정을 사용할 때 `enable_parallel_replicas = 1`을 설정해야 합니다.

## parallel_hash_join_threshold {#parallel_hash_join_threshold} 

<SettingsInfoBlock type="UInt64" default_value="100000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "100000"},{"label": "New setting"}]}, {"id": "row-2","items": [{"label": "25.4"},{"label": "0"},{"label": "New setting"}]}, {"id": "row-3","items": [{"label": "25.3"},{"label": "0"},{"label": "New setting"}]}]}/>

해시 기반 조인 알고리즘이 적용될 때, 이 임계값은 `hash`와 `parallel_hash` 중 어떤 것을 사용할지를 결정하는 데 도움이 됩니다(오른쪽 테이블의 크기 추정이 가능한 경우에만).
앞의 경우는 오른쪽 테이블의 크기가 임계값 이하인 경우에 사용됩니다.

## parallel_replica_offset {#parallel_replica_offset} 

<BetaBadge/>

<SettingsInfoBlock type="UInt64" default_value="0" />

이것은 내부 설정으로 직접 사용할 수 없으며 '병렬 복제본' 모드의 구현 세부사항을 나타냅니다. 이 설정은 쿼리 처리를 위한 복제본의 인덱스에 대해 분산 쿼리를 위한 시작 서버에 의해 자동으로 설정됩니다.

## parallel_replicas_allow_in_with_subquery {#parallel_replicas_allow_in_with_subquery} 

<BetaBadge/>

<SettingsInfoBlock type="Bool" default_value="1" />

참이면, IN에 대한 서브쿼리가 모든 팔로워 복제본에서 실행됩니다.

## parallel_replicas_connect_timeout_ms {#parallel_replicas_connect_timeout_ms} 

<BetaBadge/>

<SettingsInfoBlock type="Milliseconds" default_value="300" />

병렬 복제본으로 쿼리를 실행하는 동안 원격 복제본에 연결하기 위한 타임아웃(밀리초)입니다. 타임아웃이 만료되면 해당 복제본은 쿼리 실행에 사용되지 않습니다.

## parallel_replicas_count {#parallel_replicas_count} 

<BetaBadge/>

<SettingsInfoBlock type="UInt64" default_value="0" />

이것은 내부 설정으로 직접 사용할 수 없으며 '병렬 복제본' 모드의 구현 세부사항을 나타냅니다. 이 설정은 쿼리 처리를 위해 참여하는 병렬 복제본의 수에 대해 시작 서버에 의해 자동으로 설정됩니다.

## parallel_replicas_custom_key {#parallel_replicas_custom_key} 

<BetaBadge/>

특정 테이블의 복제본 간에 작업을 분할하는 데 사용할 수 있는 임의의 정수 표현식입니다.
값은 임의의 정수 표현식이 될 수 있습니다.

기본 키를 사용하는 간단한 표현식이 선호됩니다.

이 설정이 복제본이 여러 개인 단일 샤드로 구성된 클러스터에서 사용될 경우, 해당 복제본은 가상 샤드로 변환됩니다.
그렇지 않으면 `SAMPLE` 키에 대한 동작과 같으며, 각 샤드의 여러 복제본을 사용합니다.

## parallel_replicas_custom_key_range_lower {#parallel_replicas_custom_key_range_lower} 

<BetaBadge/>

<SettingsInfoBlock type="UInt64" default_value="0" />

사용자 정의 범위 `[parallel_replicas_custom_key_range_lower, INT_MAX]`에 따라 복제본 간에 작업을 균등하게 분할하도록 필터 유형 `range`를 허용합니다.

[parallel_replicas_custom_key_range_upper](#parallel_replicas_custom_key_range_upper)와 함께 사용할 경우, 필터가 범위 `[parallel_replicas_custom_key_range_lower, parallel_replicas_custom_key_range_upper]`에 대해 복제본 간에 작업을 균등하게 분할하도록 합니다.

참고: 이 설정은 쿼리 처리 중 추가 데이터를 필터링하지 않으며, 오히려 병렬 처리를 위한 범위 필터가 범위 `[0, INT_MAX]`를 나누는 지점을 변경합니다.

## parallel_replicas_custom_key_range_upper {#parallel_replicas_custom_key_range_upper} 

<BetaBadge/>

<SettingsInfoBlock type="UInt64" default_value="0" />

사용자 정의 범위 `[0, parallel_replicas_custom_key_range_upper]`에 따라 복제본 간에 작업을 균등하게 분할하도록 필터 유형 `range`를 허용합니다. 값이 0이면 상한이 비활성화되며, 사용자 정의 키 표현식의 최대값으로 설정됩니다.

[parallel_replicas_custom_key_range_lower](#parallel_replicas_custom_key_range_lower)와 함께 사용할 경우, 필터가 범위 `[parallel_replicas_custom_key_range_lower, parallel_replicas_custom_key_range_upper]`에 대해 복제본 간에 작업을 균등하게 분할하도록 합니다.

참고: 이 설정은 쿼리 처리 중 추가 데이터를 필터링하지 않으며, 오히려 병렬 처리를 위한 범위 필터가 범위 `[0, INT_MAX]`를 나누는 지점을 변경합니다.

## parallel_replicas_for_cluster_engines {#parallel_replicas_for_cluster_engines} 

<SettingsInfoBlock type="Bool" default_value="1" />

테이블 함수 엔진을 해당 -Cluster 대안으로 대체합니다.

## parallel_replicas_for_non_replicated_merge_tree {#parallel_replicas_for_non_replicated_merge_tree} 

<BetaBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

참이면 ClickHouse는 비복제 MergeTree 테이블에 대해서도 병렬 복제본 알고리즘을 사용할 것입니다.

## parallel_replicas_index_analysis_only_on_coordinator {#parallel_replicas_index_analysis_only_on_coordinator} 

<BetaBadge/>

<SettingsInfoBlock type="Bool" default_value="1" />

인덱스 분석은 복제본 코디네이터에서만 수행되며 다른 복제본에서는 건너뜁니다. 병렬 복제본 로컬 플랜이 활성화된 경우에만 유효합니다.

## parallel_replicas_insert_select_local_pipeline {#parallel_replicas_insert_select_local_pipeline} 

<BetaBadge/>

병렬 복제본과 함께 분산 INSERT SELECT 중 로컬 파이프라인을 사용합니다.

## parallel_replicas_local_plan {#parallel_replicas_local_plan} 

<BetaBadge/>

로컬 복제본의 로컬 계획을 구축합니다.

## parallel_replicas_mark_segment_size {#parallel_replicas_mark_segment_size} 

<BetaBadge/>

부분이 세그먼트로 가상적으로 분할되어 복제본 간에 병렬 읽기 위해 분배됩니다. 이 설정은 이러한 세그먼트의 크기를 제어합니다. 당신이 하는 일에 대해 확실하지 않다면 변경하는 것을 권장하지 않습니다. 값은 [128; 16384] 범위여야 합니다.

## parallel_replicas_min_number_of_rows_per_replica {#parallel_replicas_min_number_of_rows_per_replica} 

<BetaBadge/>

쿼리에서 사용되는 복제본 수를 (읽어야 할 예상 행 수 / 최소 행 수)로 제한합니다. 최대치는 여전히 'max_parallel_replicas'에 의해 제한됩니다.

## parallel_replicas_mode {#parallel_replicas_mode} 

<BetaBadge/>

병렬 복제본에 대한 사용자 정의 키와 함께 사용할 필터 유형입니다. 기본값 - 사용자 정의 키에서 모듈로 연산 사용, 범위 - 사용자 정의 키의 모든 가능한 값을 사용하는 범위 필터입니다.

## parallel_replicas_only_with_analyzer {#parallel_replicas_only_with_analyzer} 

<BetaBadge/>

분석기를 사용할 수 있도록 병렬 복제본을 사용할 수 있습니다. 분석기가 비활성화된 경우 쿼리 실행이 로컬 실행으로 되돌아가고, 병렬 읽기가 복제본에서 활성화된 경우에도 마찬가지입니다. 분석기 없이 병렬 복제본을 사용하는 것은 지원되지 않습니다.

## parallel_replicas_prefer_local_join {#parallel_replicas_prefer_local_join} 

<BetaBadge/>

참이면, JOIN이 병렬 복제본 알고리즘으로 실행될 수 있고 오른쪽 JOIN 부분의 모든 스토리지가 *MergeTree일 경우, 로컬 JOIN이 GLOBAL JOIN 대신 사용됩니다.

## parallel_replicas_support_projection {#parallel_replicas_support_projection} 

<BetaBadge/>

병렬 복제본에서 프로젝션의 최적화를 적용할 수 있습니다. 병렬 복제본 로컬 계획이 활성화되고 aggregation_in_order가 비활성화된 경우에만 유효합니다.

## parallel_view_processing {#parallel_view_processing} 

첨부된 뷰에 동시에 푸시하는 것을 활성화합니다.

## parallelize_output_from_storages {#parallelize_output_from_storages} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.5"},{"label": "1"},{"label": "Allow parallelism when executing queries that read from file/url/s3/etc. This may reorder rows."}]}]}/>

스토리지에서 읽기 단계의 출력을 병렬화합니다. 가능한 경우 스토리지에서 읽은 직후 쿼리 처리의 병렬화를 허용합니다.

## parsedatetime_e_requires_space_padding {#parsedatetime_e_requires_space_padding} 

<SettingsInfoBlock type="Bool" default_value="0" />

[parseDateTime] 함수의 포매터 '%e'는 단일 자릿수 일이 공백으로 패딩되어 있다고 예상합니다. 예를 들어, ' 2'는 허용되지만 '2'는 오류를 발생시킵니다.

## parsedatetime_parse_without_leading_zeros {#parsedatetime_parse_without_leading_zeros} 

<SettingsInfoBlock type="Bool" default_value="1" />

[parseDateTime] 함수의 포매터 '%c', '%l', 및 '%k'는 선행 제로 없이 월과 시간을 구문 분석합니다.

## partial_merge_join_left_table_buffer_bytes {#partial_merge_join_left_table_buffer_bytes} 

<SettingsInfoBlock type="UInt64" default_value="0" />

0이 아닌 경우, 부분 병합 조인의 왼쪽 테이블을 위해 더 큰 블록으로 그룹화합니다. 조인 스레드당 지정된 메모리의 최대 2배를 사용합니다.

## partial_merge_join_rows_in_right_blocks {#partial_merge_join_rows_in_right_blocks} 

<SettingsInfoBlock type="UInt64" default_value="65536" />

[JOIN](../../sql-reference/statements/select/join.md) 쿼리에 대한 부분 병합 조인 알고리즘에서 오른쪽 조인 데이터 블록의 크기를 제한합니다.

ClickHouse 서버:

1. 오른쪽 조인 데이터를 지정된 행 수까지 블록으로 분할합니다.
2. 각 블록을 최소값과 최대값으로 인덱싱합니다.
3. 가능한 경우 준비된 블록을 디스크로 언로드합니다.

가능한 값:

- 모든 양의 정수. 권장 범위: \[1000, 100000\].

## partial_result_on_first_cancel {#partial_result_on_first_cancel} 

쿼리가 취소된 후 부분 결과를 반환할 수 있습니다.

## parts_to_delay_insert {#parts_to_delay_insert} 

대상 테이블이 단일 파티션에서 활성 부분이 이만큼 이상 포함된 경우, 테이블에 대한 삽입을 인위적으로 지연시킵니다.

## parts_to_throw_insert {#parts_to_throw_insert} 

대상 테이블의 단일 파티션에 활성 부분이 이보다 많으면 'Too many parts ...' 예외를 발생시킵니다.

## per_part_index_stats {#per_part_index_stats} 

<SettingsInfoBlock type="Bool" default_value="0" />

        부분별 인덱스 통계를 로깅합니다.

## poll_interval {#poll_interval} 

서버에서 쿼리 대기 루프를 지정된 초 수 동안 차단합니다.

## postgresql_connection_attempt_timeout {#postgresql_connection_attempt_timeout} 

<SettingsInfoBlock type="UInt64" default_value="2" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "2"},{"label": "Allow to control 'connect_timeout' parameter of PostgreSQL connection."}]}]}/>

PostgreSQL 엔드포인트에 연결하기 위한 단일 시도의 연결 타임아웃(초)입니다. 값은 연결 URL의 `connect_timeout` 매개변수로 전달됩니다.

## postgresql_connection_pool_auto_close_connection {#postgresql_connection_pool_auto_close_connection} 

연결을 풀로 반환하기 전에 연결을 닫습니다.

## postgresql_connection_pool_retries {#postgresql_connection_pool_retries} 

<SettingsInfoBlock type="UInt64" default_value="2" />

PostgreSQL 테이블 엔진 및 데이터베이스 엔진의 연결 풀 푸시/팝 재시도 횟수입니다.

## postgresql_connection_pool_size {#postgresql_connection_pool_size} 

PostgreSQL 테이블 엔진 및 데이터베이스 엔진의 연결 풀 크기입니다.

## postgresql_connection_pool_wait_timeout {#postgresql_connection_pool_wait_timeout} 

PostgreSQL 테이블 엔진 및 데이터베이스 엔진의 비어 있는 풀에서 연결 풀 푸시/팝 타임아웃입니다. 기본적으로 비어 있는 풀에서 차단합니다.

## postgresql_fault_injection_probability {#postgresql_fault_injection_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "0"},{"label": "New setting"}]}]}/>

복제를 위한 내부 PostgreSQL 쿼리가 실패할 확률입니다. 유효한 값은 [0.0f, 1.0f]의 범위입니다.

## prefer_column_name_to_alias {#prefer_column_name_to_alias} 

쿼리 표현식 및 절에서 별칭 대신 원래 컬럼 이름을 사용하도록 허용하거나 비활성화합니다. 특히 별칭과 컬럼 이름이 동일할 때 중요합니다. ClickHouse에서 별칭 구문 규칙을 대부분의 다른 데이터베이스 엔진과 더 호환되도록 하려면 이 설정을 활성화하십시오.

가능한 값:

- 0 — 컬럼 이름이 별칭으로 대체됩니다.
- 1 — 컬럼 이름이 별칭으로 대체되지 않습니다.

**예시**

활성화된 것과 비활성화된 것의 차이:

쿼리:

```sql
SET prefer_column_name_to_alias = 0;
SELECT avg(number) AS number, max(number) FROM numbers(10);
```

결과:

```text
Received exception from server (version 21.5.1):
Code: 184. DB::Exception: Received from localhost:9000. DB::Exception: Aggregate function avg(number) is found inside another aggregate function in query: While processing avg(number) AS number.
```

쿼리:

```sql
SET prefer_column_name_to_alias = 1;
SELECT avg(number) AS number, max(number) FROM numbers(10);
```

결과:

```text
┌─number─┬─max(number)─┐
│    4.5 │           9 │
└────────┴─────────────┘
```

## prefer_external_sort_block_bytes {#prefer_external_sort_block_bytes} 

<SettingsInfoBlock type="UInt64" default_value="16744704" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "16744704"},{"label": "Prefer maximum block bytes for external sort, reduce the memory usage during merging."}]}]}/>

외부 정렬을 위한 최대 블록 바이트를 선호하여 병합 중 메모리 사용량을 줄입니다.

## prefer_global_in_and_join {#prefer_global_in_and_join} 

`IN`/`JOIN` 연산자를 `GLOBAL IN`/`GLOBAL JOIN`으로 대체하는 것을 활성화합니다.

가능한 값:

- 0 — 비활성화. `IN`/`JOIN` 연산자가 `GLOBAL IN`/`GLOBAL JOIN`으로 대체되지 않습니다.
- 1 — 활성화. `IN`/`JOIN` 연산자가 `GLOBAL IN`/`GLOBAL JOIN`으로 대체됩니다.

**사용법**

`SET distributed_product_mode=global`는 분산 테이블에 대한 쿼리 동작을 변경할 수 있지만, 로컬 테이블이나 외부 리소스의 테이블에는 적합하지 않습니다. 여기서 `prefer_global_in_and_join` 설정이 사용됩니다.

예를 들어, 로컬 테이블을 포함하는 쿼리 서비스 노드가 있을 수 있습니다. 이 테이블은 분산 처리에 적합하지 않습니다. `GLOBAL` 키워드인 `GLOBAL IN`/`GLOBAL JOIN`을 사용하여 이러한 데이터를 즉석에서 분산 처리해야 합니다.

`prefer_global_in_and_join`의 또 다른 사용 사례는 외부 엔진에 의해 생성된 테이블에 액세스하는 것입니다. 이 설정은 이러한 테이블을 JOIN할 때 외부 소스에 대한 호출 수를 줄이는 데 도움이 됩니다: 쿼리당 단일 호출만 발생합니다.

**참고:** 

- `GLOBAL IN`/`GLOBAL JOIN` 사용법에 대한 추가 정보는 [Distributed subqueries](/sql-reference/operators/in#distributed-subqueries)를 참조하십시오.

## prefer_localhost_replica {#prefer_localhost_replica} 

분산 쿼리를 처리할 때 로컬호스트 복제본을 선호하는 것을 활성화/비활성화합니다.

가능한 값:

- 1 — ClickHouse는 로컬호스트 복제본이 존재할 경우 항상 해당 복제본에 쿼리를 전송합니다.
- 0 — ClickHouse는 [load_balancing](#load_balancing) 설정에 의해 지정된 균형 조정 전략을 사용합니다.

:::note
[parallel_replicas_custom_key](#parallel_replicas_custom_key) 없이 [max_parallel_replicas](#max_parallel_replicas)를 사용하는 경우 이 설정을 비활성화하십시오.
[parallel_replicas_custom_key](#parallel_replicas_custom_key)가 설정되면, 다중 복제본을 포함한 다중 샤드가 있는 클러스터에서 사용될 경우에만 이 설정을 비활성화하십시오.
단일 샤드와 여러 복제본으로 구성된 클러스터에서 사용되는 경우 이 설정을 비활성화하면 부정적인 영향을 미칠 수 있습니다.
:::

## prefer_warmed_unmerged_parts_seconds {#prefer_warmed_unmerged_parts_seconds} 

<CloudOnlyBadge/>

<SettingsInfoBlock type="Int64" default_value="0" />

ClickHouse Cloud에서만 효과가 있습니다. 병합된 파트가 이 만한 초보다 낮고 미리 따뜻해지지 않은 상태(see [cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch))일 경우, 모든 소스 파트가 사용 가능하고 미리 따뜻해지면 SELECT 쿼리는 해당 파트에서 읽습니다. Replicated-/SharedMergeTree 전용입니다. 이 설정은 CacheWarmer가 해당 파트를 처리했는지만 확인하고, 다른 것으로 캐시에 로드된 경우 아직 차갑게 간주됩니다. CacheWarmer가 처리할 경우 따뜻하게 처리된 후 캐시에서 퇴출되면 여전히 따뜻하게 간주됩니다.

## preferred_block_size_bytes {#preferred_block_size_bytes} 

이 설정은 쿼리 처리를 위해 데이터 블록 크기를 조정하고 보다 조잡한 'max_block_size' 설정에 대한 추가 세부 조정을 나타냅니다. 열이 크고 'max_block_size' 행이 블록 크기가 지정된 바이트 수보다 클 경우, CPU 캐시의 지역성을 개선하기 위해 크기를 낮춥니다.

## preferred_max_column_in_block_size_bytes {#preferred_max_column_in_block_size_bytes} 

읽기 중 블록 내 최대 열 크기를 제한합니다. 캐시 미스 수를 줄이는 데 도움이 됩니다. L2 캐시 크기에 가깝게 설정해야 합니다.

## preferred_optimize_projection_name {#preferred_optimize_projection_name} 

비어 있지 않은 문자열로 설정된 경우, ClickHouse는 쿼리에서 지정된 프로젝션을 적용하려고 시도합니다.

가능한 값:

- 문자열: 선호하는 프로젝션 이름

## prefetch_buffer_size {#prefetch_buffer_size} 

파일 시스템에서 읽기 위한 최대 미리 가져오기 버퍼 크기입니다.

## print_pretty_type_names {#print_pretty_type_names} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "1"},{"label": "Better user experience."}]}]}/>

`DESCRIBE` 쿼리와 `toTypeName()` 함수에서 깊이 중첩된 타입 이름을 들여쓰기로 예쁘게 인쇄할 수 있도록 합니다.

예시:

```sql
CREATE TABLE test (a Tuple(b String, c Tuple(d Nullable(UInt64), e Array(UInt32), f Array(Tuple(g String, h Map(String, Array(Tuple(i String, j UInt64))))), k Date), l Nullable(String))) ENGINE=Memory;
DESCRIBE TABLE test FORMAT TSVRaw SETTINGS print_pretty_type_names=1;
```

```
a   Tuple(
    b String,
    c Tuple(
        d Nullable(UInt64),
        e Array(UInt32),
        f Array(Tuple(
            g String,
            h Map(
                String,
                Array(Tuple(
                    i String,
                    j UInt64
                ))
            )
        )),
        k Date
    ),
    l Nullable(String)
)
```

## priority {#priority} 

쿼리의 우선 순위입니다. 1 - 가장 높음, 높은 값은 낮은 우선 순위; 0 - 우선 순위를 사용하지 않음.

## promql_database {#promql_database} 

<ExperimentalBadge/>

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": ""},{"label": "New experimental setting"}]}]}/>

'promql' 방언에서 사용되는 데이터베이스 이름을 지정합니다. 빈 문자열은 현재 데이터베이스를 의미합니다.

## promql_evaluation_time {#promql_evaluation_time} 

<ExperimentalBadge/>

<SettingsInfoBlock type="FloatAuto" default_value="auto" />

'promql' 방언에 사용될 평가 시간을 설정합니다. 'auto'는 현재 시간을 의미합니다.

## promql_table {#promql_table} 

<ExperimentalBadge/>

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": ""},{"label": "New experimental setting"}]}]}/>

'promql' 방언에 의해 사용되는 TimeSeries 테이블의 이름을 지정합니다.

## push_external_roles_in_interserver_queries {#push_external_roles_in_interserver_queries} 

<SettingsInfoBlock type="Bool" default_value="1" />

쿼리를 수행할 때 사용자 역할을 원래의 노드에서 다른 노드로 푸시하는 것을 활성화합니다.

## query_cache_compress_entries {#query_cache_compress_entries} 

[쿼리 캐시](../query-cache.md)에서 항목을 압축합니다. 쿼리 캐시에 대한 메모리 소비를 줄이며, 그 대가로 삽입 / 읽기 속도가 느려집니다.

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## query_cache_max_entries {#query_cache_max_entries} 

현재 사용자가 [쿼리 캐시](../query-cache.md)에 저장할 수 있는 쿼리 결과의 최대 수입니다. 0은 무제한을 의미합니다.

가능한 값:

- 양의 정수 >= 0.

## query_cache_max_size_in_bytes {#query_cache_max_size_in_bytes} 

현재 사용자가 [쿼리 캐시](../query-cache.md)에서 할당할 수 있는 최대 메모리 양(바이트)입니다. 0은 무제한을 의미합니다.

가능한 값:

- 양의 정수 >= 0.

## query_cache_min_query_duration {#query_cache_min_query_duration} 

쿼리가 쿼리 결과를 [쿼리 캐시](../query-cache.md)에 저장하기 위해 실행되어야 하는 최소 지속 시간(밀리초)입니다.

가능한 값:

- 양의 정수 >= 0.

## query_cache_min_query_runs {#query_cache_min_query_runs} 

쿼리 결과가 [쿼리 캐시](../query-cache.md)에 저장되기 전에 `SELECT` 쿼리가 최소 몇 번 실행되어야 하는지입니다.

가능한 값:

- 양의 정수 >= 0.

## query_cache_nondeterministic_function_handling {#query_cache_nondeterministic_function_handling} 

[쿼리 캐시](../query-cache.md)에서 `rand()` 또는 `now()`와 같은 비결정론적 함수가 포함된 `SELECT` 쿼리를 처리하는 방법을 제어합니다.

가능한 값:

- `'throw'` - 예외를 발생시키고 쿼리 결과를 캐시하지 않음.
- `'save'` - 쿼리 결과를 캐시함.
- `'ignore'` - 쿼리 결과를 캐시하지 않고 예외를 발생시키지 않음.

## query_cache_share_between_users {#query_cache_share_between_users} 

켜지면, [쿼리 캐시](../query-cache.md)에 캐시된 `SELECT` 쿼리의 결과를 다른 사용자가 읽을 수 있습니다.
보안상의 이유로 이 설정을 활성화하는 것은 권장되지 않습니다.

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## query_cache_squash_partial_results {#query_cache_squash_partial_results} 

부분 결과 블록을 [max_block_size](#max_block_size) 크기의 블록으로 압축합니다. [쿼리 캐시](../query-cache.md)로의 삽입 성능을 줄이지만 캐시 항목의 압축 가능성을 향상시킵니다 (see [query_cache_compress-entries](#query_cache_compress_entries)).

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## query_cache_system_table_handling {#query_cache_system_table_handling} 

[쿼리 캐시](../query-cache.md)가 시스템 테이블에 대한 `SELECT` 쿼리를 처리하는 방법을 제어합니다. 즉, `system.*` 및 `information_schema.*`의 데이터베이스에 있는 테이블입니다.

가능한 값:

- `'throw'` - 예외를 발생시키고 쿼리 결과를 캐시하지 않음.
- `'save'` - 쿼리 결과를 캐시함.
- `'ignore'` - 쿼리 결과를 캐시하지 않고 예외를 발생시키지 않음.

## query_cache_tag {#query_cache_tag} 

[쿼리 캐시](../query-cache.md) 항목을 위한 레이블 역할을 하는 문자열입니다.
다른 태그가 있는 동일한 쿼리는 쿼리 캐시에 의해 다르게 간주됩니다.

가능한 값:

- 임의의 문자열

## query_cache_ttl {#query_cache_ttl} 

이 시간(초) 후에 [쿼리 캐시](../query-cache.md)의 항목이 오래된 상태가 됩니다.

가능한 값:

- 양의 정수 >= 0.

## query_condition_cache_store_conditions_as_plaintext {#query_condition_cache_store_conditions_as_plaintext} 

[쿼리 조건 캐시](/operations/query-condition-cache)의 필터 조건을 평문으로 저장합니다.
활성화되면 system.query_condition_cache는 필터 조건을 있는 그대로 보여주어 캐시 문제를 디버그하기 쉽게 만듭니다.
기본적으로 비활성화되어 있으며, 평문 필터 조건이 민감한 정보를 노출할 수 있습니다.

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## query_metric_log_interval {#query_metric_log_interval} 

각 쿼리에 대해 [query_metric_log](../../operations/system-tables/query_metric_log.md)를 수집하는 간격(밀리초)입니다.

음수로 설정하면 [query_metric_log 설정](/operations/server-configuration-parameters/settings#query_metric_log)의 `collect_interval_milliseconds` 값을 취하거나, 없으면 기본값 1000을 사용합니다.

단일 쿼리 수집을 비활성화하려면 `query_metric_log_interval`을 0으로 설정하십시오. 

기본값: -1

## query_plan_aggregation_in_order {#query_plan_aggregation_in_order} 

쿼리 계획 최적화에서 집계 순서를 전환합니다. [`query_plan_enable_optimizations`](#query_plan_enable_optimizations) 설정이 1인 경우에만 효과가 있습니다.

:::note
이 설정은 디버깅을 위해 개발자 전용으로 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후에 후방 호환성이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## query_plan_convert_any_join_to_semi_or_anti_join {#query_plan_convert_any_join_to_semi_or_anti_join} 

JOIN이 만족되지 않거나 일치된 행에 대해 항상 거짓으로 평가되는 필터가 있는 경우 ANY JOIN을 SEMI 또는 ANTI JOIN으로 변환할 수 있도록 허용합니다.

## query_plan_convert_join_to_in {#query_plan_convert_join_to_in} 

출력 열이 왼쪽 테이블에만 연결된 경우 `JOIN`을 `IN` 서브쿼리로 변환할 수 있도록 허용합니다. 비-ANY JOIN(예: 기본값인 ALL JOIN)에서 잘못된 결과를 초래할 수 있습니다.

## query_plan_convert_outer_join_to_inner_join {#query_plan_convert_outer_join_to_inner_join} 

JOIN 후 필터가 기본값을 항상 필터링하는 경우 `OUTER JOIN`을 `INNER JOIN`으로 변환할 수 있도록 허용합니다.

## query_plan_direct_read_from_text_index {#query_plan_direct_read_from_text_index} 

쿼리 계획에서 오히려 역 인덱스를 사용하여 전체 텍스트 검색 필터링을 수행할 수 있도록 허용합니다.

## query_plan_display_internal_aliases {#query_plan_display_internal_aliases} 

원래 쿼리에서 지정된 별칭 대신 EXPLAIN PLAN에서 내부 별칭(예: __table1)을 표시합니다.

## query_plan_enable_multithreading_after_window_functions {#query_plan_enable_multithreading_after_window_functions} 

윈도우 함수 평가 후 멀티스레딩을 활성화하여 병렬 스트림 처리를 허용합니다.

## query_plan_enable_optimizations {#query_plan_enable_optimizations} 

쿼리 계획 레벨에서 쿼리 최적화를 전환합니다.

:::note
이 설정은 디버깅을 위해 개발자 전용으로 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후에 후방 호환성이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 쿼리 계획 레벨에서 모든 최적화 비활성화
- 1 - 쿼리 계획 레벨에서 최적화 활성화 (하지만 개별 최적화는 여전히 개별 설정을 통해 비활성화될 수 있음)

## query_plan_execute_functions_after_sorting {#query_plan_execute_functions_after_sorting} 

정렬 단계 이후에 식을 이동하는 쿼리 계획 수준의 최적화를 전환합니다. `query_plan_enable_optimizations` 설정이 1인 경우에만 효과가 있습니다.

:::note
이 설정은 디버깅을 위해 개발자 전용으로 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후에 후방 호환성이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## query_plan_filter_push_down {#query_plan_filter_push_down} 

실행 계획에서 필터를 아래로 이동하는 쿼리 계획 수준의 최적화를 전환합니다. `query_plan_enable_optimizations` 설정이 1인 경우에만 효과가 있습니다.

:::note
이 설정은 디버깅을 위해 개발자 전용으로 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후에 후방 호환성이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## query_plan_join_shard_by_pk_ranges {#query_plan_join_shard_by_pk_ranges} 

JOIN 키가 두 테이블 모두에 대한 PRIMARY KEY의 접두사를 포함하는 경우 JOIN에 샤딩을 적용합니다. 해시, parallel_hash 및 full_sorting_merge 알고리즘을 지원합니다. 일반적으로 쿼리 속도를 높이지 않지만 메모리 소모를 줄일 수 있습니다.

## query_plan_join_swap_table {#query_plan_join_swap_table} 

쿼리 계획에서 조인의 어느 쪽이 빌드 테이블(해시 조인의 경우 해시 테이블에 삽입되는 내부 테이블이라고도 함)이어야 하는지를 결정합니다. 이 설정은 `JOIN ON` 절의 `ALL` 조인 엄격성에 대해서만 지원됩니다. 가능한 값은:
- 'auto': 플래너가 빌드 테이블로 사용할 테이블을 결정하도록 합니다.
- 'false': 테이블을 절대 전환하지 않음(오른쪽 테이블이 빌드 테이블).
- 'true': 항상 테이블을 전환함(왼쪽 테이블이 빌드 테이블).

## query_plan_lift_up_array_join {#query_plan_lift_up_array_join} 

쿼리 계획 수준의 최적화를 전환하여 ARRAY JOIN을 실행 계획 상단으로 이동합니다. `query_plan_enable_optimizations` 설정이 1인 경우에만 효과가 있습니다.

:::note
이 설정은 디버깅을 위해 개발자 전용으로 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후에 후방 호환성이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## query_plan_lift_up_union {#query_plan_lift_up_union} 

쿼리 계획 수준의 최적화를 전환하여 쿼리 계획의 더 큰 서브트리를 유니온으로 이동하여 추가 최적화를 가능하게 합니다. `query_plan_enable_optimizations` 설정이 1인 경우에만 효과가 있습니다.

:::note
이 설정은 디버깅을 위해 개발자 전용으로 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후에 후방 호환성이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## query_plan_max_limit_for_lazy_materialization {#query_plan_max_limit_for_lazy_materialization} 

지연 물질화 최적화를 위해 쿼리 계획을 사용할 수 있는 최대 한도 값을 제어합니다. 0이면 제한이 없습니다.

## query_plan_max_optimizations_to_apply {#query_plan_max_optimizations_to_apply} 

쿼리 계획에 적용되는 최대 최적화 수를 제한합니다. [query_plan_enable_optimizations](#query_plan_enable_optimizations) 설정을 참조하십시오.
복잡한 쿼리에 대한 긴 최적화 시간을 피하는 데 유용합니다.
EXPLAIN PLAN 쿼리에서 이 한도가 초과되면 최적화를 중단하고 계획을 있는 그대로 반환합니다.
정기적인 쿼리 실행에서 실제 최적화 수가 이 설정을 초과하면 예외가 발생합니다.

:::note
이 설정은 디버깅을 위해 개발자 전용으로 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후에 후방 호환성이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

## query_plan_max_step_description_length {#query_plan_max_step_description_length} 

EXPLAIN PLAN의 단계 설명 최대 길이입니다.

## query_plan_merge_expressions {#query_plan_merge_expressions} 

연속된 필터를 병합하는 쿼리 계획 수준의 최적화를 전환합니다. `query_plan_enable_optimizations` 설정이 1인 경우에만 효과가 있습니다.

:::note
이 설정은 디버깅을 위해 개발자 전용으로 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후에 후방 호환성이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## query_plan_merge_filter_into_join_condition {#query_plan_merge_filter_into_join_condition} 

필터를 `JOIN` 조건으로 병합하고 `CROSS JOIN`을 `INNER`로 변환할 수 있도록 허용합니다.

## query_plan_merge_filters {#query_plan_merge_filters} 

쿼리 계획에서 필터를 병합할 수 있도록 허용합니다.

## query_plan_optimize_join_order_limit {#query_plan_optimize_join_order_limit} 

동일한 서브쿼리 내 JOIN의 순서를 최적화합니다. 현재는 매우 제한된 경우에만 지원됩니다. 값은 최적화할 테이블의 최대 수입니다.

## query_plan_optimize_lazy_materialization {#query_plan_optimize_lazy_materialization} 

지연 물질화 최적화를 위해 쿼리 계획을 사용합니다.
## query_plan_optimize_prewhere {#query_plan_optimize_prewhere} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "Allow to push down filter to PREWHERE expression for supported storages"}]}]}/>

지원되는 스토리지에 대해 PREWHERE 표현식으로 필터를 푸시할 수 있도록 허용합니다.
## query_plan_push_down_limit {#query_plan_push_down_limit} 



<SettingsInfoBlock type="Bool" default_value="1" />

LIMIT를 실행 계획 아래로 이동시키는 쿼리 계획 수준 최적화를 전환합니다. 
설정 [query_plan_enable_optimizations](#query_plan_enable_optimizations)가 1일 때만 적용됩니다.

:::note
이 설정은 개발자가 디버깅 목적으로만 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후 하위 호환이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 비활성화
- 1 - 활성화
## query_plan_read_in_order {#query_plan_read_in_order} 



<SettingsInfoBlock type="Bool" default_value="1" />

쿼리 계획 수준 최적화인 읽기 순서 최적화를 전환합니다.
설정 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations)가 1일 때만 적용됩니다.

:::note
이 설정은 개발자가 디버깅 목적으로만 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후 하위 호환이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 비활성화
- 1 - 활성화
## query_plan_remove_redundant_distinct {#query_plan_remove_redundant_distinct} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.2"},{"label": "1"},{"label": "Remove redundant Distinct step in query plan"}]}]}/>

중복 DISTINCT 단계를 제거하는 쿼리 계획 수준 최적화를 전환합니다. 
설정 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations)가 1일 때만 적용됩니다.

:::note
이 설정은 개발자가 디버깅 목적으로만 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후 하위 호환이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 비활성화
- 1 - 활성화
## query_plan_remove_redundant_sorting {#query_plan_remove_redundant_sorting} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.1"},{"label": "1"},{"label": "Remove redundant sorting in query plan. For example, sorting steps related to ORDER BY clauses in subqueries"}]}]}/>

중복 정렬 단계를 제거하는 쿼리 계획 수준 최적화를 전환합니다. 예: 서브쿼리에서. 
설정 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations)가 1일 때만 적용됩니다.

:::note
이 설정은 개발자가 디버깅 목적으로만 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후 하위 호환이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 비활성화
- 1 - 활성화
## query_plan_reuse_storage_ordering_for_window_functions {#query_plan_reuse_storage_ordering_for_window_functions} 



<SettingsInfoBlock type="Bool" default_value="1" />

창 함수에 대한 정렬 시 저장소 정렬을 사용하는 쿼리 계획 수준 최적화를 전환합니다. 
설정 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations)가 1일 때만 적용됩니다.

:::note
이 설정은 개발자가 디버깅 목적으로만 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후 하위 호환이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 비활성화
- 1 - 활성화
## query_plan_split_filter {#query_plan_split_filter} 



<SettingsInfoBlock type="Bool" default_value="1" />

:::note
이 설정은 개발자가 디버깅 목적으로만 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후 하위 호환이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

필터를 표현식으로 분할하는 쿼리 계획 수준 최적화를 전환합니다.
설정 [query_plan_enable_optimizations](#query_plan_enable_optimizations)가 1일 때만 적용됩니다.

가능한 값:

- 0 - 비활성화
- 1 - 활성화
## query_plan_try_use_vector_search {#query_plan_try_use_vector_search} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "New setting."}]}]}/>

벡터 유사성 인덱스를 사용해 보려는 쿼리 계획 수준 최적화를 전환합니다. 
설정 [`query_plan_enable_optimizations`](#query_plan_enable_optimizations)가 1일 때만 적용됩니다.

:::note
이 설정은 개발자가 디버깅 목적으로만 사용해야 하는 전문가 수준의 설정입니다. 이 설정은 향후 하위 호환이 없는 방식으로 변경되거나 제거될 수 있습니다.
:::

가능한 값:

- 0 - 비활성화
- 1 - 활성화
## query_plan_use_new_logical_join_step {#query_plan_use_new_logical_join_step} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "Enable new step"}]}, {"id": "row-2","items": [{"label": "25.1"},{"label": "0"},{"label": "New join step, internal change"}]}]}/>

쿼리 계획에서 논리 조인 단계를 사용합니다. 
참고: 설정 `query_plan_use_new_logical_join_step`는 더 이상 사용되지 않으므로 대신 `query_plan_use_logical_join_step`를 사용하십시오.
## query_profiler_cpu_time_period_ns {#query_profiler_cpu_time_period_ns} 



<SettingsInfoBlock type="UInt64" default_value="1000000000" />

[쿼리 프로파일러](../../operations/optimizing-performance/sampling-query-profiler.md)의 CPU 시계 타이머 주기를 설정합니다. 이 타이머는 CPU 시간만을 계산합니다.

가능한 값:

- 양의 정수 나노초.

    추천 값:

            - 단일 쿼리의 경우 10000000 (초당 100회) 나노초 이상.
            - 클러스터 전체 프로파일링의 경우 1000000000 (초당 1회).

- 타이머를 끄려면 0을 설정합니다.

**ClickHouse Cloud에서 일시적으로 비활성화되었습니다.**

또한 참조:

- 시스템 테이블 [trace_log](/operations/system-tables/trace_log)
## query_profiler_real_time_period_ns {#query_profiler_real_time_period_ns} 



<SettingsInfoBlock type="UInt64" default_value="1000000000" />

[쿼리 프로파일러](../../operations/optimizing-performance/sampling-query-profiler.md)의 실제 시계 타이머 주기를 설정합니다. 실제 시계 타이머는 벽시계 시간을 계산합니다.

가능한 값:

- 양의 정수 나노초.

    추천 값:

            - 단일 쿼리의 경우 10000000 (초당 100회) 나노초 이하.
            - 클러스터 전체 프로파일링의 경우 1000000000 (초당 1회).

- 타이머를 끄려면 0을 설정합니다.

**ClickHouse Cloud에서 일시적으로 비활성화되었습니다.**

또한 참조:

- 시스템 테이블 [trace_log](/operations/system-tables/trace_log)
## queue_max_wait_ms {#queue_max_wait_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="0" />

최대 요청 수를 초과할 경우 요청 대기열에서의 대기 시간입니다.
## rabbitmq_max_wait_ms {#rabbitmq_max_wait_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="5000" />

재시도 전 RabbitMQ에서 읽는 대기 시간입니다.
## read_backoff_max_throughput {#read_backoff_max_throughput} 



<SettingsInfoBlock type="UInt64" default_value="1048576" />

느린 읽기에서 스레드 수를 줄이기 위한 설정입니다. 읽기 대역폭이 초당 이보다 적은 바이트일 때 이벤트를 수집합니다.
## read_backoff_min_concurrency {#read_backoff_min_concurrency} 



<SettingsInfoBlock type="UInt64" default_value="1" />

느린 읽기에서 최소 스레드 수를 유지하려고 시도하기 위한 설정입니다.
## read_backoff_min_events {#read_backoff_min_events} 



<SettingsInfoBlock type="UInt64" default_value="2" />

느린 읽기에서 스레드 수를 줄이기 위한 설정입니다. 스레드 수가 줄어들 이벤트 수입니다.
## read_backoff_min_interval_between_events_ms {#read_backoff_min_interval_between_events_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="1000" />

느린 읽기에서 스레드 수를 줄이기 위한 설정입니다. 이전 이벤트가 특정 시간보다 짧게 지나지 않은 경우에 이벤트를 무시합니다.
## read_backoff_min_latency_ms {#read_backoff_min_latency_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="1000" />

느린 읽기에서 스레드 수를 줄이기 위한 설정입니다. 최소한 이만큼의 시간이 걸린 읽기만 고려합니다.
## read_from_distributed_cache_if_exists_otherwise_bypass_cache {#read_from_distributed_cache_if_exists_otherwise_bypass_cache} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "0"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. read_from_filesystem_cache_if_exists_otherwise_bypass_cache와 동일하지만 분산 캐시에 대해 적용됩니다.
## read_from_filesystem_cache_if_exists_otherwise_bypass_cache {#read_from_filesystem_cache_if_exists_otherwise_bypass_cache} 



<SettingsInfoBlock type="Bool" default_value="0" />

패시브 모드에서 파일 시스템 캐시를 사용하도록 허용합니다 - 기존 캐시 항목의 이점을 누리되, 캐시에 더 많은 항목을 추가하지는 않습니다. 이 설정을 무거운 애드혹 쿼리에 적용하고, 짧은 실시간 쿼리에 대해 비활성화할 경우, 너무 무거운 쿼리로 인해 캐시 갈림 현상을 피하고 전체 시스템 효율성을 개선할 수 있습니다.
## read_from_page_cache_if_exists_otherwise_bypass_cache {#read_from_page_cache_if_exists_otherwise_bypass_cache} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "Added userspace page cache"}]}]}/>

파일 시스템 캐시와 유사하게 사용자의 페이지 캐시를 패시브 모드에서 사용합니다.
## read_in_order_two_level_merge_threshold {#read_in_order_two_level_merge_threshold} 



<SettingsInfoBlock type="UInt64" default_value="100" />

기본 키 순서로 다중 스레드 읽기를 수행하는 동안 초기 병합 단계를 실행하기 위해 읽어야 하는 최소 파트 수입니다.
## read_in_order_use_buffering {#read_in_order_use_buffering} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "1"},{"label": "Use buffering before merging while reading in order of primary key"}]}]}/>

기본 키 순서로 읽는 동안 병합 전에 버퍼링을 사용합니다. 이는 쿼리 실행의 병렬성을 증가시킵니다.
## read_in_order_use_virtual_row {#read_in_order_use_virtual_row} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "Use virtual row while reading in order of primary key or its monotonic function fashion. It is useful when searching over multiple parts as only relevant ones are touched."}]}]}/>

기본 키 또는 그 단조 함수 방식으로 읽는 동안 가상 행을 사용합니다. 이는 여러 파트에서 검색할 때 관련 파트만 접근하도록 유용합니다.
## read_overflow_mode {#read_overflow_mode} 



<SettingsInfoBlock type="OverflowMode" default_value="throw" />

제한이 초과될 때 수행할 작업입니다.
## read_overflow_mode_leaf {#read_overflow_mode_leaf} 



<SettingsInfoBlock type="OverflowMode" default_value="throw" />

읽은 데이터의 양이 일부 리프 한도를 초과할 때 발생하는 일을 설정합니다.

가능한 옵션:
- `throw`: 예외를 발생시킵니다(기본값).
- `break`: 쿼리 실행을 중지하고 부분 결과를 반환합니다.
## read_priority {#read_priority} 



<SettingsInfoBlock type="Int64" default_value="0" />

로컬 파일 시스템 또는 원격 파일 시스템에서 데이터를 읽는 우선 순위입니다. 로컬 파일 시스템의 경우 'pread_threadpool' 방법과 원격 파일 시스템의 경우 `threadpool` 방법에 대해서만 지원됩니다.
## read_through_distributed_cache {#read_through_distributed_cache} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 분산 캐시에서 읽는 것을 허용합니다.
## readonly {#readonly} 



<SettingsInfoBlock type="UInt64" default_value="0" />

0 - 읽기 전용 제한 없음. 1 - 읽기 요청만 가능하며, 명시적으로 허용된 설정만 변경 가능. 2 - 읽기 요청과 설정 변경만 가능하며, 'readonly' 설정은 제외합니다.
## receive_data_timeout_ms {#receive_data_timeout_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="2000" />

첫 번째 데이터 패킷 또는 복제본의 진행이 긍정적인 패킷을 수신하기 위한 연결 시간 초과입니다.
## receive_timeout {#receive_timeout} 



<SettingsInfoBlock type="Seconds" default_value="300" />

네트워크에서 데이터를 수신하는 시간 초과(초). 이 간격 동안 바이트를 수신하지 못하면 예외가 발생합니다. 클라이언트에서 이 설정을 설정하면, 해당하는 서버의 소켓에서도 'send_timeout'이 설정됩니다.
## regexp_max_matches_per_row {#regexp_max_matches_per_row} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

단일 행당 단일 정규 표현식의 최대 일치를 설정합니다. [extractAllGroupsHorizontal](/sql-reference/functions/string-search-functions#extractAllGroupsHorizontal) 함수에서 탐욕적인 정규 표현식을 사용할 때 메모리 과부하를 방지하는 데 사용합니다.

가능한 값:

- 양의 정수.
## reject_expensive_hyperscan_regexps {#reject_expensive_hyperscan_regexps} 



<SettingsInfoBlock type="Bool" default_value="1" />

고비용으로 평가될 가능성이 있는 패턴을 거부합니다(상태 폭발로 인해).
## remerge_sort_lowered_memory_bytes_ratio {#remerge_sort_lowered_memory_bytes_ratio} 



<SettingsInfoBlock type="Float" default_value="2" />

리머지 후 메모리 사용량이 이 비율만큼 감소하지 않으면 리머지를 비활성화합니다.
## remote_filesystem_read_method {#remote_filesystem_read_method} 



<SettingsInfoBlock type="String" default_value="threadpool" />

원격 파일 시스템에서 데이터를 읽는 방법으로, read 또는 threadpool 중 하나입니다.
## remote_filesystem_read_prefetch {#remote_filesystem_read_prefetch} 



<SettingsInfoBlock type="Bool" default_value="1" />

원격 파일 시스템에서 데이터를 읽을 때 프리패치를 사용해야 합니다.
## remote_fs_read_backoff_max_tries {#remote_fs_read_backoff_max_tries} 



<SettingsInfoBlock type="UInt64" default_value="5" />

백오프 시도 횟수 최대값입니다.
## remote_fs_read_max_backoff_ms {#remote_fs_read_max_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="10000" />

원격 디스크의 데이터를 읽으려는 경우 최대 대기 시간입니다.
## remote_read_min_bytes_for_seek {#remote_read_min_bytes_for_seek} 



<SettingsInfoBlock type="UInt64" default_value="4194304" />

원격 읽기(url, s3)를 수행하기 위해 필요한 최소 바이트로, 무시하고 읽는 대신 시킹을 수행할 수 있습니다.
## rename_files_after_processing {#rename_files_after_processing} 

- **유형:** 문자열

- **기본값:** 빈 문자열

이 설정은 `file` 테이블 함수가 처리한 파일에 대한 이름 바꾸기 패턴을 지정할 수 있도록 합니다. 옵션이 설정되면, `file` 테이블 함수가 읽은 모든 파일은 처리 성공 시 지정된 패턴과 플레이스홀더에 따라 이름이 바뀝니다.
### 플레이스홀더

- `%a` — 전체 원래 파일 이름(예: "sample.csv").
- `%f` — 확장자가 없는 원래 파일 이름(예: "sample").
- `%e` — 점이 포함된 원래 파일 확장자(예: ".csv").
- `%t` — 타임스탬프(마이크로초).
- `%%` — 백분율 기호 ("%").
### 예제
- 옵션: `--rename_files_after_processing="processed_%f_%t%e"`

- 쿼리: `SELECT * FROM file('sample.csv')`


`sample.csv` 읽기가 성공하면 파일 이름이 `processed_sample_1683473210851438.csv`로 변경됩니다.
## replace_running_query {#replace_running_query} 



<SettingsInfoBlock type="Bool" default_value="0" />

HTTP 인터페이스를 사용할 때 'query_id' 매개변수를 전달할 수 있습니다. 이는 쿼리 식별자로 사용되는 문자열입니다.
현재 같은 사용자로부터 같은 'query_id'를 가진 쿼리가 존재할 경우 동작은 'replace_running_query' 매개변수에 따라 달라집니다.

`0` (기본값) – 예외를 발생시킵니다(동일한 'query_id'를 가진 쿼리가 이미 실행 중인 경우 쿼리 실행을 허용하지 않습니다).

`1` – 이전 쿼리를 취소하고 새 쿼리를 실행합니다.

세그먼트 조건에 대한 제안을 구현하기 위해 이 매개변수를 1로 설정합니다. 다음 문자를 입력한 후, 이전 쿼리가 아직 끝나지 않았다면 취소되어야 합니다.
## replace_running_query_max_wait_ms {#replace_running_query_max_wait_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="5000" />

[replace_running_query](#replace_running_query) 설정이 활성화된 경우, 동일한 `query_id`를 가진 쿼리를 실행 중인 쿼리가 완료될 때까지 대기하는 시간입니다.

가능한 값:

- 양의 정수.
- 0 — 서버가 동일한 `query_id`를 가진 쿼리를 이미 실행 중인 경우 새 쿼리를 실행하지 못하도록 예외를 발생시킵니다.
## replication_wait_for_inactive_replica_timeout {#replication_wait_for_inactive_replica_timeout} 



<SettingsInfoBlock type="Int64" default_value="120" />

[`ALTER`](../../sql-reference/statements/alter/index.md), [`OPTIMIZE`](../../sql-reference/statements/optimize.md) 또는 [`TRUNCATE`](../../sql-reference/statements/truncate.md) 쿼리를 실행하기 위해 비활성 복제본을 대기하는 시간(초)을 지정합니다.

가능한 값:

- `0` — 대기하지 않음.
- 음의 정수 — 무제한 시간 대기.
- 양의 정수 — 대기할 초 수.
## restore_replace_external_dictionary_source_to_null {#restore_replace_external_dictionary_source_to_null} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "New setting."}]}]}/>

복원 시 외부 딕셔너리 소스를 Null로 교체합니다. 테스트 목적에 유용합니다.
## restore_replace_external_engines_to_null {#restore_replace_external_engines_to_null} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "New setting."}]}]}/>

테스트 목적입니다. 모든 외부 엔진을 Null로 대체하여 외부 연결을 시작하지 않도록 합니다.
## restore_replace_external_table_functions_to_null {#restore_replace_external_table_functions_to_null} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "New setting."}]}]}/>

테스트 목적입니다. 모든 외부 테이블 함수를 Null로 교체하여 외부 연결을 시작하지 않도록 합니다.
## restore_replicated_merge_tree_to_shared_merge_tree {#restore_replicated_merge_tree_to_shared_merge_tree} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "0"},{"label": "New setting."}]}]}/>

복원하는 동안 테이블 엔진을 Replicated*MergeTree에서 Shared*MergeTree로 교체합니다.
## result_overflow_mode {#result_overflow_mode} 



<SettingsInfoBlock type="OverflowMode" default_value="throw" />

클라우드 기본값: `throw`

결과의 양이 한계를 초과할 경우 할 일을 설정합니다.

가능한 값:
- `throw`: 예외를 발생시킵니다(기본값).
- `break`: 쿼리 실행을 중지하고 부분 결과를 반환합니다. 소스 데이터가 소진된 것처럼.
  
`break`를 사용하는 것은 LIMIT를 사용하는 것과 유사합니다. `Break`는 블록 수준에서만 실행을 중단합니다. 이는 반환된 행의 수가 [`max_result_rows`](/operations/settings/settings#max_result_rows), [`max_block_size`](/operations/settings/settings#max_block_size)의 배수이며 [`max_threads`](/operations/settings/settings#max_threads)에 따라 결정됨을 의미합니다.

**예제**

```sql title="Query"
SET max_threads = 3, max_block_size = 3333;
SET max_result_rows = 3334, result_overflow_mode = 'break';

SELECT *
FROM numbers_mt(100000)
FORMAT Null;
```

```text title="Result"
6666 rows in set. ...
```
## rewrite_count_distinct_if_with_count_distinct_implementation {#rewrite_count_distinct_if_with_count_distinct_implementation} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.8"},{"label": "1"},{"label": "Rewrite countDistinctIf with count_distinct_implementation configuration"}]}]}/>

`countDistcintIf`을 [count_distinct_implementation](#count_distinct_implementation) 설정으로 다시 작성할 수 있도록 합니다.

가능한 값:

- true — 허용.
- false — 허용하지 않음.
## rewrite_in_to_join {#rewrite_in_to_join} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "0"},{"label": "New experimental setting"}]}]}/>

'x IN 서브쿼리'와 같은 표현식을 JOIN으로 다시 작성합니다. 이는 조인 재정렬로 전체 쿼리를 최적화하는 데 유용할 수 있습니다.
## s3_allow_multipart_copy {#s3_allow_multipart_copy} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "New setting."}]}]}/>

S3에서 다중 파트 복사를 허용합니다.
## s3_allow_parallel_part_upload {#s3_allow_parallel_part_upload} 



<SettingsInfoBlock type="Bool" default_value="1" />

s3 다중 부하 업로드에 대해 여러 스레드를 사용합니다. 메모리 사용량이 약간 증가할 수 있습니다.
## s3_check_objects_after_upload {#s3_check_objects_after_upload} 



<SettingsInfoBlock type="Bool" default_value="0" />

업로드가 성공했는지 확인하기 위해 S3에 업로드된 각 객체를 head 요청으로 확인합니다.
## s3_connect_timeout_ms {#s3_connect_timeout_ms} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1000"},{"label": "Introduce new dedicated setting for s3 connection timeout"}]}]}/>

S3 디스크에서 호스트에 대한 연결 시간 초과입니다.
## s3_create_new_file_on_insert {#s3_create_new_file_on_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

S3 엔진 테이블에 각 삽입 시 새 파일을 생성할지 여부를 활성화하거나 비활성화합니다. 활성화된 경우, 각 삽입 시 다음과 유사한 패턴으로 키가 생성된 새로운 S3 객체가 생성됩니다:

초기: `data.Parquet.gz` -> `data.1.Parquet.gz` -> `data.2.Parquet.gz` 등.

가능한 값:
- 0 — `INSERT` 쿼리가 새 파일을 생성하거나 파일이 존재할 경우 실패합니다(s3_truncate_on_insert가 설정되지 않은 경우).
- 1 — `INSERT` 쿼리가 두 번째 삽입부터 접미사를 사용하여 각 삽입에 대해 새 파일을 생성합니다( s3_truncate_on_insert가 설정되지 않은 경우).

자세한 내용은 [여기](/integrations/s3#inserting-data)를 참조하세요.
## s3_disable_checksum {#s3_disable_checksum} 



<SettingsInfoBlock type="Bool" default_value="0" />

S3에 파일을 전송할 때 체크섬을 계산하지 않습니다. 이는 파일에 대한 과도한 처리 통과를 피하여 쓰기를 가속화합니다. 이는 대부분 안전합니다. MergeTree 테이블의 데이터는 ClickHouse에 의해 체크섬이 предостав되며, S3에 HTTPS로 접근할 경우 TLS 계층이 이미 네트워크 전송 중 무결성을 제공합니다. S3에 대한 추가 체크섬은 깊이 있는 방어를 제공합니다.
## s3_ignore_file_doesnt_exist {#s3_ignore_file_doesnt_exist} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "Allow to return 0 rows when the requested files don't exist instead of throwing an exception in S3 table engine"}]}]}/>

특정 키를 읽을 때 파일이 존재하지 않으면 해당 부재를 무시합니다.

가능한 값:
- 1 — `SELECT`가 빈 결과를 반환합니다.
- 0 — `SELECT`가 예외를 발생시킵니다.
## s3_list_object_keys_size {#s3_list_object_keys_size} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

ListObject 요청에서 배치로 반환될 수 있는 최대 파일 수입니다.
## s3_max_connections {#s3_max_connections} 



<SettingsInfoBlock type="UInt64" default_value="1024" />

서버당 최대 연결 수입니다.
## s3_max_get_burst {#s3_max_get_burst} 



<SettingsInfoBlock type="UInt64" default_value="0" />

초당 요청 제한에 도달하기 전에 동시에 발행할 수 있는 최대 요청 수입니다. 기본값(0)은 `s3_max_get_rps`와 동일합니다.
## s3_max_get_rps {#s3_max_get_rps} 



<SettingsInfoBlock type="UInt64" default_value="0" />

스로틀링 전에 초당 S3 GET 요청의 한도입니다. 0은 무제한을 의미합니다.
## s3_max_inflight_parts_for_one_file {#s3_max_inflight_parts_for_one_file} 



<SettingsInfoBlock type="UInt64" default_value="20" />

다중 파트 업로드 요청에서 동시에 로드된 최대 파트 수입니다. 0은 무제한을 의미합니다.
## s3_max_part_number {#s3_max_part_number} 



<SettingsInfoBlock type="UInt64" default_value="10000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "10000"},{"label": "Maximum part number number for s3 upload part"}]}]}/>

s3 업로드 파트의 최대 파트 번호입니다.
## s3_max_put_burst {#s3_max_put_burst} 



<SettingsInfoBlock type="UInt64" default_value="0" />

초당 요청 제한에 도달하기 전에 동시에 발행할 수 있는 최대 요청 수입니다. 기본값(0)은 `s3_max_put_rps`와 같습니다.
## s3_max_put_rps {#s3_max_put_rps} 



<SettingsInfoBlock type="UInt64" default_value="0" />

스로틀링 전에 초당 S3 PUT 요청의 한도입니다. 0은 무제한을 의미합니다.
## s3_max_single_operation_copy_size {#s3_max_single_operation_copy_size} 



<SettingsInfoBlock type="UInt64" default_value="33554432" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "33554432"},{"label": "Maximum size for a single copy operation in s3"}]}]}/>

S3에서 다중 파트 복사를 허용합니다. 이 설정은 s3_allow_multipart_copy가 true인 경우에만 사용됩니다.
## s3_max_single_part_upload_size {#s3_max_single_part_upload_size} 



<SettingsInfoBlock type="UInt64" default_value="33554432" />

단일 파트 업로드를 사용하여 S3에 업로드할 객체의 최대 크기입니다.
## s3_max_single_read_retries {#s3_max_single_read_retries} 



<SettingsInfoBlock type="UInt64" default_value="4" />

단일 S3 읽기 시 최대 재시도 횟수입니다.
## s3_max_unexpected_write_error_retries {#s3_max_unexpected_write_error_retries} 



<SettingsInfoBlock type="UInt64" default_value="4" />

S3 쓰기 중 예상치 못한 오류 발생 시 최대 재시도 횟수입니다.
## s3_max_upload_part_size {#s3_max_upload_part_size} 



<SettingsInfoBlock type="UInt64" default_value="5368709120" />

다중 파트 업로드 중 S3에 업로드할 파트의 최대 크기입니다.
## s3_min_upload_part_size {#s3_min_upload_part_size} 



<SettingsInfoBlock type="UInt64" default_value="16777216" />

다중 파트 업로드 중 S3에 업로드할 파트의 최소 크기입니다.
## s3_request_timeout_ms {#s3_request_timeout_ms} 



<SettingsInfoBlock type="UInt64" default_value="30000" />

S3에 대한 데이터 송수신의 유휴 시간 초과입니다. TCP 읽기 또는 쓰기 호출이 이 시간 동안 차단되는 경우 실패합니다.
## s3_skip_empty_files {#s3_skip_empty_files} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "We hope it will provide better UX"}]}]}/>

S3 엔진 테이블에서 빈 파일의 건너뛰기를 활성화하거나 비활성화합니다.

가능한 값:
- 0 — 빈 파일이 요청된 형식과 호환되지 않는 경우 `SELECT`가 예외를 발생시킵니다.
- 1 — 빈 파일에 대해 `SELECT`가 빈 결과를 반환합니다.
## s3_slow_all_threads_after_network_error {#s3_slow_all_threads_after_network_error} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "New setting"}]}]}/>

`true`로 설정된 경우, 동일한 백업 엔드포인트에 대해 S3 요청을 실행 중인 모든 스레드는 단일 S3 요청에서 재시도 가능한 네트워크 오류(예: 소켓 시간 초과)가 발생한 후 느려집니다.
`false`로 설정된 경우, 각 스레드는 다른 스레드와 독립적으로 S3 요청 백오프를 처리합니다.
## s3_strict_upload_part_size {#s3_strict_upload_part_size} 



<SettingsInfoBlock type="UInt64" default_value="0" />

다중 파트 업로드 중 S3에 업로드할 파트의 정확한 크기입니다(일부 구현은 가변 크기 파트를 지원하지 않습니다).
## s3_throw_on_zero_files_match {#s3_throw_on_zero_files_match} 



<SettingsInfoBlock type="Bool" default_value="0" />

ListObjects 요청이 파일과 일치하지 않는 경우 오류를 발생시킵니다.
## s3_truncate_on_insert {#s3_truncate_on_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

S3 엔진 테이블에서 삽입 전에 잘라내기를 활성화하거나 비활성화합니다. 비활성화된 경우, S3 객체가 이미 존재하는 경우 삽입 시도 시 예외가 발생합니다.

가능한 값:
- 0 — `INSERT` 쿼리가 새 파일을 생성하거나 파일이 존재할 경우 실패합니다(s3_create_new_file_on_insert가 설정되지 않은 경우).
- 1 — `INSERT` 쿼리가 파일의 기존 콘텐츠를 새 데이터로 대체합니다.

자세한 내용은 [여기](/integrations/s3#inserting-data)를 참조하세요.
## s3_upload_part_size_multiply_factor {#s3_upload_part_size_multiply_factor} 



<SettingsInfoBlock type="UInt64" default_value="2" />

s3_multiply_parts_count_threshold의 파트 수에서 S3에 업로드할 때마다 s3_min_upload_part_size를 이 계수로 곱합니다.
## s3_upload_part_size_multiply_parts_count_threshold {#s3_upload_part_size_multiply_parts_count_threshold} 



<SettingsInfoBlock type="UInt64" default_value="500" />

이 수의 파트를 S3에 업로드할 때마다 s3_min_upload_part_size가 s3_upload_part_size_multiply_factor로 곱해집니다.
## s3_use_adaptive_timeouts {#s3_use_adaptive_timeouts} 



<SettingsInfoBlock type="Bool" default_value="1" />

`true`로 설정하면 모든 s3 요청의 처음 두 시도는 짧은 송신 및 수신 시간 초과로 수행됩니다.
`false`로 설정하면 모든 시도가 동일한 시간 초과로 수행됩니다.
## s3_validate_request_settings {#s3_validate_request_settings} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "Allow to disable S3 request settings validation"}]}]}/>

s3 요청 설정 유효성을 검증합니다.
가능한 값:
- 1 — 설정을 검증합니다.
- 0 — 설정을 검증하지 않습니다.
## s3queue_default_zookeeper_path {#s3queue_default_zookeeper_path} 



<SettingsInfoBlock type="String" default_value="/clickhouse/s3queue/" />

S3Queue 엔진에 대한 기본 zookeeper 경로 접두사입니다.
## s3queue_enable_logging_to_s3queue_log {#s3queue_enable_logging_to_s3queue_log} 



<SettingsInfoBlock type="Bool" default_value="0" />

system.s3queue_log에 기록을 활성화합니다. 값은 테이블 설정을 통해 재정의할 수 있습니다.
## s3queue_keeper_fault_injection_probability {#s3queue_keeper_fault_injection_probability} 



<SettingsInfoBlock type="Float" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.10"},{"label": "0"},{"label": "New setting."}]}]}/>

S3Queue에 대한 Keeper 결함 주입 확률입니다.
## s3queue_migrate_old_metadata_to_buckets {#s3queue_migrate_old_metadata_to_buckets} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "New setting."}]}]}/>

S3Queue 테이블의 오래된 메타데이터 구조를 새 구조로 마이그레이션합니다.
## schema_inference_cache_require_modification_time_for_url {#schema_inference_cache_require_modification_time_for_url} 



<SettingsInfoBlock type="Bool" default_value="1" />

마지막 수정 시간 유효성을 위한 URL 캐시에서 스키마를 사용합니다(Last-Modified 헤더가 있는 URL의 경우).
## schema_inference_use_cache_for_azure {#schema_inference_use_cache_for_azure} 



<SettingsInfoBlock type="Bool" default_value="1" />

azure 테이블 함수 사용 시 스키마 추론에서 캐시를 사용합니다.
## schema_inference_use_cache_for_file {#schema_inference_use_cache_for_file} 



<SettingsInfoBlock type="Bool" default_value="1" />

file 테이블 함수 사용 시 스키마 추론에서 캐시를 사용합니다.
## schema_inference_use_cache_for_hdfs {#schema_inference_use_cache_for_hdfs} 



<SettingsInfoBlock type="Bool" default_value="1" />

hdfs 테이블 함수 사용 시 스키마 추론에서 캐시를 사용합니다.
## schema_inference_use_cache_for_s3 {#schema_inference_use_cache_for_s3} 



<SettingsInfoBlock type="Bool" default_value="1" />

s3 테이블 함수 사용 시 스키마 추론에서 캐시를 사용합니다.
## schema_inference_use_cache_for_url {#schema_inference_use_cache_for_url} 



<SettingsInfoBlock type="Bool" default_value="1" />

url 테이블 함수 사용 시 스키마 추론에서 캐시를 사용합니다.
## secondary_indices_enable_bulk_filtering {#secondary_indices_enable_bulk_filtering} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "A new algorithm for filtering by data skipping indices"}]}]}/>

인덱스의 대량 필터링 알고리즘을 활성화합니다. 항상 더 나은 성능을 기대하지만, 호환성과 제어를 위해 이 설정이 있습니다.
## select_sequential_consistency {#select_sequential_consistency} 



<SettingsInfoBlock type="UInt64" default_value="0" />

:::note
이 설정은 SharedMergeTree와 ReplicatedMergeTree 간에 동작이 다릅니다. `select_sequential_consistency`의 SharedMergeTree에서의 동작에 대한 자세한 내용은 [SharedMergeTree 일관성](/cloud/reference/shared-merge-tree#consistency)을 참조하십시오.
:::

`SELECT` 쿼리에 대한 순차적 일관성을 활성화 또는 비활성화합니다. `insert_quorum_parallel`가 비활성화되어 있어야 합니다(기본적으로 활성화됨).

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.

사용법

순차적 일관성이 활성화되면 ClickHouse는 클라이언트가 `insert_quorum`으로 실행된 모든 이전 `INSERT` 쿼리의 데이터를 포함하는 복제본에 대해서만 `SELECT` 쿼리를 실행하도록 허용합니다. 클라이언트가 부분 복제본을 참조하면 ClickHouse는 예외를 생성합니다. SELECT 쿼리는 아직 쿼럼 복제본에 작성되지 않은 데이터를 포함하지 않습니다.

`insert_quorum_parallel`가 활성화되어 있으면(기본값), `select_sequential_consistency`는 작동하지 않습니다. 이는 병렬 `INSERT` 쿼리가 서로 다른 쿼럼 복제본 세트에 쓰일 수 있어 단일 복제본이 모든 쓰기를 수신했다고 보장할 수 없기 때문입니다.

또한 참조:

- [insert_quorum](#insert_quorum)
- [insert_quorum_timeout](#insert_quorum_timeout)
- [insert_quorum_parallel](#insert_quorum_parallel)
## send_logs_level {#send_logs_level} 



<SettingsInfoBlock type="LogsLevel" default_value="fatal" />

서버 텍스트 로그를 지정된 최소 레벨로 클라이언트에 전송합니다. 유효한 값: 'trace', 'debug', 'information', 'warning', 'error', 'fatal', 'none'
## send_logs_source_regexp {#send_logs_source_regexp} 

로그 소스 이름과 일치하는 지정된 정규 표현식으로 서버 텍스트 로그를 전송합니다. 비어있는 것은 모든 소스를 의미합니다.
## send_profile_events {#send_profile_events} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.11"},{"label": "1"},{"label": "New setting. Whether to send profile events to the clients."}]}]}/>

클라이언트에 [ProfileEvents](/native-protocol/server.md#profile-events) 패킷 전송을 활성화하거나 비활성화합니다.

프로파일 이벤트가 필요하지 않은 클라이언트의 경우 네트워크 트래픽을 줄이기 위해 비활성화할 수 있습니다.

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.
## send_progress_in_http_headers {#send_progress_in_http_headers} 



<SettingsInfoBlock type="Bool" default_value="0" />

`clickhouse-server` 응답에서 `X-ClickHouse-Progress` HTTP 응답 헤더를 활성화하거나 비활성화합니다.

자세한 내용은 [HTTP 인터페이스 설명](../../interfaces/http.md)을 참조하세요.

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.
## send_timeout {#send_timeout} 



<SettingsInfoBlock type="Seconds" default_value="300" />

네트워크에 데이터를 전송하기 위한 시간 초과(초). 클라이언트가 일부 데이터를 전송해야 하지만 이 간격 동안 바이트를 전송할 수 없는 경우 예외가 발생합니다. 클라이언트에서 이 설정을 설정하면, 해당하는 서버의 소켓에서도 'receive_timeout'이 설정됩니다.
## serialize_query_plan {#serialize_query_plan} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "NewSetting"}]}]}/>

분산 처리를 위해 쿼리 계획을 직렬화합니다.
## session_timezone {#session_timezone} 

<BetaBadge/>

현재 세션 또는 쿼리의 암묵적 시간대를 설정합니다.
암묵적 시간대는 명시적으로 지정된 시간대가 없는 DateTime/DateTime64 유형의 값에 적용되는 시간대입니다.
이 설정은 전역적으로 구성된(서버 수준) 암묵적 시간대보다 우선합니다.
''(빈 문자열)의 경우, 현재 세션 또는 쿼리의 암묵적 시간대가 [서버 시간대](../server-configuration-parameters/settings.md/#timezone)와 같음을 의미합니다.

세션 시간대 및 서버 시간대를 얻기 위해 `timeZone()` 및 `serverTimeZone()` 함수를 사용할 수 있습니다.

가능한 값:

- `system.time_zones`의 모든 시간대 이름, 예: `Europe/Berlin`, `UTC` 또는 `Zulu`

예시:

```sql
SELECT timeZone(), serverTimeZone() FORMAT CSV

"Europe/Berlin","Europe/Berlin"
```

```sql
SELECT timeZone(), serverTimeZone() SETTINGS session_timezone = 'Asia/Novosibirsk' FORMAT CSV

"Asia/Novosibirsk","Europe/Berlin"
```

명시적 시간대가 지정되지 않은 내장 DateTime에 세션 시간대 'America/Denver'를 할당합니다:

```sql
SELECT toDateTime64(toDateTime64('1999-12-12 23:23:23.123', 3), 3, 'Europe/Zurich') SETTINGS session_timezone = 'America/Denver' FORMAT TSV

1999-12-13 07:23:23.123
```

:::warning
DateTime/DateTime64를 파싱하는 모든 함수가 `session_timezone`를 준수하지 않습니다. 이로 인해 미세한 오류가 발생할 수 있습니다.
다음 예제 및 설명을 참조하십시오.
:::

```sql
CREATE TABLE test_tz (`d` DateTime('UTC')) ENGINE = Memory AS SELECT toDateTime('2000-01-01 00:00:00', 'UTC');

SELECT *, timeZone() FROM test_tz WHERE d = toDateTime('2000-01-01 00:00:00') SETTINGS session_timezone = 'Asia/Novosibirsk'
0 rows in set.

SELECT *, timeZone() FROM test_tz WHERE d = '2000-01-01 00:00:00' SETTINGS session_timezone = 'Asia/Novosibirsk'
┌───────────────────d─┬─timeZone()───────┐
│ 2000-01-01 00:00:00 │ Asia/Novosibirsk │
└─────────────────────┴──────────────────┘
```

이는 서로 다른 파싱 파이프라인으로 인해 발생합니다:

- 명시적인 시간대가 없는 `toDateTime()`은 첫 번째 `SELECT` 쿼리에서 `session_timezone` 및 전역 시간대를 준수합니다.
- 두 번째 쿼리에서는 문자열에서 DateTime을 파싱하고 기존 열 `d`의 유형 및 시간대를 상속받습니다. 따라서 `session_timezone` 및 전역 시간대 설정은 준수되지 않습니다.

**또한 참조**

- [timezone](../server-configuration-parameters/settings.md/#timezone)
## set_overflow_mode {#set_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

데이터 양이 한계를 초과할 때 무엇이 발생하는지 설정합니다.

가능한 값:
- `throw`: 예외를 발생시킵니다 (기본값).
- `break`: 쿼리 실행을 중단하고 마치 소스 데이터가 부족한 것처럼 부분 결과를 반환합니다.

## shared_merge_tree_sync_parts_on_partition_operations {#shared_merge_tree_sync_parts_on_partition_operations} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "1"},{"label": "New setting. By default parts are always synchronized"}]}]}/>

SMT 테이블에서 MOVE|REPLACE|ATTACH 파티션 작업 후 데이터 파트 집합을 자동으로 동기화합니다. 클라우드 전용

## short_circuit_function_evaluation {#short_circuit_function_evaluation} 

<SettingsInfoBlock type="ShortCircuitFunctionEvaluation" default_value="enable" />

[if](../../sql-reference/functions/conditional-functions.md/#if), [multiIf](../../sql-reference/functions/conditional-functions.md/#multiIf), [and](/sql-reference/functions/logical-functions#and), [or](/sql-reference/functions/logical-functions#or) 함수를 [단축 평가 방식](https://en.wikipedia.org/wiki/Short-circuit_evaluation)으로 계산할 수 있도록 해줍니다. 이는 이러한 함수에서 복잡한 표현식의 실행을 최적화하고 예기치 않은 경우에 나오는 예외 (예: 제로로 나누기)를 방지하는 데 도움이 됩니다.

가능한 값:

- `enable` — 적합한 함수에 대해 단축 기능 평가를 활성화합니다 (예외를 발생시킬 수 있거나 계산을 많이 소모할 수 있음).
- `force_enable` — 모든 함수에 대해 단축 기능 평가를 활성화합니다.
- `disable` — 단축 기능 평가를 비활성화합니다.

## short_circuit_function_evaluation_for_nulls {#short_circuit_function_evaluation_for_nulls} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "Allow to execute functions with Nullable arguments only on rows with non-NULL values in all arguments"}]}]}/>

인수 중 하나가 NULL일 때 NULL을 반환하는 함수의 평가를 최적화합니다. 함수의 인수에서 NULL 값의 비율이 short_circuit_function_evaluation_for_nulls_threshold를 초과하면 시스템은 행 단위로 함수를 평가하지 않고 즉시 모든 행에 대한 NULL을 반환하여 불필요한 계산을 피합니다.

## short_circuit_function_evaluation_for_nulls_threshold {#short_circuit_function_evaluation_for_nulls_threshold} 

<SettingsInfoBlock type="Double" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "Ratio threshold of NULL values to execute functions with Nullable arguments only on rows with non-NULL values in all arguments. Applies when setting short_circuit_function_evaluation_for_nulls is enabled."}]}]}/>

모든 인수가 비-NULL 값인 행에서만 Nullable 인수가 있는 함수가 실행되기 위한 NULL 값의 비율 임계값. short_circuit_function_evaluation_for_nulls 설정이 활성화될 때 적용됩니다. NULL 값을 포함한 행의 비율이 총 행 수를 초과하면 이 NULL 값을 포함한 행은 평가되지 않습니다.

## show_data_lake_catalogs_in_system_tables {#show_data_lake_catalogs_in_system_tables} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "1"},{"label": "New setting"}]}, {"id": "row-2","items": [{"label": "25.10"},{"label": "0"},{"label": "Disable catalogs in system tables by default"}]}]}/>

시스템 테이블에서 데이터 레이크 카탈로그를 표시할 수 있도록 활성화합니다.

## show_table_uuid_in_table_create_query_if_not_nil {#show_table_uuid_in_table_create_query_if_not_nil} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "20.7"},{"label": "0"},{"label": "Stop showing  UID of the table in its CREATE query for Engine=Atomic"}]}]}/>

`SHOW TABLE` 쿼리 표시를 설정합니다.

가능한 값:

- 0 — UUID 없이 쿼리가 표시됩니다.
- 1 — UUID가 포함된 쿼리가 표시됩니다.

## single_join_prefer_left_table {#single_join_prefer_left_table} 

단일 JOIN에서 식별자가 모호할 경우 왼쪽 테이블을 선호합니다.

## skip_redundant_aliases_in_udf {#skip_redundant_aliases_in_udf} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "0"},{"label": "When enabled, this allows you to use the same user defined function several times for several materialized columns in the same table."}]}]}/>

사용자 정의 함수에서 불필요한 별칭을 사용하지 않습니다 (대체). 사용이 간편해지도록 합니다.

가능한 값:

- 1 — UDF에서 별칭을 건너뜁니다 (대체).
- 0 — UDF에서 별칭을 건너뛰지 않습니다 (대체).

**예**

활성화 및 비활성화 시의 차이:

쿼리:

```sql
SET skip_redundant_aliases_in_udf = 0;
CREATE FUNCTION IF NOT EXISTS test_03274 AS ( x ) -> ((x + 1 as y, y + 2));

EXPLAIN SYNTAX SELECT test_03274(4 + 2);
```

결과:

```text
SELECT ((4 + 2) + 1 AS y, y + 2)
```

쿼리:

```sql
SET skip_redundant_aliases_in_udf = 1;
CREATE FUNCTION IF NOT EXISTS test_03274 AS ( x ) -> ((x + 1 as y, y + 2));

EXPLAIN SYNTAX SELECT test_03274(4 + 2);
```

결과:

```text
SELECT ((4 + 2) + 1, ((4 + 2) + 1) + 2)
```

## skip_unavailable_shards {#skip_unavailable_shards} 

<SettingsInfoBlock type="Bool" default_value="0" />

사용할 수 없는 샤드를 조용히 건너뛰는 기능을 활성화 또는 비활성화합니다.

샤드는 모든 복제본이 사용할 수 없는 경우 사용 불가능하다고 간주됩니다. 복제본이 사용 불가능한 경우는 다음과 같습니다:

- ClickHouse가 어떤 이유로 복제본에 연결할 수 없는 경우.
  
    복제본에 연결할 때 ClickHouse는 여러 번 시도를 수행합니다. 이러한 모든 시도가 실패할 경우 복제본은 사용 불가능하다고 간주됩니다.

- DNS를 통해 복제본이 확인되지 않는 경우.
  
    복제본의 호스트 이름이 DNS를 통해 확인되지 않는 경우 다음과 같은 상황을 나타낼 수 있습니다:

    - 복제본의 호스트에 DNS 레코드가 없습니다. 이는 동적 DNS를 사용하는 시스템, 예를 들어 [Kubernetes](https://kubernetes.io)에서 노드가 다운타임 동안 확인할 수 없을 때 발생할 수 있으며, 이는 오류가 아닙니다.

    - 구성 오류. ClickHouse 구성 파일에 잘못된 호스트 이름이 포함되어 있습니다.

가능한 값:

- 1 — 건너뛰기 활성화.

    샤드가 사용 불가능한 경우 ClickHouse는 부분 데이터에 따라 결과를 반환하고 노드 상태 문제를 보고하지 않습니다.

- 0 — 건너뛰기 비활성화.

    샤드가 사용 불가능한 경우 ClickHouse는 예외를 발생시킵니다.

## sleep_after_receiving_query_ms {#sleep_after_receiving_query_ms} 

쿼리를 수신한 후 TCPHandler에서 대기하는 시간

## sleep_in_send_data_ms {#sleep_in_send_data_ms} 

TCPHandler에서 데이터를 전송하는 동안 대기하는 시간

## sleep_in_send_tables_status_ms {#sleep_in_send_tables_status_ms} 

TCPHandler에서 테이블 상태 응답을 전송하는 동안 대기하는 시간

## sort_overflow_mode {#sort_overflow_mode} 

정렬 전에 수신된 행 수가 한계 중 하나를 초과할 경우 발생하는 일을 설정합니다.

가능한 값:
- `throw`: 예외를 발생시킵니다.
- `break`: 쿼리 실행을 중단하고 부분 결과를 반환합니다.

## split_intersecting_parts_ranges_into_layers_final {#split_intersecting_parts_ranges_into_layers_final} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "Allow to split intersecting parts ranges into layers during FINAL optimization"}]}, {"id": "row-2","items": [{"label": "24.1"},{"label": "1"},{"label": "Allow to split intersecting parts ranges into layers during FINAL optimization"}]}]}/>

FINAL 최적화 중 겹치는 파트 범위를 레이어로 분할합니다.

## split_parts_ranges_into_intersecting_and_non_intersecting_final {#split_parts_ranges_into_intersecting_and_non_intersecting_final} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "Allow to split parts ranges into intersecting and non intersecting during FINAL optimization"}]}, {"id": "row-2","items": [{"label": "24.1"},{"label": "1"},{"label": "Allow to split parts ranges into intersecting and non intersecting during FINAL optimization"}]}]}/>

FINAL 최적화 중 파트 범위를 겹치는 범위와 비겹치는 범위로 분할합니다.

## splitby_max_substrings_includes_remaining_string {#splitby_max_substrings_includes_remaining_string} 

함수 [splitBy*()](../../sql-reference/functions/splitting-merging-functions.md)에서 인수 `max_substrings` > 0이 남은 문자열을 결과 배열의 마지막 요소에 포함할지 여부를 제어합니다.

가능한 값:

- `0` - 남은 문자열은 결과 배열의 마지막 요소에 포함되지 않습니다.
- `1` - 남은 문자열은 결과 배열의 마지막 요소에 포함됩니다. 이는 Spark의 [`split()`](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.split.html) 함수 및 Python의 ['string.split()'](https://docs.python.org/3/library/stdtypes.html#str.split) 메소드의 동작입니다.

## stop_refreshable_materialized_views_on_startup {#stop_refreshable_materialized_views_on_startup} 

<ExperimentalBadge/>

서버 시작 시, SYSTEM STOP VIEWS와 마찬가지로 새로 고칠 수 있는 물리화된 뷰의 예약을 방지합니다. 이후 `SYSTEM START VIEWS` 또는 `SYSTEM START VIEW <name>`로 수동 시작할 수 있습니다. 새로 생성된 뷰에도 적용됩니다. 새로 고칠 수 없는 물리화된 뷰에는 영향을 미치지 않습니다.

## storage_file_read_method {#storage_file_read_method} 

저장 파일에서 데이터를 읽는 방법으로, `read`, `pread`, `mmap` 중 하나입니다. mmap 방법은 clickhouse-server에 적용되지 않습니다 (clickhouse-local을 위한 것입니다).

## storage_system_stack_trace_pipe_read_timeout_ms {#storage_system_stack_trace_pipe_read_timeout_ms} 

`system.stack_trace` 테이블을 쿼리할 때 스레드로부터 정보를 수신하기 위해 파이프에서 읽는 최대 시간. 이 설정은 테스트 용도로 사용되며 사용자가 변경하려는 것이 아닙니다.

## stream_flush_interval_ms {#stream_flush_interval_ms} 

타임아웃 발생 시 또는 쓰레드가 [max_insert_block_size](#max_insert_block_size) 행을 생성할 때 스트리밍인 테이블에 대해 작동합니다.

기본값은 7500입니다.

값이 작을수록 데이터를 테이블에 더 자주 플러시합니다. 값이 너무 낮으면 성능 저하가 발생합니다.

## stream_like_engine_allow_direct_select {#stream_like_engine_allow_direct_select} 

Kafka, RabbitMQ, FileLog, Redis Streams 및 NATS 엔진에 대한 직접 SELECT 쿼리를 허용합니다. 연결된 물리화된 뷰가 있는 경우, 이 설정이 활성화되어도 SELECT 쿼리는 허용되지 않습니다.

## stream_like_engine_insert_queue {#stream_like_engine_insert_queue} 

스트림처럼 보이는 엔진이 여러 큐에서 읽을 경우, 쓰기 시 삽입할 큐를 사용자에게 선택하게 합니다. Redis Streams 및 NATS에서 사용됩니다.

## stream_poll_timeout_ms {#stream_poll_timeout_ms} 

스트리밍 스토리지에서 데이터를 폴링하기 위한 타임아웃.

## system_events_show_zero_values {#system_events_show_zero_values} 

[`system.events`](../../operations/system-tables/events.md)에서 0값 이벤트를 선택할 수 있도록 합니다.

일부 모니터링 시스템은 메트릭 값이 0일 경우에도 각 체크포인트에 모든 메트릭 값을 전달해야 합니다.

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.

**예제**

쿼리

```sql
SELECT * FROM system.events WHERE event='QueryMemoryLimitExceeded';
```

결과

```text
Ok.
```

쿼리
```sql
SET system_events_show_zero_values = 1;
SELECT * FROM system.events WHERE event='QueryMemoryLimitExceeded';
```

결과

```text
┌─event────────────────────┬─value─┬─description───────────────────────────────────────────┐
│ QueryMemoryLimitExceeded │     0 │ Number of times when memory limit exceeded for query. │
└──────────────────────────┴───────┴───────────────────────────────────────────────────────┘
```

## table_engine_read_through_distributed_cache {#table_engine_read_through_distributed_cache} 

<CloudOnlyBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.7"},{"label": "0"},{"label": "New setting"}]}]}/>

ClickHouse Cloud에서만 적용됩니다. 테이블 엔진 / 테이블 함수 (s3, azure 등)를 통해 분산 캐시에서 읽기를 허용합니다.

## table_function_remote_max_addresses {#table_function_remote_max_addresses} 

[remote](../../sql-reference/table-functions/remote.md) 함수에 대해 패턴에서 생성되는 최대 주소 수를 설정합니다.

가능한 값:

- 양의 정수.

## tcp_keep_alive_timeout {#tcp_keep_alive_timeout} 

TCP가 keepalive 프로브를 전송하기 시작하기 전에 연결이 유휴 상태로 유지되어야 하는 시간(초)

## temporary_data_in_cache_reserve_space_wait_lock_timeout_milliseconds {#temporary_data_in_cache_reserve_space_wait_lock_timeout_milliseconds} 

파일 시스템 캐시에서 임시 데이터의 공간 예약을 위한 캐시 잠금 대기 시간

## temporary_files_buffer_size {#temporary_files_buffer_size} 

임시 파일 작성자를 위한 버퍼 크기. 더 큰 버퍼 크기는 시스템 호출을 줄이지만, 메모리 소비가 더 많아집니다.

## temporary_files_codec {#temporary_files_codec} 

디스크에서 정렬 및 조인 작업에 사용되는 임시 파일에 대한 압축 코덱을 설정합니다.

가능한 값:

- LZ4 — [LZ4](https://en.wikipedia.org/wiki/LZ4_(compression_algorithm)) 압축이 적용됩니다.
- NONE — 압축이 적용되지 않습니다.

## text_index_use_bloom_filter {#text_index_use_bloom_filter} 

테스트 목적으로, 텍스트 인덱스에서 블룸 필터 사용을 활성화 또는 비활성화합니다.

## throw_if_deduplication_in_dependent_materialized_views_enabled_with_async_insert {#throw_if_deduplication_in_dependent_materialized_views_enabled_with_async_insert} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "Deduplication in dependent materialized view cannot work together with async inserts."}]}]}/>

`async_insert`와 함께 `deduplicate_blocks_in_dependent_materialized_views` 설정이 활성화된 경우 INSERT 쿼리에서 예외를 발생시킵니다. 이러한 기능은 함께 작동할 수 없기 때문에 정확성을 보장합니다.

## throw_if_no_data_to_insert {#throw_if_no_data_to_insert} 

빈 INSERT를 허용하거나 금지합니다. 기본적으로 활성화되어 있으며 (빈 삽입 시 오류를 발생시킴) [`clickhouse-client`](/interfaces/cli) 또는 [gRPC 인터페이스](/interfaces/grpc)를 사용하는 INSERT에만 적용됩니다.

## throw_on_error_from_cache_on_write_operations {#throw_on_error_from_cache_on_write_operations} 

쓰기 작업 (INSERT, 머지)에서 캐시 오류를 무시합니다.

## throw_on_max_partitions_per_insert_block {#throw_on_max_partitions_per_insert_block} 

`max_partitions_per_insert_block`에 도달했을 때의 동작을 제어할 수 있습니다.

가능한 값:
- `true`  - 삽입 블록이 `max_partitions_per_insert_block`에 도달했을 때 예외가 발생합니다.
- `false` - `max_partitions_per_insert_block`에 도달했을 때 경고가 로그됩니다.

:::tip
이 설정은 [`max_partitions_per_insert_block`](/operations/settings/settings#max_partitions_per_insert_block)를 변경할 때 사용자에게 미치는 영향을 이해하는 데 유용할 수 있습니다.
:::

## throw_on_unsupported_query_inside_transaction {#throw_on_unsupported_query_inside_transaction} 

<ExperimentalBadge/>

트랜잭션 내에서 지원되지 않는 쿼리가 사용되면 예외를 발생시킵니다.

## timeout_before_checking_execution_speed {#timeout_before_checking_execution_speed} 

지정된 시간이 초과한 후 실행 속도가 너무 느리지 않은지 체크합니다 (최소 실행 속도보다 낮지 않음).

## timeout_overflow_mode {#timeout_overflow_mode} 

쿼리가 `max_execution_time`를 초과하거나 예상 실행 시간이 `max_estimated_execution_time`보다 길 경우 수행할 작업을 설정합니다.

가능한 값:
- `throw`: 예외를 발생시킵니다 (기본값).
- `break`: 쿼리 실행을 중단하고 마치 소스 데이터가 부족한 것처럼 부분 결과를 반환합니다.

## timeout_overflow_mode_leaf {#timeout_overflow_mode_leaf} 

리프 노드에서 쿼리가 `max_execution_time_leaf`보다 길 경우 발생하는 일을 설정합니다.

가능한 값:
- `throw`: 예외를 발생시킵니다 (기본값).
- `break`: 쿼리 실행을 중단하고 마치 소스 데이터가 부족한 것처럼 부분 결과를 반환합니다.

## totals_auto_threshold {#totals_auto_threshold} 

`totals_mode = 'auto'`의 임계값입니다. "WITH TOTALS modifier" 섹션을 참조하세요.

## totals_mode {#totals_mode} 

HAVING이 존재할 때 또는 max_rows_to_group_by 및 group_by_overflow_mode = 'any'가 존재할 때 TOTALS를 계산하는 방법입니다. "WITH TOTALS modifier" 섹션을 참조하세요.

## trace_profile_events {#trace_profile_events} 

프로파일 이벤트 업데이트 시 스택 추적 수집을 활성화 또는 비활성화하며, 프로파일 이벤트의 이름과 증가 값을 함께 수집하여 [trace_log](/operations/system-tables/trace_log)로 전송합니다.

가능한 값:

- 1 — 프로파일 이벤트 추적 활성화.
- 0 — 프로파일 이벤트 추적 비활성화.

## transfer_overflow_mode {#transfer_overflow_mode} 

데이터 양이 한계를 초과할 때 발생하는 일을 설정합니다.

가능한 값:
- `throw`: 예외를 발생시킵니다 (기본값).
- `break`: 쿼리 실행을 중단하고 마치 소스 데이터가 부족한 것처럼 부분 결과를 반환합니다.

## transform_null_in {#transform_null_in} 

[IN](../../sql-reference/operators/in.md) 연산자에 대해 [NULL](/sql-reference/syntax#null) 값의 동등성을 활성화합니다.

기본적으로 `NULL` 값은 비교할 수 없다는 것을 의미합니다. 따라서 비교 `expr = NULL`은 항상 `false`를 반환해야 합니다. 이 설정이 활성화되면 `NULL = NULL`이 `IN` 연산자에 대해 `true`를 반환합니다.

가능한 값:

- 0 — `IN` 연산자에서 `NULL` 값 비교가 `false`를 반환합니다.
- 1 — `IN` 연산자에서 `NULL` 값 비교가 `true`를 반환합니다.

**예제**

`null_in` 테이블을 고려해 보세요:

```text
┌──idx─┬─────i─┐
│    1 │     1 │
│    2 │  NULL │
│    3 │     3 │
└──────┴───────┘
```

쿼리:

```sql
SELECT idx, i FROM null_in WHERE i IN (1, NULL) SETTINGS transform_null_in = 0;
```

결과:

```text
┌──idx─┬────i─┐
│    1 │    1 │
└──────┴──────┘
```

쿼리:

```sql
SELECT idx, i FROM null_in WHERE i IN (1, NULL) SETTINGS transform_null_in = 1;
```

결과:

```text
┌──idx─┬─────i─┐
│    1 │     1 │
│    2 │  NULL │
└──────┴───────┘
```

**참고**

- [IN 연산자에서의 NULL 처리](/sql-reference/operators/in#null-processing)

## traverse_shadow_remote_data_paths {#traverse_shadow_remote_data_paths} 

쿼리 system.remote_data_paths에서 실제 테이블 데이터 외에 얼어붙은 데이터(그림자 디렉토리)를 탐색합니다.

## union_default_mode {#union_default_mode} 

`SELECT` 쿼리 결과를 결합하는 모드를 설정합니다. 이 설정은 명시적으로 `UNION ALL`이나 `UNION DISTINCT`를 지정하지 않을 경우에만 사용됩니다.

가능한 값:

- `'DISTINCT'` — ClickHouse는 중복된 행을 제거하고 쿼리를 결합한 결과로 행을 출력합니다.
- `'ALL'` — ClickHouse는 중복된 행을 포함하여 쿼리를 결합한 모든 행을 출력합니다.
- `''` — `UNION`과 함께 사용할 경우 ClickHouse는 예외를 발생시킵니다.

[UNION](../../sql-reference/statements/select/union.md)에서 예제를 참조하세요.

## unknown_packet_in_send_data {#unknown_packet_in_send_data} 

N번째 데이터 패킷 대신 알 수 없는 패킷을 전송합니다.

## update_parallel_mode {#update_parallel_mode} 

동시 업데이트 쿼리의 동작을 결정합니다.

가능한 값:
- `sync` - 모든 `UPDATE` 쿼리를 순차적으로 실행합니다.
- `auto` - 한 쿼리에서 업데이트된 열 간에 의존성이 있는 경우에만 `UPDATE` 쿼리를 순차적으로 실행합니다.
- `async` - 업데이트 쿼리를 동기화하지 않습니다.

## update_sequential_consistency {#update_sequential_consistency} 

true로 설정된 경우 실행 전에 부품 세트를 최신 버전으로 업데이트합니다.

## use_async_executor_for_materialized_views {#use_async_executor_for_materialized_views} 

물리화된 뷰 쿼리를 비동기 및 잠재적으로 다중 스레드로 실행하도록 하여 INSERT 중 뷰 처리 속도를 높일 수 있지만, 메모리 사용량이 증가할 수 있습니다.

## use_cache_for_count_from_files {#use_cache_for_count_from_files} 

테이블 함수 `file`/`s3`/`url`/`hdfs`/`azureBlobStorage`로 파일에서 개수를 확인하는 동안 행 수를 캐시할 수 있도록 활성화합니다.

기본적으로 활성화되어 있습니다.

## use_client_time_zone {#use_client_time_zone} 

서버 시간대 대신 클라이언트 시간대를 사용하여 DateTime 문자열 값을 해석합니다.

## use_compact_format_in_distributed_parts_names {#use_compact_format_in_distributed_parts_names} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.1"},{"label": "1"},{"label": "Use compact format for async INSERT into Distributed tables by default"}]}]}/>

`Distributed` 엔진이 있는 테이블에 대해 배경(`distributed_foreground_insert`) INSERT를 위한 블록 저장에 대해 압축된 형식을 사용합니다.

가능한 값:

- 0 — `user[:password]@host:port#default_database` 디렉토리 형식을 사용합니다.
- 1 — `[shard{shard_index}[_replica{replica_index}]]` 디렉토리 형식을 사용합니다.

:::note
- `use_compact_format_in_distributed_parts_names=0`일 경우, 클러스터 정의의 변경 사항이 배경 INSERT에 적용되지 않습니다.
- `use_compact_format_in_distributed_parts_names=1`일 경우, 클러스터 정의에서 노드 순서를 변경하면 `shard_index`/`replica_index`가 변경되므로 주의하세요.
:::

## use_concurrency_control {#use_concurrency_control} 

서버의 동시성 제어를 준수합니다 (전역 서버 설정인 `concurrent_threads_soft_limit_num` 및 `concurrent_threads_soft_limit_ratio_to_cores` 참조). 비활성화할 경우, 서버가 과부하 상태일지라도 더 많은 스레드를 사용할 수 있도록 허용합니다 (일반 사용에는 권장되지 않으며 주로 테스트에 필요함).

## use_hedged_requests {#use_hedged_requests} 

원격 쿼리에 대한 헤지 요청 논리를 활성화합니다. 쿼리에 대해 다양한 복제본과 여러 연결을 설정할 수 있습니다. 새 연결은 기존 연결(복제본)이 `hedged_connection_timeout` 내에 설정되지 않았거나 `receive_data_timeout` 내에 데이터가 수신되지 않은 경우에 활성화됩니다. 쿼리는 비어 있지 않은 진행 패킷 (또는 데이터 패킷, `allow_changing_replica_until_first_data_packet`가 설정된 경우)을 전송하는 첫 번째 연결을 사용하며, 다른 연결은 취소됩니다. `max_parallel_replicas > 1`인 쿼리가 지원됩니다.

기본적으로 활성화되어 있습니다.

클라우드 기본값: `1`

## use_hive_partitioning {#use_hive_partitioning} 

활성화될 경우, ClickHouse는 파일과 같은 테이블 엔진 [File](/sql-reference/table-functions/file#hive-style-partitioning)/[S3](/sql-reference/table-functions/s3#hive-style-partitioning)/[URL](/sql-reference/table-functions/url#hive-style-partitioning)/[HDFS](/sql-reference/table-functions/hdfs#hive-style-partitioning)/[AzureBlobStorage](/sql-reference/table-functions/azureBlobStorage#hive-style-partitioning)에서 경로(`/name=value/`)의 하이브 스타일 파티셔닝을 감지하고 이를 쿼리에서 가상 열로 사용할 수 있도록 허용합니다. 이러한 가상 열은 파티셔닝 경로와 같은 이름을 가지지만 `_`로 시작합니다.

## use_iceberg_metadata_files_cache {#use_iceberg_metadata_files_cache} 

활성화될 경우, 아이스버그 테이블 함수 및 아이스버그 저장소가 아이스버그 메타데이터 파일 캐시를 활용할 수 있습니다.

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## use_iceberg_partition_pruning {#use_iceberg_partition_pruning} 

아이스버그 테이블에 대해 아이스버그 파티션 프루닝을 사용합니다.

## use_index_for_in_with_subqueries {#use_index_for_in_with_subqueries} 

IN 연산자의 오른쪽에 서브쿼리나 테이블 표현식이 있을 경우 인덱스를 사용해 보도록 합니다.

## use_index_for_in_with_subqueries_max_values {#use_index_for_in_with_subqueries_max_values} 

필터링을 위해 테이블 인덱스를 사용할 수 있는 IN 연산자의 오른쪽 측의 집합의 최대 크기입니다. 이는 성능 저하와 추가 데이터 구조 준비로 인한 메모리 사용 증가를 피하도록 도와줍니다. 0은 제한 없음입니다.

## use_join_disjunctions_push_down {#use_join_disjunctions_push_down} 

JOIN 조건의 OR로 연결된 부분을 해당 입력 측으로 푸시하는 것을 활성화합니다 ("부분 푸시다운"). 이를 통해 스토리지 엔진은 더 일찍 필터링할 수 있으며 데이터 읽기를 줄일 수 있습니다. 이 최적화는 의미론을 보존하며, 최상위 OR 분기가 대상 측에 대해 적어도 하나의 결정론적 술어를 제공할 때만 적용됩니다.

## use_legacy_to_time {#use_legacy_to_time} 

활성화될 경우, 고정된 날짜로 날짜 및 시간을 변환하는 구식 toTime 함수를 사용할 수 있습니다. 그렇지 않으면, 다양한 유형의 데이터를 Time 형식으로 변환하는 새로운 toTime 함수를 사용합니다. 구식 함수는 또한 toTimeWithFixedDate로 조건 없이 접근할 수 있습니다.

## use_page_cache_for_disks_without_file_cache {#use_page_cache_for_disks_without_file_cache} 

파일 시스템 캐시가 활성화되지 않은 원격 디스크에 대해 사용자 공간 페이지 캐시를 사용합니다.

## use_page_cache_with_distributed_cache {#use_page_cache_with_distributed_cache} 

분산 캐시를 사용하는 경우 사용자 공간 페이지 캐시를 사용합니다.

## use_query_cache {#use_query_cache} 

활성화될 경우, `SELECT` 쿼리는 [쿼리 캐시](../query-cache.md)를 활용할 수 있습니다. [enable_reads_from_query_cache](#enable_reads_from_query_cache) 및 [enable_writes_to_query_cache](#enable_writes_to_query_cache) 매개변수는 캐시의 사용 방식에 대해 좀 더 구체적으로 제어합니다.

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## use_query_condition_cache {#use_query_condition_cache} 

[쿼리 조건 캐시](/operations/query-condition-cache)를 활성화합니다. 캐시는 WHERE 절에서 조건을 충족하지 않는 데이터 파트의 범위를 저장하고, 이후 쿼리에 대해 일시적인 인덱스로 이 정보를 재사용합니다.

가능한 값:

- 0 - 비활성화
- 1 - 활성화

## use_roaring_bitmap_iceberg_positional_deletes {#use_roaring_bitmap_iceberg_positional_deletes} 

아이스버그 위치 삭제를 위해 로리빙 비트맵을 사용합니다.

## use_skip_indexes {#use_skip_indexes} 

쿼리 실행 중 데이터 스킵 인덱스를 사용합니다.

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.

## use_skip_indexes_if_final {#use_skip_indexes_if_final} 

FINAL 수정자가 있는 쿼리를 실행할 때 스킵 인덱스가 사용되는지 여부를 제어합니다.

스킵 인덱스는 최신 데이터를 포함하는 행(그라뉼)을 제외할 수 있으므로 FINAL 수정자가 있는 쿼리에서 잘못된 결과를 초래할 수 있습니다. 이 설정이 활성화되면 FINAL 수정자가 있는 경우에도 스킵 인덱스가 적용되어 성능이 개선될 수 있지만 최근 업데이트가 놓칠 위험이 있습니다. 이 설정은 기본값이 활성화된 use_skip_indexes_if_final_exact_mode 설정과 동기화하여 활성화해야 합니다.

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.

## use_skip_indexes_if_final_exact_mode {#use_skip_indexes_if_final_exact_mode} 

FINAL 수정자가 있는 쿼리 실행 시 스킵 인덱스에 의해 반환된 그라뉼이 최신 데이터가 포함된 새 파트에서 확장되는지 여부를 제어합니다.

스킵 인덱스를 사용하면 최신 데이터를 포함하는 행(그라뉼)을 제외할 수 있으므로 잘못된 결과를 초래할 수 있습니다. 이 설정은 스킵 인덱스가 반환한 범위와 겹치는 새 파트를 스캔하여 정확한 결과가 반환되도록 보장할 수 있습니다. 이 설정은 가까운 결과가 애플리케이션에 괜찮은 경우가 아닌 한 비활성화해야 합니다.

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.

## use_skip_indexes_on_data_read {#use_skip_indexes_on_data_read} 

데이터 읽기 중에 데이터 스킵 인덱스 사용을 활성화합니다.

활성화되면, 스킵 인덱스는 각 데이터 그라뉼이 읽힐 때 동적으로 평가되며, 쿼리 실행이 시작되기 전에 미리 분석되지 않습니다. 이는 쿼리 시작 지연을 줄일 수 있습니다.

가능한 값:

- 0 — 비활성화.
- 1 — 활성화.

## use_statistics_cache {#use_statistics_cache} 

<ExperimentalBadge/>

각 파트의 통계를 로드하는 오버헤드를 피하기 위해 쿼리에서 통계 캐시를 사용합니다.

## use_structure_from_insertion_table_in_table_functions {#use_structure_from_insertion_table_in_table_functions} 

데이터로부터 스키마 추론 대신 삽입 테이블의 구조를 사용합니다. 가능한 값: 0 - 비활성화, 1 - 활성화, 2 - 자동.

## use_text_index_dictionary_cache {#use_text_index_dictionary_cache} 

역직렬화된 텍스트 인덱스 사전 블록의 캐시를 사용할지 여부입니다. 텍스트 인덱스 사전 블록 캐싱을 사용하면 대량의 텍스트 인덱스 쿼리를 처리할 때 지연 시간을 줄이고 처리량을 증가시킬 수 있습니다.

## use_text_index_header_cache {#use_text_index_header_cache} 

역직렬화된 텍스트 인덱스 헤더의 캐시를 사용할지 여부입니다. 텍스트 인덱스 헤더 캐싱을 사용하면 대량의 텍스트 인덱스 쿼리를 처리할 때 지연 시간을 줄이고 처리량을 증가시킬 수 있습니다.

## use_text_index_postings_cache {#use_text_index_postings_cache} 

역직렬화된 텍스트 인덱스 게시 목록의 캐시를 사용할지 여부입니다. 텍스트 인덱스 게시 캐싱을 사용하면 대량의 텍스트 인덱스 쿼리를 처리할 때 지연 시간을 줄이고 처리량을 증가시킬 수 있습니다.

## use_uncompressed_cache {#use_uncompressed_cache} 

압축되지 않은 블록의 캐시를 사용할지 여부입니다. 0 또는 1을 사용합니다. 기본적으로 0 (비활성화)입니다. 압축되지 않은 캐시 (MergeTree 계열의 테이블 전용)를 사용하면 짧은 쿼리를 대량으로 처리할 때 지연 시간을 줄이고 처리량을 증가시킬 수 있습니다. 빈번한 짧은 요청을 보내는 사용자에게 이 설정을 활성화합니다. 또한 [uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size) 구성 매개변수 (구성 파일에만 설정됨)의 크기에 주의하세요. 기본값은 8 GiB입니다. 압축되지 않은 캐시는 필요에 따라 채워지고 가장 적게 사용되는 데이터가 자동으로 삭제됩니다.

최소한 어느 정도 대량의 데이터를 읽는 쿼리 (백만 행 이상)에서는 진정으로 작은 쿼리를 위해 여유 공간을 절약하기 위해 압축되지 않은 캐시가 자동으로 비활성화됩니다. 이는 'use_uncompressed_cache' 설정을 항상 1로 설정할 수 있음을 의미합니다.

## use_variant_as_common_type {#use_variant_as_common_type} 

인수 유형에 대한 공통 유형이 없을 때 [if](../../sql-reference/functions/conditional-functions.md/#if)/[multiIf](../../sql-reference/functions/conditional-functions.md/#multiIf)/[array](../../sql-reference/functions/array-functions.md)/[map](../../sql-reference/functions/tuple-map-functions.md) 함수의 결과 유형으로 `Variant` 유형을 사용할 수 있도록 허용합니다.

예:

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(if(number % 2, number, range(number))) as variant_type FROM numbers(1);
SELECT if(number % 2, number, range(number)) as variant FROM numbers(5);
```

```text
┌─variant_type───────────────────┐
│ Variant(Array(UInt64), UInt64) │
└────────────────────────────────┘
┌─variant───┐
│ []        │
│ 1         │
│ [0,1]     │
│ 3         │
│ [0,1,2,3] │
└───────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(multiIf((number % 4) = 0, 42, (number % 4) = 1, [1, 2, 3], (number % 4) = 2, 'Hello, World!', NULL)) AS variant_type FROM numbers(1);
SELECT multiIf((number % 4) = 0, 42, (number % 4) = 1, [1, 2, 3], (number % 4) = 2, 'Hello, World!', NULL) AS variant FROM numbers(4);
```

```text
─variant_type─────────────────────────┐
│ Variant(Array(UInt8), String, UInt8) │
└──────────────────────────────────────┘

┌─variant───────┐
│ 42            │
│ [1,2,3]       │
│ Hello, World! │
│ ᴺᵁᴸᴸ          │
└───────────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(array(range(number), number, 'str_' || toString(number))) as array_of_variants_type from numbers(1);
SELECT array(range(number), number, 'str_' || toString(number)) as array_of_variants FROM numbers(3);
```

```text
┌─array_of_variants_type────────────────────────┐
│ Array(Variant(Array(UInt64), String, UInt64)) │
└───────────────────────────────────────────────┘

┌─array_of_variants─┐
│ [[],0,'str_0']    │
│ [[0],1,'str_1']   │
│ [[0,1],2,'str_2'] │
└───────────────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(map('a', range(number), 'b', number, 'c', 'str_' || toString(number))) as map_of_variants_type from numbers(1);
SELECT map('a', range(number), 'b', number, 'c', 'str_' || toString(number)) as map_of_variants FROM numbers(3);
```

```text
┌─map_of_variants_type────────────────────────────────┐
│ Map(String, Variant(Array(UInt64), String, UInt64)) │
└─────────────────────────────────────────────────────┘

┌─map_of_variants───────────────┐
│ {'a':[],'b':0,'c':'str_0'}    │
│ {'a':[0],'b':1,'c':'str_1'}   │
│ {'a':[0,1],'b':2,'c':'str_2'} │
└───────────────────────────────┘
```

## use_with_fill_by_sorting_prefix {#use_with_fill_by_sorting_prefix} 

ORDER BY 절에서 WITH FILL 열 앞에 있는 열이 정렬 접두사를 형성합니다. 정렬 접두사에서 서로 다른 값이 있는 행은 독립적으로 채워집니다.

## validate_enum_literals_in_operators {#validate_enum_literals_in_operators} 

활성화될 경우, `IN`, `NOT IN`, `==`, `!=`와 같은 연산자에서 열거형 리터럴을 열거형 유형과 비교하고 리터럴이 유효한 열거형 값이 아닐 경우 예외를 발생시킵니다.

## validate_mutation_query {#validate_mutation_query} 

변경 쿼리를 수용하기 전에 검증합니다. 변경은 백그라운드에서 실행되며 잘못된 쿼리를 실행하면 변경이 정지되어 수동 개입이 필요하게 됩니다.

오류가 발생하는 비역호환성 버그를 만나면 이 설정을 변경하세요.

## validate_polygons {#validate_polygons} 

다각형이 자기 교차하거나 점 접할 경우 [pointInPolygon](/sql-reference/functions/geo/coordinates#pointinpolygon) 함수에서 예외를 발생시키는 기능을 활성화 또는 비활성화합니다.

가능한 값:

- 0 — 예외 발생이 비활성화됩니다. `pointInPolygon`은 유효하지 않은 다각형을 허용하고 잘못된 결과를 반환할 수 있습니다.
- 1 — 예외 발생이 활성화됩니다.
## vector_search_filter_strategy {#vector_search_filter_strategy} 



<SettingsInfoBlock type="VectorSearchFilterStrategy" default_value="auto" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "auto"},{"label": "New setting"}]}]}/>

벡터 검색 쿼리에 WHERE 절이 포함되어 있는 경우, 이 설정은 먼저 평가될지 (사전 필터링) 아니면 벡터 유사성 인덱스가 먼저 확인될지 (사후 필터링)를 결정합니다. 가능한 값은 다음과 같습니다:
- 'auto' - 사후 필터링 (정확한 의미는 향후 변경될 수 있습니다).
- 'postfilter' - 벡터 유사성 인덱스를 사용하여 가장 가까운 이웃을 식별한 다음 다른 필터를 적용합니다.
- 'prefilter' - 다른 필터를 먼저 평가한 다음, 이웃을 식별하기 위해 브루트 포스 검색을 수행합니다.
## vector_search_index_fetch_multiplier {#vector_search_index_fetch_multiplier} 



<SettingsInfoBlock type="Float" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "1"},{"label": "Alias for setting 'vector_search_postfilter_multiplier'"}]}]}/>

벡터 유사성 인덱스에서 가져온 가장 가까운 이웃의 수를 이 숫자로 곱합니다. 다른 술어와 함께 사후 필터링을 할 때 또는 'vector_search_with_rescoring = 1'로 설정할 때만 적용됩니다.
## vector_search_with_rescoring {#vector_search_with_rescoring} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting."}]}]}/>

ClickHouse가 벡터 유사성 인덱스를 사용하는 쿼리에 대해 재점수를 수행하는지 여부입니다.
재점수 없이 벡터 유사성 인덱스는 가장 잘 맞는 행을 직접 반환합니다.
재점수와 함께, 행은 그라뉼 수준으로 외삽되고 그라뉼 내의 모든 행이 다시 확인됩니다.
대부분의 상황에서, 재점수는 정확도에만 미미한 도움을 주지만 벡터 검색 쿼리의 성능을 크게 저하시킵니다.
참고: 재점수 없이 실행되고 병렬 복제본이 활성화된 쿼리는 재점수로 되돌아갈 수 있습니다.
## wait_changes_become_visible_after_commit_mode {#wait_changes_become_visible_after_commit_mode} 

<ExperimentalBadge/>



<SettingsInfoBlock type="TransactionsWaitCSNMode" default_value="wait_unknown" />

커밋된 변경 사항이 최신 스냅샷에서 실제로 보이도록 대기합니다.
## wait_for_async_insert {#wait_for_async_insert} 



<SettingsInfoBlock type="Bool" default_value="1" />

true인 경우 비동기 삽입 처리를 대기합니다.
## wait_for_async_insert_timeout {#wait_for_async_insert_timeout} 



<SettingsInfoBlock type="Seconds" default_value="120" />

비동기 삽입 처리를 대기하기 위한 타임아웃입니다.
## wait_for_window_view_fire_signal_timeout {#wait_for_window_view_fire_signal_timeout} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Seconds" default_value="10" />

이벤트 시간 처리에서 윈도우 뷰 신호를 대기하기 위한 타임아웃입니다.
## window_view_clean_interval {#window_view_clean_interval} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Seconds" default_value="60" />

구식 데이터 정리를 위한 윈도우 뷰의 청소 간격(초)입니다.
## window_view_heartbeat_interval {#window_view_heartbeat_interval} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Seconds" default_value="15" />

쿼리가 살아 있음을 나타내기 위한 하트비트 간격(초)입니다.
## workload {#workload} 



<SettingsInfoBlock type="String" default_value="default" />

리소스에 접근하기 위해 사용될 작업의 이름입니다.
## write_full_path_in_iceberg_metadata {#write_full_path_in_iceberg_metadata} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.8"},{"label": "0"},{"label": "New setting."}]}]}/>

아이스버그 메타데이터 파일에 전체 경로(예: s3:// 포함)를 기록합니다.
## write_through_distributed_cache {#write_through_distributed_cache} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 분산 캐시에 쓰는 것을 허용합니다 (s3에 대한 쓰기도 분산 캐시를 통해 이루어집니다).
## write_through_distributed_cache_buffer_size {#write_through_distributed_cache_buffer_size} 

<CloudOnlyBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.7"},{"label": "0"},{"label": "New cloud setting"}]}]}/>

ClickHouse Cloud에서만 효과가 있습니다. 쓰기-통과 분산 캐시의 버퍼 크기를 설정합니다. 0이면 분산 캐시가 없었을 때 사용되었을 버퍼 크기를 사용합니다.
## zstd_window_log_max {#zstd_window_log_max} 



<SettingsInfoBlock type="Int64" default_value="0" />

ZSTD의 최대 윈도우 로그를 선택할 수 있습니다 (MergeTree 계열에는 사용되지 않음).
