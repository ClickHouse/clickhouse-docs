---
title: ClickHouse의 "Too many parts" 오류 해결
description: ClickHouse에서 "Too many parts" 오류를 데이터 삽입 속도를 최적화하고 MergeTree 설정을 조정하며 파티션을 효율적으로 관리하여 해결하는 방법을 알아봅니다.
date: 2023-03-20
tags: ['에러 및 예외']
keywords: ['Too many parts']
---

{frontMatter.description}

{/* 생략 */}

## DB::Exception: Too many parts (오류: 252). 머지 작업이 INSERT보다 현저히 느리게 처리됩니다 \{#dbexception-too-many-parts-252-merges-are-processing-significantly-slower-than-inserts\}

MergeTree 테이블에서 `parts_to_throw_insert` SETTING 한도에 도달했습니다.

다음과 같이 특정 테이블의 활성 파트 수를 모니터링할 수 있습니다:

```sql
select count(*) from system.parts where table = '<table_name>' and active == 1
```

ClickHouse에 데이터를 삽입할 때의 주요 요구 사항은 초당 너무 많은 `INSERT` SQL 문을 보내지 말아야 한다는 점입니다. 이상적인 기준은 초당(또는 몇 초에 한 번) 한 번의 insert입니다.

초당 100K 행을 삽입할 수는 있지만, 이는 하나의 큰 bulk `INSERT` SQL 문으로만 해야 합니다. *MergeTree 테이블에 초당 수백/수천 개의 insert SQL 문을 보내면 항상 어떤 오류가 발생하게 되며, 이는 설정을 조정한다고 해서 바뀌지 않습니다.

외부 시스템에서 여러 insert를 하나의 큰 bulk insert SQL 문으로 합칠 수 없다면, *MergeTree 테이블 앞에 Buffer 테이블을 만들어야 합니다.

1. 각 insert는 `/var/lib/clickhouse/.../table_name/`에 폴더 하나를 생성합니다. 해당 폴더 내부에는 각 컬럼마다 2개의 파일이 있는데, 하나는 데이터(압축) 파일이고, 다른 하나는 인덱스 파일입니다. 데이터는 이 파일들 안에서 기본 키(primary key)를 기준으로 물리적으로 정렬됩니다. 이 폴더들을 「**parts**」라고 부릅니다.

2. ClickHouse는 백그라운드에서 이런 작은 파트들을 더 큰 파트로 머지(merge)합니다. 머지할 파트는 몇 가지 규칙에 따라 선택됩니다. 두 개(또는 그 이상)의 파트를 머지한 후에는 더 큰 파트 하나가 생성되고, 기존 파트들은 삭제 대기 상태가 됩니다. 질문에 나열한 설정은 파트를 머지하는 규칙을 세밀하게 조정하는 데 사용됩니다. 머지 프로세스의 목표는 각 파티션별로 하나의 큰 파트(또는 너무 커서 머지할 가치가 없는 몇 개의 큰 파트)만 남기는 것입니다. 이 [코멘트](https://github.com/yandex/ClickHouse/issues/1661#issuecomment-352739726)도 함께 확인하십시오.

3. (예: 매우 많은 작은 insert를 수행하여) 새 파트를 너무 빠르게 생성하고, ClickHouse가 충분한 속도로 이를 머지하지 못하는 경우(새 파트가 ClickHouse가 머지할 수 있는 속도보다 더 빨리 생성되는 경우) 「Merges are processing significantly slower than inserts」 예외가 발생합니다. 제한값을 높여 볼 수는 있지만, 그러면 파일/디렉터리 수가 지나치게 많아져 파일 시스템(inode 제한 등)에 문제가 생길 수 있습니다.

4. 많은 파티션에 동시에 insert를 수행하면, 이 문제는 insert로 인해 영향을 받는 파티션 수만큼 증폭됩니다.

5. 나열된 설정 중 하나 또는 `max_insert_block_size` / `max_block_size` / `insert_format_max_block_size` / `max_client_network_bandwidth` 값으로 ClickHouse의 동작을 조정해 볼 수 있습니다. 그러나 더 나은 해결책은 단순히 예상된 속도로 데이터를 삽입하는 것입니다. 예상되는 속도는 다음과 같습니다: **1–2초에 한 번 insert, 각 insert는 10K–500K 행의 데이터**를 포함합니다.

6. 따라서 「Merges are processing significantly slower than inserts」 문제를 올바르게 해결하는 방법은 초당 insert 횟수와 각 insert에 포함되는 행 수를 조정하는 것입니다. 데이터가 행 단위로 들어오는 경우, 배치 insert를 사용해 작은 insert들을 하나의 더 큰 insert로 합치십시오. 한 번에 삽입해야 할 데이터가 너무 많은 경우에는 큰 insert를 조절하여 속도를 낮추십시오. 의미를 충분히 잘 이해하지 못한다면 ClickHouse 내부 동작을 변경하지 마십시오.

7. 데이터가 초당 500K 행보다 빠르게 들어온다면, 설정 조정이 아니라 해당 트래픽을 처리하기 위해 클러스터에 더 많은 서버가 필요할 가능성이 높습니다.

8. 백그라운드 머지 속도는 일반적으로 스토리지 속도, 사용 중인 압축 설정, MergeTree 옵션(머지 알고리즘: plain merge/aggregating/summing/collapsing 등), 그리고 사용 중인 정렬 키에 따라 달라집니다.
