[
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/cloud/features/04_infrastructure/warehouses.md",
    "line": 20,
    "header": "What is compute-compute separation?",
    "anchor": "what-is-compute-compute-separation",
    "issue_type": "what_is_delayed_answer",
    "reasoning": "Header asks 'What is X?' but the definition doesn't appear until later in the section",
    "first_sentence": "Compute-compute separation is available for Scale and Enterprise tiers. Each ClickHouse Cloud service includes: - A group of two or more ClickHouse nodes (or replicas) is required, but the child servi",
    "suggested_header": null,
    "full_content": "Compute-compute separation is available for Scale and Enterprise tiers.\n\nEach ClickHouse Cloud service includes:\n- A group of two or more ClickHouse nodes (or replicas) is required, but the child services can be single replica.\n- An endpoint (or multiple endpoints created via ClickHouse Cloud UI console), which is a service URL that you use to connect to the service (for example, `https://dv2fzne24g.us-east-1.aws.clickhouse.cloud:8443`).\n- An object storage folder where the service stores all the data and partially metadata:\n\n:::note\nChild single services can scale vertically unlike single parent services.\n:::\n\n<Image img={compute_1} size=\"md\" alt=\"Current service in ClickHouse Cloud\" />\n\n<br />\n\n_Fig. 1 - current service in ClickHouse Cloud_\n\nCompute-compute separation allows you to create multiple compute node groups, each with its own endpoint, that are using the same object storage folder, and thus, with the same tables, views, etc.\n\nEach compute node group will have its own endpoi"
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/cloud/guides/infrastructure/01_deployment_options/byoc/03_onboarding/01_standard.md",
    "line": 16,
    "header": "What is Standard Onboarding?",
    "anchor": "what-is-standard-onboarding",
    "issue_type": "what_is_delayed_answer",
    "reasoning": "Header asks 'What is X?' but the definition doesn't appear until later in the section",
    "first_sentence": "**Standard onboarding** is the default, guided workflow for deploying ClickHouse in your own cloud account using BYOC. In this approach, ClickHouse Cloud provisions all of the core cloud resources req",
    "suggested_header": null,
    "full_content": "**Standard onboarding** is the default, guided workflow for deploying ClickHouse in your own cloud account using BYOC. In this approach, ClickHouse Cloud provisions all of the core cloud resources required for your deployment\u2014such as the VPC, subnets, security groups, Kubernetes (EKS/GKE) cluster, and supporting IAM roles/service accounts\u2014within your AWS account/GCP project. This ensures consistent, secure configuration, and minimizes the manual steps required from your team.\n\nWith standard onboarding, you simply provide a dedicated AWS account/GCP project, and run an initial stack (via CloudFormation or Terraform) to create the minimum IAM permissions and trust required for ClickHouse Cloud to orchestrate further setup. All subsequent steps\u2014including infrastructure provisioning and service launch\u2014are managed through the ClickHouse Cloud web console.\n\nCustomers are strongly recommended to prepare a **dedicated** AWS account or GCP project for hosting the ClickHouse BYOC deployment to e"
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/cloud/onboard/01_discover/02_use_cases/03_data_warehousing.md",
    "line": 23,
    "header": "What are the components of the data lakehouse?",
    "anchor": "components-of-the-data-lakehouse",
    "issue_type": "what_is_delayed_answer",
    "reasoning": "Header asks 'What is X?' but the definition doesn't appear until later in the section",
    "first_sentence": "The modern data lakehouse architecture represents a convergence of data warehouse and data lake technologies, combining the best aspects of both approaches. This architecture comprises several distinc",
    "suggested_header": null,
    "full_content": "The modern data lakehouse architecture represents a convergence of data warehouse\nand data lake technologies, combining the best aspects of both approaches. This \narchitecture comprises several distinct but interconnected layers providing a \nflexible, robust data storage, management, and analysis platform.\n\nUnderstanding these components is essential for organizations looking to \nimplement or optimize their data lakehouse strategy. The layered approach allows\nfor component substitution and independent evolution of each layer, providing \narchitectural flexibility and future-proofing.\n\nLet's explore the core building blocks of a typical data lakehouse architecture \nand how they interact to create a cohesive data management platform.\n\n<Image img={datalakehouse_01} alt=\"Components of the data lakehouse\" size=\"md\"/>\n\n| Component               | Description                                                                                                                                         "
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/concepts/olap.md",
    "line": 11,
    "header": "What is OLAP?",
    "anchor": null,
    "issue_type": "what_is_delayed_answer",
    "reasoning": "Header asks 'What is X?' but the definition doesn't appear until later in the section",
    "first_sentence": "[OLAP](https://en.wikipedia.org/wiki/Online_analytical_processing) stands for Online Analytical Processing. It is a broad term that can be looked at from two perspectives: technical and business. At t",
    "suggested_header": null,
    "full_content": "[OLAP](https://en.wikipedia.org/wiki/Online_analytical_processing) stands for Online Analytical Processing. It is a broad term that can be looked at from two perspectives: technical and business. At the highest level, you can just read these words backward:\n\n**Processing** \u2014 Some source data is processed\u2026\n\n**Analytical** \u2014 \u2026to produce some analytical reports and insights\u2026\n\n**Online** \u2014 \u2026in real-time."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/faq/general/columnar-database.md",
    "line": 15,
    "header": "What is a columnar database?",
    "anchor": "what-is-a-columnar-database",
    "issue_type": "what_is_delayed_answer",
    "reasoning": "Header asks 'What is X?' but the definition doesn't appear until later in the section",
    "first_sentence": "A columnar database stores the data of each column independently. This allows reading data from disk only for those columns that are used in any given query. The cost is that operations that affect wh",
    "suggested_header": null,
    "full_content": "A columnar database stores the data of each column independently. This allows reading data from disk only for those columns that are used in any given query. The cost is that operations that affect whole rows become proportionally more expensive. The synonym for a columnar database is a column-oriented database management system. ClickHouse is a typical example of such a system.\n\nKey columnar database advantages are:\n\n- Queries that use only a few columns out of many.\n- Aggregating queries against large volumes of data.\n- Column-wise data compression.\n\nHere is the illustration of the difference between traditional row-oriented systems and columnar databases when building reports:\n\n**Traditional row-oriented**\n<Image img={RowOriented} alt=\"Traditional row-oriented database\" size=\"md\" border />\n\n**Columnar**\n<Image img={ColumnOriented} alt=\"Columnar database\" size=\"md\" border />\n\nA columnar database is the preferred choice for analytical applications because it allows having many columns"
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/faq/general/dependencies.md",
    "line": 11,
    "header": "What are the 3rd-party dependencies for running ClickHouse?",
    "anchor": null,
    "issue_type": "what_is_delayed_answer",
    "reasoning": "Header asks 'What is X?' but the definition doesn't appear until later in the section",
    "first_sentence": "ClickHouse does not have any runtime dependencies. It is distributed as a single binary application which is fully self-contained. This application provides all the functionality of the cluster, serve",
    "suggested_header": null,
    "full_content": "ClickHouse does not have any runtime dependencies. It is distributed as a single binary application which is fully self-contained. This application provides all the functionality of the cluster, serves queries, acts as a worker node in the cluster, as a coordination system providing the RAFT consensus algorithm, as a client or a local query engine.\n\nThis unique architecture choice differentiates it from other systems, that often have dedicated frontend, backend, or aggregation nodes, as it makes the deployment, cluster management, and monitoring easier.\n\n:::info\nMany years ago, ClickHouse used to require ZooKeeper for coordination of distributed clusters. It is no longer needed, and while we support using ZooKeeper, it's no longer recommended.\n:::"
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/faq/general/olap.md",
    "line": 11,
    "header": "What Is OLAP?",
    "anchor": "what-is-olap",
    "issue_type": "what_is_delayed_answer",
    "reasoning": "Header asks 'What is X?' but the definition doesn't appear until later in the section",
    "first_sentence": "[OLAP](https://en.wikipedia.org/wiki/Online_analytical_processing) stands for Online Analytical Processing. It is a broad term that can be looked at from two perspectives: technical and business. But ",
    "suggested_header": null,
    "full_content": "[OLAP](https://en.wikipedia.org/wiki/Online_analytical_processing) stands for Online Analytical Processing. It is a broad term that can be looked at from two perspectives: technical and business. But at the very high level, you can just read these words backward:\n\nProcessing\n:   Some source data is processed...\n\nAnalytical\n:   ...to produce some analytical reports and insights...\n\nOnline\n:   ...in real-time."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/cloud/onboard/02_migrate/01_migration_guides/07_OSS_to_Cloud/02_oss_to_cloud_backups.md",
    "line": 23,
    "header": "Overview",
    "anchor": "overview-migration-approaches",
    "issue_type": "too_generic",
    "reasoning": "Header 'Overview' is generic but content discusses specific features/concepts",
    "first_sentence": "There are two primary methods to migrate data from self-managed ClickHouse (OSS) to ClickHouse Cloud: - Using the [`remoteSecure()`](/cloud/migration/clickhouse-to-cloud) function in which data is dir",
    "suggested_header": null,
    "full_content": "There are two primary methods to migrate data from self-managed ClickHouse (OSS) to ClickHouse Cloud:\n\n- Using the [`remoteSecure()`](/cloud/migration/clickhouse-to-cloud) function in which data is directly pulled/pushed.\n- Using `BACKUP`/`RESTORE` commands via cloud object storage\n\n>This migration guide focuses on the `BACKUP`/`RESTORE` approach and offers a practical example\nof migrating a database or full service in open source ClickHouse to Cloud via an S3 bucket.\n\n**Prerequisites**\n- You have Docker installed\n- You have an [S3 bucket and IAM user](/integrations/s3/creating-iam-user-and-s3-bucket)\n- You're able to create a new service ClickHouse Cloud service\n\nTo make the steps in this guide easy to follow along with and reproducible, we'll use one of the docker compose recipes\nfor a ClickHouse cluster with two shards, and two replicas.\n\n:::note[Cluster required]\nThis backup method requires a ClickHouse cluster because tables must be converted from the `MergeTree` engine to `Replic"
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/anyIf.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`any`](/sql-reference/aggregate-functions/reference/any) aggregate function to select the first encount",
    "suggested_header": null,
    "full_content": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`any`](/sql-reference/aggregate-functions/reference/any)\naggregate function to select the first encountered element from a given column\nthat matches the given condition."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/argMaxIf.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`argMax`](/sql-reference/aggregate-functions/reference/argmax) function to find the value of `arg` that",
    "suggested_header": null,
    "full_content": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`argMax`](/sql-reference/aggregate-functions/reference/argmax)\nfunction to find the value of `arg` that corresponds to the maximum value of `val` for rows where the condition is true,\nusing the `argMaxIf` aggregate combinator function.\n\nThe `argMaxIf` function is useful when you need to find the value associated with\nthe maximum value in a dataset, but only for rows that satisfy a specific \ncondition."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/argMinIf.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`argMin`](/sql-reference/aggregate-functions/reference/argmin) function to find the value of `arg` that",
    "suggested_header": null,
    "full_content": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`argMin`](/sql-reference/aggregate-functions/reference/argmin)\nfunction to find the value of `arg` that corresponds to the minimum value of `val` for rows where the condition is true,\nusing the `argMinIf` aggregate combinator function.\n\nThe `argMinIf` function is useful when you need to find the value associated \nwith the minimum value in a dataset, but only for rows that satisfy a specific \ncondition."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/avgIf.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`avg`](/sql-reference/aggregate-functions/reference/avg) function to calculate the arithmetic mean of v",
    "suggested_header": null,
    "full_content": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`avg`](/sql-reference/aggregate-functions/reference/avg)\nfunction to calculate the arithmetic mean of values for rows where the condition is true,\nusing the `avgIf` aggregate combinator function."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/avgMap.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`Map`](/sql-reference/aggregate-functions/combinators#-map) combinator can be applied to the [`avg`](/sql-reference/aggregate-functions/reference/avg) function to calculate the arithmetic mean of",
    "suggested_header": null,
    "full_content": "The [`Map`](/sql-reference/aggregate-functions/combinators#-map) combinator can be applied to the [`avg`](/sql-reference/aggregate-functions/reference/avg)\nfunction to calculate the arithmetic mean of values in a Map according to each key, using the `avgMap` \naggregate combinator function."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/avgMerge.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`Merge`](/sql-reference/aggregate-functions/combinators#-state) combinator can be applied to the [`avg`](/sql-reference/aggregate-functions/reference/avg) function to produce a final result by co",
    "suggested_header": null,
    "full_content": "The [`Merge`](/sql-reference/aggregate-functions/combinators#-state) combinator\ncan be applied to the [`avg`](/sql-reference/aggregate-functions/reference/avg)\nfunction to produce a final result by combining partial aggregate states."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/avgMergeState.md",
    "line": 15,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`MergeState`](/sql-reference/aggregate-functions/combinators#-state) combinator can be applied to the [`avg`](/sql-reference/aggregate-functions/reference/avg) function to merge partial aggregate",
    "suggested_header": null,
    "full_content": "The [`MergeState`](/sql-reference/aggregate-functions/combinators#-state) combinator\ncan be applied to the [`avg`](/sql-reference/aggregate-functions/reference/avg)\nfunction to merge partial aggregate states of type `AverageFunction(avg, T)` and\nreturn a new intermediate aggregation state."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/avgResample.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`Resample`](/sql-reference/aggregate-functions/combinators#-resample) combinator can be applied to the [`count`](/sql-reference/aggregate-functions/reference/count) aggregate function to count va",
    "suggested_header": null,
    "full_content": "The [`Resample`](/sql-reference/aggregate-functions/combinators#-resample) \ncombinator can be applied to the [`count`](/sql-reference/aggregate-functions/reference/count)\naggregate function to count values of a specified key column in a fixed number\nof intervals (`N`)."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/avgState.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`State`](/sql-reference/aggregate-functions/combinators#-state) combinator can be applied to the [`avg`](/sql-reference/aggregate-functions/reference/avg) function to produce an intermediate stat",
    "suggested_header": null,
    "full_content": "The [`State`](/sql-reference/aggregate-functions/combinators#-state) combinator \ncan be applied to the [`avg`](/sql-reference/aggregate-functions/reference/avg) \nfunction to produce an intermediate state of `AggregateFunction(avg, T)` type where\n`T` is the specified type for the average."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/countIf.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`count`](/sql-reference/aggregate-functions/reference/count) function to count the number of rows where",
    "suggested_header": null,
    "full_content": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`count`](/sql-reference/aggregate-functions/reference/count)\nfunction to count the number of rows where the condition is true,\nusing the `countIf` aggregate combinator function."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/countResample.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`Resample`](/sql-reference/aggregate-functions/combinators#-resample) combinator can be applied to the [`count`](/sql-reference/aggregate-functions/reference/count) aggregate function to count va",
    "suggested_header": null,
    "full_content": "The [`Resample`](/sql-reference/aggregate-functions/combinators#-resample) \ncombinator can be applied to the [`count`](/sql-reference/aggregate-functions/reference/count)\naggregate function to count values of a specified key column in a fixed number\nof intervals (`N`)."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/groupArrayDistinct.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`groupArrayDistinct`](/sql-reference/aggregate-functions/combinators#-foreach) combinator can be applied to the [`groupArray`](/sql-reference/aggregate-functions/reference/sum) aggregate function",
    "suggested_header": null,
    "full_content": "The [`groupArrayDistinct`](/sql-reference/aggregate-functions/combinators#-foreach) combinator\ncan be applied to the [`groupArray`](/sql-reference/aggregate-functions/reference/sum) aggregate function to create an array\nof distinct argument values."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/groupArrayResample.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`Resample`](/sql-reference/aggregate-functions/combinators#-resample) combinator can be applied to the [`groupArray`](/sql-reference/aggregate-functions/reference/sum) aggregate function to divid",
    "suggested_header": null,
    "full_content": "The [`Resample`](/sql-reference/aggregate-functions/combinators#-resample) \ncombinator can be applied to the [`groupArray`](/sql-reference/aggregate-functions/reference/sum) aggregate function to\ndivide the range of a specified key column into a fixed number of intervals (`N`) \nand construct the resulting array by selecting one representative value \n(corresponding to the minimum key) from the data points falling into each interval.\nIt creates a downsampled view of the data rather than collecting all values."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/maxMap.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`Map`](/sql-reference/aggregate-functions/combinators#-map) combinator can be applied to the [`max`](/sql-reference/aggregate-functions/reference/max) function to calculate the maximum value in a",
    "suggested_header": null,
    "full_content": "The [`Map`](/sql-reference/aggregate-functions/combinators#-map) combinator can be applied to the [`max`](/sql-reference/aggregate-functions/reference/max)\nfunction to calculate the maximum value in a Map according to each key, using the `maxMap` \naggregate combinator function."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/maxSimpleState.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`SimpleState`](/sql-reference/aggregate-functions/combinators#-simplestate) combinator can be applied to the [`max`](/sql-reference/aggregate-functions/reference/max) function to return the maxim",
    "suggested_header": null,
    "full_content": "The [`SimpleState`](/sql-reference/aggregate-functions/combinators#-simplestate) combinator can be applied to the [`max`](/sql-reference/aggregate-functions/reference/max)\nfunction to return the maximum value across all input values. It returns the\nresult with type `SimpleAggregateState`."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/minMap.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`Map`](/sql-reference/aggregate-functions/combinators#-map) combinator can be applied to the [`min`](/sql-reference/aggregate-functions/reference/min) function to calculate the minimum value in a",
    "suggested_header": null,
    "full_content": "The [`Map`](/sql-reference/aggregate-functions/combinators#-map) combinator can be applied to the [`min`](/sql-reference/aggregate-functions/reference/min)\nfunction to calculate the minimum value in a Map according to each key, using the `minMap` \naggregate combinator function."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/minSimpleState.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`SimpleState`](/sql-reference/aggregate-functions/combinators#-simplestate) combinator can be applied to the [`min`](/sql-reference/aggregate-functions/reference/min) function to return the minim",
    "suggested_header": null,
    "full_content": "The [`SimpleState`](/sql-reference/aggregate-functions/combinators#-simplestate) combinator can be applied to the [`min`](/sql-reference/aggregate-functions/reference/min)\nfunction to return the minimum value across all input values. It returns the \nresult with type [`SimpleAggregateFunction`](/docs/sql-reference/data-types/simpleaggregatefunction)."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/quantilesTimingArrayIf.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`Array`](/sql-reference/aggregate-functions/combinators#-array) and [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`quantilesTiming`](/sql-reference/",
    "suggested_header": null,
    "full_content": "The [`Array`](/sql-reference/aggregate-functions/combinators#-array) and [`If`](/sql-reference/aggregate-functions/combinators#-if) \ncombinator can be applied to the [`quantilesTiming`](/sql-reference/aggregate-functions/reference/quantiletiming)\nfunction to calculate quantiles of timing values in arrays for rows where the condition is true,\nusing the `quantilesTimingArrayIf` aggregate combinator function."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/quantilesTimingIf.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`quantilesTiming`](/sql-reference/aggregate-functions/reference/quantiletiming) function to calculate q",
    "suggested_header": null,
    "full_content": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`quantilesTiming`](/sql-reference/aggregate-functions/reference/quantiletiming)\nfunction to calculate quantiles of timing values for rows where the condition is true,\nusing the `quantilesTimingIf` aggregate combinator function."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/sumArray.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`Array`](/sql-reference/aggregate-functions/combinators#-array) combinator can be applied to the [`sum`](/sql-reference/aggregate-functions/reference/sum) function to calculate the sum of all ele",
    "suggested_header": null,
    "full_content": "The [`Array`](/sql-reference/aggregate-functions/combinators#-array) combinator \ncan be applied to the [`sum`](/sql-reference/aggregate-functions/reference/sum)\nfunction to calculate the sum of all elements in an array, using the `sumArray` \naggregate combinator function.\n\nThe `sumArray` function is useful when you need to calculate the total sum of \nall elements across multiple arrays in a dataset."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/sumForEach.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`ForEach`](/sql-reference/aggregate-functions/combinators#-foreach) combinator can be applied to the [`sum`](/sql-reference/aggregate-functions/reference/sum) aggregate function to turn it from a",
    "suggested_header": null,
    "full_content": "The [`ForEach`](/sql-reference/aggregate-functions/combinators#-foreach) combinator\ncan be applied to the [`sum`](/sql-reference/aggregate-functions/reference/sum) aggregate function to turn it from an aggregate\nfunction which operates on row values to an aggregate function which operates on\narray columns, applying the aggregate to each element in the array across rows."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/sumIf.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`sum`](/sql-reference/aggregate-functions/reference/sum) function to calculate the sum of values for ro",
    "suggested_header": null,
    "full_content": "The [`If`](/sql-reference/aggregate-functions/combinators#-if) combinator can be applied to the [`sum`](/sql-reference/aggregate-functions/reference/sum)\nfunction to calculate the sum of values for rows where the condition is true,\nusing the `sumIf` aggregate combinator function."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/sumMap.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`Map`](/sql-reference/aggregate-functions/combinators#-map) combinator can be applied to the [`sum`](/sql-reference/aggregate-functions/reference/sum) function to calculate the sum of values in a",
    "suggested_header": null,
    "full_content": "The [`Map`](/sql-reference/aggregate-functions/combinators#-map) combinator can be applied to the [`sum`](/sql-reference/aggregate-functions/reference/sum)\nfunction to calculate the sum of values in a Map according to each key, using the `sumMap` \naggregate combinator function."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/sumSimpleState.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`SimpleState`](/sql-reference/aggregate-functions/combinators#-simplestate) combinator can be applied to the [`sum`](/sql-reference/aggregate-functions/reference/sum) function to return the sum a",
    "suggested_header": null,
    "full_content": "The [`SimpleState`](/sql-reference/aggregate-functions/combinators#-simplestate) combinator can be applied to the [`sum`](/sql-reference/aggregate-functions/reference/sum)\nfunction to return the sum across all input values. It returns the result with \ntype [`SimpleAggregateFunction`](/docs/sql-reference/data-types/simpleaggregatefunction)."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/uniqArray.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`Array`](/sql-reference/aggregate-functions/combinators#-array) combinator can be applied to the [`uniq`](/sql-reference/aggregate-functions/reference/uniq) function to calculate the approximate ",
    "suggested_header": null,
    "full_content": "The [`Array`](/sql-reference/aggregate-functions/combinators#-array) combinator \ncan be applied to the [`uniq`](/sql-reference/aggregate-functions/reference/uniq)\nfunction to calculate the approximate number of unique elements across all arrays, \nusing the `uniqArray` aggregate combinator function.\n\nThe `uniqArray` function is useful when you need to count unique elements across \nmultiple arrays in a dataset. It's equivalent to using `uniq(arrayJoin())`, where \n`arrayJoin` first flattens the arrays and then `uniq` counts the unique elements."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/examples/aggregate_function_combinators/uniqArrayIf.md",
    "line": 12,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "The [`Array`](/sql-reference/aggregate-functions/combinators#-array) and [`If`](/sql-reference/aggregate-functions/combinators#-if) combinators can be applied to the [`uniq`](/sql-reference/aggregate-",
    "suggested_header": null,
    "full_content": "The [`Array`](/sql-reference/aggregate-functions/combinators#-array) and [`If`](/sql-reference/aggregate-functions/combinators#-if) combinators can be applied to the [`uniq`](/sql-reference/aggregate-functions/reference/uniq)\nfunction to count the number of unique values in arrays for rows where the \ncondition is true, using the `uniqArrayIf` aggregate combinator function.\n\n:::note\n-`If` and -`Array` can be combined. However, `Array` must come first, then `If`.\n:::\n\nThis is useful when you want to count unique elements in an array based on \nspecific conditions without having to use `arrayJoin`."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/sre/keeper/index.md",
    "line": 941,
    "header": "Description",
    "anchor": "description",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "This article describes how to use the built-in `{uuid}` macro setting to create unique entries in ClickHouse Keeper or ZooKeeper. Unique paths help when creating and dropping tables frequently because",
    "suggested_header": null,
    "full_content": "This article describes how to use the built-in `{uuid}` macro setting\nto create unique entries in ClickHouse Keeper or ZooKeeper. Unique\npaths help when creating and dropping tables frequently because\nthis avoids having to wait several minutes for Keeper garbage collection\nto remove path entries as each time a path is created a new `uuid` is used\nin that path; paths are never reused."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/guides/sre/keeper/index.md",
    "line": 1242,
    "header": "Description",
    "anchor": "description-1",
    "issue_type": "too_generic",
    "reasoning": "Header 'Description' is generic but content discusses specific features/concepts",
    "first_sentence": "ClickHouse Keeper partially supports ZooKeeper [`reconfig`](https://zookeeper.apache.org/doc/r3.5.3-beta/zookeeperReconfig.html#sc_reconfig_modifying) command for dynamic cluster reconfiguration if `k",
    "suggested_header": null,
    "full_content": "ClickHouse Keeper partially supports ZooKeeper [`reconfig`](https://zookeeper.apache.org/doc/r3.5.3-beta/zookeeperReconfig.html#sc_reconfig_modifying)\ncommand for dynamic cluster reconfiguration if `keeper_server.enable_reconfiguration` is turned on.\n\n:::note\nIf this setting is turned off, you may reconfigure the cluster by altering the replica's `raft_configuration`\nsection manually. Make sure you the edit files on all replicas as only the leader will apply changes.\nAlternatively, you can send a `reconfig` query through any ZooKeeper-compatible client.\n:::\n\nA virtual node `/keeper/config` contains last committed cluster configuration in the following format:\n\n```text\nserver.id = server_host:server_port[;server_type][;server_priority]\nserver.id2 = ...\n...\n```\n\n- Each server entry is delimited by a newline.\n- `server_type` is either `participant` or `learner` ([learner](https://github.com/eBay/NuRaft/blob/master/docs/readonly_member.md) does not participate in leader elections).\n- `serv"
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/integrations/data-ingestion/kafka/kafka-table-engine-named-collections.md",
    "line": 11,
    "header": "Introduction",
    "anchor": "introduction",
    "issue_type": "too_generic",
    "reasoning": "Header 'Introduction' is generic but content discusses specific features/concepts",
    "first_sentence": "In this guide, we will explore how to connect ClickHouse to Kafka using named collections. Using the configuration file for named collections offers several advantages: - Centralized and easier manage",
    "suggested_header": null,
    "full_content": "In this guide, we will explore how to connect ClickHouse to Kafka using named collections. Using the configuration file for named collections offers several advantages:\n- Centralized and easier management of configuration settings.\n- Changes to settings can be made without altering SQL table definitions.\n- Easier review and troubleshooting of configurations by inspecting a single configuration file.\n\nThis guide has been tested on Apache Kafka 3.4.1 and ClickHouse 24.5.1."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/integrations/language-clients/python/index.md",
    "line": 19,
    "header": "Introduction",
    "anchor": "introduction",
    "issue_type": "too_generic",
    "reasoning": "Header 'Introduction' is generic but content discusses specific features/concepts",
    "first_sentence": "ClickHouse Connect is a core database driver providing interoperability with a wide range of Python applications. - The main interface is the `Client` object in the package `clickhouse_connect.driver`",
    "suggested_header": null,
    "full_content": "ClickHouse Connect is a core database driver providing interoperability with a wide range of Python applications.\n\n- The main interface is the `Client` object in the package `clickhouse_connect.driver`. That core package also includes assorted helper classes and utility functions used for communicating with the ClickHouse server and \"context\" implementations for advanced management of insert and select queries.\n- The `clickhouse_connect.datatypes` package provides a base implementation and subclasses for all non-experimental ClickHouse datatypes. Its primary functionality is serialization and deserialization of ClickHouse data into the ClickHouse \"Native\" binary columnar format, used to achieve the most efficient transport between ClickHouse and client applications.\n- The Cython/C classes in the `clickhouse_connect.cdriver` package optimize some of the most common serializations and deserializations for significantly improved performance over pure Python.\n- There is a [SQLAlchemy](http"
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/integrations/language-clients/rust.md",
    "line": 18,
    "header": "Overview",
    "anchor": "overview",
    "issue_type": "too_generic",
    "reasoning": "Header 'Overview' is generic but content discusses specific features/concepts",
    "first_sentence": "* Uses `serde` for encoding/decoding rows. * Supports `serde` attributes: `skip_serializing`, `skip_deserializing`, `rename`. * Uses [`RowBinary`](/interfaces/formats/RowBinary) format over the HTTP t",
    "suggested_header": null,
    "full_content": "* Uses `serde` for encoding/decoding rows.\n* Supports `serde` attributes: `skip_serializing`, `skip_deserializing`, `rename`.\n* Uses [`RowBinary`](/interfaces/formats/RowBinary) format over the HTTP transport.\n  * There are plans to switch to [`Native`](/interfaces/formats/Native) over TCP.\n* Supports TLS (via `native-tls` and `rustls-tls` features).\n* Supports compression and decompression (LZ4).\n* Provides APIs for selecting or inserting data, executing DDLs, and client-side batching.\n* Provides convenient mocks for unit testing."
  },
  {
    "file": "/home/runner/work/clickhouse-docs/clickhouse-docs/docs/use-cases/observability/clickstack/managing/materialized_views.md",
    "line": 24,
    "header": "Introduction",
    "anchor": "introduction",
    "issue_type": "too_generic",
    "reasoning": "Header 'Introduction' is generic but content discusses specific features/concepts",
    "first_sentence": "ClickStack can exploit [Incremental Materialized Views (IMV)](/materialized-view/incremental-materialized-view) to accelerate visualizations that rely on aggregation-heavy queries, such as computing a",
    "suggested_header": null,
    "full_content": "ClickStack can exploit [Incremental Materialized Views (IMV)](/materialized-view/incremental-materialized-view) to accelerate visualizations that rely on aggregation-heavy queries, such as computing average request duration per minute over time. This feature can dramatically improve query performance and is typically most beneficial for larger deployments, around 10 TB per day and above, while enabling scaling into the petabytes-per-day range. Incremental materialized views are in Beta and should be used with care.\n\n:::note\nAlerts can also benefit from materialized views, and will exploit them automatically.\nThis can reduce the computational overhead of running many alerts, especially since these typically run very frequently.\nReducing the execution time can be beneficial with respect to both responsiveness, and resource consumption.\n:::"
  }
]